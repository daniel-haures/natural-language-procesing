{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "LEN_VOCABULARY=1866"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump posted on 18-4-2024 at 15:47 : i wonder what the haters and losers a very happy easter! \n"
     ]
    }
   ],
   "source": [
    "tweet_df=pd.read_csv('data\\\\tweets.csv')\n",
    "\n",
    "#ignores the retweets\n",
    "tweet_df=tweet_df[tweet_df['is_retweet'] == False]\n",
    "tweet_df=tweet_df[\"text\"].astype(str).values.tolist()\n",
    "\n",
    "def clean_tweets(tweet_list):\n",
    "    cleaned_tweets = []\n",
    "    char_rem = list(set(\"#$%'()*+,./:;<=>?[\\]^_`{|}~\" + \"“\" + \"”\"))\n",
    "    for tweet in tweet_list:\n",
    "        # Removes links starting with \"https://\"\n",
    "        cleaned_tweet = re.sub(r'https?://\\S+', '', tweet)\n",
    "        cleaned_tweet = re.sub('\\s-\\s',' ', cleaned_tweet)\n",
    "        # Makes all characters lowercase\n",
    "        cleaned_tweet = cleaned_tweet.lower()\n",
    "        # ignores characters that are inside char_rem \n",
    "        cleaned_tweet = ''.join(char for char in cleaned_tweet if char not in char_rem)\n",
    "        cleaned_tweets.append(cleaned_tweet)\n",
    "    array_tweets = [tweet.split() for tweet in cleaned_tweets]\n",
    "\n",
    "    return array_tweets\n",
    "\n",
    "#add start tag and end tag\n",
    "def add_begin_end(tweet_list):\n",
    "    for tweet in tweet_list:\n",
    "        tweet.insert(0,\"<b>\")\n",
    "        tweet.append(\"<end>\")\n",
    "    return tweet_list\n",
    "\n",
    "#generates all the trigrams from array_tweets, and saves them in the dictionary tridict key:bigram value:occurence\n",
    "def trigrams_generator(array_tweets):\n",
    "    tridict = {}\n",
    "    for tweet in array_tweets:\n",
    "        for i in range(0,len(tweet)-2):\n",
    "            jword= tweet[i]+\" \"+tweet[i+1]+\" \"+tweet[i+2]\n",
    "            if jword in tridict:\n",
    "                tridict.update({jword:(tridict.get(jword)+1)})\n",
    "            else:\n",
    "                tridict.update({jword:1})\n",
    "    return tridict\n",
    "\n",
    "#generates all the bigrams from array_tweets, and saves them in the bidict dictionary key:bigram value:occurence\n",
    "def bigrams_generator(array_tweets):\n",
    "    bidict = {}\n",
    "    for tweet in array_tweets:\n",
    "        for i in range(0,len(tweet)-1):\n",
    "            jword= tweet[i]+\" \"+tweet[i+1]\n",
    "            if jword in bidict:\n",
    "                bidict.update({jword:(bidict.get(jword)+1)})\n",
    "            else:\n",
    "                bidict.update({jword:1})\n",
    "    return bidict  \n",
    "\n",
    "#generates a tweet from a random trigram\n",
    "def generate_tweet(trigram_dictionary):\n",
    "    starting_point=[key for key in trigram_dictionary if key.startswith(\"<b>\")]\n",
    "    sentence=random.choice(starting_point).split()\n",
    "    while(sentence[-1]!=\"<end>\"):\n",
    "        partial_key=sentence[-2]+\" \"+sentence[-1]\n",
    "        max_value=0\n",
    "        max_key=\"<end>\"\n",
    "        for key in trigram_dictionary:\n",
    "            splitted_key=key.split()\n",
    "            if(((splitted_key[0]+\" \"+splitted_key[1]) == partial_key) and (key not in \" \".join(sentence))):\n",
    "                current_value=trigram_dictionary.get(key)\n",
    "                if(current_value>max_value):\n",
    "                    max_value=current_value\n",
    "                    max_key=splitted_key[2]\n",
    "        sentence.append(max_key)\n",
    "    return sentence\n",
    "\n",
    "#probrability estimation of each trigram with normalization\n",
    "def estimate_probability(trigram_dict,bigram_dict):\n",
    "    for key in trigram_dict:\n",
    "        words=key.split()\n",
    "        partial_word=words[0]+\" \"+words[1]\n",
    "        freq_partial=bigram_dict.get(partial_word)\n",
    "        trigram_dict.update({key:((trigram_dict.get(key)+1)/(freq_partial+LEN_VOCABULARY))})\n",
    "    return trigram_dict\n",
    "\n",
    "# add \"Trump posted on\" before the generated tweet\n",
    "def ultimate_tweet(generated_tweet):\n",
    "    str_tweet = ' '.join(map(str,generated_tweet))\n",
    "    current_date = datetime.datetime.now()\n",
    "    current_hour = time.strftime(\"%H:%M\")\n",
    "    str_tweet = str_tweet.replace(\"<b>\", \"Trump posted on \" + str(current_date.day) + \"-\" + str(current_date.month) + \"-\" + str(current_date.year) + \" at \" + str(current_hour) + \" :\")\n",
    "    str_tweet = str_tweet.replace(\"<end>\", \"\")\n",
    "    return str_tweet\n",
    "    \n",
    "array_tweets = clean_tweets(tweet_df)\n",
    "array_tweets = add_begin_end(array_tweets) \n",
    "trigram_dict = trigrams_generator(array_tweets)\n",
    "bigram_dict = bigrams_generator(array_tweets)\n",
    "\n",
    "trigram_dict=estimate_probability(trigram_dict,bigram_dict)\n",
    "generated_tweet=generate_tweet(trigram_dict)\n",
    "print(ultimate_tweet(generated_tweet))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
