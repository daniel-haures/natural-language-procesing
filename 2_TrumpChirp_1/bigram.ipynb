{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "LEN_VOCABULARY=1866"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump posted on 22-4-2024 at 09:18 : @sirmax andreajmarkley rubio finally gets nothing for john mccain ’08 &amp jennifer horn got two other senators have quit trying mike was under investigation by everyone can either jealous of bernie has more political consultants took him fawning over crazy bernie sanders if she can keep tweeting that have beaten biden in coal now he made up lie just watched sloppy graydon carter is all losers but abe i didn’t give @karlrove just doesn’t get even for evan mcmuffin mcmullin to honest abe lincoln project goes into our opponents hands! \n"
     ]
    }
   ],
   "source": [
    "tweet_df=pd.read_csv('data\\\\tweets.csv')\n",
    "\n",
    "#ignores the retweets\n",
    "tweet_df=tweet_df[tweet_df['is_retweet'] == False]\n",
    "tweet_df=tweet_df[\"text\"].astype(str).values.tolist()\n",
    "\n",
    "def clean_tweets(tweet_list):\n",
    "    cleaned_tweets = []\n",
    "    char_rem = list(set(\"#$%'()*+,./:;<=>?[\\]^_`{|}~\" + \"“\" + \"”\"))\n",
    "    for tweet in tweet_list:\n",
    "        # Removes links starting with \"https://\"\n",
    "        cleaned_tweet = re.sub(r'https?://\\S+', '', tweet)\n",
    "        cleaned_tweet = re.sub('\\s-\\s',' ', cleaned_tweet)\n",
    "        # Makes all characters lowercase\n",
    "        cleaned_tweet = cleaned_tweet.lower()\n",
    "        # ignores characters that are inside char_rem\n",
    "        cleaned_tweet = ''.join(char for char in cleaned_tweet if char not in char_rem)\n",
    "        cleaned_tweets.append(cleaned_tweet)\n",
    "    array_tweets = [tweet.split() for tweet in cleaned_tweets]\n",
    "    return array_tweets\n",
    "\n",
    "#add start tag and end tag\n",
    "def add_begin_end(tweet_list):\n",
    "    for tweet in tweet_list:\n",
    "        tweet.insert(0,\"<b>\")\n",
    "        tweet.append(\"<end>\")\n",
    "    return tweet_list\n",
    "\n",
    "#generates all the bigrams from array_tweets, and saves them in the bidict dictionary key:bigram value:occurence\n",
    "def bigrams_generator(array_tweets):\n",
    "    bidict = {}\n",
    "    for tweet in array_tweets:\n",
    "        for i in range(0,len(tweet)-1):\n",
    "            jword= tweet[i]+\" \"+tweet[i+1]\n",
    "            if jword in bidict:\n",
    "                bidict.update({jword:(bidict.get(jword)+1)})\n",
    "            else:\n",
    "                bidict.update({jword:1})\n",
    "    return bidict            \n",
    "\n",
    "#calculates the occurence of every single word (unigram) key:unigram value:occurence\n",
    "def unigram_generator(array_tweets):\n",
    "    wdict = {}\n",
    "    for tweet in array_tweets:\n",
    "        for word in tweet:\n",
    "            if word in wdict:\n",
    "                wdict.update({word:(wdict.get(word)+1)})\n",
    "            else:\n",
    "                wdict.update({word:1})\n",
    "    return wdict\n",
    "\n",
    "#generates a tweet from a random bigram\n",
    "def generate_tweet(bigram_dictionary):\n",
    "    starting_point=[key for key in bigram_dictionary if key.startswith(\"<b>\")]\n",
    "    sentence=random.choice(starting_point).split()\n",
    "    while(sentence[-1]!=\"<end>\"):\n",
    "        partial_key=sentence[-1]\n",
    "        possible_tail=[possible_key for possible_key in bigram_dictionary if possible_key.split()[0]==partial_key]\n",
    "        possible_tail=sorted(possible_tail,key= lambda x: bigram_dict.get(x))[:3]\n",
    "        #print(possible_tail)\n",
    "        possible_probability= list(map(lambda x: bigram_dict.get(x), possible_tail))\n",
    "        #print(possible_probability)\n",
    "        chosen_key=random.choices(possible_tail,weights=possible_probability, k=1)\n",
    "        #print(chosen_key)\n",
    "        if chosen_key[0] not in \" \".join(sentence):\n",
    "            ck=chosen_key[0].split()\n",
    "            sentence.append(ck[-1])\n",
    "    return sentence\n",
    "\n",
    "#probrability estimation of each trigram with normalization\n",
    "def estimate_probability(bigram_dict,unigram_dict):\n",
    "    for key in bigram_dict:\n",
    "        first_word=key.split()[0]\n",
    "        freq_fw=unigram_dict.get(first_word)\n",
    "        bigram_dict.update({key:((bigram_dict.get(key)+1)/(freq_fw+LEN_VOCABULARY))})\n",
    "    return bigram_dict\n",
    "\n",
    "# adds \"Trump posted on\" before the generated tweet\n",
    "def ultimate_tweet(generated_tweet):\n",
    "    str_tweet = ' '.join(map(str,generated_tweet))\n",
    "    current_date = datetime.datetime.now()\n",
    "    current_hour = time.strftime(\"%H:%M\")\n",
    "    str_tweet = str_tweet.replace(\"<b>\", \"Trump posted on \" + str(current_date.day) + \"-\" + str(current_date.month) + \"-\" + str(current_date.year) + \" at \" + str(current_hour) + \" :\")\n",
    "    str_tweet = str_tweet.replace(\"<end>\", \"\")\n",
    "    return str_tweet\n",
    "\n",
    "array_tweets = clean_tweets(tweet_df)\n",
    "array_tweets = add_begin_end(array_tweets) \n",
    "bigram_dict = bigrams_generator(array_tweets)\n",
    "unigram_dict= unigram_generator(array_tweets)\n",
    "\n",
    "bigram_dict = estimate_probability(bigram_dict,unigram_dict)\n",
    "\n",
    "generated_tweet = generate_tweet(bigram_dict)\n",
    "\n",
    "print(ultimate_tweet(generated_tweet))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
