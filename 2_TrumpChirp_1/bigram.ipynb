{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "\n",
    "LEN_VOCABULARY=1866"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it\n",
      "will\n",
      "be\n",
      "a\n",
      "loser\n",
      "<end>\n",
      "['<b>', 'get', 'it', 'will', 'be', 'a', 'loser', '<end>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:9: SyntaxWarning: invalid escape sequence '\\]'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\]'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_16396\\4091001576.py:9: SyntaxWarning: invalid escape sequence '\\]'\n",
      "  char_rem = list(set(\"#$%'()*+,./:;<=>?[\\]^_`{|}~\" + \"“\" + \"”\"))\n",
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_16396\\4091001576.py:13: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  cleaned_tweet = re.sub('\\s-\\s',' ', cleaned_tweet)\n"
     ]
    }
   ],
   "source": [
    "tweet_df=pd.read_csv('data\\\\tweets.csv')\n",
    "\n",
    "tweet_df=tweet_df[tweet_df['is_retweet'] == False]\n",
    "tweet_df=tweet_df[\"text\"].astype(str).values.tolist()\n",
    "#print(tweet_df)\n",
    "\n",
    "def clean_tweets(tweet_list):\n",
    "    cleaned_tweets = []\n",
    "    char_rem = list(set(\"#$%'()*+,./:;<=>?[\\]^_`{|}~\" + \"“\" + \"”\"))\n",
    "    for tweet in tweet_list:\n",
    "        # Rimuovere i link che iniziano con \"https://\"\n",
    "        cleaned_tweet = re.sub(r'https?://\\S+', '', tweet)\n",
    "        cleaned_tweet = re.sub('\\s-\\s',' ', cleaned_tweet)\n",
    "        # Mettere tutti i caratteri in minuscolo\n",
    "        cleaned_tweet = cleaned_tweet.lower()\n",
    "        # rimuovo caratteri che non sono lettere\n",
    "        cleaned_tweet = ''.join(char for char in cleaned_tweet if char not in char_rem)\n",
    "        cleaned_tweets.append(cleaned_tweet)\n",
    "    array_tweets = [tweet.split() for tweet in cleaned_tweets]\n",
    "\n",
    "    return array_tweets\n",
    "\n",
    "def add_begin_end(tweet_list):\n",
    "    for tweet in tweet_list:\n",
    "        tweet.insert(0,\"<b>\")\n",
    "        tweet.append(\"<end>\")\n",
    "    return tweet_list\n",
    "\n",
    "def bigrams_generator(array_tweets):\n",
    "    bidict = {}\n",
    "    for tweet in array_tweets:\n",
    "        for i in range(0,len(tweet)-1):\n",
    "            jword= tweet[i]+\" \"+tweet[i+1]\n",
    "            if jword in bidict:\n",
    "                bidict.update({jword:(bidict.get(jword)+1)})\n",
    "            else:\n",
    "                bidict.update({jword:1})\n",
    "    return bidict            \n",
    "\n",
    "def count_words(array_tweets):\n",
    "    wdict = {}\n",
    "    for tweet in array_tweets:\n",
    "        for word in tweet:\n",
    "            if word in wdict:\n",
    "                wdict.update({word:(wdict.get(word)+1)})\n",
    "            else:\n",
    "                wdict.update({word:1})\n",
    "    return wdict\n",
    "\n",
    "\n",
    "def generate_tweet(bigram_dictionary):\n",
    "    starting_point=[key for key in bigram_dictionary if key.startswith(\"<b>\")]\n",
    "    sentence=random.choice(starting_point).split()\n",
    "    while(sentence[-1]!=\"<end>\"):\n",
    "        partial_key=sentence[-1]\n",
    "        max_value=0\n",
    "        max_key=\"<end>\"\n",
    "        for key in bigram_dictionary:\n",
    "            splitted_key=key.split()\n",
    "            if(splitted_key[0] == partial_key):\n",
    "                current_value=bigram_dictionary.get(key)\n",
    "                if(current_value>max_value):\n",
    "                    max_value=current_value\n",
    "                    max_key=splitted_key[1]\n",
    "        sentence.append(max_key)\n",
    "        print(max_key)\n",
    "    return sentence\n",
    "\n",
    "def estimate_probability(bigram_dict,unigram_dict):\n",
    "    for key in bigram_dict:\n",
    "        first_word=key.split()[0]\n",
    "        freq_fw=unigram_dict.get(first_word)\n",
    "        bigram_dict.update({key:((bigram_dict.get(key)+1)/(freq_fw+LEN_VOCABULARY))})\n",
    "    return bigram_dict\n",
    "\n",
    "array_tweets = clean_tweets(tweet_df)\n",
    "array_tweets = add_begin_end(array_tweets) \n",
    "#print(array_tweets)\n",
    "bigram_dict = bigrams_generator(array_tweets)\n",
    "unigram_dict= count_words(array_tweets)\n",
    "\n",
    "bigram_dict = estimate_probability(bigram_dict,unigram_dict)\n",
    "\n",
    "\n",
    "print(generate_tweet(bigram_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
