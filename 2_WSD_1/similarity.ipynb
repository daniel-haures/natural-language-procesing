{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import csv\n",
    "from nltk.corpus import wordnet as wn\n",
    "from libs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Word 1    Word 2  Human (mean)  wu_palmer  shortest_path  leak_chod\n",
      "0            love       sex          6.77      0.923           39.0   0.500000\n",
      "1           tiger       cat          7.35      0.966           39.0   0.500000\n",
      "2           tiger     tiger         10.00      1.000           40.0   1.000000\n",
      "3            book     paper          7.46      0.875           38.0   0.333333\n",
      "4        computer  keyboard          7.62      0.824           37.0   0.250000\n",
      "..            ...       ...           ...        ...            ...        ...\n",
      "348        shower     flood          6.03      0.636           36.0   0.200000\n",
      "349       weather  forecast          8.34      0.133           27.0   0.200000\n",
      "350      disaster      area          6.25      0.500           32.0   0.111111\n",
      "351      governor    office          6.34      0.526           31.0   0.100000\n",
      "352  architecture   century          3.78      0.308           31.0   0.100000\n",
      "\n",
      "[353 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    word_sym=pd.read_csv('data\\\\WordSim353.csv')\n",
    "    word_sym.insert(3,\"wu_palmer\",np.zeros(353))\n",
    "    word_sym.insert(4,\"shortest_path\",np.zeros(353))\n",
    "    word_sym.insert(5,\"leak_chod\",np.zeros(353))\n",
    "    #print(word_sym)\n",
    "    for i in range(0,353):\n",
    "        v1 = word_sym.at[i,'Word 1']\n",
    "        v2 = word_sym.at[i,'Word 2']\n",
    "        max_wu=0\n",
    "        max_sp=0\n",
    "        max_lch=0\n",
    "        for s1 in wn.synsets(v1):\n",
    "            for s2 in wn.synsets(v2):\n",
    "                actual_wu=wu_similarity(s1,s2)\n",
    "                actual_sp=sp_similarity(s1,s2)\n",
    "                actual_lch=wn.path_similarity(s1,s2)\n",
    "                if actual_wu>max_wu:\n",
    "                    max_wu=actual_wu\n",
    "                if actual_sp>max_sp:\n",
    "                    max_sp=actual_sp\n",
    "                if actual_lch>max_lch:\n",
    "                    max_lch=actual_lch\n",
    "        word_sym.iat[i,3]= max_wu\n",
    "        word_sym.iat[i,4]= max_sp\n",
    "        word_sym.iat[i,5]= max_lch\n",
    "\n",
    "    print(word_sym)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
