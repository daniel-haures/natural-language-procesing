{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libs.corpus import openConllu, check_projectivity\n",
    "import pyconll\n",
    "import pyconll.util\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pack_sequence, unpack_sequence\n",
    "import os\n",
    "from sklearn import preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pyconll.load_from_file('data/it_isdt-ud-train.conllu')\n",
    "train_prepocesed=[]\n",
    "for i,sent in enumerate(train):        \n",
    "    sentence_preprocesed=[]\n",
    "    for j,token in enumerate(sent):\n",
    "        if(token.head is not None):\n",
    "            sentence_preprocesed.append(token)\n",
    "    train_prepocesed.append(sentence_preprocesed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0:SHIFT 1:RIGHTARC 2:LEFTARC\n",
    "moves = [0, 1, 2]\n",
    "\n",
    "\n",
    "#creiamo un oggetto Dependencies per salvare le dependencies\n",
    "class Dependencies(object):\n",
    "    def __init__(self,n):\n",
    "        self.n = n\n",
    "        self.heads = [None] * (n+1)\n",
    "        self.arcs = []\n",
    "    \n",
    "    def get_heads(self):\n",
    "        return self.heads\n",
    "    \n",
    "    def add_arc(self, head, child):\n",
    "        child=child\n",
    "        self.heads[child]=head\n",
    "        self.arcs.append((head,child))\n",
    "\n",
    "    def contains(self,head,child):\n",
    "        child=child\n",
    "        if self.heads[child]==head:\n",
    "            return True\n",
    "        else: return False\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "class Oracle(object):\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        #BERT encoder\n",
    "        encoder_name = \"dbmdz/bert-base-italian-xxl-cased\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(encoder_name)\n",
    "        self.encoder = AutoModel.from_pretrained(encoder_name)\n",
    "\n",
    "        #LSTM oracle\n",
    "        input_size = 4608  \n",
    "        hidden_size = 64\n",
    "        num_layers = 1\n",
    "        output_size = 3  \n",
    "        self.model = torch.nn.LSTM(input_size,hidden_size,num_layers,batch_first=True,bidirectional=False,proj_size=output_size)\n",
    "\n",
    "        #Oracle critenion and optimazation\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "    \n",
    "    def tokens(self,words,lemmas):\n",
    "        words_token=[102]\n",
    "        for i in range(0,len(lemmas)):\n",
    "            word_token=self.tokenizer.convert_tokens_to_ids(words[i])\n",
    "            lemma_token=self.tokenizer.convert_tokens_to_ids(lemmas[i])\n",
    "            if(word_token!=101):\n",
    "                words_token.append(word_token)\n",
    "            else:\n",
    "                words_token.append(lemma_token)\n",
    "        words_token.append(103)\n",
    "        return words_token\n",
    "    \n",
    "    def encode(self,words,lemmas):\n",
    "        words_token=self.tokens(words,lemmas)\n",
    "        #max_length = 64  # Example max length ????\n",
    "        padded_input_ids = words_token\n",
    "        input_tensor = torch.tensor([padded_input_ids])\n",
    "        with torch.no_grad():\n",
    "            outputs = self.encoder(input_tensor)\n",
    "        return outputs.last_hidden_state\n",
    "    \n",
    "    #prende i batches dalla cartella, e allena il modello\n",
    "    def train_on_batches(self):\n",
    "        files = os.listdir(\"data/batches\")\n",
    "        for i in range(0,len(files)):\n",
    "            if(i==0):\n",
    "                \n",
    "                print(\"Loadind \"+str(i))\n",
    "                batch_features,batch_moves,batch_pos=torch.load(f\"data/batches/{files[i]}\") \n",
    "                batch_features=unpack_sequence(batch_features)\n",
    "                batch_moves=unpack_sequence(batch_moves)\n",
    "                for j in range(0,len(batch_moves)):\n",
    "                    predicted_output, _ = self.model(batch_features[j])\n",
    "                    loss = self.criterion(predicted_output, batch_moves[j])\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "    \n",
    "    def score(self,features):\n",
    "        predicted_output,_ = self.model(features)\n",
    "        return predicted_output\n",
    "    \n",
    "    #prende gli ultimi tre elementi dello stack\n",
    "    def get_stack_context(self,list):\n",
    "        depth=len(list)\n",
    "\n",
    "        if depth >= 3:\n",
    "            return [list[-1], list[-2], list[-3]]\n",
    "        \n",
    "        elif depth >= 2:\n",
    "\n",
    "            return [list[-1], list[-2], -1]\n",
    "        \n",
    "        elif depth == 1:\n",
    "            return [list[-1], -1 , -1]\n",
    "        else:\n",
    "            return [-1, -1, -1]\n",
    "\n",
    "    #prende gli ultimi due elementi dell buffer\n",
    "    def get_buffer_context(self,index,len_phrase):\n",
    "        if(index==len_phrase-1):\n",
    "            return [index,index+1,-1]\n",
    "        elif(index==len_phrase):\n",
    "            return [index,-1,-1]\n",
    "        elif(index>len_phrase):\n",
    "            return [-1,-1,-1]\n",
    "        else: return [index,index+1,index+2]  \n",
    "\n",
    "    def flatten_embedded_features(self,matrix):\n",
    "        flat_list = torch.tensor([])\n",
    "        for row in matrix:\n",
    "            flat_list=torch.cat((flat_list,row))\n",
    "        return flat_list\n",
    "\n",
    "    def extract_features(self,phrase,phrases_lemma,stacks,buffers):\n",
    "        embeddings = self.encode(phrase,phrases_lemma)\n",
    "        root_embeding=embeddings[0][0]\n",
    "        empty_embedding=torch.tensor(np.zeros(768))\n",
    "        embedded_features=[]\n",
    "        for i in range(0,len(stacks)):\n",
    "            stack_feature=self.get_stack_context(stacks[i])\n",
    "            for j,el in enumerate(stack_feature):\n",
    "                if(el>=1):\n",
    "                    stack_feature[j]=embeddings[0][el]\n",
    "                elif(el==0):\n",
    "                    stack_feature[j]=root_embeding\n",
    "                else:\n",
    "                    stack_feature[j]=empty_embedding\n",
    "            buffer_feature=self.get_buffer_context(buffers[i],len(phrase))\n",
    "            for j,el in enumerate(buffer_feature):\n",
    "                if(el>=1):\n",
    "                    buffer_feature[j]=embeddings[0][el]\n",
    "                else:\n",
    "                    buffer_feature[j]=empty_embedding\n",
    "            embedded_features.append(self.flatten_embedded_features(stack_feature+buffer_feature))\n",
    "        return embedded_features\n",
    "\n",
    "\n",
    "\n",
    "class Parser(object):\n",
    "    def __init__(self,oracle):\n",
    "        self.oracle=oracle\n",
    "\n",
    "    #applica la mossa andando ad aggiornare lo stack e l'indice del buffer  \n",
    "    def transition(self,move, stack, i, dependencies):\n",
    "        match move:\n",
    "            case 0:\n",
    "                stack.append(i)\n",
    "                return stack,i+1,dependencies\n",
    "            case 1:\n",
    "                dependencies.add_arc(stack[-2], stack.pop())\n",
    "                return stack,i,dependencies\n",
    "            case 2:\n",
    "                dependencies.add_arc(stack[-1], stack[-2])\n",
    "                stack.pop(-2)\n",
    "                return stack,i,dependencies\n",
    "            case _:\n",
    "                raise \"Wrong Move\"\n",
    "\n",
    "    #ritorna le mosse possibili che si possono applicare        \n",
    "    def get_valid_moves(self,i, n, stack_depth):\n",
    "        moves = []\n",
    "        if i <= n:\n",
    "            moves.append(0)\n",
    "        if stack_depth >= 2:\n",
    "            moves.append(1)\n",
    "            moves.append(2)\n",
    "        return moves\n",
    "\n",
    "    def parsing(self,words,phrases_lemma):\n",
    "        n=len(words)\n",
    "        deps=Dependencies(n)\n",
    "        stack=[0]\n",
    "        i_buffer=1\n",
    "        moves=self.get_valid_moves(i_buffer,n,len(stack))\n",
    "        old_stack=[]\n",
    "        old_buffer=[]\n",
    "        memory=2\n",
    "        while moves:\n",
    "            features = self.oracle.extract_features(words,phrases_lemma,[stack],[i_buffer])\n",
    "            features=torch.stack(features)\n",
    "            scores = self.oracle.score(features)\n",
    "            print(scores)\n",
    "            scores=scores[-1].tolist()\n",
    "            print(scores)\n",
    "            next_move = max(moves, key=lambda move: scores[move])\n",
    "            stack,i_buffer,deps = self.transition(next_move, stack, i_buffer, deps)\n",
    "            moves = self.get_valid_moves(i_buffer,n,len(stack))\n",
    "\n",
    "            if(len(old_stack)<memory):\n",
    "                old_stack.append(stack)\n",
    "                old_buffer.append(i_buffer)\n",
    "            else:\n",
    "                old_stack.pop(0)\n",
    "                old_buffer.pop(0)\n",
    "                old_stack.append(stack)\n",
    "                old_buffer.append(i_buffer)\n",
    "\n",
    "        return deps\n",
    "    \n",
    "    #sceglie la mossa migliore da eseguire nel simulate_parse\n",
    "    def check_best(self,heads,stack,buffer,deps,i):\n",
    "        move=-1\n",
    "        if(len(stack)>=2):\n",
    "            children_list=[]\n",
    "            for child,head in enumerate(heads):\n",
    "                if head == stack[-1]:\n",
    "                    children_list.append(child)\n",
    "            if(heads[stack[-2]]==stack[-1]):\n",
    "                move=2\n",
    "            if(((heads[stack[-1]])==(stack[-2])) and all([deps.contains(stack[-1],child) for child in children_list])):\n",
    "                move=1\n",
    "        if(i<=len(buffer) and move==-1):\n",
    "            move=0\n",
    "        elif(i>len(buffer) and move==-1):\n",
    "            move=None\n",
    "        return move\n",
    "    \n",
    "    #fa reverse engineering, dato lo stato finale ricostruisce lo stack, buffer e le mosse\n",
    "    def simulate_parse(self,heads,buffer):\n",
    "        deps=Dependencies(len(buffer))\n",
    "        stack=[0]\n",
    "        moves=[]\n",
    "        buffers=[]\n",
    "        stacks=[]\n",
    "        i=1\n",
    "        best_move=self.check_best(heads,stack,buffer,deps,i)\n",
    "        while best_move!=None:\n",
    "            buffers.append(i)\n",
    "            stacks.append(stack[:])\n",
    "            moves.append(best_move)\n",
    "            stack,i,deps=self.transition(best_move,stack,i,deps)\n",
    "            best_move=self.check_best(heads,stack,buffer,deps,i)\n",
    "        if(i>len(buffer)):\n",
    "            return stacks,buffers,moves\n",
    "        else: return None \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[tensor([11, 12], dtype=torch.int32), tensor([ 7,  1,  5,  7, 12], dtype=torch.int32), tensor([11, 12], dtype=torch.int32), tensor([ 0,  7,  1,  5, 11, 11, 12], dtype=torch.int32), tensor([ 5,  7,  3,  3,  3, 15,  1,  5,  7,  1,  7,  0,  1,  5,  7,  0,  1,  7,\n",
      "        10, 15, 12,  5,  7,  1,  5,  7, 12, 12], dtype=torch.int32), tensor([15,  5,  7,  1,  7,  1, 10,  1,  5,  7,  0, 10, 15,  5,  7, 12,  5,  7,\n",
      "         3, 15, 15,  5,  0,  7,  1,  7,  4,  1,  8,  7,  5,  7,  3, 15,  5,  7,\n",
      "        12], dtype=torch.int32), tensor([ 5,  7,  3,  1,  5,  0, 11, 11, 12], dtype=torch.int32), tensor([15, 12, 11,  1, 11, 12, 12, 15,  5,  7,  1,  5,  7,  4,  1,  5,  7, 15,\n",
      "         7, 12, 10, 15,  1,  5,  7, 10,  3, 15,  1,  7, 12], dtype=torch.int32), tensor([11, 11,  3, 15,  1,  5,  8,  1,  8,  7, 12], dtype=torch.int32), tensor([ 0,  5,  7, 15,  7,  0,  0, 12], dtype=torch.int32), tensor([ 7,  1, 11,  1,  5,  8,  7,  1,  7,  4,  1, 11, 11,  1,  5,  7, 12],\n",
      "       dtype=torch.int32), tensor([ 0,  7, 12,  7,  0,  1,  5,  7, 12], dtype=torch.int32), tensor([ 3, 15, 11, 11, 12,  0,  1, 11, 11, 12,  1,  5,  7,  1,  5,  8,  7,  1,\n",
      "         7, 12, 11, 11, 12,  0, 12,  3,  3,  2, 15, 12, 12,  3, 15,  5,  0, 11,\n",
      "        11, 12,  0,  2,  0,  7,  1,  5,  7,  1,  5,  7,  7, 11, 11, 12,  1,  5,\n",
      "         7,  1,  5,  7,  0, 12], dtype=torch.int32), tensor([11, 11,  1,  5,  7,  1,  8, 12,  2, 15,  1,  8, 12,  3, 15,  2,  1,  7,\n",
      "         1,  5,  7, 10,  3, 15,  5,  0,  7,  1,  5,  0,  7, 12,  5,  7, 11, 11,\n",
      "        12], dtype=torch.int32), tensor([15, 12, 11, 11,  3, 15, 12,  1,  5, 11, 12,  1,  5,  7, 15,  1,  7, 15,\n",
      "         5,  7,  1,  5,  5,  0,  7, 12], dtype=torch.int32), tensor([12,  6, 11, 12, 10,  3, 15,  5,  7, 12, 12], dtype=torch.int32), tensor([11, 12], dtype=torch.int32), tensor([ 7,  1,  7,  1,  5,  7, 15,  4, 15,  1,  8,  7, 12], dtype=torch.int32), tensor([11, 12,  5,  7,  3,  3, 15,  1,  5,  7,  1,  5,  7,  4, 15,  1,  7,  1,\n",
      "         5,  7, 12,  1, 11, 12], dtype=torch.int32), tensor([ 7, 12, 11, 11, 12,  8,  7, 12,  0, 12, 10,  2,  2,  1,  5,  8,  1,  2,\n",
      "         7, 10, 15,  1,  5,  7,  1,  5,  7, 11, 11, 12,  8,  7, 12,  7,  1,  7,\n",
      "         1,  7, 12,  1,  5,  7,  1,  5,  7,  2,  1,  5,  7,  1, 11, 12],\n",
      "       dtype=torch.int32), tensor([ 5,  7,  3,  3, 15,  1,  5,  7,  4, 15,  1,  8,  7, 15,  1,  7, 12,  2,\n",
      "         8,  7,  1,  5, 11,  1,  5, 11, 12], dtype=torch.int32), tensor([ 1,  5,  5,  7,  5,  7,  3, 15,  7,  1,  7, 12,  1, 10,  5,  8,  7,  1,\n",
      "         5,  7,  2,  3, 15,  5,  7, 12], dtype=torch.int32), tensor([ 7, 10,  3,  3, 15,  1,  5,  7, 12], dtype=torch.int32), tensor([ 5,  8,  3, 10,  7,  0, 12], dtype=torch.int32), tensor([10,  1, 10,  3,  2,  3, 15,  1,  5,  8,  7, 12], dtype=torch.int32), tensor([ 2, 10, 15,  5,  7, 12], dtype=torch.int32), tensor([11,  4, 11, 12, 10, 10, 15,  1,  2,  8,  7, 12,  3, 15,  1,  7,  1,  5,\n",
      "         8,  1,  7,  4, 10,  3, 15,  2,  1,  5,  7,  1,  5,  7, 12],\n",
      "       dtype=torch.int32), tensor([ 1,  5,  7, 12, 11, 11,  3, 15,  1,  5,  7,  1,  5,  7,  2,  0,  4,  3,\n",
      "        15,  5,  7, 12], dtype=torch.int32), tensor([ 5,  7,  1, 11,  3, 15,  1,  5,  5,  7, 12,  1,  7, 12,  7,  1,  7,  4,\n",
      "         7, 12], dtype=torch.int32), tensor([ 5,  7, 12,  7,  1,  5,  7,  1,  5,  7,  2, 15,  1,  5,  7, 12,  3, 15,\n",
      "         1,  7,  1,  5,  8, 12,  1,  7,  1,  7, 12, 13,  3,  3, 15,  1,  5,  7,\n",
      "        12], dtype=torch.int32), tensor([ 7,  1,  5,  7,  1,  5,  7,  1,  5, 11, 12], dtype=torch.int32), tensor([ 5,  7, 15,  1,  8,  1,  8,  7,  1,  7, 12], dtype=torch.int32), tensor([ 7,  1,  7,  2,  5,  7,  1,  5,  7, 12], dtype=torch.int32), tensor([ 7,  1,  5, 11,  0, 12], dtype=torch.int32), tensor([11, 12,  1,  5,  7,  1,  5,  7,  1,  5,  7,  1,  5,  7, 10,  3, 15,  5,\n",
      "         7,  0,  1,  5,  7,  1,  5, 11,  1, 11, 12,  2,  5,  7,  1,  5,  7, 12],\n",
      "       dtype=torch.int32), tensor([ 1,  5,  7, 15,  2, 15, 10,  7,  1,  5,  7,  1,  7,  1,  5,  7,  1,  5,\n",
      "        11, 12], dtype=torch.int32), tensor([ 1,  5,  7, 12,  0, 12,  1, 10,  1,  5,  7,  1,  7,  1,  5, 11,  1,  5,\n",
      "        11,  3,  3, 15,  5,  7,  1,  0,  7,  1,  5,  7,  1, 11, 11, 11,  4,  1,\n",
      "         5,  7, 11, 12], dtype=torch.int32), tensor([ 1, 10,  1,  5,  7, 15,  1,  5, 12,  8, 12,  3,  3,  2, 15,  5,  7,  1,\n",
      "         5,  7, 12], dtype=torch.int32), tensor([ 5,  7,  3,  3, 15,  4,  5,  5,  7,  3, 12,  0,  7, 12, 12],\n",
      "       dtype=torch.int32), tensor([ 1,  5,  7,  5,  7,  0,  1,  5,  7, 11, 11,  3, 15,  5,  7, 12],\n",
      "       dtype=torch.int32), tensor([10, 15,  1,  5,  7,  1,  7,  1,  5,  7,  1,  5,  7,  1,  5, 11, 12, 10,\n",
      "        15,  1,  5,  8,  1,  5,  8,  7,  1,  7,  0, 12], dtype=torch.int32), tensor([ 5,  7,  3, 15,  5,  0,  7, 12], dtype=torch.int32), tensor([ 5,  0,  7,  3, 15,  1, 15,  1,  7,  5,  7,  1,  7,  4,  5,  7,  1,  5,\n",
      "         7,  1,  5, 10,  3, 15, 12], dtype=torch.int32), tensor([ 5,  7,  1,  5,  7,  3,  3,  2, 15, 12], dtype=torch.int32), tensor([ 5,  0,  7,  3,  3, 15,  1,  5, 11,  1,  5, 11, 12,  2,  5,  7,  3, 15,\n",
      "         1,  5,  7,  1,  5,  7,  1,  7,  1,  5, 11, 12], dtype=torch.int32), tensor([ 5,  7,  3,  3, 15, 12], dtype=torch.int32), tensor([ 1,  7,  3, 15,  2,  1,  5,  7, 13,  2, 15, 15, 10,  1,  7,  4, 13,  1,\n",
      "        10, 10,  3, 15,  1,  5, 12,  7, 12, 12], dtype=torch.int32), tensor([ 7,  0,  1,  8,  7, 12], dtype=torch.int32), tensor([11, 12,  5,  7,  3, 15,  2,  8,  7,  1,  5, 11, 12,  1, 11, 11, 12],\n",
      "       dtype=torch.int32), tensor([ 3,  0,  4,  5,  7,  3,  3, 10,  0, 12], dtype=torch.int32), tensor([13,  3,  3, 15,  1,  5,  7,  1,  5,  7, 12,  3, 15,  1,  5,  7, 12,  1,\n",
      "         7,  4,  7,  1,  7, 12, 15, 10,  1,  5,  7, 12], dtype=torch.int32), tensor([ 5,  0,  7,  1,  7,  3, 15,  7,  2,  1,  5,  7,  4,  1,  5,  7, 12],\n",
      "       dtype=torch.int32), tensor([ 8,  7,  3, 15, 12, 10,  3,  5,  7,  1,  5,  7, 12,  4,  5, 10,  3, 15,\n",
      "         5,  7, 15,  1,  5,  7, 12], dtype=torch.int32), tensor([ 1,  5,  7,  2,  7,  4,  8,  7,  1,  7, 12], dtype=torch.int32), tensor([15,  1,  7,  1, 11, 12], dtype=torch.int32), tensor([ 3,  1,  7,  4, 15,  1,  7,  1, 15,  5,  7, 12], dtype=torch.int32), tensor([ 7,  1,  7,  1,  5, 11, 12], dtype=torch.int32), tensor([ 8,  7,  4,  8,  7,  0, 15,  1,  5,  7,  1,  5,  7, 12],\n",
      "       dtype=torch.int32), tensor([11, 12,  8,  7, 12,  8,  7,  0,  4,  8,  5,  7, 12,  3,  3, 15,  4,  2,\n",
      "        15,  1,  5,  7,  1,  7,  1,  5,  7,  1,  5,  7,  0,  1, 11, 12,  5,  7,\n",
      "         1,  5,  7, 12,  0,  1,  7, 12], dtype=torch.int32), tensor([ 5,  8, 15,  1,  5, 11,  1,  7,  1, 12,  7,  0, 12, 12,  5,  7,  2,  0,\n",
      "         1,  5,  7,  1,  7,  1, 11, 12,  1,  5,  7,  1,  5,  7,  4,  1,  5,  7,\n",
      "         0,  1, 11, 12,  1,  5,  7, 11, 12], dtype=torch.int32), tensor([ 5,  7,  3,  5,  7, 11, 11, 12,  8,  7, 12,  1, 11, 11, 12, 11, 12, 12,\n",
      "         5,  5,  7, 11, 12,  8,  7, 12,  4, 11, 12,  8, 12,  5,  7, 11, 11, 12,\n",
      "         8,  7, 12,  1, 11, 12, 11, 12, 12,  5,  7, 11, 11, 12,  8, 12,  1, 11,\n",
      "        12,  5,  7, 11, 11, 12,  8,  7, 12,  1, 11, 12], dtype=torch.int32), tensor([15,  4,  1,  7,  1,  7,  5,  7,  0,  1, 11, 12, 11, 12],\n",
      "       dtype=torch.int32), tensor([15, 12], dtype=torch.int32), tensor([12,  3, 15,  1,  7,  0,  2,  1,  5,  7, 12, 12], dtype=torch.int32), tensor([ 5,  7,  3, 15,  7,  7, 12,  4,  5,  7,  3, 15,  1, 11,  2,  2, 12,  1,\n",
      "         5,  7, 10, 15,  1,  5,  7,  1, 11, 12, 10,  1,  5,  2,  0,  4,  0,  7,\n",
      "         0,  1,  5,  7, 12, 15,  1,  5,  8, 12], dtype=torch.int32), tensor([ 1, 15,  5,  7,  1,  5,  7,  3, 15,  5,  7,  1,  7,  1,  7,  0,  4,  1,\n",
      "         5,  7,  0, 12], dtype=torch.int32), tensor([ 5, 11,  3, 15,  1,  7, 10,  1,  5,  7,  2,  0,  1,  5,  5, 11, 12, 15,\n",
      "         1,  7, 12,  7,  1,  5, 11, 12,  7,  0, 12], dtype=torch.int32), tensor([ 2, 15, 13,  5,  7,  1,  5,  7,  3, 15,  7, 12], dtype=torch.int32), tensor([15,  1, 11,  2, 10, 15,  5,  7,  7,  1, 12,  7,  0, 12, 12,  3, 15,  5,\n",
      "         7,  2,  0, 12], dtype=torch.int32), tensor([ 1,  5,  8,  1,  5,  0,  7,  3,  3, 15,  5,  7, 11, 11, 12, 10, 10, 15,\n",
      "         1,  5,  7,  1,  5,  7, 12], dtype=torch.int32), tensor([11, 12, 11, 11,  1,  7,  8, 11,  1,  7], dtype=torch.int32), tensor([ 8,  7,  1,  7, 12], dtype=torch.int32), tensor([12,  5, 11,  2, 15,  2, 12, 12], dtype=torch.int32), tensor([11, 12,  0,  7,  0,  1,  5, 11, 15,  1,  5,  7,  0, 12],\n",
      "       dtype=torch.int32), tensor([ 1,  5,  7,  1,  5, 11,  0, 10,  3, 15,  5,  7,  0,  8,  7,  1,  7,  1,\n",
      "         7, 12,  1,  7,  4,  1,  7, 12], dtype=torch.int32), tensor([ 2,  7,  3, 15,  1,  5,  7, 12,  1,  7,  4,  1,  7, 12],\n",
      "       dtype=torch.int32), tensor([ 1,  5, 11,  3,  8,  8,  5,  7,  1,  7, 12,  7, 11, 12, 12],\n",
      "       dtype=torch.int32), tensor([ 5,  7,  0,  3,  2, 15, 13,  5,  7,  3,  2,  0, 12], dtype=torch.int32), tensor([ 1,  7, 12], dtype=torch.int32), tensor([15, 15,  1,  5,  7, 12], dtype=torch.int32), tensor([11,  1, 11, 12, 11, 12, 12,  5,  0,  7, 12, 11, 11,  1,  8,  7, 12,  1,\n",
      "         7,  1,  5,  7, 12, 11, 12,  1, 11,  1, 11,  1,  5, 11, 12,  3, 15,  7,\n",
      "         1,  5,  7,  0, 13, 15,  5,  7,  1,  5,  7, 10, 15,  1,  5,  7, 12],\n",
      "       dtype=torch.int32), tensor([ 2, 15,  1,  5,  7,  4,  1,  5,  7,  0,  1,  5,  7, 12,  5,  7,  3, 15,\n",
      "         7,  1,  5,  7,  1, 11,  1, 11, 12], dtype=torch.int32), tensor([ 5,  7, 12,  0,  1, 11,  2, 13,  1,  7,  0, 12,  3, 15,  5,  7,  1,  7,\n",
      "        12], dtype=torch.int32), tensor([ 1,  5,  7,  1,  5,  7,  5, 11,  1, 11,  3, 15,  5,  7, 12],\n",
      "       dtype=torch.int32), tensor([ 5,  7, 12], dtype=torch.int32), tensor([11, 12,  5,  7, 12,  2, 15,  7,  7,  7,  1,  5,  7, 12,  3,  3, 15,  1,\n",
      "         5,  8, 12], dtype=torch.int32), tensor([ 1,  2,  5,  2,  8,  7, 10, 15,  1,  5,  7,  0,  4,  1,  5,  7,  1,  5,\n",
      "        11, 12], dtype=torch.int32), tensor([ 1, 10,  2,  1,  5,  0,  7,  3, 15,  1,  7,  4,  7,  0, 12],\n",
      "       dtype=torch.int32), tensor([ 1,  5,  8, 11, 11, 15,  5,  7,  1,  5,  7, 15, 10,  1,  7,  7,  7, 12,\n",
      "         1,  7,  1,  5,  7,  4,  1,  5,  7, 12], dtype=torch.int32), tensor([ 5,  7, 15,  5,  7,  4, 11, 11, 11,  3, 15,  5,  0,  7, 12],\n",
      "       dtype=torch.int32), tensor([ 7, 12], dtype=torch.int32), tensor([ 7,  1,  7,  1,  5, 11, 12], dtype=torch.int32), tensor([11, 12, 11, 12, 12,  5,  7, 12, 10, 10,  3, 15,  1,  7,  0, 12,  3,  2,\n",
      "        15,  1, 11, 12, 11, 12, 12,  5,  7,  1,  7,  1, 11, 11, 12,  0,  1,  5,\n",
      "         5,  7, 12], dtype=torch.int32), tensor([ 5,  7,  1,  5, 11,  2,  3,  1,  7, 12], dtype=torch.int32), tensor([ 3, 15,  5,  7,  0,  1,  0,  7,  1, 11, 12], dtype=torch.int32), tensor([ 5,  7,  0,  3, 15,  1,  5,  7,  1,  5,  7,  1,  5, 11, 12],\n",
      "       dtype=torch.int32), tensor([ 1, 15,  5,  7, 12,  5,  7,  1,  5,  7,  3, 15,  1, 11, 12],\n",
      "       dtype=torch.int32), tensor([ 1,  5,  7,  3, 15,  2,  5,  7,  1,  5,  7,  1, 11, 12, 10,  3, 15,  7,\n",
      "        12], dtype=torch.int32), tensor([ 1,  5,  7,  2,  3, 15, 15,  7, 12], dtype=torch.int32), tensor([ 7, 12], dtype=torch.int32)]\n"
     ]
    }
   ],
   "source": [
    "def encode_moves(oracle,parser,heads,phrase,phrases_lemma):\n",
    "    stacks,buffers,moves=parser.simulate_parse(heads,phrase)\n",
    "    embedded_features=oracle.extract_features(phrase,phrases_lemma,stacks,buffers)\n",
    "    \n",
    "\n",
    "    expanded_moves=[]\n",
    "    for move in moves:\n",
    "        if(move==0): expanded_moves.append(torch.tensor([1,0,0]))\n",
    "        if(move==1): expanded_moves.append(torch.tensor([0,1,0]))\n",
    "        if(move==2): expanded_moves.append(torch.tensor([0,0,1]))\n",
    "\n",
    "    return embedded_features,expanded_moves\n",
    "\n",
    "#prende il dataset e per ogni frase genera il batch corrispettivo, genererà n=batch-size file    \n",
    "def create_batches(oracle,parser,batch_size,dataset):\n",
    "    batch_feature=[]\n",
    "    batch_moves=[]\n",
    "    batch_pos=[]\n",
    "\n",
    "    pos_tags = ['ADJ', 'ADV', 'INTJ', 'NOUN', 'PROPN','VERB','ADP','AUX','CCONJ','DET','NUM','PART','PRON','SCONJ','PUNCT','SYM','X']\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le = le.fit(pos_tags)\n",
    "\n",
    "    index_batch=0\n",
    "    for sent in dataset:     \n",
    "        if(index_batch==0):\n",
    "            heads=[-1]\n",
    "            words=[]\n",
    "            lemmas=[]\n",
    "            pos=[]\n",
    "\n",
    "\n",
    "            wrong_sent=0\n",
    "            for token in sent:\n",
    "                if(token.head is None): wrong_sent=1\n",
    "                if(token.form is None): wrong_sent=1\n",
    "                if(token.lemma is None): wrong_sent=1\n",
    "                if(token.upos is None): \n",
    "                    wrong_sent=1\n",
    "                    print(\"wrongpos\")\n",
    "\n",
    "                heads.append(int(token.head))\n",
    "                words.append(token.form)\n",
    "                lemmas.append(token.lemma)\n",
    "                pos.append(token.upos)\n",
    "            \n",
    "            if(wrong_sent==0):\n",
    "                sent_features,sent_moves = encode_moves(oracle,parser,heads,words,lemmas)\n",
    "                sent_features=torch.stack(sent_features,dim=0).to(torch.float32)\n",
    "                sent_moves=torch.stack(sent_moves).to(torch.float32)\n",
    "                batch_feature.append(sent_features)\n",
    "                batch_moves.append(sent_moves)\n",
    "\n",
    "                pos_int=le.transform(pos)\n",
    "                batch_pos.append(torch.tensor(pos_int))\n",
    "                \n",
    "            \n",
    "\n",
    "            if(len(batch_moves)==batch_size): \n",
    "                #print(sent_moves)\n",
    "                print(index_batch)\n",
    "                print(batch_pos)\n",
    "                packed_features=pack_sequence(batch_feature,enforce_sorted=False)\n",
    "                packed_moves=pack_sequence(batch_moves,enforce_sorted=False)\n",
    "                packed_pos=pack_sequence(batch_pos,enforce_sorted=False)\n",
    "\n",
    "\n",
    "                torch.save((packed_features,packed_moves,packed_pos), f\"data/batches/tensor{index_batch}.pt\")\n",
    "                index_batch+=1\n",
    "                batch_feature=[]\n",
    "                batch_moves=[]\n",
    "#DA FARE:\n",
    "#1. Salvare batch da 50-100 frasi su file dati, ossia per ogni frase gli stati con relativi stack,buffer e move. \n",
    "#2. Importare batch per batch come nell'esempio di chat gpt.\n",
    "#3. Per ogni batch fare forward e back-prop di adam optimizer come nell'esempio di chat_gpt.\n",
    "\n",
    "\n",
    "\n",
    "#p1,m1=parser.encode_moves(heads,phrase,phrase)\n",
    "#p2,m2=parser.encode_moves(heads2,phrase2,phrase2)\n",
    "#print(m2)\n",
    "#torch.set_printoptions(profile=\"full\")\n",
    "#p1 = torch.stack(p1, dim=0)\n",
    "#p2 = torch.stack(p2, dim=0)\n",
    "#print(p1)\n",
    "#print(p2)\n",
    "#input=pack_sequence([p1, p2])\n",
    "\n",
    "#input_size = 3840  # Each element in the sequence is a vector of size 2\n",
    "#hidden_size = 64\n",
    "#num_layers = 1\n",
    "#output_size = 3  # Example output size\n",
    "#model = torch.nn.LSTM(input_size,hidden_size,num_layers,batch_first=True,bidirectional=False,proj_size=output_size)\n",
    "#model.half()\n",
    "#\n",
    "#output = model(input)\n",
    "#print(output)\n",
    "#print(\"OUTPUT\")\n",
    "#print(unpack_sequence(output[0]))\n",
    "\n",
    "\n",
    "oracle = Oracle()\n",
    "parser = Parser(oracle)\n",
    "create_batches(oracle,parser,100,train_prepocesed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "oracle.train_on_batches()\n",
    "phrases=\"Hamad Butt è morto nel 1994 a 32 anni .\".split()\n",
    "deps = parser.parsing(phrases,phrases)\n",
    "print(deps.get_heads())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
