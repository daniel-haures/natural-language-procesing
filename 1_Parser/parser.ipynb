{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fast\\TLN\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#from libs.corpus import openConllu, check_projectivity\n",
    "import pyconll\n",
    "import pyconll.util\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pack_sequence\n",
    "from torch.nn.utils.rnn import unpack_sequence\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pyconll.load_from_file('data/it_isdt-ud-train.conllu')\n",
    "train_prepocesed=[]\n",
    "for i,sent in enumerate(train):        \n",
    "    sentence_preprocesed=[]\n",
    "    for j,token in enumerate(sent):\n",
    "        if(token.head is not None):\n",
    "            sentence_preprocesed.append(token)\n",
    "    train_prepocesed.append(sentence_preprocesed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fast\\TLN\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loadind 0\n",
      "Batch features sizes\n",
      "prima tensor([[-0.1012, -0.2063, -0.1362],\n",
      "        [ 0.1542,  0.1914, -0.0817],\n",
      "        [-0.1973,  0.2412, -0.0466],\n",
      "        [ 0.0679,  0.2443, -0.0079]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2280, 0.1779, 0.2333],\n",
      "        [0.2944, 0.2649, 0.2463],\n",
      "        [0.2072, 0.2783, 0.2551],\n",
      "        [0.2703, 0.2791, 0.2651]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1036,  0.0609, -0.0650],\n",
      "        [ 0.2236,  0.1260,  0.3057],\n",
      "        [ 0.3188,  0.1394, -0.0506],\n",
      "        [ 0.1237,  0.2213,  0.0989],\n",
      "        [ 0.0807,  0.2083,  0.1257],\n",
      "        [ 0.0902,  0.0470,  0.0706],\n",
      "        [ 0.1575,  0.1517, -0.2333],\n",
      "        [ 0.2140,  0.3530,  0.0729],\n",
      "        [ 0.1913,  0.2935, -0.3030],\n",
      "        [ 0.2007,  0.3496,  0.2242]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0771, 0.0870, 0.0900],\n",
      "        [0.1071, 0.0928, 0.1304],\n",
      "        [0.1178, 0.0941, 0.0912],\n",
      "        [0.0969, 0.1021, 0.1060],\n",
      "        [0.0928, 0.1008, 0.1089],\n",
      "        [0.0937, 0.0858, 0.1030],\n",
      "        [0.1002, 0.0953, 0.0760],\n",
      "        [0.1060, 0.1165, 0.1033],\n",
      "        [0.1037, 0.1097, 0.0709],\n",
      "        [0.1047, 0.1161, 0.1202]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1012, -0.2063, -0.1362],\n",
      "        [ 0.1542,  0.1914, -0.0817],\n",
      "        [-0.1973,  0.2412, -0.0466],\n",
      "        [ 0.0679,  0.2443, -0.0079]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2280, 0.1779, 0.2333],\n",
      "        [0.2944, 0.2649, 0.2463],\n",
      "        [0.2072, 0.2783, 0.2551],\n",
      "        [0.2703, 0.2791, 0.2651]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0157, -0.1633,  0.2224],\n",
      "        [ 0.0801, -0.0916,  0.3901],\n",
      "        [ 0.0638, -0.2532,  0.0224],\n",
      "        [ 0.2607,  0.0030,  0.2551],\n",
      "        [-0.0089, -0.1681,  0.3105],\n",
      "        [-0.1444, -0.0663,  0.1447],\n",
      "        [-0.1600, -0.0440,  0.2347],\n",
      "        [-0.0067,  0.0030,  0.3013],\n",
      "        [-0.0619, -0.1802,  0.1483],\n",
      "        [-0.1117, -0.1514,  0.3015],\n",
      "        [ 0.1997, -0.2194,  0.2434],\n",
      "        [ 0.4531, -0.0416,  0.2156],\n",
      "        [ 0.1577, -0.0675,  0.0027],\n",
      "        [ 0.3184,  0.0872,  0.2869]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0662, 0.0665, 0.0712],\n",
      "        [0.0706, 0.0715, 0.0842],\n",
      "        [0.0695, 0.0608, 0.0583],\n",
      "        [0.0847, 0.0786, 0.0735],\n",
      "        [0.0646, 0.0662, 0.0778],\n",
      "        [0.0564, 0.0733, 0.0659],\n",
      "        [0.0555, 0.0750, 0.0721],\n",
      "        [0.0648, 0.0786, 0.0771],\n",
      "        [0.0613, 0.0654, 0.0661],\n",
      "        [0.0583, 0.0673, 0.0771],\n",
      "        [0.0797, 0.0629, 0.0728],\n",
      "        [0.1025, 0.0752, 0.0707],\n",
      "        [0.0763, 0.0732, 0.0572],\n",
      "        [0.0897, 0.0854, 0.0760]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0772, -0.1705, -0.0671],\n",
      "        [ 0.0734,  0.2080,  0.0107],\n",
      "        [-0.1284, -0.0081,  0.2886],\n",
      "        [ 0.1890,  0.3259,  0.1967],\n",
      "        [ 0.3123, -0.0033,  0.0904],\n",
      "        [ 0.0087, -0.0614,  0.3477],\n",
      "        [-0.0600, -0.1165,  0.4905],\n",
      "        [ 0.0147, -0.1527,  0.3052],\n",
      "        [-0.0889, -0.1024,  0.3896],\n",
      "        [-0.1220, -0.0641,  0.6123],\n",
      "        [-0.0142, -0.2886,  0.4417],\n",
      "        [ 0.1121, -0.0560,  0.5591],\n",
      "        [ 0.2150, -0.3696,  0.2637],\n",
      "        [ 0.2866, -0.0791,  0.4412],\n",
      "        [ 0.2413, -0.3123,  0.3770],\n",
      "        [ 0.0290, -0.2703,  0.6108],\n",
      "        [ 0.1414, -0.3674,  0.1487],\n",
      "        [-0.0254, -0.0522,  0.3672],\n",
      "        [ 0.0028,  0.0483,  0.2683],\n",
      "        [-0.1069,  0.2042,  0.3674],\n",
      "        [ 0.1522,  0.0934,  0.2681],\n",
      "        [ 0.0834,  0.1121,  0.1188],\n",
      "        [ 0.0634,  0.0143, -0.2180],\n",
      "        [ 0.1077,  0.1219,  0.0370],\n",
      "        [ 0.1868,  0.0127,  0.1704],\n",
      "        [-0.0164, -0.2491,  0.2698],\n",
      "        [ 0.0516, -0.0197,  0.3066],\n",
      "        [-0.0269, -0.0608,  0.3047],\n",
      "        [-0.0527, -0.1306,  0.1737],\n",
      "        [-0.2734, -0.1953,  0.3528],\n",
      "        [-0.1747,  0.0045,  0.3975],\n",
      "        [-0.1405,  0.0126,  0.4807],\n",
      "        [-0.1776,  0.0500,  0.4246],\n",
      "        [-0.0732,  0.0008,  0.1173],\n",
      "        [-0.0419, -0.2854,  0.1881],\n",
      "        [-0.1012, -0.2057,  0.2397],\n",
      "        [-0.0807, -0.0726,  0.1621],\n",
      "        [-0.0342, -0.0084,  0.4629],\n",
      "        [ 0.0807,  0.0734,  0.5225],\n",
      "        [ 0.0245, -0.2181,  0.2346],\n",
      "        [-0.0235, -0.0894,  0.2822],\n",
      "        [-0.0328,  0.0278,  0.2339],\n",
      "        [-0.1259,  0.0190,  0.1748],\n",
      "        [-0.0649,  0.0386,  0.6396],\n",
      "        [-0.1697,  0.0299,  0.6914],\n",
      "        [-0.1277,  0.0251,  0.4045],\n",
      "        [-0.2172, -0.0044,  0.6113],\n",
      "        [-0.1682,  0.1470,  0.4260],\n",
      "        [-0.0857,  0.0522,  0.3726],\n",
      "        [-0.0523,  0.0683,  0.1609],\n",
      "        [ 0.0385,  0.1111,  0.3594],\n",
      "        [-0.1304,  0.1163,  0.3167],\n",
      "        [ 0.1749, -0.0571,  0.0200],\n",
      "        [ 0.3906,  0.3621,  0.3652],\n",
      "        [ 0.3279,  0.0285, -0.0856],\n",
      "        [ 0.4854,  0.1584,  0.3098]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0161, 0.0153, 0.0122],\n",
      "        [0.0187, 0.0224, 0.0131],\n",
      "        [0.0153, 0.0180, 0.0173],\n",
      "        [0.0210, 0.0251, 0.0158],\n",
      "        [0.0237, 0.0181, 0.0142],\n",
      "        [0.0175, 0.0171, 0.0184],\n",
      "        [0.0164, 0.0162, 0.0212],\n",
      "        [0.0176, 0.0156, 0.0176],\n",
      "        [0.0159, 0.0164, 0.0192],\n",
      "        [0.0154, 0.0170, 0.0240],\n",
      "        [0.0171, 0.0136, 0.0202],\n",
      "        [0.0194, 0.0172, 0.0227],\n",
      "        [0.0216, 0.0126, 0.0169],\n",
      "        [0.0232, 0.0168, 0.0202],\n",
      "        [0.0221, 0.0133, 0.0190],\n",
      "        [0.0179, 0.0139, 0.0239],\n",
      "        [0.0200, 0.0126, 0.0151],\n",
      "        [0.0170, 0.0172, 0.0188],\n",
      "        [0.0174, 0.0191, 0.0170],\n",
      "        [0.0156, 0.0223, 0.0188],\n",
      "        [0.0202, 0.0199, 0.0170],\n",
      "        [0.0189, 0.0203, 0.0146],\n",
      "        [0.0185, 0.0184, 0.0105],\n",
      "        [0.0194, 0.0205, 0.0135],\n",
      "        [0.0210, 0.0184, 0.0154],\n",
      "        [0.0171, 0.0141, 0.0170],\n",
      "        [0.0183, 0.0178, 0.0177],\n",
      "        [0.0169, 0.0171, 0.0176],\n",
      "        [0.0165, 0.0159, 0.0155],\n",
      "        [0.0132, 0.0149, 0.0185],\n",
      "        [0.0146, 0.0182, 0.0193],\n",
      "        [0.0151, 0.0184, 0.0210],\n",
      "        [0.0145, 0.0191, 0.0199],\n",
      "        [0.0162, 0.0182, 0.0146],\n",
      "        [0.0167, 0.0136, 0.0157],\n",
      "        [0.0157, 0.0148, 0.0165],\n",
      "        [0.0160, 0.0169, 0.0153],\n",
      "        [0.0168, 0.0180, 0.0207],\n",
      "        [0.0188, 0.0195, 0.0219],\n",
      "        [0.0178, 0.0146, 0.0164],\n",
      "        [0.0170, 0.0166, 0.0172],\n",
      "        [0.0168, 0.0187, 0.0164],\n",
      "        [0.0153, 0.0185, 0.0155],\n",
      "        [0.0163, 0.0189, 0.0247],\n",
      "        [0.0147, 0.0187, 0.0260],\n",
      "        [0.0153, 0.0186, 0.0195],\n",
      "        [0.0140, 0.0181, 0.0240],\n",
      "        [0.0147, 0.0210, 0.0199],\n",
      "        [0.0160, 0.0191, 0.0189],\n",
      "        [0.0165, 0.0194, 0.0153],\n",
      "        [0.0181, 0.0203, 0.0186],\n",
      "        [0.0153, 0.0204, 0.0179],\n",
      "        [0.0207, 0.0172, 0.0133],\n",
      "        [0.0257, 0.0261, 0.0187],\n",
      "        [0.0241, 0.0187, 0.0119],\n",
      "        [0.0282, 0.0213, 0.0177]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 2.9297e-01, -3.9276e-02, -8.7219e-02],\n",
      "        [ 3.0713e-01,  2.2119e-01, -8.7769e-02],\n",
      "        [ 2.7490e-01,  2.4597e-01, -1.8298e-01],\n",
      "        [-2.7008e-02,  2.0923e-01,  1.3745e-01],\n",
      "        [-7.5073e-02,  3.0670e-02,  3.4546e-02],\n",
      "        [ 7.0610e-03,  3.8184e-01, -2.5177e-03],\n",
      "        [-3.8300e-02,  5.3076e-01,  1.7212e-01],\n",
      "        [-2.2900e-01,  2.2083e-01, -1.4931e-02],\n",
      "        [-2.4341e-01,  3.6401e-01,  2.7130e-02],\n",
      "        [-3.4393e-02,  1.1823e-01, -2.5082e-03],\n",
      "        [ 6.1249e-02,  2.8076e-01,  2.5464e-01],\n",
      "        [-1.5393e-01,  2.5171e-01,  7.8064e-02],\n",
      "        [-8.4473e-02,  3.5278e-01,  3.1494e-01],\n",
      "        [-2.8857e-01,  1.1865e-01,  6.3818e-01],\n",
      "        [-4.7180e-02,  1.9128e-01,  6.7480e-01],\n",
      "        [-6.0225e-04,  2.8979e-01,  4.7534e-01],\n",
      "        [-1.2842e-01,  3.0078e-01,  3.3398e-01],\n",
      "        [-1.3892e-01,  3.5767e-01,  2.1094e-01],\n",
      "        [-1.6394e-01,  1.4526e-01,  1.4502e-01],\n",
      "        [ 9.8450e-02,  1.4502e-01,  4.1504e-01],\n",
      "        [-5.9082e-02,  1.5015e-01,  5.5811e-01],\n",
      "        [-1.6907e-01,  2.8638e-01,  5.1953e-01],\n",
      "        [-2.3804e-01,  2.5464e-01,  4.5386e-01],\n",
      "        [-1.2769e-01,  3.2422e-01,  4.9072e-01],\n",
      "        [-1.8542e-01,  2.6880e-01,  4.9146e-01],\n",
      "        [-7.2937e-02,  1.7627e-01,  4.4873e-01],\n",
      "        [-1.4197e-01,  1.7432e-01,  3.0322e-01],\n",
      "        [-3.9111e-01,  2.1826e-01,  2.4329e-01],\n",
      "        [-6.6772e-02,  2.6758e-01,  1.2042e-01],\n",
      "        [ 7.4280e-02,  4.3213e-01,  1.6541e-01],\n",
      "        [ 2.2632e-01,  1.4209e-01,  6.7444e-02],\n",
      "        [ 1.5649e-01,  5.1074e-01,  2.8052e-01],\n",
      "        [ 1.6980e-01, -2.8613e-01,  4.4746e-03],\n",
      "        [-4.5319e-02, -5.5634e-02,  3.6133e-01],\n",
      "        [ 1.9119e-02, -9.0515e-02,  1.2659e-01],\n",
      "        [-1.7102e-01, -1.8481e-01,  3.6621e-01],\n",
      "        [ 9.3079e-02,  1.5249e-03,  3.5571e-01],\n",
      "        [ 2.0410e-01,  6.9946e-02,  4.0088e-01],\n",
      "        [ 9.2712e-02, -7.2815e-02,  3.4375e-01],\n",
      "        [ 2.9980e-01,  5.7422e-01,  3.4985e-01],\n",
      "        [ 1.5906e-01,  1.0413e-01,  1.2323e-01],\n",
      "        [ 2.7783e-01,  2.3596e-01,  6.7383e-01],\n",
      "        [ 4.0918e-01,  6.5002e-02,  4.3774e-01],\n",
      "        [ 2.5122e-01,  1.3403e-01,  4.6777e-01],\n",
      "        [ 2.9321e-01,  2.4368e-02,  4.3042e-01],\n",
      "        [ 3.7207e-01,  7.2876e-02,  5.0488e-01],\n",
      "        [ 5.8228e-02,  1.3367e-02,  1.7908e-01],\n",
      "        [ 4.3652e-01,  6.0730e-02, -1.5671e-02],\n",
      "        [ 4.2822e-01,  8.5999e-02, -1.3293e-01],\n",
      "        [ 5.6348e-01, -1.1279e-01,  1.9409e-01],\n",
      "        [ 9.6863e-02, -6.8164e-01, -1.1688e-02],\n",
      "        [ 5.1758e-01,  5.9387e-02,  1.1066e-01],\n",
      "        [ 4.1113e-01, -2.4561e-01, -1.2042e-01],\n",
      "        [ 3.0151e-01,  1.1664e-01,  9.2712e-02],\n",
      "        [ 2.5742e-02,  2.0520e-01,  1.1127e-01],\n",
      "        [-5.4016e-02,  1.6284e-01,  3.6572e-01],\n",
      "        [-1.4612e-01,  2.7246e-01,  4.6069e-01],\n",
      "        [ 3.8147e-02,  2.1204e-01,  3.6548e-01],\n",
      "        [-1.8982e-02,  2.1851e-02,  4.9585e-01],\n",
      "        [-9.5947e-02, -2.1265e-01,  4.8511e-01],\n",
      "        [-2.2913e-01, -2.6001e-01,  3.0957e-01],\n",
      "        [-1.1255e-01, -2.6270e-01,  4.1772e-01],\n",
      "        [ 1.1639e-01, -1.9299e-01,  2.4109e-01],\n",
      "        [ 4.1699e-01, -1.6199e-01,  4.4165e-01],\n",
      "        [ 3.0078e-01, -1.3269e-01,  1.4807e-01],\n",
      "        [ 3.3936e-01, -2.3230e-01,  4.6729e-01],\n",
      "        [ 2.6880e-01, -3.9038e-01,  1.2805e-01],\n",
      "        [-9.3750e-02,  8.7967e-03,  6.3916e-01],\n",
      "        [ 1.0382e-01,  4.4373e-02,  3.6572e-01],\n",
      "        [ 1.4197e-01,  1.1725e-01,  3.5254e-01],\n",
      "        [-3.4271e-02, -1.3074e-01,  9.8877e-02],\n",
      "        [ 3.2129e-01,  4.6997e-01,  7.2449e-02],\n",
      "        [ 2.8369e-01, -8.8135e-02,  1.2915e-01],\n",
      "        [ 2.8735e-01,  4.0063e-01,  1.9824e-01]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0164, 0.0114, 0.0094],\n",
      "        [0.0167, 0.0148, 0.0093],\n",
      "        [0.0161, 0.0152, 0.0085],\n",
      "        [0.0119, 0.0147, 0.0117],\n",
      "        [0.0114, 0.0123, 0.0106],\n",
      "        [0.0123, 0.0174, 0.0102],\n",
      "        [0.0118, 0.0202, 0.0121],\n",
      "        [0.0097, 0.0148, 0.0100],\n",
      "        [0.0096, 0.0171, 0.0105],\n",
      "        [0.0118, 0.0134, 0.0102],\n",
      "        [0.0130, 0.0157, 0.0132],\n",
      "        [0.0105, 0.0153, 0.0110],\n",
      "        [0.0113, 0.0169, 0.0140],\n",
      "        [0.0092, 0.0134, 0.0193],\n",
      "        [0.0117, 0.0144, 0.0200],\n",
      "        [0.0122, 0.0159, 0.0164],\n",
      "        [0.0108, 0.0161, 0.0143],\n",
      "        [0.0107, 0.0170, 0.0126],\n",
      "        [0.0104, 0.0137, 0.0118],\n",
      "        [0.0135, 0.0137, 0.0154],\n",
      "        [0.0116, 0.0138, 0.0178],\n",
      "        [0.0104, 0.0158, 0.0172],\n",
      "        [0.0097, 0.0153, 0.0161],\n",
      "        [0.0108, 0.0164, 0.0167],\n",
      "        [0.0102, 0.0155, 0.0167],\n",
      "        [0.0114, 0.0142, 0.0160],\n",
      "        [0.0106, 0.0141, 0.0138],\n",
      "        [0.0083, 0.0148, 0.0130],\n",
      "        [0.0115, 0.0155, 0.0115],\n",
      "        [0.0132, 0.0183, 0.0120],\n",
      "        [0.0154, 0.0137, 0.0109],\n",
      "        [0.0143, 0.0198, 0.0135],\n",
      "        [0.0145, 0.0089, 0.0103],\n",
      "        [0.0117, 0.0112, 0.0146],\n",
      "        [0.0125, 0.0109, 0.0116],\n",
      "        [0.0103, 0.0099, 0.0147],\n",
      "        [0.0134, 0.0119, 0.0146],\n",
      "        [0.0150, 0.0127, 0.0152],\n",
      "        [0.0134, 0.0110, 0.0144],\n",
      "        [0.0165, 0.0211, 0.0145],\n",
      "        [0.0144, 0.0132, 0.0115],\n",
      "        [0.0162, 0.0150, 0.0200],\n",
      "        [0.0184, 0.0127, 0.0158],\n",
      "        [0.0158, 0.0136, 0.0163],\n",
      "        [0.0164, 0.0122, 0.0157],\n",
      "        [0.0178, 0.0128, 0.0169],\n",
      "        [0.0130, 0.0120, 0.0122],\n",
      "        [0.0190, 0.0126, 0.0100],\n",
      "        [0.0188, 0.0130, 0.0089],\n",
      "        [0.0215, 0.0106, 0.0124],\n",
      "        [0.0135, 0.0060, 0.0101],\n",
      "        [0.0206, 0.0126, 0.0114],\n",
      "        [0.0185, 0.0093, 0.0090],\n",
      "        [0.0166, 0.0134, 0.0112],\n",
      "        [0.0126, 0.0146, 0.0114],\n",
      "        [0.0116, 0.0140, 0.0147],\n",
      "        [0.0106, 0.0156, 0.0162],\n",
      "        [0.0127, 0.0147, 0.0147],\n",
      "        [0.0120, 0.0121, 0.0167],\n",
      "        [0.0111, 0.0096, 0.0166],\n",
      "        [0.0097, 0.0092, 0.0139],\n",
      "        [0.0110, 0.0091, 0.0155],\n",
      "        [0.0138, 0.0098, 0.0130],\n",
      "        [0.0186, 0.0101, 0.0159],\n",
      "        [0.0166, 0.0104, 0.0118],\n",
      "        [0.0172, 0.0094, 0.0163],\n",
      "        [0.0160, 0.0080, 0.0116],\n",
      "        [0.0112, 0.0120, 0.0193],\n",
      "        [0.0136, 0.0124, 0.0147],\n",
      "        [0.0141, 0.0134, 0.0145],\n",
      "        [0.0118, 0.0104, 0.0113],\n",
      "        [0.0169, 0.0190, 0.0110],\n",
      "        [0.0163, 0.0109, 0.0116],\n",
      "        [0.0163, 0.0177, 0.0124]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.1232, -0.3108,  0.0839],\n",
      "        [ 0.0199,  0.0824,  0.2401],\n",
      "        [-0.1726, -0.0517,  0.2512],\n",
      "        [ 0.0284,  0.2296,  0.1826],\n",
      "        [-0.3088,  0.0790,  0.1594],\n",
      "        [-0.2202,  0.1675,  0.3372],\n",
      "        [-0.1385,  0.2893,  0.2351],\n",
      "        [-0.0183,  0.1460,  0.4590],\n",
      "        [-0.2036,  0.0621,  0.3220],\n",
      "        [-0.0746, -0.0555,  0.5264],\n",
      "        [ 0.0449, -0.1254,  0.5615],\n",
      "        [-0.0024, -0.1220,  0.5537],\n",
      "        [-0.2861, -0.3989,  0.3555],\n",
      "        [ 0.1760, -0.0942,  0.3210],\n",
      "        [-0.2004,  0.0723,  0.3396],\n",
      "        [-0.0344, -0.1383,  0.3401],\n",
      "        [-0.0719, -0.1658,  0.5039],\n",
      "        [ 0.0756,  0.0616,  0.4949]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0668, 0.0407, 0.0422],\n",
      "        [0.0602, 0.0603, 0.0494],\n",
      "        [0.0497, 0.0528, 0.0500],\n",
      "        [0.0608, 0.0699, 0.0466],\n",
      "        [0.0434, 0.0602, 0.0456],\n",
      "        [0.0474, 0.0657, 0.0544],\n",
      "        [0.0514, 0.0742, 0.0492],\n",
      "        [0.0580, 0.0643, 0.0615],\n",
      "        [0.0482, 0.0591, 0.0536],\n",
      "        [0.0548, 0.0526, 0.0657],\n",
      "        [0.0617, 0.0490, 0.0681],\n",
      "        [0.0589, 0.0492, 0.0676],\n",
      "        [0.0443, 0.0373, 0.0555],\n",
      "        [0.0704, 0.0506, 0.0536],\n",
      "        [0.0483, 0.0598, 0.0545],\n",
      "        [0.0570, 0.0484, 0.0546],\n",
      "        [0.0549, 0.0471, 0.0643],\n",
      "        [0.0637, 0.0591, 0.0637]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.1164, -0.2115, -0.0885],\n",
      "        [ 0.3057,  0.3215,  0.0212],\n",
      "        [ 0.2659,  0.1879, -0.1146],\n",
      "        [ 0.0942,  0.1422,  0.1385],\n",
      "        [ 0.1830, -0.2191, -0.1987],\n",
      "        [ 0.1167,  0.0459,  0.2600],\n",
      "        [-0.1365,  0.0505,  0.1970],\n",
      "        [-0.2551, -0.0053,  0.3489],\n",
      "        [-0.2180, -0.0888,  0.0797],\n",
      "        [-0.0917,  0.0812,  0.2084],\n",
      "        [-0.1886, -0.1469,  0.1516],\n",
      "        [ 0.0706,  0.1829,  0.0997],\n",
      "        [ 0.0804, -0.1263,  0.2125],\n",
      "        [ 0.1239,  0.0553,  0.1105],\n",
      "        [ 0.2910, -0.0652,  0.1246],\n",
      "        [ 0.0417,  0.2847,  0.0126],\n",
      "        [ 0.2030,  0.1835,  0.0376],\n",
      "        [ 0.2183,  0.2208,  0.2561],\n",
      "        [ 0.1769,  0.0306,  0.1248],\n",
      "        [ 0.1100,  0.2238,  0.4006],\n",
      "        [ 0.0498,  0.3218,  0.3425],\n",
      "        [-0.0305, -0.2583,  0.5562],\n",
      "        [ 0.0007, -0.2583,  0.5620],\n",
      "        [ 0.0992,  0.0176,  0.5264],\n",
      "        [-0.0432,  0.1562,  0.0880],\n",
      "        [ 0.0924,  0.2761,  0.3430],\n",
      "        [ 0.0547,  0.2866,  0.0786],\n",
      "        [ 0.2920,  0.1929,  0.3289],\n",
      "        [-0.1089, -0.0215,  0.5518],\n",
      "        [-0.1438,  0.1960,  0.5762],\n",
      "        [-0.0740,  0.1891,  0.5410],\n",
      "        [ 0.0463,  0.0675,  0.6367],\n",
      "        [-0.2852,  0.1555,  0.4382],\n",
      "        [ 0.0494, -0.0080,  0.3677],\n",
      "        [-0.1821, -0.3076,  0.1226],\n",
      "        [-0.1848,  0.0306,  0.4067],\n",
      "        [ 0.0678,  0.2048,  0.2805],\n",
      "        [ 0.0316,  0.1029,  0.6914],\n",
      "        [ 0.1830,  0.3425,  0.3218],\n",
      "        [-0.0748,  0.1429,  0.4568],\n",
      "        [ 0.1295, -0.1460,  0.1644],\n",
      "        [ 0.1387,  0.1575,  0.5376],\n",
      "        [ 0.4294,  0.2200,  0.1847],\n",
      "        [ 0.4348,  0.3875,  0.1102],\n",
      "        [ 0.6738,  0.5376,  0.0749],\n",
      "        [ 0.4050,  0.0891,  0.4070],\n",
      "        [ 0.6655,  0.1003,  0.2510],\n",
      "        [ 0.4175,  0.1274,  0.2715],\n",
      "        [ 0.5659,  0.4395,  0.3579],\n",
      "        [ 0.4229,  0.3054,  0.4893],\n",
      "        [ 0.2307,  0.2367,  0.3318],\n",
      "        [ 0.3687,  0.0181,  0.4724],\n",
      "        [ 0.2781,  0.0881,  0.1997],\n",
      "        [ 0.1599,  0.4282,  0.1449],\n",
      "        [-0.0256,  0.2076,  0.2319],\n",
      "        [ 0.0228,  0.2406,  0.1354],\n",
      "        [ 0.2051,  0.2778,  0.1173],\n",
      "        [ 0.0260,  0.2222,  0.3689],\n",
      "        [-0.0281,  0.0209,  0.1697],\n",
      "        [ 0.1720,  0.2098,  0.1182],\n",
      "        [ 0.3020,  0.0821,  0.0851],\n",
      "        [ 0.0466,  0.0767,  0.1219]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0157, 0.0114, 0.0112],\n",
      "        [0.0190, 0.0195, 0.0125],\n",
      "        [0.0183, 0.0170, 0.0109],\n",
      "        [0.0154, 0.0163, 0.0141],\n",
      "        [0.0168, 0.0113, 0.0100],\n",
      "        [0.0157, 0.0148, 0.0159],\n",
      "        [0.0122, 0.0148, 0.0149],\n",
      "        [0.0108, 0.0140, 0.0173],\n",
      "        [0.0113, 0.0129, 0.0133],\n",
      "        [0.0128, 0.0153, 0.0151],\n",
      "        [0.0116, 0.0122, 0.0142],\n",
      "        [0.0150, 0.0170, 0.0135],\n",
      "        [0.0152, 0.0124, 0.0151],\n",
      "        [0.0158, 0.0149, 0.0137],\n",
      "        [0.0187, 0.0132, 0.0139],\n",
      "        [0.0146, 0.0188, 0.0124],\n",
      "        [0.0172, 0.0170, 0.0127],\n",
      "        [0.0174, 0.0176, 0.0158],\n",
      "        [0.0167, 0.0146, 0.0139],\n",
      "        [0.0156, 0.0177, 0.0183],\n",
      "        [0.0147, 0.0195, 0.0172],\n",
      "        [0.0136, 0.0109, 0.0213],\n",
      "        [0.0140, 0.0109, 0.0215],\n",
      "        [0.0155, 0.0144, 0.0207],\n",
      "        [0.0134, 0.0165, 0.0134],\n",
      "        [0.0154, 0.0186, 0.0173],\n",
      "        [0.0148, 0.0188, 0.0132],\n",
      "        [0.0187, 0.0171, 0.0170],\n",
      "        [0.0126, 0.0138, 0.0213],\n",
      "        [0.0121, 0.0172, 0.0218],\n",
      "        [0.0130, 0.0171, 0.0210],\n",
      "        [0.0147, 0.0151, 0.0231],\n",
      "        [0.0105, 0.0165, 0.0190],\n",
      "        [0.0147, 0.0140, 0.0177],\n",
      "        [0.0117, 0.0104, 0.0138],\n",
      "        [0.0116, 0.0146, 0.0184],\n",
      "        [0.0150, 0.0173, 0.0162],\n",
      "        [0.0145, 0.0157, 0.0244],\n",
      "        [0.0168, 0.0199, 0.0169],\n",
      "        [0.0130, 0.0163, 0.0193],\n",
      "        [0.0159, 0.0122, 0.0144],\n",
      "        [0.0161, 0.0165, 0.0210],\n",
      "        [0.0215, 0.0176, 0.0147],\n",
      "        [0.0216, 0.0208, 0.0137],\n",
      "        [0.0275, 0.0242, 0.0132],\n",
      "        [0.0210, 0.0154, 0.0184],\n",
      "        [0.0272, 0.0156, 0.0157],\n",
      "        [0.0213, 0.0160, 0.0161],\n",
      "        [0.0247, 0.0219, 0.0175],\n",
      "        [0.0214, 0.0192, 0.0200],\n",
      "        [0.0176, 0.0179, 0.0171],\n",
      "        [0.0202, 0.0144, 0.0196],\n",
      "        [0.0185, 0.0154, 0.0150],\n",
      "        [0.0164, 0.0217, 0.0142],\n",
      "        [0.0136, 0.0174, 0.0154],\n",
      "        [0.0143, 0.0180, 0.0140],\n",
      "        [0.0172, 0.0186, 0.0138],\n",
      "        [0.0144, 0.0176, 0.0177],\n",
      "        [0.0136, 0.0144, 0.0145],\n",
      "        [0.0166, 0.0174, 0.0138],\n",
      "        [0.0189, 0.0153, 0.0133],\n",
      "        [0.0147, 0.0153, 0.0138]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 1.7200e-01, -2.4902e-01, -1.1816e-01],\n",
      "        [ 2.5024e-01,  1.3098e-01,  1.8311e-02],\n",
      "        [ 3.9886e-02, -4.8859e-02, -1.3161e-02],\n",
      "        [ 2.1191e-01,  3.0762e-02, -6.9275e-02],\n",
      "        [-2.5131e-02,  6.4354e-03, -1.2189e-01],\n",
      "        [-2.6074e-01, -1.4795e-01,  1.1218e-01],\n",
      "        [-1.4905e-01, -1.7102e-01,  2.2314e-01],\n",
      "        [ 1.2103e-01,  1.1139e-01, -1.8005e-01],\n",
      "        [-2.8564e-01,  2.5535e-04, -2.9395e-01],\n",
      "        [-7.6752e-03,  9.3933e-02, -3.6957e-02],\n",
      "        [-1.4160e-01,  6.7688e-02, -1.7090e-01],\n",
      "        [-2.4255e-01,  7.9834e-02, -2.3389e-01],\n",
      "        [-4.2505e-01, -2.8833e-01, -1.4844e-01],\n",
      "        [-3.2300e-01, -8.2550e-03, -1.7358e-01],\n",
      "        [-6.1523e-02,  3.1204e-02, -4.0332e-01],\n",
      "        [-1.5576e-01,  2.6636e-01, -2.4707e-01],\n",
      "        [ 9.4421e-02,  4.6460e-01,  1.2903e-01],\n",
      "        [-1.7236e-01,  4.3872e-01,  8.2336e-02],\n",
      "        [-1.2030e-01,  1.5308e-01,  2.7344e-02],\n",
      "        [-1.5564e-01,  1.4392e-01, -8.0017e-02],\n",
      "        [-1.4246e-01,  1.3159e-01, -4.7913e-02],\n",
      "        [-1.4368e-01,  2.0618e-01,  8.0872e-03]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0580, 0.0326, 0.0432],\n",
      "        [0.0627, 0.0477, 0.0496],\n",
      "        [0.0508, 0.0399, 0.0480],\n",
      "        [0.0604, 0.0432, 0.0454],\n",
      "        [0.0476, 0.0421, 0.0431],\n",
      "        [0.0377, 0.0361, 0.0544],\n",
      "        [0.0421, 0.0353, 0.0608],\n",
      "        [0.0551, 0.0468, 0.0406],\n",
      "        [0.0367, 0.0418, 0.0363],\n",
      "        [0.0485, 0.0460, 0.0469],\n",
      "        [0.0424, 0.0448, 0.0410],\n",
      "        [0.0383, 0.0453, 0.0385],\n",
      "        [0.0319, 0.0314, 0.0419],\n",
      "        [0.0353, 0.0415, 0.0409],\n",
      "        [0.0459, 0.0432, 0.0325],\n",
      "        [0.0418, 0.0546, 0.0380],\n",
      "        [0.0537, 0.0666, 0.0554],\n",
      "        [0.0411, 0.0649, 0.0529],\n",
      "        [0.0433, 0.0488, 0.0500],\n",
      "        [0.0418, 0.0483, 0.0449],\n",
      "        [0.0424, 0.0477, 0.0464],\n",
      "        [0.0423, 0.0515, 0.0491]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0111,  0.0098, -0.2546],\n",
      "        [ 0.2527,  0.4871, -0.1160],\n",
      "        [ 0.1222,  0.0591, -0.1475],\n",
      "        [ 0.0651,  0.0170,  0.1259],\n",
      "        [-0.0340, -0.2157,  0.1093],\n",
      "        [ 0.0018,  0.1846,  0.2045],\n",
      "        [-0.1246, -0.2920,  0.1305],\n",
      "        [ 0.1127,  0.1161, -0.0589],\n",
      "        [-0.0497, -0.1484,  0.1116],\n",
      "        [ 0.0549,  0.2451,  0.2637],\n",
      "        [-0.1669,  0.0638,  0.1660],\n",
      "        [-0.0464,  0.4224,  0.2019],\n",
      "        [-0.1846,  0.1635,  0.1786],\n",
      "        [-0.1279,  0.4434,  0.1152],\n",
      "        [-0.1914,  0.1298,  0.2671],\n",
      "        [-0.0740,  0.4705,  0.2396]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0642, 0.0537, 0.0435],\n",
      "        [0.0818, 0.0865, 0.0500],\n",
      "        [0.0718, 0.0564, 0.0485],\n",
      "        [0.0678, 0.0541, 0.0637],\n",
      "        [0.0614, 0.0429, 0.0626],\n",
      "        [0.0637, 0.0640, 0.0689],\n",
      "        [0.0561, 0.0397, 0.0640],\n",
      "        [0.0711, 0.0597, 0.0529],\n",
      "        [0.0605, 0.0459, 0.0628],\n",
      "        [0.0671, 0.0680, 0.0731],\n",
      "        [0.0537, 0.0567, 0.0663],\n",
      "        [0.0607, 0.0812, 0.0687],\n",
      "        [0.0528, 0.0626, 0.0671],\n",
      "        [0.0559, 0.0828, 0.0630],\n",
      "        [0.0525, 0.0606, 0.0734],\n",
      "        [0.0590, 0.0851, 0.0714]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0436, -0.0406, -0.1782],\n",
      "        [ 0.0190, -0.0441, -0.2925],\n",
      "        [ 0.0712,  0.0197, -0.1931],\n",
      "        [ 0.1891,  0.2423, -0.0850],\n",
      "        [ 0.2622, -0.0412, -0.0382],\n",
      "        [ 0.3435,  0.1698,  0.0922],\n",
      "        [-0.1740,  0.0981,  0.4250],\n",
      "        [-0.2910,  0.0862,  0.4915],\n",
      "        [ 0.0159, -0.0135,  0.5498],\n",
      "        [-0.3491, -0.1261,  0.5059],\n",
      "        [-0.1895, -0.2339,  0.7246],\n",
      "        [-0.2423, -0.2705,  0.5688],\n",
      "        [-0.2483, -0.0667,  0.6587],\n",
      "        [-0.4104,  0.1445,  0.5425],\n",
      "        [-0.5479,  0.1052,  0.6816],\n",
      "        [-0.2729,  0.0237,  0.5151],\n",
      "        [-0.3328, -0.1825,  0.8438],\n",
      "        [ 0.0026, -0.0493,  0.4565],\n",
      "        [ 0.1740,  0.0213,  0.4514],\n",
      "        [-0.1139,  0.1202,  0.5830],\n",
      "        [-0.1260, -0.1411,  0.5840],\n",
      "        [-0.1425, -0.0101,  0.6826],\n",
      "        [-0.2257, -0.2396,  0.7207],\n",
      "        [-0.2159,  0.2319,  0.8247],\n",
      "        [-0.3354, -0.0299,  0.6689],\n",
      "        [-0.3098,  0.1815,  0.5117],\n",
      "        [-0.1676,  0.1410,  0.4363],\n",
      "        [-0.1026,  0.2705,  0.5767]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0416, 0.0335, 0.0184],\n",
      "        [0.0406, 0.0334, 0.0164],\n",
      "        [0.0428, 0.0356, 0.0182],\n",
      "        [0.0481, 0.0444, 0.0202],\n",
      "        [0.0518, 0.0335, 0.0212],\n",
      "        [0.0562, 0.0414, 0.0242],\n",
      "        [0.0335, 0.0385, 0.0337],\n",
      "        [0.0298, 0.0380, 0.0360],\n",
      "        [0.0405, 0.0344, 0.0382],\n",
      "        [0.0281, 0.0307, 0.0365],\n",
      "        [0.0330, 0.0276, 0.0455],\n",
      "        [0.0312, 0.0266, 0.0389],\n",
      "        [0.0311, 0.0326, 0.0426],\n",
      "        [0.0264, 0.0403, 0.0379],\n",
      "        [0.0230, 0.0388, 0.0436],\n",
      "        [0.0303, 0.0357, 0.0369],\n",
      "        [0.0285, 0.0291, 0.0512],\n",
      "        [0.0399, 0.0332, 0.0348],\n",
      "        [0.0474, 0.0356, 0.0346],\n",
      "        [0.0355, 0.0393, 0.0395],\n",
      "        [0.0351, 0.0303, 0.0395],\n",
      "        [0.0345, 0.0345, 0.0436],\n",
      "        [0.0318, 0.0275, 0.0453],\n",
      "        [0.0321, 0.0440, 0.0502],\n",
      "        [0.0285, 0.0339, 0.0430],\n",
      "        [0.0292, 0.0418, 0.0367],\n",
      "        [0.0337, 0.0402, 0.0341],\n",
      "        [0.0359, 0.0457, 0.0392]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.1088, -0.0441,  0.1606],\n",
      "        [ 0.0666,  0.4167, -0.0236],\n",
      "        [ 0.0898,  0.2815, -0.0663],\n",
      "        [ 0.1259,  0.0734, -0.0492],\n",
      "        [ 0.0822, -0.1936,  0.3379],\n",
      "        [ 0.2391,  0.2471, -0.0229],\n",
      "        [-0.0692,  0.1805,  0.6250],\n",
      "        [ 0.1031,  0.1416,  0.2637],\n",
      "        [-0.0502,  0.1494,  0.5220],\n",
      "        [-0.0837,  0.3186,  0.5435],\n",
      "        [-0.2322,  0.4131,  0.4146],\n",
      "        [ 0.1547,  0.3354,  0.3584],\n",
      "        [ 0.2111,  0.2788,  0.5103],\n",
      "        [ 0.0263,  0.3579,  0.4272],\n",
      "        [ 0.0147,  0.3264,  0.6670],\n",
      "        [ 0.1602,  0.3308,  0.2749],\n",
      "        [ 0.0071,  0.2776,  0.3284],\n",
      "        [ 0.2061,  0.4221,  0.0660]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0577, 0.0414, 0.0472],\n",
      "        [0.0553, 0.0656, 0.0393],\n",
      "        [0.0566, 0.0572, 0.0376],\n",
      "        [0.0587, 0.0465, 0.0383],\n",
      "        [0.0562, 0.0356, 0.0564],\n",
      "        [0.0657, 0.0553, 0.0393],\n",
      "        [0.0483, 0.0517, 0.0751],\n",
      "        [0.0573, 0.0498, 0.0523],\n",
      "        [0.0492, 0.0501, 0.0678],\n",
      "        [0.0476, 0.0594, 0.0693],\n",
      "        [0.0410, 0.0653, 0.0609],\n",
      "        [0.0604, 0.0604, 0.0576],\n",
      "        [0.0639, 0.0571, 0.0670],\n",
      "        [0.0531, 0.0618, 0.0616],\n",
      "        [0.0525, 0.0599, 0.0784],\n",
      "        [0.0607, 0.0601, 0.0529],\n",
      "        [0.0521, 0.0570, 0.0559],\n",
      "        [0.0636, 0.0659, 0.0430]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 1.9275e-01, -4.9500e-02,  3.6499e-02],\n",
      "        [ 6.1615e-02, -8.6182e-02, -1.9104e-02],\n",
      "        [-1.0425e-01, -2.9077e-01,  1.0455e-01],\n",
      "        [-5.7434e-02, -9.7778e-02,  1.4832e-01],\n",
      "        [ 8.7830e-02, -2.9321e-01, -8.7036e-02],\n",
      "        [-2.5659e-01,  2.3499e-01,  1.0089e-01],\n",
      "        [-1.3550e-01,  1.4807e-01, -2.8809e-01],\n",
      "        [-5.4741e-04,  2.8394e-01, -2.5708e-01],\n",
      "        [ 3.4546e-02, -6.6223e-02, -9.8572e-02],\n",
      "        [-2.2156e-01, -9.7717e-02, -2.3773e-02],\n",
      "        [-2.8931e-01,  2.6001e-01,  2.0874e-01],\n",
      "        [-2.2058e-01,  1.4526e-01, -8.5083e-02],\n",
      "        [-3.2812e-01, -2.2507e-04, -1.5247e-01],\n",
      "        [-2.2998e-01,  1.8030e-01,  1.6248e-01],\n",
      "        [-1.6638e-01,  1.1243e-01,  1.4685e-01],\n",
      "        [-3.2593e-01, -5.4108e-02,  4.3506e-01],\n",
      "        [-3.6646e-01, -7.2937e-02,  4.2603e-01],\n",
      "        [-1.0400e-01,  1.6260e-01,  2.6538e-01],\n",
      "        [ 1.0663e-01, -1.5038e-02,  2.3547e-01],\n",
      "        [-7.0801e-02,  2.4109e-01,  1.4319e-01],\n",
      "        [ 1.6882e-01, -1.0553e-01,  2.4377e-01],\n",
      "        [-1.6187e-01,  1.7749e-01,  7.8796e-02],\n",
      "        [-5.5420e-02,  7.9346e-02,  2.0081e-01],\n",
      "        [-7.4585e-02,  2.6074e-01,  1.5344e-01],\n",
      "        [ 9.0881e-02, -1.0767e-01,  4.1162e-01],\n",
      "        [-3.8269e-02,  9.3018e-02,  6.5125e-02],\n",
      "        [ 1.7493e-01,  2.3206e-01,  1.5430e-01],\n",
      "        [-8.5205e-02,  1.2103e-01,  2.9980e-01],\n",
      "        [-8.7402e-02,  1.8787e-03,  3.8037e-01],\n",
      "        [-3.4277e-01,  1.0706e-01,  4.0625e-01],\n",
      "        [-1.8152e-01,  1.8640e-01,  3.9502e-01],\n",
      "        [-4.7461e-01,  8.4595e-02,  4.3896e-01],\n",
      "        [-1.5002e-01, -8.7097e-02,  2.3486e-01],\n",
      "        [-1.1926e-01, -6.1249e-02,  4.9268e-01],\n",
      "        [-1.4819e-01, -1.6992e-01,  3.9917e-01],\n",
      "        [-2.0264e-01, -2.8366e-02,  5.0146e-01],\n",
      "        [ 7.9117e-03, -1.1115e-01,  3.4790e-01],\n",
      "        [ 9.4788e-02, -1.5356e-01,  3.4888e-01],\n",
      "        [-2.0813e-01, -1.9006e-01,  1.3745e-01],\n",
      "        [-1.6687e-01, -2.6392e-01,  3.2642e-01],\n",
      "        [-2.5952e-01,  1.7871e-01,  1.9507e-01],\n",
      "        [-5.2399e-02, -3.7939e-01,  2.6001e-01],\n",
      "        [-7.6294e-02, -1.2091e-01,  3.8452e-01],\n",
      "        [-3.1738e-01, -1.8384e-01,  3.3618e-01],\n",
      "        [-8.3008e-02,  1.9730e-02,  2.5049e-01],\n",
      "        [-5.7068e-02, -1.6479e-01,  9.3689e-02],\n",
      "        [ 2.8488e-02, -4.5532e-02,  2.3572e-01],\n",
      "        [-3.1372e-02, -1.6687e-01,  2.9224e-01],\n",
      "        [-5.1904e-01, -1.5369e-01,  2.2656e-01],\n",
      "        [-2.3254e-01, -2.3047e-01,  4.2383e-01],\n",
      "        [-9.8511e-02, -2.5171e-01,  5.6580e-02],\n",
      "        [-2.5589e-02, -3.8477e-01,  1.2274e-01],\n",
      "        [-2.7783e-01, -4.2896e-01,  3.1812e-01],\n",
      "        [ 5.1636e-02, -3.1030e-01,  7.0923e-02],\n",
      "        [-3.6652e-02, -3.9062e-01,  2.8467e-01],\n",
      "        [ 3.6011e-02, -4.4434e-01,  3.1958e-01],\n",
      "        [-2.1558e-01, -2.6392e-01,  2.3877e-01],\n",
      "        [ 2.4658e-02, -1.3892e-01,  2.5635e-01],\n",
      "        [-2.9199e-01, -1.3269e-01,  3.4106e-01],\n",
      "        [ 3.5767e-01, -2.2351e-01,  3.7378e-01],\n",
      "        [ 3.6035e-01, -3.5095e-02,  2.3132e-01],\n",
      "        [ 1.3855e-01,  3.5934e-03,  5.3857e-01],\n",
      "        [ 1.4539e-01, -2.7515e-01,  4.6729e-01],\n",
      "        [-1.7358e-01, -1.1987e-01,  4.5630e-01],\n",
      "        [ 9.9121e-02, -2.6025e-01,  4.0332e-01],\n",
      "        [-4.0283e-02,  2.4097e-01,  5.1465e-01],\n",
      "        [-1.6272e-01, -3.0273e-01,  5.3467e-01],\n",
      "        [-6.2866e-02, -1.9775e-01,  5.0934e-02],\n",
      "        [ 4.6234e-02, -5.8411e-02,  2.1008e-01],\n",
      "        [ 1.1721e-03, -2.9663e-02,  3.5864e-01],\n",
      "        [-8.7097e-02,  4.5563e-02,  2.2437e-01],\n",
      "        [-2.3474e-01, -2.7710e-01,  3.3325e-01],\n",
      "        [-1.1658e-01,  4.3091e-02,  2.9297e-01],\n",
      "        [-1.2012e-01, -1.7517e-02,  1.6663e-01],\n",
      "        [-2.9495e-02, -2.6855e-02,  3.0176e-01],\n",
      "        [-5.8044e-02,  4.4128e-02,  1.4453e-01],\n",
      "        [-7.0557e-02,  1.1121e-01,  1.4099e-01],\n",
      "        [-1.8042e-01,  5.2124e-02,  4.0698e-01],\n",
      "        [-2.4243e-01, -9.8633e-02,  5.2734e-01],\n",
      "        [-4.0308e-01,  3.5370e-02,  5.8643e-01],\n",
      "        [-3.7402e-01,  1.4343e-01,  3.0249e-01],\n",
      "        [-4.5459e-01,  1.7249e-01,  3.7402e-01],\n",
      "        [-2.2522e-01,  1.2610e-01,  7.0435e-02],\n",
      "        [-2.2913e-01, -5.4413e-02,  2.9785e-01],\n",
      "        [-3.0566e-01, -1.2042e-01,  1.5234e-01],\n",
      "        [-2.9077e-01,  2.0520e-01,  1.6492e-01],\n",
      "        [-2.8760e-01, -1.6931e-01,  3.9966e-01],\n",
      "        [-4.3994e-01, -2.1350e-01,  4.6021e-01],\n",
      "        [-4.7943e-02, -5.7129e-02,  4.5288e-01],\n",
      "        [-3.3081e-01, -1.5320e-01,  3.5742e-01],\n",
      "        [-3.3325e-01, -3.1958e-01,  5.8057e-01],\n",
      "        [-1.8848e-01, -2.5244e-01,  2.8540e-01],\n",
      "        [-3.6401e-01, -3.4570e-01,  7.0850e-01],\n",
      "        [-8.5999e-02,  1.6876e-02,  9.2896e-02],\n",
      "        [-4.0405e-01, -1.4999e-02,  2.1997e-01],\n",
      "        [-3.4570e-01,  1.0455e-01,  1.2927e-01],\n",
      "        [-4.7827e-01,  1.5820e-01,  2.2229e-01],\n",
      "        [-4.5190e-01, -2.2354e-03,  2.0496e-01],\n",
      "        [-2.1277e-01,  9.7656e-03,  1.7065e-01],\n",
      "        [-3.2715e-01,  7.2144e-02,  4.6460e-01],\n",
      "        [-3.2446e-01,  2.3514e-02,  2.4792e-01],\n",
      "        [-4.1919e-01,  9.1187e-02,  7.8857e-01],\n",
      "        [-2.1057e-01, -1.7786e-01,  5.6396e-01],\n",
      "        [-2.4097e-01, -3.1738e-02,  6.1963e-01],\n",
      "        [-9.8877e-02,  1.8042e-01,  1.6504e-01],\n",
      "        [ 2.9785e-01,  1.8152e-01,  1.8225e-01],\n",
      "        [ 7.1411e-03,  3.0566e-01,  9.6313e-02],\n",
      "        [-2.6294e-01,  2.2632e-01,  2.6709e-01],\n",
      "        [ 1.3123e-01,  4.0186e-01, -2.0056e-01],\n",
      "        [ 1.2561e-01,  6.4600e-01, -1.1871e-01],\n",
      "        [-6.0150e-02,  2.6514e-01,  1.9714e-01],\n",
      "        [ 1.2140e-01,  3.3032e-01,  1.9446e-01],\n",
      "        [ 8.8867e-02,  3.8379e-01,  3.3472e-01],\n",
      "        [-1.8250e-01,  4.5117e-01,  4.9408e-02],\n",
      "        [-1.0272e-01,  3.7549e-01,  1.3879e-01],\n",
      "        [-1.2891e-01,  1.1237e-01,  3.3057e-01],\n",
      "        [-3.0823e-02, -6.8787e-02,  2.2705e-01],\n",
      "        [ 2.3718e-01,  1.1493e-01, -3.7289e-03],\n",
      "        [ 6.0974e-02,  2.2754e-01, -1.1969e-01],\n",
      "        [ 2.3730e-01,  2.4207e-01,  3.9337e-02]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0112, 0.0078, 0.0066],\n",
      "        [0.0098, 0.0075, 0.0063],\n",
      "        [0.0083, 0.0062, 0.0071],\n",
      "        [0.0087, 0.0075, 0.0074],\n",
      "        [0.0101, 0.0061, 0.0059],\n",
      "        [0.0072, 0.0104, 0.0071],\n",
      "        [0.0081, 0.0095, 0.0048],\n",
      "        [0.0092, 0.0109, 0.0049],\n",
      "        [0.0096, 0.0077, 0.0058],\n",
      "        [0.0074, 0.0075, 0.0062],\n",
      "        [0.0069, 0.0107, 0.0079],\n",
      "        [0.0074, 0.0095, 0.0059],\n",
      "        [0.0067, 0.0082, 0.0055],\n",
      "        [0.0073, 0.0099, 0.0075],\n",
      "        [0.0078, 0.0092, 0.0074],\n",
      "        [0.0067, 0.0078, 0.0099],\n",
      "        [0.0064, 0.0077, 0.0098],\n",
      "        [0.0083, 0.0097, 0.0083],\n",
      "        [0.0103, 0.0081, 0.0081],\n",
      "        [0.0086, 0.0105, 0.0074],\n",
      "        [0.0109, 0.0074, 0.0082],\n",
      "        [0.0079, 0.0098, 0.0069],\n",
      "        [0.0087, 0.0089, 0.0078],\n",
      "        [0.0086, 0.0107, 0.0075],\n",
      "        [0.0101, 0.0074, 0.0097],\n",
      "        [0.0089, 0.0090, 0.0068],\n",
      "        [0.0110, 0.0104, 0.0075],\n",
      "        [0.0085, 0.0093, 0.0086],\n",
      "        [0.0085, 0.0082, 0.0094],\n",
      "        [0.0066, 0.0092, 0.0096],\n",
      "        [0.0077, 0.0099, 0.0095],\n",
      "        [0.0058, 0.0090, 0.0099],\n",
      "        [0.0080, 0.0075, 0.0081],\n",
      "        [0.0082, 0.0077, 0.0105],\n",
      "        [0.0080, 0.0069, 0.0095],\n",
      "        [0.0075, 0.0080, 0.0106],\n",
      "        [0.0093, 0.0074, 0.0091],\n",
      "        [0.0102, 0.0071, 0.0091],\n",
      "        [0.0075, 0.0068, 0.0073],\n",
      "        [0.0078, 0.0063, 0.0089],\n",
      "        [0.0071, 0.0098, 0.0078],\n",
      "        [0.0088, 0.0056, 0.0083],\n",
      "        [0.0086, 0.0073, 0.0094],\n",
      "        [0.0067, 0.0068, 0.0090],\n",
      "        [0.0085, 0.0084, 0.0082],\n",
      "        [0.0087, 0.0070, 0.0070],\n",
      "        [0.0095, 0.0079, 0.0081],\n",
      "        [0.0090, 0.0070, 0.0086],\n",
      "        [0.0055, 0.0071, 0.0080],\n",
      "        [0.0073, 0.0065, 0.0098],\n",
      "        [0.0084, 0.0064, 0.0068],\n",
      "        [0.0090, 0.0056, 0.0072],\n",
      "        [0.0070, 0.0054, 0.0088],\n",
      "        [0.0097, 0.0060, 0.0069],\n",
      "        [0.0089, 0.0056, 0.0085],\n",
      "        [0.0096, 0.0053, 0.0088],\n",
      "        [0.0075, 0.0063, 0.0081],\n",
      "        [0.0095, 0.0072, 0.0083],\n",
      "        [0.0069, 0.0072, 0.0090],\n",
      "        [0.0132, 0.0066, 0.0093],\n",
      "        [0.0133, 0.0079, 0.0081],\n",
      "        [0.0106, 0.0083, 0.0110],\n",
      "        [0.0107, 0.0062, 0.0102],\n",
      "        [0.0078, 0.0073, 0.0101],\n",
      "        [0.0102, 0.0063, 0.0096],\n",
      "        [0.0089, 0.0105, 0.0107],\n",
      "        [0.0079, 0.0061, 0.0109],\n",
      "        [0.0087, 0.0068, 0.0067],\n",
      "        [0.0097, 0.0078, 0.0079],\n",
      "        [0.0093, 0.0080, 0.0092],\n",
      "        [0.0085, 0.0086, 0.0080],\n",
      "        [0.0073, 0.0062, 0.0089],\n",
      "        [0.0082, 0.0086, 0.0086],\n",
      "        [0.0082, 0.0081, 0.0076],\n",
      "        [0.0090, 0.0080, 0.0087],\n",
      "        [0.0087, 0.0086, 0.0074],\n",
      "        [0.0086, 0.0092, 0.0074],\n",
      "        [0.0077, 0.0087, 0.0096],\n",
      "        [0.0073, 0.0075, 0.0108],\n",
      "        [0.0062, 0.0085, 0.0115],\n",
      "        [0.0064, 0.0095, 0.0087],\n",
      "        [0.0059, 0.0098, 0.0093],\n",
      "        [0.0074, 0.0093, 0.0069],\n",
      "        [0.0074, 0.0078, 0.0086],\n",
      "        [0.0068, 0.0073, 0.0075],\n",
      "        [0.0069, 0.0101, 0.0075],\n",
      "        [0.0069, 0.0069, 0.0095],\n",
      "        [0.0060, 0.0066, 0.0101],\n",
      "        [0.0088, 0.0078, 0.0101],\n",
      "        [0.0066, 0.0071, 0.0091],\n",
      "        [0.0066, 0.0060, 0.0114],\n",
      "        [0.0077, 0.0064, 0.0085],\n",
      "        [0.0064, 0.0058, 0.0130],\n",
      "        [0.0085, 0.0084, 0.0070],\n",
      "        [0.0062, 0.0081, 0.0080],\n",
      "        [0.0065, 0.0091, 0.0073],\n",
      "        [0.0057, 0.0096, 0.0080],\n",
      "        [0.0059, 0.0082, 0.0079],\n",
      "        [0.0075, 0.0083, 0.0076],\n",
      "        [0.0067, 0.0089, 0.0102],\n",
      "        [0.0067, 0.0084, 0.0082],\n",
      "        [0.0061, 0.0090, 0.0141],\n",
      "        [0.0075, 0.0069, 0.0112],\n",
      "        [0.0073, 0.0080, 0.0119],\n",
      "        [0.0084, 0.0099, 0.0075],\n",
      "        [0.0125, 0.0099, 0.0077],\n",
      "        [0.0093, 0.0112, 0.0070],\n",
      "        [0.0071, 0.0103, 0.0084],\n",
      "        [0.0105, 0.0123, 0.0052],\n",
      "        [0.0105, 0.0157, 0.0057],\n",
      "        [0.0087, 0.0107, 0.0078],\n",
      "        [0.0104, 0.0115, 0.0078],\n",
      "        [0.0101, 0.0121, 0.0089],\n",
      "        [0.0077, 0.0129, 0.0067],\n",
      "        [0.0083, 0.0120, 0.0073],\n",
      "        [0.0081, 0.0092, 0.0089],\n",
      "        [0.0090, 0.0077, 0.0080],\n",
      "        [0.0117, 0.0092, 0.0064],\n",
      "        [0.0098, 0.0103, 0.0057],\n",
      "        [0.0117, 0.0105, 0.0067]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0856, -0.3330,  0.1420],\n",
      "        [ 0.0632, -0.2795,  0.0438],\n",
      "        [ 0.0437, -0.3259, -0.0134],\n",
      "        [ 0.2742, -0.0102, -0.1316],\n",
      "        [ 0.1467, -0.0809, -0.0323],\n",
      "        [ 0.3716, -0.1410,  0.1147],\n",
      "        [ 0.2101, -0.2300,  0.2739],\n",
      "        [ 0.3701, -0.2920,  0.2534],\n",
      "        [ 0.1832, -0.2805,  0.1050],\n",
      "        [ 0.4038, -0.1783,  0.3687],\n",
      "        [-0.0056, -0.0537,  0.4785],\n",
      "        [ 0.1727, -0.0395,  0.4062],\n",
      "        [ 0.0576,  0.1949,  0.2739],\n",
      "        [ 0.1521, -0.0098,  0.0583],\n",
      "        [-0.1166,  0.1296,  0.1696],\n",
      "        [-0.1012, -0.2610,  0.6304],\n",
      "        [ 0.0356, -0.1259,  0.5254],\n",
      "        [-0.1058, -0.0528,  0.5488],\n",
      "        [-0.1388, -0.3225,  0.3831],\n",
      "        [ 0.0862, -0.1506,  0.5049],\n",
      "        [ 0.0854, -0.3044,  0.3025],\n",
      "        [-0.0167, -0.2996,  0.5059],\n",
      "        [ 0.1598, -0.1390, -0.0063],\n",
      "        [ 0.1890, -0.1525,  0.3433],\n",
      "        [ 0.1709, -0.2054,  0.0361],\n",
      "        [ 0.2369,  0.0885,  0.4233],\n",
      "        [ 0.2769,  0.1594,  0.1641],\n",
      "        [ 0.4646,  0.3191,  0.0773],\n",
      "        [ 0.1550,  0.2157,  0.1055],\n",
      "        [ 0.2881,  0.2546, -0.1549],\n",
      "        [ 0.0545,  0.0786,  0.3955],\n",
      "        [ 0.1824,  0.3315, -0.0327],\n",
      "        [-0.1061, -0.0334,  0.6353],\n",
      "        [ 0.0197,  0.1980,  0.4980],\n",
      "        [-0.0988,  0.3708,  0.3740],\n",
      "        [ 0.1943,  0.3162, -0.0725],\n",
      "        [ 0.1965,  0.0301, -0.1736],\n",
      "        [ 0.0110,  0.0441,  0.4089],\n",
      "        [ 0.2839, -0.1440,  0.2075],\n",
      "        [ 0.1671,  0.0036,  0.3684],\n",
      "        [ 0.1592, -0.0517,  0.0859],\n",
      "        [ 0.2059, -0.0555,  0.3367],\n",
      "        [-0.0115, -0.3455,  0.2014],\n",
      "        [ 0.2488, -0.0240,  0.1155],\n",
      "        [-0.0607, -0.1671,  0.2323],\n",
      "        [ 0.1066, -0.1225,  0.3770],\n",
      "        [ 0.2566, -0.2019,  0.4604],\n",
      "        [ 0.4409, -0.1702,  0.4026],\n",
      "        [ 0.3108, -0.2268,  0.1917],\n",
      "        [ 0.3262, -0.4163,  0.3774],\n",
      "        [ 0.5215, -0.3276,  0.2152],\n",
      "        [ 0.3823, -0.0757,  0.2581],\n",
      "        [ 0.4131, -0.0756,  0.2329],\n",
      "        [ 0.1947, -0.0266,  0.0544],\n",
      "        [ 0.0356,  0.0078,  0.1600],\n",
      "        [-0.0250,  0.1197,  0.3220],\n",
      "        [ 0.0744,  0.2734,  0.4072],\n",
      "        [-0.0598,  0.1116,  0.5244],\n",
      "        [ 0.3635, -0.1399,  0.4600],\n",
      "        [ 0.2401,  0.2277,  0.2957],\n",
      "        [ 0.1986, -0.0924,  0.4819],\n",
      "        [ 0.0508,  0.1305,  0.4497],\n",
      "        [ 0.2372,  0.0153,  0.3811],\n",
      "        [-0.0993,  0.0611,  0.3740],\n",
      "        [ 0.0138,  0.0776,  0.2289],\n",
      "        [ 0.0242,  0.0956,  0.2372],\n",
      "        [ 0.1906, -0.1649,  0.1642],\n",
      "        [-0.0093,  0.0334,  0.1414],\n",
      "        [-0.1270,  0.0573, -0.1132],\n",
      "        [ 0.0617, -0.0273,  0.2390],\n",
      "        [ 0.2100,  0.1559, -0.0737],\n",
      "        [ 0.3586,  0.3474, -0.2343],\n",
      "        [ 0.4221,  0.1312, -0.3276],\n",
      "        [ 0.4062,  0.3914, -0.3745]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0125, 0.0098, 0.0121],\n",
      "        [0.0122, 0.0103, 0.0110],\n",
      "        [0.0120, 0.0098, 0.0104],\n",
      "        [0.0151, 0.0135, 0.0092],\n",
      "        [0.0133, 0.0126, 0.0102],\n",
      "        [0.0166, 0.0119, 0.0118],\n",
      "        [0.0141, 0.0108, 0.0138],\n",
      "        [0.0166, 0.0102, 0.0135],\n",
      "        [0.0138, 0.0103, 0.0117],\n",
      "        [0.0172, 0.0114, 0.0152],\n",
      "        [0.0114, 0.0129, 0.0170],\n",
      "        [0.0136, 0.0131, 0.0158],\n",
      "        [0.0121, 0.0166, 0.0138],\n",
      "        [0.0133, 0.0135, 0.0111],\n",
      "        [0.0102, 0.0155, 0.0125],\n",
      "        [0.0104, 0.0105, 0.0198],\n",
      "        [0.0119, 0.0120, 0.0178],\n",
      "        [0.0103, 0.0130, 0.0182],\n",
      "        [0.0100, 0.0099, 0.0154],\n",
      "        [0.0125, 0.0117, 0.0174],\n",
      "        [0.0125, 0.0101, 0.0142],\n",
      "        [0.0113, 0.0101, 0.0174],\n",
      "        [0.0135, 0.0119, 0.0104],\n",
      "        [0.0139, 0.0117, 0.0148],\n",
      "        [0.0136, 0.0111, 0.0109],\n",
      "        [0.0145, 0.0149, 0.0161],\n",
      "        [0.0151, 0.0160, 0.0124],\n",
      "        [0.0182, 0.0188, 0.0114],\n",
      "        [0.0134, 0.0169, 0.0117],\n",
      "        [0.0153, 0.0176, 0.0090],\n",
      "        [0.0121, 0.0148, 0.0156],\n",
      "        [0.0138, 0.0190, 0.0102],\n",
      "        [0.0103, 0.0132, 0.0199],\n",
      "        [0.0117, 0.0166, 0.0173],\n",
      "        [0.0104, 0.0198, 0.0153],\n",
      "        [0.0139, 0.0187, 0.0098],\n",
      "        [0.0140, 0.0141, 0.0088],\n",
      "        [0.0116, 0.0143, 0.0158],\n",
      "        [0.0152, 0.0118, 0.0129],\n",
      "        [0.0135, 0.0137, 0.0152],\n",
      "        [0.0135, 0.0130, 0.0115],\n",
      "        [0.0141, 0.0129, 0.0147],\n",
      "        [0.0113, 0.0097, 0.0129],\n",
      "        [0.0147, 0.0133, 0.0118],\n",
      "        [0.0108, 0.0116, 0.0133],\n",
      "        [0.0127, 0.0121, 0.0153],\n",
      "        [0.0148, 0.0112, 0.0167],\n",
      "        [0.0178, 0.0115, 0.0157],\n",
      "        [0.0156, 0.0109, 0.0127],\n",
      "        [0.0159, 0.0090, 0.0153],\n",
      "        [0.0193, 0.0098, 0.0130],\n",
      "        [0.0168, 0.0127, 0.0136],\n",
      "        [0.0173, 0.0127, 0.0133],\n",
      "        [0.0139, 0.0133, 0.0111],\n",
      "        [0.0119, 0.0138, 0.0123],\n",
      "        [0.0112, 0.0154, 0.0145],\n",
      "        [0.0124, 0.0179, 0.0158],\n",
      "        [0.0108, 0.0153, 0.0178],\n",
      "        [0.0165, 0.0119, 0.0167],\n",
      "        [0.0146, 0.0171, 0.0141],\n",
      "        [0.0140, 0.0125, 0.0170],\n",
      "        [0.0121, 0.0156, 0.0165],\n",
      "        [0.0145, 0.0139, 0.0154],\n",
      "        [0.0104, 0.0145, 0.0153],\n",
      "        [0.0116, 0.0148, 0.0132],\n",
      "        [0.0117, 0.0150, 0.0133],\n",
      "        [0.0139, 0.0116, 0.0124],\n",
      "        [0.0114, 0.0141, 0.0121],\n",
      "        [0.0101, 0.0145, 0.0094],\n",
      "        [0.0122, 0.0133, 0.0134],\n",
      "        [0.0141, 0.0159, 0.0098],\n",
      "        [0.0164, 0.0193, 0.0083],\n",
      "        [0.0175, 0.0156, 0.0076],\n",
      "        [0.0172, 0.0202, 0.0072]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 9.0332e-03, -1.1337e-02,  2.4536e-01],\n",
      "        [ 2.2607e-01,  5.0621e-03,  6.7017e-02],\n",
      "        [-1.1993e-01, -2.7295e-01,  3.0029e-01],\n",
      "        [-2.7649e-02, -1.8079e-01,  2.5708e-01],\n",
      "        [ 1.0168e-01, -4.1309e-01,  3.5547e-01],\n",
      "        [ 3.5742e-01, -1.1157e-01,  2.3669e-01],\n",
      "        [-1.5039e-01, -1.3489e-01,  1.7053e-01],\n",
      "        [-1.5602e-02, -2.1924e-01,  2.6538e-01],\n",
      "        [-2.9800e-02, -1.0645e-01, -1.3074e-01],\n",
      "        [-1.6833e-01, -6.3660e-02,  2.6880e-01],\n",
      "        [ 1.5613e-01, -7.5378e-02, -1.3542e-02],\n",
      "        [ 2.0105e-01,  6.7444e-02,  9.4788e-02],\n",
      "        [ 3.8477e-01, -3.7500e-01,  1.3220e-01],\n",
      "        [ 6.1914e-01, -4.7791e-02,  1.8994e-01],\n",
      "        [ 2.8003e-01, -3.6597e-01,  8.7814e-03],\n",
      "        [ 5.1575e-02,  1.1682e-01,  4.3018e-01],\n",
      "        [ 6.3538e-02, -1.6235e-02,  4.9878e-01],\n",
      "        [-8.6426e-02, -2.0802e-05,  4.5898e-01],\n",
      "        [-5.1270e-02, -9.5459e-02,  1.5735e-01],\n",
      "        [ 1.6064e-01, -6.3820e-03,  2.0337e-01],\n",
      "        [ 3.2861e-01, -3.9093e-02,  4.9957e-02],\n",
      "        [ 4.7217e-01,  8.6670e-02, -1.5900e-02],\n",
      "        [ 1.8311e-01, -2.0300e-01,  1.5637e-01],\n",
      "        [-1.6479e-02,  2.8275e-02,  2.0898e-01],\n",
      "        [-1.7529e-01,  1.1792e-01,  2.8613e-01],\n",
      "        [-2.1802e-01,  1.9299e-01,  2.2595e-01],\n",
      "        [-3.2788e-01, -7.0129e-02, -7.4310e-03],\n",
      "        [-2.2522e-01,  8.8196e-02, -1.2560e-03],\n",
      "        [-9.7046e-02,  8.3923e-02,  3.0371e-01],\n",
      "        [-1.2537e-01, -2.0142e-02,  2.9321e-01],\n",
      "        [-1.0052e-01,  1.1024e-03,  5.1270e-01],\n",
      "        [-2.0605e-01, -1.6663e-01,  3.7988e-01],\n",
      "        [-3.0127e-01, -2.2412e-01,  1.9641e-01],\n",
      "        [ 3.1763e-01,  1.9531e-01,  1.7993e-01],\n",
      "        [-2.0959e-01, -9.9976e-02,  3.9795e-02],\n",
      "        [-1.4233e-01,  5.7068e-02,  4.2676e-01],\n",
      "        [ 6.2164e-02, -2.1350e-01,  3.3789e-01],\n",
      "        [-3.2410e-02, -2.3792e-01,  5.1465e-01],\n",
      "        [-1.5564e-01, -3.0127e-01,  2.1619e-01],\n",
      "        [-5.0446e-02, -2.5635e-01,  4.5898e-01],\n",
      "        [-6.7993e-02, -2.7588e-01,  4.2944e-01],\n",
      "        [-5.2307e-02, -2.2217e-01,  3.4814e-01],\n",
      "        [-6.7261e-02, -5.8472e-02,  3.5181e-01],\n",
      "        [-6.4148e-02,  1.0144e-01,  1.1902e-01],\n",
      "        [-9.2834e-02,  1.8176e-01,  5.3253e-02],\n",
      "        [-3.0411e-02, -5.2490e-03,  1.2927e-01],\n",
      "        [-1.3855e-01, -1.2610e-01,  1.9910e-01],\n",
      "        [-1.3965e-01, -1.7932e-01,  2.2095e-01],\n",
      "        [-1.8958e-01, -3.4943e-02,  2.2449e-01],\n",
      "        [ 1.9006e-01,  8.5754e-02, -7.1655e-02],\n",
      "        [ 1.2634e-01, -5.8014e-02,  2.0203e-01],\n",
      "        [ 2.1606e-01,  8.5876e-02, -5.3925e-02]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0188, 0.0202, 0.0196],\n",
      "        [0.0233, 0.0206, 0.0164],\n",
      "        [0.0165, 0.0156, 0.0207],\n",
      "        [0.0181, 0.0171, 0.0198],\n",
      "        [0.0206, 0.0135, 0.0219],\n",
      "        [0.0266, 0.0183, 0.0194],\n",
      "        [0.0160, 0.0179, 0.0182],\n",
      "        [0.0183, 0.0164, 0.0200],\n",
      "        [0.0180, 0.0184, 0.0135],\n",
      "        [0.0157, 0.0192, 0.0201],\n",
      "        [0.0217, 0.0190, 0.0151],\n",
      "        [0.0227, 0.0219, 0.0169],\n",
      "        [0.0273, 0.0141, 0.0175],\n",
      "        [0.0345, 0.0195, 0.0185],\n",
      "        [0.0246, 0.0142, 0.0155],\n",
      "        [0.0196, 0.0230, 0.0236],\n",
      "        [0.0198, 0.0201, 0.0253],\n",
      "        [0.0171, 0.0205, 0.0243],\n",
      "        [0.0177, 0.0186, 0.0179],\n",
      "        [0.0218, 0.0203, 0.0188],\n",
      "        [0.0258, 0.0197, 0.0161],\n",
      "        [0.0298, 0.0223, 0.0151],\n",
      "        [0.0223, 0.0167, 0.0179],\n",
      "        [0.0183, 0.0210, 0.0189],\n",
      "        [0.0156, 0.0230, 0.0204],\n",
      "        [0.0149, 0.0248, 0.0192],\n",
      "        [0.0134, 0.0191, 0.0152],\n",
      "        [0.0148, 0.0224, 0.0153],\n",
      "        [0.0169, 0.0222, 0.0208],\n",
      "        [0.0164, 0.0201, 0.0206],\n",
      "        [0.0168, 0.0205, 0.0256],\n",
      "        [0.0151, 0.0173, 0.0224],\n",
      "        [0.0138, 0.0163, 0.0187],\n",
      "        [0.0255, 0.0249, 0.0184],\n",
      "        [0.0151, 0.0185, 0.0160],\n",
      "        [0.0161, 0.0217, 0.0235],\n",
      "        [0.0198, 0.0165, 0.0215],\n",
      "        [0.0180, 0.0161, 0.0257],\n",
      "        [0.0159, 0.0151, 0.0190],\n",
      "        [0.0177, 0.0158, 0.0243],\n",
      "        [0.0174, 0.0155, 0.0236],\n",
      "        [0.0176, 0.0164, 0.0217],\n",
      "        [0.0174, 0.0193, 0.0218],\n",
      "        [0.0174, 0.0226, 0.0173],\n",
      "        [0.0169, 0.0245, 0.0162],\n",
      "        [0.0180, 0.0204, 0.0175],\n",
      "        [0.0162, 0.0180, 0.0187],\n",
      "        [0.0162, 0.0171, 0.0191],\n",
      "        [0.0154, 0.0198, 0.0192],\n",
      "        [0.0225, 0.0223, 0.0143],\n",
      "        [0.0211, 0.0193, 0.0188],\n",
      "        [0.0231, 0.0223, 0.0145]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0332,  0.0542,  0.0441],\n",
      "        [ 0.1741,  0.6128,  0.2092],\n",
      "        [ 0.1243,  0.0277,  0.0247],\n",
      "        [ 0.0627,  0.3020,  0.0492],\n",
      "        [-0.1624,  0.0881,  0.1383],\n",
      "        [ 0.0316, -0.0834,  0.2480],\n",
      "        [ 0.0970, -0.0385, -0.1344],\n",
      "        [-0.2001,  0.0867,  0.2610],\n",
      "        [ 0.0379, -0.2439,  0.3652],\n",
      "        [-0.1073, -0.0566,  0.5288],\n",
      "        [-0.0651, -0.1199,  0.3994],\n",
      "        [-0.0857, -0.0753,  0.2676],\n",
      "        [-0.3521,  0.0188,  0.1891],\n",
      "        [-0.1113, -0.0862,  0.2039],\n",
      "        [-0.1429,  0.0482, -0.0408],\n",
      "        [-0.2803, -0.0128,  0.1588],\n",
      "        [-0.2280, -0.0563,  0.1464],\n",
      "        [-0.2050, -0.0654,  0.3445],\n",
      "        [-0.3438,  0.2072,  0.2522],\n",
      "        [-0.1259,  0.0922,  0.2834],\n",
      "        [-0.0276,  0.2059, -0.0792],\n",
      "        [ 0.1774,  0.2472,  0.0096]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0502, 0.0448, 0.0393],\n",
      "        [0.0577, 0.0782, 0.0464],\n",
      "        [0.0550, 0.0436, 0.0386],\n",
      "        [0.0517, 0.0574, 0.0395],\n",
      "        [0.0413, 0.0463, 0.0432],\n",
      "        [0.0501, 0.0390, 0.0482],\n",
      "        [0.0535, 0.0408, 0.0329],\n",
      "        [0.0397, 0.0462, 0.0489],\n",
      "        [0.0504, 0.0332, 0.0542],\n",
      "        [0.0436, 0.0401, 0.0638],\n",
      "        [0.0455, 0.0376, 0.0561],\n",
      "        [0.0445, 0.0393, 0.0492],\n",
      "        [0.0341, 0.0432, 0.0455],\n",
      "        [0.0434, 0.0389, 0.0461],\n",
      "        [0.0421, 0.0445, 0.0361],\n",
      "        [0.0367, 0.0419, 0.0441],\n",
      "        [0.0386, 0.0401, 0.0435],\n",
      "        [0.0395, 0.0397, 0.0531],\n",
      "        [0.0344, 0.0522, 0.0484],\n",
      "        [0.0428, 0.0465, 0.0500],\n",
      "        [0.0472, 0.0521, 0.0348],\n",
      "        [0.0580, 0.0543, 0.0380]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0616, -0.1675,  0.0391],\n",
      "        [ 0.0992,  0.1875,  0.0536],\n",
      "        [-0.1670,  0.1863,  0.0204],\n",
      "        [-0.0019,  0.2073,  0.1333]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2418, 0.1885, 0.2443],\n",
      "        [0.2839, 0.2688, 0.2478],\n",
      "        [0.2175, 0.2686, 0.2396],\n",
      "        [0.2566, 0.2742, 0.2683]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.1520, -0.1243,  0.0261],\n",
      "        [ 0.3699,  0.0949,  0.0228],\n",
      "        [ 0.0909,  0.0681, -0.0768],\n",
      "        [ 0.2310,  0.4521, -0.0142],\n",
      "        [ 0.2114,  0.1481, -0.0151],\n",
      "        [ 0.2205,  0.4951,  0.0820],\n",
      "        [ 0.0754,  0.3569, -0.3005],\n",
      "        [-0.0800,  0.3860,  0.2922],\n",
      "        [-0.0689,  0.1610,  0.6055],\n",
      "        [-0.2030,  0.1177,  0.6274],\n",
      "        [-0.0974, -0.0040,  0.2241],\n",
      "        [-0.0444,  0.0063,  0.5474],\n",
      "        [-0.0176, -0.0224,  0.5054],\n",
      "        [-0.0930, -0.1235,  0.3721],\n",
      "        [ 0.2092,  0.0235,  0.2031],\n",
      "        [ 0.1070,  0.2010,  0.4819],\n",
      "        [ 0.0598,  0.2981,  0.2118],\n",
      "        [-0.0657,  0.3586,  0.5610],\n",
      "        [-0.1437,  0.1031,  0.5176],\n",
      "        [-0.2878,  0.1917,  0.6162],\n",
      "        [-0.1694,  0.1949,  0.5308],\n",
      "        [-0.0949,  0.2307,  0.5029],\n",
      "        [-0.0638,  0.2334, -0.1237],\n",
      "        [ 0.1217,  0.5601,  0.2065],\n",
      "        [ 0.0451,  0.2460, -0.0294],\n",
      "        [ 0.3369,  0.5679,  0.2659]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0428, 0.0273, 0.0293],\n",
      "        [0.0533, 0.0340, 0.0292],\n",
      "        [0.0403, 0.0331, 0.0264],\n",
      "        [0.0463, 0.0486, 0.0282],\n",
      "        [0.0454, 0.0358, 0.0281],\n",
      "        [0.0459, 0.0507, 0.0310],\n",
      "        [0.0397, 0.0442, 0.0211],\n",
      "        [0.0340, 0.0454, 0.0383],\n",
      "        [0.0343, 0.0363, 0.0523],\n",
      "        [0.0300, 0.0348, 0.0535],\n",
      "        [0.0334, 0.0308, 0.0357],\n",
      "        [0.0352, 0.0311, 0.0494],\n",
      "        [0.0361, 0.0302, 0.0474],\n",
      "        [0.0335, 0.0273, 0.0414],\n",
      "        [0.0453, 0.0316, 0.0350],\n",
      "        [0.0410, 0.0378, 0.0463],\n",
      "        [0.0391, 0.0416, 0.0353],\n",
      "        [0.0345, 0.0442, 0.0500],\n",
      "        [0.0319, 0.0343, 0.0479],\n",
      "        [0.0276, 0.0374, 0.0529],\n",
      "        [0.0311, 0.0375, 0.0486],\n",
      "        [0.0334, 0.0389, 0.0472],\n",
      "        [0.0345, 0.0390, 0.0252],\n",
      "        [0.0415, 0.0541, 0.0351],\n",
      "        [0.0385, 0.0395, 0.0277],\n",
      "        [0.0515, 0.0545, 0.0373]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.1240, -0.1149, -0.1133],\n",
      "        [ 0.0562,  0.3677,  0.1149],\n",
      "        [ 0.0499,  0.0457,  0.0091],\n",
      "        [ 0.2041,  0.2496, -0.3015],\n",
      "        [-0.0047,  0.2159,  0.0613],\n",
      "        [ 0.0616,  0.0475,  0.2122],\n",
      "        [ 0.1372, -0.0485,  0.0239],\n",
      "        [ 0.2166, -0.2747,  0.0469],\n",
      "        [ 0.0015, -0.0926,  0.3645],\n",
      "        [-0.0497, -0.4263,  0.4333],\n",
      "        [-0.2059, -0.3206,  0.6079],\n",
      "        [-0.1881, -0.1891,  0.4905],\n",
      "        [-0.2389, -0.3750,  0.3958],\n",
      "        [-0.1395, -0.2151,  0.1245],\n",
      "        [-0.2465, -0.3696,  0.2961],\n",
      "        [-0.0714,  0.2576,  0.2815],\n",
      "        [-0.1730,  0.2554,  0.3879],\n",
      "        [ 0.0209,  0.3918,  0.4604],\n",
      "        [ 0.0115,  0.2179, -0.0499],\n",
      "        [-0.0737,  0.4863,  0.5757],\n",
      "        [-0.1692,  0.4011,  0.1904],\n",
      "        [-0.0585,  0.0112,  0.4001],\n",
      "        [-0.2759, -0.0914,  0.3376],\n",
      "        [-0.2015, -0.0452,  0.4226],\n",
      "        [-0.2686, -0.0058,  0.3540],\n",
      "        [-0.0710, -0.0487,  0.2073],\n",
      "        [-0.0609,  0.0097,  0.0720],\n",
      "        [-0.3105, -0.0287,  0.3438],\n",
      "        [-0.0983, -0.0758,  0.2288],\n",
      "        [-0.1198, -0.0684,  0.4084],\n",
      "        [-0.0446,  0.1121,  0.5000],\n",
      "        [ 0.0947,  0.0454,  0.4087],\n",
      "        [ 0.0797,  0.0870,  0.1907],\n",
      "        [-0.0338,  0.0206,  0.2878],\n",
      "        [-0.2303, -0.0281,  0.0686],\n",
      "        [-0.2800, -0.0134,  0.2854],\n",
      "        [-0.2095, -0.0215,  0.2292],\n",
      "        [-0.1400,  0.2734,  0.3430],\n",
      "        [-0.1796, -0.1367,  0.3335],\n",
      "        [-0.0507,  0.2017,  0.2964],\n",
      "        [ 0.0033, -0.2939,  0.2991],\n",
      "        [-0.0392, -0.0624,  0.4070],\n",
      "        [ 0.0417,  0.0332,  0.2054],\n",
      "        [ 0.0481,  0.0950,  0.2333],\n",
      "        [ 0.1562, -0.1125,  0.2166],\n",
      "        [ 0.2408,  0.0705, -0.0773],\n",
      "        [ 0.1125, -0.1517,  0.0493],\n",
      "        [ 0.1247,  0.0797,  0.0631]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0246, 0.0181, 0.0143],\n",
      "        [0.0230, 0.0292, 0.0180],\n",
      "        [0.0228, 0.0212, 0.0162],\n",
      "        [0.0266, 0.0260, 0.0119],\n",
      "        [0.0216, 0.0251, 0.0171],\n",
      "        [0.0231, 0.0212, 0.0198],\n",
      "        [0.0249, 0.0193, 0.0164],\n",
      "        [0.0269, 0.0154, 0.0168],\n",
      "        [0.0217, 0.0184, 0.0231],\n",
      "        [0.0207, 0.0132, 0.0247],\n",
      "        [0.0177, 0.0147, 0.0295],\n",
      "        [0.0180, 0.0167, 0.0262],\n",
      "        [0.0171, 0.0139, 0.0238],\n",
      "        [0.0189, 0.0163, 0.0182],\n",
      "        [0.0170, 0.0140, 0.0216],\n",
      "        [0.0202, 0.0262, 0.0213],\n",
      "        [0.0182, 0.0261, 0.0237],\n",
      "        [0.0222, 0.0299, 0.0254],\n",
      "        [0.0219, 0.0252, 0.0153],\n",
      "        [0.0202, 0.0329, 0.0285],\n",
      "        [0.0183, 0.0302, 0.0194],\n",
      "        [0.0205, 0.0205, 0.0239],\n",
      "        [0.0165, 0.0185, 0.0225],\n",
      "        [0.0177, 0.0193, 0.0245],\n",
      "        [0.0166, 0.0201, 0.0229],\n",
      "        [0.0202, 0.0193, 0.0197],\n",
      "        [0.0204, 0.0204, 0.0172],\n",
      "        [0.0159, 0.0197, 0.0226],\n",
      "        [0.0197, 0.0188, 0.0202],\n",
      "        [0.0193, 0.0189, 0.0241],\n",
      "        [0.0208, 0.0226, 0.0265],\n",
      "        [0.0238, 0.0212, 0.0241],\n",
      "        [0.0235, 0.0221, 0.0194],\n",
      "        [0.0210, 0.0207, 0.0214],\n",
      "        [0.0172, 0.0197, 0.0172],\n",
      "        [0.0164, 0.0200, 0.0213],\n",
      "        [0.0176, 0.0198, 0.0202],\n",
      "        [0.0189, 0.0266, 0.0226],\n",
      "        [0.0181, 0.0176, 0.0224],\n",
      "        [0.0206, 0.0248, 0.0216],\n",
      "        [0.0218, 0.0151, 0.0216],\n",
      "        [0.0209, 0.0190, 0.0241],\n",
      "        [0.0226, 0.0209, 0.0197],\n",
      "        [0.0228, 0.0223, 0.0203],\n",
      "        [0.0254, 0.0181, 0.0199],\n",
      "        [0.0276, 0.0217, 0.0148],\n",
      "        [0.0243, 0.0174, 0.0169],\n",
      "        [0.0246, 0.0219, 0.0171]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1046,  0.0564, -0.0984],\n",
      "        [-0.0029, -0.0016, -0.1919],\n",
      "        [-0.1014, -0.0914,  0.0544],\n",
      "        [-0.0593, -0.0242, -0.0213],\n",
      "        [ 0.1816,  0.0870, -0.1109],\n",
      "        [ 0.2091,  0.4365, -0.2502],\n",
      "        [ 0.2703,  0.1197, -0.0671],\n",
      "        [ 0.3689,  0.3391, -0.0383],\n",
      "        [ 0.2874,  0.2102,  0.0638],\n",
      "        [ 0.2908,  0.4282, -0.0098],\n",
      "        [ 0.1259,  0.1047,  0.1609],\n",
      "        [-0.1647,  0.2385,  0.2888],\n",
      "        [-0.1459, -0.0877,  0.1014],\n",
      "        [-0.0031, -0.0279,  0.3640],\n",
      "        [-0.2266, -0.1130,  0.1904],\n",
      "        [ 0.0172,  0.2096,  0.4944],\n",
      "        [-0.0848, -0.0525,  0.2181],\n",
      "        [ 0.2030,  0.1902,  0.3804],\n",
      "        [-0.0972, -0.0455,  0.3826],\n",
      "        [ 0.4043,  0.3743,  0.4788],\n",
      "        [-0.0041, -0.1232,  0.1666],\n",
      "        [ 0.1248, -0.0744,  0.3752],\n",
      "        [ 0.1006, -0.0150, -0.0875],\n",
      "        [ 0.4399,  0.1416,  0.0900],\n",
      "        [ 0.2413,  0.3203, -0.0414],\n",
      "        [ 0.4597,  0.2671,  0.0857],\n",
      "        [ 0.3118, -0.0356, -0.0564],\n",
      "        [ 0.2793,  0.1248, -0.0797],\n",
      "        [-0.0864,  0.0275, -0.2703],\n",
      "        [-0.0488, -0.1709, -0.1409],\n",
      "        [ 0.0925,  0.3594,  0.0210],\n",
      "        [ 0.1329,  0.0953,  0.1775],\n",
      "        [ 0.2260,  0.1621,  0.0502],\n",
      "        [-0.0018,  0.0545,  0.1809],\n",
      "        [ 0.2534,  0.0436,  0.1656],\n",
      "        [-0.0313, -0.0257,  0.1726],\n",
      "        [ 0.2886, -0.2061,  0.2639],\n",
      "        [ 0.2030, -0.1129,  0.4392],\n",
      "        [ 0.3459, -0.1714,  0.1648],\n",
      "        [ 0.1331, -0.0547,  0.2983],\n",
      "        [ 0.1469, -0.0284, -0.1398],\n",
      "        [-0.2473,  0.0099,  0.3955],\n",
      "        [ 0.1134,  0.0872,  0.2844],\n",
      "        [ 0.2372,  0.2749,  0.3416],\n",
      "        [ 0.0518,  0.1455,  0.4255],\n",
      "        [-0.0449,  0.0653,  0.2712],\n",
      "        [-0.0402, -0.0228,  0.3572],\n",
      "        [ 0.0909,  0.3345,  0.3687],\n",
      "        [-0.0934,  0.3965,  0.2815],\n",
      "        [ 0.0886,  0.2791,  0.2898],\n",
      "        [-0.0098, -0.0398,  0.0627],\n",
      "        [-0.1790,  0.0833,  0.2397],\n",
      "        [-0.0424,  0.0389,  0.1233],\n",
      "        [-0.0738, -0.0338,  0.5610],\n",
      "        [-0.0580, -0.0226,  0.5547],\n",
      "        [-0.0627, -0.1060,  0.3020],\n",
      "        [-0.0983, -0.1490,  0.2915],\n",
      "        [ 0.0426, -0.0157,  0.4958],\n",
      "        [-0.0583,  0.0360,  0.4131],\n",
      "        [-0.0119,  0.0320,  0.4419],\n",
      "        [-0.0645, -0.0021,  0.3523],\n",
      "        [-0.0368,  0.0773,  0.3296],\n",
      "        [ 0.1337,  0.1278,  0.1412],\n",
      "        [ 0.1812, -0.1494,  0.1858],\n",
      "        [ 0.1710, -0.0252,  0.6934],\n",
      "        [ 0.1377, -0.1252,  0.3105],\n",
      "        [ 0.2041, -0.2007,  0.2358],\n",
      "        [-0.0165,  0.1627,  0.2700],\n",
      "        [-0.0301,  0.0746,  0.2378],\n",
      "        [ 0.0550,  0.1152,  0.1077],\n",
      "        [ 0.2170,  0.1006,  0.1375],\n",
      "        [ 0.2010,  0.1519,  0.2334],\n",
      "        [-0.0332,  0.1447,  0.1974],\n",
      "        [-0.1748,  0.0770,  0.0282],\n",
      "        [-0.1285,  0.0778, -0.2749],\n",
      "        [-0.2008, -0.0673,  0.2136],\n",
      "        [-0.1931, -0.1289, -0.1573],\n",
      "        [-0.2063, -0.2336,  0.1566],\n",
      "        [-0.0082,  0.0938,  0.3850],\n",
      "        [-0.2357,  0.0690,  0.5039],\n",
      "        [ 0.0101,  0.0560,  0.5840],\n",
      "        [-0.0361, -0.0242,  0.3162],\n",
      "        [-0.0754, -0.0073,  0.5322],\n",
      "        [-0.0268,  0.1254,  0.2739],\n",
      "        [-0.2183,  0.0744,  0.7227],\n",
      "        [-0.3665,  0.0325,  0.6880],\n",
      "        [-0.2935,  0.2581,  0.5122],\n",
      "        [-0.1586,  0.0502,  0.3813],\n",
      "        [ 0.0909,  0.3120,  0.1738],\n",
      "        [-0.0562,  0.1774,  0.2346],\n",
      "        [-0.0285,  0.0649,  0.2136],\n",
      "        [-0.0790, -0.3018,  0.5239],\n",
      "        [-0.2866, -0.2766,  0.3311],\n",
      "        [-0.3237, -0.4443,  0.2705],\n",
      "        [-0.1608, -0.1882,  0.3105],\n",
      "        [-0.1184,  0.0534,  0.2896],\n",
      "        [-0.0147,  0.0641,  0.1604],\n",
      "        [-0.2673,  0.1054,  0.3735],\n",
      "        [-0.3403,  0.0440,  0.3826],\n",
      "        [-0.3237,  0.0763,  0.3064],\n",
      "        [ 0.0977, -0.1345,  0.2427],\n",
      "        [-0.0129,  0.0786,  0.1211],\n",
      "        [ 0.0305, -0.0521,  0.0356],\n",
      "        [ 0.2189,  0.1714,  0.1427]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0084, 0.0096, 0.0068],\n",
      "        [0.0093, 0.0090, 0.0062],\n",
      "        [0.0084, 0.0083, 0.0079],\n",
      "        [0.0088, 0.0088, 0.0074],\n",
      "        [0.0111, 0.0099, 0.0067],\n",
      "        [0.0115, 0.0140, 0.0059],\n",
      "        [0.0122, 0.0102, 0.0070],\n",
      "        [0.0134, 0.0127, 0.0072],\n",
      "        [0.0124, 0.0112, 0.0080],\n",
      "        [0.0124, 0.0139, 0.0075],\n",
      "        [0.0105, 0.0100, 0.0088],\n",
      "        [0.0079, 0.0115, 0.0100],\n",
      "        [0.0080, 0.0083, 0.0083],\n",
      "        [0.0093, 0.0088, 0.0108],\n",
      "        [0.0074, 0.0081, 0.0091],\n",
      "        [0.0095, 0.0112, 0.0123],\n",
      "        [0.0085, 0.0086, 0.0094],\n",
      "        [0.0114, 0.0109, 0.0110],\n",
      "        [0.0084, 0.0086, 0.0110],\n",
      "        [0.0139, 0.0132, 0.0122],\n",
      "        [0.0093, 0.0080, 0.0089],\n",
      "        [0.0105, 0.0084, 0.0110],\n",
      "        [0.0103, 0.0089, 0.0069],\n",
      "        [0.0144, 0.0104, 0.0082],\n",
      "        [0.0118, 0.0125, 0.0072],\n",
      "        [0.0147, 0.0118, 0.0082],\n",
      "        [0.0127, 0.0087, 0.0071],\n",
      "        [0.0123, 0.0103, 0.0070],\n",
      "        [0.0085, 0.0093, 0.0057],\n",
      "        [0.0089, 0.0076, 0.0065],\n",
      "        [0.0102, 0.0130, 0.0077],\n",
      "        [0.0106, 0.0100, 0.0090],\n",
      "        [0.0117, 0.0106, 0.0079],\n",
      "        [0.0093, 0.0096, 0.0090],\n",
      "        [0.0120, 0.0095, 0.0089],\n",
      "        [0.0090, 0.0088, 0.0089],\n",
      "        [0.0124, 0.0074, 0.0098],\n",
      "        [0.0114, 0.0081, 0.0117],\n",
      "        [0.0131, 0.0076, 0.0089],\n",
      "        [0.0106, 0.0086, 0.0101],\n",
      "        [0.0108, 0.0088, 0.0065],\n",
      "        [0.0073, 0.0091, 0.0112],\n",
      "        [0.0104, 0.0099, 0.0100],\n",
      "        [0.0118, 0.0119, 0.0106],\n",
      "        [0.0098, 0.0105, 0.0115],\n",
      "        [0.0089, 0.0097, 0.0099],\n",
      "        [0.0089, 0.0088, 0.0108],\n",
      "        [0.0102, 0.0126, 0.0109],\n",
      "        [0.0085, 0.0135, 0.0100],\n",
      "        [0.0102, 0.0120, 0.0101],\n",
      "        [0.0092, 0.0087, 0.0080],\n",
      "        [0.0078, 0.0098, 0.0096],\n",
      "        [0.0089, 0.0094, 0.0085],\n",
      "        [0.0086, 0.0088, 0.0132],\n",
      "        [0.0088, 0.0088, 0.0131],\n",
      "        [0.0087, 0.0081, 0.0102],\n",
      "        [0.0084, 0.0078, 0.0101],\n",
      "        [0.0097, 0.0089, 0.0124],\n",
      "        [0.0088, 0.0094, 0.0114],\n",
      "        [0.0092, 0.0093, 0.0117],\n",
      "        [0.0087, 0.0090, 0.0107],\n",
      "        [0.0089, 0.0098, 0.0105],\n",
      "        [0.0106, 0.0103, 0.0087],\n",
      "        [0.0111, 0.0078, 0.0091],\n",
      "        [0.0110, 0.0088, 0.0151],\n",
      "        [0.0107, 0.0080, 0.0103],\n",
      "        [0.0114, 0.0074, 0.0095],\n",
      "        [0.0091, 0.0106, 0.0099],\n",
      "        [0.0090, 0.0098, 0.0096],\n",
      "        [0.0098, 0.0102, 0.0084],\n",
      "        [0.0115, 0.0100, 0.0086],\n",
      "        [0.0114, 0.0105, 0.0095],\n",
      "        [0.0090, 0.0105, 0.0092],\n",
      "        [0.0078, 0.0098, 0.0077],\n",
      "        [0.0082, 0.0098, 0.0057],\n",
      "        [0.0076, 0.0085, 0.0093],\n",
      "        [0.0077, 0.0080, 0.0064],\n",
      "        [0.0076, 0.0072, 0.0088],\n",
      "        [0.0092, 0.0099, 0.0111],\n",
      "        [0.0073, 0.0097, 0.0125],\n",
      "        [0.0094, 0.0096, 0.0135],\n",
      "        [0.0090, 0.0088, 0.0103],\n",
      "        [0.0086, 0.0090, 0.0128],\n",
      "        [0.0090, 0.0103, 0.0099],\n",
      "        [0.0075, 0.0098, 0.0155],\n",
      "        [0.0064, 0.0093, 0.0150],\n",
      "        [0.0069, 0.0117, 0.0126],\n",
      "        [0.0079, 0.0095, 0.0110],\n",
      "        [0.0102, 0.0124, 0.0090],\n",
      "        [0.0088, 0.0108, 0.0095],\n",
      "        [0.0090, 0.0097, 0.0093],\n",
      "        [0.0086, 0.0067, 0.0127],\n",
      "        [0.0070, 0.0069, 0.0105],\n",
      "        [0.0067, 0.0058, 0.0099],\n",
      "        [0.0079, 0.0075, 0.0103],\n",
      "        [0.0083, 0.0095, 0.0101],\n",
      "        [0.0092, 0.0096, 0.0088],\n",
      "        [0.0071, 0.0101, 0.0109],\n",
      "        [0.0066, 0.0095, 0.0110],\n",
      "        [0.0067, 0.0098, 0.0102],\n",
      "        [0.0102, 0.0079, 0.0096],\n",
      "        [0.0092, 0.0098, 0.0085],\n",
      "        [0.0096, 0.0086, 0.0078],\n",
      "        [0.0116, 0.0107, 0.0087]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0914, -0.0436,  0.1431],\n",
      "        [ 0.1088,  0.0264,  0.0013],\n",
      "        [-0.0441, -0.3164,  0.2118],\n",
      "        [ 0.1536, -0.1116, -0.0410],\n",
      "        [ 0.2500, -0.3938,  0.0133],\n",
      "        [ 0.0772,  0.0508,  0.3044],\n",
      "        [ 0.1642, -0.1973,  0.4243],\n",
      "        [ 0.0830,  0.1384,  0.2917],\n",
      "        [ 0.0656, -0.2115, -0.0167],\n",
      "        [ 0.2449, -0.0605, -0.0282],\n",
      "        [ 0.1791, -0.0583, -0.0143],\n",
      "        [-0.0682,  0.3135,  0.0267],\n",
      "        [-0.0175,  0.0809,  0.1520],\n",
      "        [-0.0560,  0.2118,  0.0328],\n",
      "        [-0.0156,  0.0580, -0.1069],\n",
      "        [ 0.1049,  0.2090,  0.2083],\n",
      "        [ 0.1748,  0.0945,  0.0057],\n",
      "        [-0.2225,  0.3281,  0.1691],\n",
      "        [ 0.1404,  0.1126,  0.0432],\n",
      "        [-0.1898,  0.2776,  0.0968],\n",
      "        [ 0.0854,  0.1240,  0.0144],\n",
      "        [ 0.0255,  0.1646,  0.3232],\n",
      "        [ 0.1536,  0.0441,  0.2751],\n",
      "        [ 0.0396,  0.0601,  0.0630],\n",
      "        [-0.1952, -0.5562,  0.2766],\n",
      "        [-0.0368,  0.0913,  0.4226],\n",
      "        [ 0.0292,  0.0335,  0.5503],\n",
      "        [-0.1703,  0.1331,  0.4832],\n",
      "        [-0.2281, -0.3108,  0.6797],\n",
      "        [-0.0396, -0.1259,  0.6426],\n",
      "        [-0.1434,  0.0063,  0.5308],\n",
      "        [ 0.0228, -0.0165,  0.6650],\n",
      "        [-0.0934, -0.3225,  0.2861],\n",
      "        [-0.0640, -0.2974,  0.5645],\n",
      "        [-0.3020, -0.1779,  0.4595],\n",
      "        [-0.2068, -0.2072,  0.4988],\n",
      "        [ 0.0183, -0.1923,  0.4390],\n",
      "        [ 0.0076,  0.0405,  0.5972],\n",
      "        [ 0.0525, -0.0523,  0.5913],\n",
      "        [ 0.0170,  0.0008,  0.3154],\n",
      "        [ 0.0504,  0.1172,  0.4419],\n",
      "        [ 0.2393,  0.0746,  0.5181],\n",
      "        [ 0.0667,  0.0518,  0.4224],\n",
      "        [-0.1130, -0.1305,  0.2932],\n",
      "        [ 0.0137,  0.0581,  0.3171],\n",
      "        [ 0.0942,  0.2151,  0.3657],\n",
      "        [ 0.0217,  0.1732,  0.2742],\n",
      "        [ 0.1095,  0.2377,  0.2279],\n",
      "        [-0.1255, -0.0922,  0.2527],\n",
      "        [-0.1606,  0.0941,  0.3721],\n",
      "        [ 0.0941, -0.0800,  0.2394],\n",
      "        [ 0.3906,  0.2515,  0.2883],\n",
      "        [ 0.1428,  0.0931,  0.0623],\n",
      "        [ 0.2198,  0.1678,  0.2942]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0196, 0.0174, 0.0159],\n",
      "        [0.0200, 0.0186, 0.0137],\n",
      "        [0.0172, 0.0132, 0.0170],\n",
      "        [0.0209, 0.0162, 0.0132],\n",
      "        [0.0230, 0.0122, 0.0139],\n",
      "        [0.0194, 0.0191, 0.0186],\n",
      "        [0.0211, 0.0149, 0.0210],\n",
      "        [0.0195, 0.0208, 0.0184],\n",
      "        [0.0191, 0.0147, 0.0135],\n",
      "        [0.0229, 0.0171, 0.0134],\n",
      "        [0.0214, 0.0171, 0.0135],\n",
      "        [0.0167, 0.0248, 0.0141],\n",
      "        [0.0176, 0.0197, 0.0160],\n",
      "        [0.0169, 0.0224, 0.0142],\n",
      "        [0.0176, 0.0192, 0.0123],\n",
      "        [0.0199, 0.0224, 0.0169],\n",
      "        [0.0213, 0.0199, 0.0138],\n",
      "        [0.0143, 0.0252, 0.0163],\n",
      "        [0.0206, 0.0203, 0.0143],\n",
      "        [0.0148, 0.0240, 0.0151],\n",
      "        [0.0195, 0.0206, 0.0139],\n",
      "        [0.0184, 0.0214, 0.0190],\n",
      "        [0.0209, 0.0190, 0.0181],\n",
      "        [0.0186, 0.0193, 0.0146],\n",
      "        [0.0147, 0.0104, 0.0181],\n",
      "        [0.0173, 0.0199, 0.0210],\n",
      "        [0.0184, 0.0188, 0.0238],\n",
      "        [0.0151, 0.0207, 0.0223],\n",
      "        [0.0143, 0.0133, 0.0271],\n",
      "        [0.0172, 0.0160, 0.0261],\n",
      "        [0.0155, 0.0183, 0.0234],\n",
      "        [0.0183, 0.0179, 0.0267],\n",
      "        [0.0163, 0.0131, 0.0183],\n",
      "        [0.0168, 0.0135, 0.0242],\n",
      "        [0.0133, 0.0152, 0.0217],\n",
      "        [0.0146, 0.0148, 0.0226],\n",
      "        [0.0182, 0.0150, 0.0213],\n",
      "        [0.0181, 0.0189, 0.0249],\n",
      "        [0.0189, 0.0172, 0.0248],\n",
      "        [0.0182, 0.0182, 0.0188],\n",
      "        [0.0188, 0.0204, 0.0214],\n",
      "        [0.0228, 0.0195, 0.0231],\n",
      "        [0.0191, 0.0191, 0.0210],\n",
      "        [0.0160, 0.0159, 0.0184],\n",
      "        [0.0182, 0.0192, 0.0189],\n",
      "        [0.0197, 0.0225, 0.0198],\n",
      "        [0.0183, 0.0216, 0.0181],\n",
      "        [0.0200, 0.0230, 0.0173],\n",
      "        [0.0158, 0.0166, 0.0177],\n",
      "        [0.0153, 0.0199, 0.0199],\n",
      "        [0.0197, 0.0168, 0.0175],\n",
      "        [0.0265, 0.0233, 0.0183],\n",
      "        [0.0207, 0.0199, 0.0146],\n",
      "        [0.0223, 0.0215, 0.0184]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.1050, -0.2986, -0.0457],\n",
      "        [ 0.3328,  0.4619, -0.1923],\n",
      "        [ 0.2020,  0.0056, -0.1331],\n",
      "        [ 0.2262,  0.1519, -0.0233],\n",
      "        [ 0.1520,  0.0417, -0.0149],\n",
      "        [-0.1035, -0.0153,  0.1804],\n",
      "        [-0.2145, -0.0775,  0.3193],\n",
      "        [ 0.0248, -0.0567, -0.1572],\n",
      "        [ 0.0099, -0.2207,  0.3594],\n",
      "        [-0.1678, -0.4402,  0.3442],\n",
      "        [ 0.0878, -0.1738,  0.2408],\n",
      "        [-0.0321, -0.0552,  0.2458],\n",
      "        [-0.1333, -0.1007,  0.4062],\n",
      "        [-0.1621, -0.1968,  0.4863],\n",
      "        [ 0.3271, -0.1388,  0.2664],\n",
      "        [ 0.3191,  0.1633,  0.5903],\n",
      "        [ 0.1726, -0.1410,  0.1011],\n",
      "        [ 0.2327, -0.0475,  0.4619],\n",
      "        [ 0.1968,  0.0434,  0.5400],\n",
      "        [ 0.2798,  0.0354,  0.4268],\n",
      "        [ 0.2181,  0.0151,  0.2883],\n",
      "        [ 0.2563,  0.0900,  0.3704],\n",
      "        [ 0.1153, -0.0139,  0.4622],\n",
      "        [ 0.0074,  0.0803,  0.3540],\n",
      "        [ 0.0190, -0.0382,  0.2339],\n",
      "        [-0.2288,  0.3806,  0.4155],\n",
      "        [-0.4446,  0.0987,  0.6128],\n",
      "        [-0.2949, -0.0710,  0.4958],\n",
      "        [-0.3840, -0.1754,  0.5391],\n",
      "        [-0.2081, -0.0117,  0.5332],\n",
      "        [-0.0265, -0.1455,  0.6260],\n",
      "        [-0.1617,  0.1194,  0.8184],\n",
      "        [-0.0356,  0.0532,  0.4673],\n",
      "        [-0.0368, -0.1085,  0.4656],\n",
      "        [ 0.0939, -0.1248,  0.4639],\n",
      "        [ 0.0218, -0.2573,  0.5469],\n",
      "        [ 0.2686, -0.0168,  0.1355],\n",
      "        [-0.2174, -0.2087,  0.3125],\n",
      "        [ 0.0171, -0.1440,  0.0607],\n",
      "        [-0.1031, -0.1949,  0.1208],\n",
      "        [-0.0082,  0.2189,  0.0758],\n",
      "        [-0.0706,  0.0099,  0.3235],\n",
      "        [ 0.0662, -0.1290,  0.2922],\n",
      "        [ 0.1169, -0.0266,  0.4302],\n",
      "        [-0.1719,  0.1054,  0.4810],\n",
      "        [-0.1080,  0.0149,  0.5229],\n",
      "        [-0.0559, -0.0894,  0.4441],\n",
      "        [ 0.0273,  0.2227,  0.4761],\n",
      "        [-0.0591, -0.2686,  0.6084],\n",
      "        [-0.0241,  0.2167,  0.5649],\n",
      "        [ 0.0299, -0.0492,  0.2927],\n",
      "        [ 0.0932,  0.1289,  0.2676]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0208, 0.0145, 0.0128],\n",
      "        [0.0261, 0.0309, 0.0111],\n",
      "        [0.0229, 0.0196, 0.0117],\n",
      "        [0.0235, 0.0227, 0.0131],\n",
      "        [0.0218, 0.0203, 0.0132],\n",
      "        [0.0169, 0.0192, 0.0161],\n",
      "        [0.0151, 0.0180, 0.0185],\n",
      "        [0.0192, 0.0184, 0.0115],\n",
      "        [0.0189, 0.0156, 0.0192],\n",
      "        [0.0158, 0.0125, 0.0189],\n",
      "        [0.0204, 0.0164, 0.0171],\n",
      "        [0.0181, 0.0184, 0.0172],\n",
      "        [0.0164, 0.0176, 0.0201],\n",
      "        [0.0159, 0.0160, 0.0218],\n",
      "        [0.0260, 0.0170, 0.0175],\n",
      "        [0.0258, 0.0229, 0.0242],\n",
      "        [0.0222, 0.0169, 0.0148],\n",
      "        [0.0236, 0.0186, 0.0213],\n",
      "        [0.0228, 0.0203, 0.0230],\n",
      "        [0.0248, 0.0202, 0.0206],\n",
      "        [0.0233, 0.0198, 0.0179],\n",
      "        [0.0242, 0.0213, 0.0194],\n",
      "        [0.0210, 0.0192, 0.0213],\n",
      "        [0.0189, 0.0211, 0.0191],\n",
      "        [0.0191, 0.0187, 0.0170],\n",
      "        [0.0149, 0.0285, 0.0203],\n",
      "        [0.0120, 0.0215, 0.0248],\n",
      "        [0.0139, 0.0181, 0.0220],\n",
      "        [0.0127, 0.0163, 0.0230],\n",
      "        [0.0152, 0.0192, 0.0229],\n",
      "        [0.0182, 0.0168, 0.0251],\n",
      "        [0.0159, 0.0219, 0.0304],\n",
      "        [0.0181, 0.0205, 0.0214],\n",
      "        [0.0180, 0.0175, 0.0214],\n",
      "        [0.0206, 0.0172, 0.0213],\n",
      "        [0.0191, 0.0151, 0.0232],\n",
      "        [0.0245, 0.0191, 0.0154],\n",
      "        [0.0151, 0.0158, 0.0183],\n",
      "        [0.0190, 0.0169, 0.0143],\n",
      "        [0.0169, 0.0160, 0.0151],\n",
      "        [0.0186, 0.0242, 0.0145],\n",
      "        [0.0174, 0.0197, 0.0186],\n",
      "        [0.0200, 0.0171, 0.0180],\n",
      "        [0.0210, 0.0190, 0.0206],\n",
      "        [0.0158, 0.0216, 0.0217],\n",
      "        [0.0168, 0.0198, 0.0226],\n",
      "        [0.0177, 0.0178, 0.0209],\n",
      "        [0.0192, 0.0243, 0.0216],\n",
      "        [0.0176, 0.0149, 0.0247],\n",
      "        [0.0183, 0.0242, 0.0236],\n",
      "        [0.0193, 0.0185, 0.0180],\n",
      "        [0.0206, 0.0222, 0.0175]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.1805, -0.2554, -0.0311],\n",
      "        [ 0.4795, -0.0188, -0.0232],\n",
      "        [ 0.2322, -0.0509, -0.0970],\n",
      "        [-0.0823,  0.1399, -0.2766],\n",
      "        [-0.3860, -0.0654,  0.0154],\n",
      "        [-0.0214,  0.2656,  0.0799],\n",
      "        [-0.0654,  0.2651, -0.0338],\n",
      "        [-0.2008,  0.1896,  0.1687],\n",
      "        [-0.4543, -0.0115, -0.1764],\n",
      "        [-0.2710,  0.0526,  0.1600],\n",
      "        [-0.0646,  0.2250, -0.4832],\n",
      "        [-0.0752,  0.0687, -0.1110],\n",
      "        [ 0.0620,  0.0105, -0.2715],\n",
      "        [ 0.0837, -0.0271, -0.0875],\n",
      "        [ 0.1677,  0.2073, -0.4165],\n",
      "        [ 0.2124,  0.2803, -0.0670],\n",
      "        [ 0.1456,  0.3198, -0.2146],\n",
      "        [ 0.2062,  0.3501,  0.2217]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0643, 0.0381, 0.0580],\n",
      "        [0.0867, 0.0483, 0.0584],\n",
      "        [0.0677, 0.0468, 0.0543],\n",
      "        [0.0494, 0.0566, 0.0453],\n",
      "        [0.0365, 0.0461, 0.0608],\n",
      "        [0.0526, 0.0642, 0.0648],\n",
      "        [0.0503, 0.0642, 0.0578],\n",
      "        [0.0439, 0.0595, 0.0708],\n",
      "        [0.0341, 0.0487, 0.0501],\n",
      "        [0.0410, 0.0519, 0.0703],\n",
      "        [0.0504, 0.0616, 0.0369],\n",
      "        [0.0498, 0.0528, 0.0535],\n",
      "        [0.0571, 0.0497, 0.0456],\n",
      "        [0.0584, 0.0479, 0.0548],\n",
      "        [0.0635, 0.0606, 0.0395],\n",
      "        [0.0664, 0.0652, 0.0559],\n",
      "        [0.0621, 0.0678, 0.0483],\n",
      "        [0.0660, 0.0699, 0.0747]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0811, -0.1819,  0.0593],\n",
      "        [ 0.0630,  0.2859,  0.1009],\n",
      "        [-0.1576, -0.1100, -0.0757],\n",
      "        [-0.0045,  0.1118, -0.1281],\n",
      "        [ 0.0152, -0.2108,  0.0806],\n",
      "        [-0.1120,  0.0101,  0.2262],\n",
      "        [-0.0621, -0.0517,  0.3896],\n",
      "        [-0.1038,  0.0619,  0.3069],\n",
      "        [-0.1580, -0.2212,  0.1998],\n",
      "        [-0.0162,  0.1963,  0.2800],\n",
      "        [-0.3562,  0.1572,  0.4712],\n",
      "        [-0.2054,  0.3379,  0.2898],\n",
      "        [-0.1351, -0.0576,  0.3293],\n",
      "        [ 0.0557,  0.2225,  0.4902]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0717, 0.0564, 0.0601],\n",
      "        [0.0828, 0.0900, 0.0627],\n",
      "        [0.0664, 0.0606, 0.0525],\n",
      "        [0.0773, 0.0756, 0.0499],\n",
      "        [0.0789, 0.0547, 0.0614],\n",
      "        [0.0695, 0.0683, 0.0710],\n",
      "        [0.0730, 0.0641, 0.0836],\n",
      "        [0.0700, 0.0719, 0.0770],\n",
      "        [0.0663, 0.0542, 0.0692],\n",
      "        [0.0764, 0.0823, 0.0750],\n",
      "        [0.0544, 0.0790, 0.0907],\n",
      "        [0.0633, 0.0947, 0.0757],\n",
      "        [0.0679, 0.0638, 0.0787],\n",
      "        [0.0822, 0.0844, 0.0925]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0699, -0.1204, -0.0313],\n",
      "        [ 0.0387,  0.0935, -0.0339],\n",
      "        [-0.0282,  0.0854,  0.2097],\n",
      "        [-0.1138,  0.2109,  0.0264],\n",
      "        [-0.2494,  0.1296,  0.1132],\n",
      "        [ 0.1809,  0.3674, -0.2100],\n",
      "        [-0.1637,  0.2944,  0.2147],\n",
      "        [ 0.0618,  0.4084, -0.0597],\n",
      "        [-0.0058,  0.2900,  0.3423],\n",
      "        [ 0.1691,  0.0775,  0.1683],\n",
      "        [ 0.2373,  0.0410,  0.1426],\n",
      "        [ 0.4287,  0.1527, -0.0903],\n",
      "        [ 0.1251, -0.1851, -0.0273],\n",
      "        [ 0.2888,  0.1478,  0.1895],\n",
      "        [ 0.2438,  0.1061, -0.0525],\n",
      "        [ 0.0905,  0.1364, -0.0242],\n",
      "        [ 0.1715,  0.0153,  0.1820],\n",
      "        [ 0.1322,  0.4241, -0.1519],\n",
      "        [ 0.1724,  0.2917, -0.1002],\n",
      "        [ 0.0817,  0.3005, -0.0234],\n",
      "        [ 0.1542, -0.0525,  0.0582],\n",
      "        [ 0.2128,  0.2551,  0.1594],\n",
      "        [ 0.2007,  0.0803, -0.0890],\n",
      "        [ 0.3267,  0.2600,  0.0852]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0393, 0.0311, 0.0384],\n",
      "        [0.0381, 0.0386, 0.0383],\n",
      "        [0.0356, 0.0383, 0.0489],\n",
      "        [0.0327, 0.0434, 0.0406],\n",
      "        [0.0285, 0.0400, 0.0444],\n",
      "        [0.0439, 0.0507, 0.0321],\n",
      "        [0.0311, 0.0471, 0.0491],\n",
      "        [0.0390, 0.0529, 0.0373],\n",
      "        [0.0364, 0.0470, 0.0558],\n",
      "        [0.0434, 0.0380, 0.0469],\n",
      "        [0.0464, 0.0366, 0.0457],\n",
      "        [0.0562, 0.0409, 0.0362],\n",
      "        [0.0415, 0.0292, 0.0385],\n",
      "        [0.0489, 0.0407, 0.0479],\n",
      "        [0.0467, 0.0391, 0.0376],\n",
      "        [0.0401, 0.0403, 0.0387],\n",
      "        [0.0435, 0.0357, 0.0475],\n",
      "        [0.0418, 0.0537, 0.0340],\n",
      "        [0.0435, 0.0470, 0.0358],\n",
      "        [0.0397, 0.0475, 0.0387],\n",
      "        [0.0427, 0.0334, 0.0420],\n",
      "        [0.0453, 0.0453, 0.0464],\n",
      "        [0.0448, 0.0381, 0.0363],\n",
      "        [0.0508, 0.0456, 0.0431]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0017,  0.0237,  0.1501],\n",
      "        [-0.0629,  0.0643,  0.2258],\n",
      "        [-0.4148,  0.1406,  0.2303],\n",
      "        [-0.2081,  0.0165,  0.4683],\n",
      "        [-0.1753, -0.0820,  0.7437],\n",
      "        [-0.1015, -0.0533,  0.2480],\n",
      "        [ 0.0013,  0.0517,  0.2815],\n",
      "        [-0.0738,  0.2050,  0.1677],\n",
      "        [-0.0560,  0.2300,  0.0670],\n",
      "        [ 0.2212,  0.4392, -0.0908],\n",
      "        [ 0.1775,  0.0212,  0.0715],\n",
      "        [ 0.1715,  0.0498,  0.1447]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0856, 0.0771, 0.0756],\n",
      "        [0.0806, 0.0803, 0.0815],\n",
      "        [0.0566, 0.0866, 0.0819],\n",
      "        [0.0696, 0.0765, 0.1039],\n",
      "        [0.0720, 0.0693, 0.1368],\n",
      "        [0.0775, 0.0714, 0.0834],\n",
      "        [0.0859, 0.0792, 0.0862],\n",
      "        [0.0797, 0.0923, 0.0769],\n",
      "        [0.0811, 0.0947, 0.0695],\n",
      "        [0.1070, 0.1168, 0.0594],\n",
      "        [0.1024, 0.0768, 0.0699],\n",
      "        [0.1019, 0.0790, 0.0751]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1415, -0.2585, -0.0641],\n",
      "        [ 0.0627,  0.1166, -0.0528],\n",
      "        [-0.0196, -0.0197,  0.1547],\n",
      "        [-0.0722,  0.1373,  0.3062],\n",
      "        [-0.1993,  0.1566,  0.1956],\n",
      "        [ 0.1259,  0.2446,  0.3721],\n",
      "        [-0.2157, -0.3147,  0.2123],\n",
      "        [ 0.0204,  0.3191,  0.6758],\n",
      "        [ 0.0748, -0.1743,  0.2874],\n",
      "        [-0.1093, -0.1815,  0.4890],\n",
      "        [ 0.0358, -0.1050,  0.2908],\n",
      "        [-0.1624, -0.1576,  0.2798],\n",
      "        [-0.0073, -0.3120,  0.4871],\n",
      "        [-0.0089, -0.1937,  0.1941],\n",
      "        [ 0.1287, -0.0291,  0.1208],\n",
      "        [ 0.2312,  0.2830,  0.1625],\n",
      "        [ 0.2937,  0.1528,  0.0768],\n",
      "        [ 0.2361,  0.0797,  0.2372],\n",
      "        [-0.0159, -0.1043,  0.0778],\n",
      "        [-0.0542, -0.3140,  0.4619],\n",
      "        [ 0.0019, -0.1364,  0.1764],\n",
      "        [ 0.2299,  0.1101,  0.3301],\n",
      "        [ 0.0681, -0.2236,  0.2646],\n",
      "        [ 0.1738, -0.1284,  0.5376],\n",
      "        [ 0.0900, -0.1654,  0.0081],\n",
      "        [-0.1674, -0.0593,  0.4844],\n",
      "        [-0.0017, -0.3145,  0.1707],\n",
      "        [ 0.0889, -0.0462,  0.0672],\n",
      "        [-0.1407, -0.1598,  0.0568],\n",
      "        [-0.0337,  0.0430,  0.2419],\n",
      "        [ 0.0753, -0.1876,  0.1076],\n",
      "        [ 0.4727,  0.0209,  0.0181],\n",
      "        [ 0.1926, -0.1538,  0.0296],\n",
      "        [ 0.6523, -0.0117,  0.1776],\n",
      "        [ 0.4414, -0.0814,  0.1987],\n",
      "        [ 0.4387,  0.1147,  0.0191],\n",
      "        [ 0.2737,  0.0817,  0.0008],\n",
      "        [ 0.1921,  0.5684, -0.1072],\n",
      "        [ 0.2664,  0.0970,  0.4033],\n",
      "        [ 0.4465,  0.3235,  0.0649],\n",
      "        [ 0.1979, -0.0212,  0.0742],\n",
      "        [ 0.2710,  0.1064,  0.1746],\n",
      "        [ 0.2137,  0.0465,  0.0154],\n",
      "        [-0.0191,  0.3254,  0.0887],\n",
      "        [-0.0332,  0.4526,  0.4009],\n",
      "        [-0.1571,  0.4109,  0.2458],\n",
      "        [-0.3411,  0.6157,  0.2332],\n",
      "        [-0.2734,  0.4924,  0.3040],\n",
      "        [-0.0124, -0.0870,  0.3701],\n",
      "        [-0.2842,  0.2886,  0.1471],\n",
      "        [ 0.2168, -0.0460, -0.2852],\n",
      "        [ 0.1736, -0.1807, -0.0622],\n",
      "        [-0.1381,  0.0225, -0.0504],\n",
      "        [ 0.0249,  0.3120,  0.1096],\n",
      "        [ 0.1677,  0.3567, -0.0373],\n",
      "        [ 0.0356,  0.2312,  0.0442],\n",
      "        [ 0.1433,  0.0620,  0.0480],\n",
      "        [-0.1285,  0.2705,  0.2367],\n",
      "        [-0.0682,  0.3772, -0.0620],\n",
      "        [-0.0195,  0.2336,  0.2463],\n",
      "        [ 0.1006,  0.3281,  0.1191],\n",
      "        [ 0.0676,  0.2856,  0.1403],\n",
      "        [ 0.0510, -0.1074,  0.1530],\n",
      "        [ 0.0579, -0.0575,  0.2426],\n",
      "        [-0.0591,  0.0931,  0.1293],\n",
      "        [ 0.2097,  0.2250,  0.1429]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0121, 0.0107, 0.0118],\n",
      "        [0.0148, 0.0156, 0.0119],\n",
      "        [0.0136, 0.0136, 0.0147],\n",
      "        [0.0129, 0.0159, 0.0171],\n",
      "        [0.0114, 0.0162, 0.0153],\n",
      "        [0.0158, 0.0177, 0.0182],\n",
      "        [0.0112, 0.0101, 0.0155],\n",
      "        [0.0142, 0.0191, 0.0247],\n",
      "        [0.0150, 0.0117, 0.0167],\n",
      "        [0.0125, 0.0116, 0.0205],\n",
      "        [0.0144, 0.0125, 0.0168],\n",
      "        [0.0118, 0.0118, 0.0166],\n",
      "        [0.0138, 0.0102, 0.0204],\n",
      "        [0.0138, 0.0114, 0.0152],\n",
      "        [0.0158, 0.0135, 0.0142],\n",
      "        [0.0175, 0.0184, 0.0148],\n",
      "        [0.0187, 0.0162, 0.0136],\n",
      "        [0.0176, 0.0150, 0.0159],\n",
      "        [0.0137, 0.0125, 0.0136],\n",
      "        [0.0132, 0.0101, 0.0199],\n",
      "        [0.0139, 0.0121, 0.0150],\n",
      "        [0.0175, 0.0155, 0.0175],\n",
      "        [0.0149, 0.0111, 0.0164],\n",
      "        [0.0166, 0.0122, 0.0215],\n",
      "        [0.0152, 0.0118, 0.0127],\n",
      "        [0.0118, 0.0131, 0.0204],\n",
      "        [0.0139, 0.0101, 0.0149],\n",
      "        [0.0152, 0.0133, 0.0134],\n",
      "        [0.0121, 0.0118, 0.0133],\n",
      "        [0.0135, 0.0145, 0.0160],\n",
      "        [0.0150, 0.0115, 0.0140],\n",
      "        [0.0223, 0.0142, 0.0128],\n",
      "        [0.0169, 0.0119, 0.0129],\n",
      "        [0.0267, 0.0137, 0.0150],\n",
      "        [0.0217, 0.0128, 0.0153],\n",
      "        [0.0216, 0.0156, 0.0128],\n",
      "        [0.0183, 0.0151, 0.0126],\n",
      "        [0.0169, 0.0245, 0.0113],\n",
      "        [0.0182, 0.0153, 0.0188],\n",
      "        [0.0218, 0.0192, 0.0134],\n",
      "        [0.0170, 0.0136, 0.0135],\n",
      "        [0.0182, 0.0154, 0.0150],\n",
      "        [0.0172, 0.0145, 0.0127],\n",
      "        [0.0136, 0.0192, 0.0137],\n",
      "        [0.0135, 0.0218, 0.0188],\n",
      "        [0.0119, 0.0209, 0.0161],\n",
      "        [0.0099, 0.0257, 0.0159],\n",
      "        [0.0106, 0.0227, 0.0170],\n",
      "        [0.0138, 0.0127, 0.0182],\n",
      "        [0.0105, 0.0185, 0.0145],\n",
      "        [0.0173, 0.0133, 0.0094],\n",
      "        [0.0166, 0.0116, 0.0118],\n",
      "        [0.0121, 0.0142, 0.0119],\n",
      "        [0.0143, 0.0190, 0.0140],\n",
      "        [0.0164, 0.0198, 0.0121],\n",
      "        [0.0144, 0.0175, 0.0131],\n",
      "        [0.0161, 0.0148, 0.0132],\n",
      "        [0.0122, 0.0182, 0.0159],\n",
      "        [0.0130, 0.0202, 0.0118],\n",
      "        [0.0136, 0.0175, 0.0161],\n",
      "        [0.0154, 0.0193, 0.0142],\n",
      "        [0.0149, 0.0185, 0.0145],\n",
      "        [0.0146, 0.0125, 0.0146],\n",
      "        [0.0147, 0.0131, 0.0160],\n",
      "        [0.0131, 0.0152, 0.0143],\n",
      "        [0.0172, 0.0174, 0.0145]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 3.1665e-01,  4.7874e-03, -1.6516e-01],\n",
      "        [ 3.6816e-01,  2.7441e-01,  9.5062e-03],\n",
      "        [ 1.6125e-01,  2.0105e-01,  8.6609e-02],\n",
      "        [ 1.1877e-01,  2.6367e-01, -6.7383e-02],\n",
      "        [-7.4707e-02,  1.7297e-01,  1.3379e-01],\n",
      "        [ 7.6256e-03,  2.0276e-01,  2.1655e-01],\n",
      "        [ 8.9783e-02,  7.4280e-02,  1.7029e-01],\n",
      "        [ 1.9763e-01,  3.1055e-01,  2.5488e-01],\n",
      "        [ 3.1128e-01, -9.4238e-02,  6.1005e-02],\n",
      "        [-2.2900e-01,  1.5125e-01,  2.1643e-01],\n",
      "        [ 1.6614e-01, -8.1543e-02, -6.4392e-02],\n",
      "        [-4.2328e-02, -6.2988e-02,  4.1528e-01],\n",
      "        [-1.1316e-01, -6.7261e-02,  1.1243e-01],\n",
      "        [-4.9774e-02,  4.1534e-02,  2.7612e-01],\n",
      "        [ 5.7312e-02, -1.7688e-01,  2.9785e-01],\n",
      "        [ 1.1444e-01, -2.9648e-02,  5.7568e-01],\n",
      "        [ 5.8868e-02, -1.5906e-01,  3.6255e-01],\n",
      "        [-1.7725e-01,  7.8125e-02,  3.6548e-01],\n",
      "        [-9.9548e-02,  2.0251e-01,  3.8281e-01],\n",
      "        [-1.3525e-01,  2.3889e-01,  4.3793e-02],\n",
      "        [-2.8076e-01, -3.7964e-01,  3.3252e-01],\n",
      "        [-6.9885e-02, -2.5903e-01,  4.8169e-01],\n",
      "        [ 4.8065e-02,  7.0984e-02,  3.5278e-01],\n",
      "        [ 2.9495e-02, -1.5173e-01,  1.2573e-01],\n",
      "        [-7.6065e-03, -6.5552e-02,  2.5513e-01],\n",
      "        [ 1.3025e-01, -4.7638e-02,  1.3110e-01],\n",
      "        [ 6.9458e-02, -2.8662e-01,  3.8838e-04],\n",
      "        [-1.0413e-01,  1.2128e-01, -2.1881e-02],\n",
      "        [-1.0272e-01,  7.1594e-02,  3.2520e-01],\n",
      "        [-8.5632e-02,  7.8125e-03,  8.5083e-02],\n",
      "        [-1.5762e-02, -4.1431e-01,  9.2773e-02],\n",
      "        [ 3.3203e-01,  1.5213e-02,  1.7746e-02],\n",
      "        [ 2.4963e-01, -1.3770e-01,  4.2381e-03],\n",
      "        [-1.7932e-01, -2.3987e-01,  1.6687e-01],\n",
      "        [-1.6077e-01, -2.3718e-01,  5.6641e-01],\n",
      "        [-3.5767e-01, -2.2986e-01,  3.8574e-01],\n",
      "        [-2.7588e-01, -5.7764e-01,  3.7256e-01],\n",
      "        [-2.0898e-01, -2.9199e-01,  3.9355e-01],\n",
      "        [-2.0312e-01, -1.8640e-01,  3.6133e-01],\n",
      "        [-2.4609e-01, -9.8694e-02,  4.3408e-01],\n",
      "        [ 7.8796e-02, -3.5400e-01,  4.2480e-01],\n",
      "        [ 1.4673e-01, -2.1436e-01,  4.3286e-01],\n",
      "        [ 4.1553e-01, -1.3477e-01,  5.2307e-02],\n",
      "        [ 4.2529e-01,  5.1605e-02,  2.7173e-01]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0301, 0.0236, 0.0152],\n",
      "        [0.0317, 0.0310, 0.0181],\n",
      "        [0.0258, 0.0288, 0.0195],\n",
      "        [0.0247, 0.0306, 0.0168],\n",
      "        [0.0204, 0.0280, 0.0205],\n",
      "        [0.0221, 0.0288, 0.0223],\n",
      "        [0.0240, 0.0253, 0.0212],\n",
      "        [0.0267, 0.0321, 0.0231],\n",
      "        [0.0300, 0.0214, 0.0191],\n",
      "        [0.0175, 0.0274, 0.0223],\n",
      "        [0.0259, 0.0217, 0.0168],\n",
      "        [0.0210, 0.0221, 0.0271],\n",
      "        [0.0196, 0.0220, 0.0201],\n",
      "        [0.0209, 0.0245, 0.0236],\n",
      "        [0.0232, 0.0197, 0.0241],\n",
      "        [0.0246, 0.0228, 0.0319],\n",
      "        [0.0233, 0.0201, 0.0258],\n",
      "        [0.0184, 0.0255, 0.0258],\n",
      "        [0.0199, 0.0288, 0.0263],\n",
      "        [0.0192, 0.0299, 0.0187],\n",
      "        [0.0166, 0.0161, 0.0250],\n",
      "        [0.0205, 0.0182, 0.0290],\n",
      "        [0.0230, 0.0253, 0.0255],\n",
      "        [0.0226, 0.0202, 0.0203],\n",
      "        [0.0218, 0.0220, 0.0231],\n",
      "        [0.0250, 0.0224, 0.0204],\n",
      "        [0.0235, 0.0177, 0.0179],\n",
      "        [0.0198, 0.0266, 0.0175],\n",
      "        [0.0198, 0.0253, 0.0248],\n",
      "        [0.0202, 0.0237, 0.0195],\n",
      "        [0.0216, 0.0155, 0.0197],\n",
      "        [0.0306, 0.0239, 0.0182],\n",
      "        [0.0282, 0.0205, 0.0180],\n",
      "        [0.0183, 0.0185, 0.0212],\n",
      "        [0.0187, 0.0186, 0.0316],\n",
      "        [0.0154, 0.0187, 0.0264],\n",
      "        [0.0167, 0.0132, 0.0260],\n",
      "        [0.0178, 0.0176, 0.0266],\n",
      "        [0.0179, 0.0195, 0.0257],\n",
      "        [0.0172, 0.0213, 0.0277],\n",
      "        [0.0237, 0.0165, 0.0274],\n",
      "        [0.0254, 0.0190, 0.0276],\n",
      "        [0.0333, 0.0206, 0.0189],\n",
      "        [0.0336, 0.0248, 0.0235]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0450, -0.3708,  0.1053],\n",
      "        [ 0.2556,  0.1804,  0.1177],\n",
      "        [ 0.1548, -0.1942, -0.1880],\n",
      "        [ 0.3184, -0.0688, -0.4236],\n",
      "        [ 0.3071,  0.0325, -0.4663],\n",
      "        [ 0.0392,  0.2986,  0.1832],\n",
      "        [ 0.0838, -0.2491,  0.1068],\n",
      "        [ 0.3037,  0.1748, -0.1301],\n",
      "        [ 0.2834,  0.1752, -0.1339],\n",
      "        [ 0.2169,  0.4663,  0.1367],\n",
      "        [ 0.4695,  0.1884, -0.2302],\n",
      "        [ 0.3499,  0.2316, -0.3772],\n",
      "        [ 0.6035,  0.1469, -0.0710],\n",
      "        [ 0.1842,  0.0293,  0.1102],\n",
      "        [ 0.0735, -0.0780,  0.2489],\n",
      "        [ 0.1693,  0.3132,  0.2854],\n",
      "        [ 0.2264,  0.3330,  0.0236],\n",
      "        [ 0.1915,  0.3093, -0.0522],\n",
      "        [ 0.0897,  0.2896,  0.0768],\n",
      "        [ 0.1080,  0.3411, -0.1853],\n",
      "        [ 0.2213,  0.1595, -0.1512],\n",
      "        [ 0.3562,  0.4756, -0.1020],\n",
      "        [ 0.2043,  0.1316, -0.1025],\n",
      "        [ 0.2009,  0.2288,  0.1340],\n",
      "        [ 0.0429,  0.0485, -0.0729],\n",
      "        [ 0.2712,  0.2439,  0.6201],\n",
      "        [ 0.2676,  0.0636,  0.4116],\n",
      "        [ 0.3931, -0.0645,  0.6025],\n",
      "        [-0.0318, -0.0507,  0.7051],\n",
      "        [ 0.3188, -0.1190,  0.4163],\n",
      "        [ 0.0328, -0.1826,  0.5547],\n",
      "        [ 0.0441,  0.0880,  0.5664],\n",
      "        [-0.1136, -0.0735,  0.2573],\n",
      "        [-0.0959, -0.4597,  0.5562],\n",
      "        [ 0.0934,  0.1654,  0.1328],\n",
      "        [ 0.1436,  0.1595,  0.3706],\n",
      "        [-0.2057, -0.0528,  0.3635],\n",
      "        [ 0.0706,  0.2942,  0.1943],\n",
      "        [ 0.1381, -0.0977,  0.0840],\n",
      "        [ 0.2401,  0.1675, -0.0505]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0198, 0.0154, 0.0237],\n",
      "        [0.0268, 0.0267, 0.0240],\n",
      "        [0.0242, 0.0184, 0.0177],\n",
      "        [0.0285, 0.0208, 0.0140],\n",
      "        [0.0282, 0.0231, 0.0134],\n",
      "        [0.0216, 0.0301, 0.0256],\n",
      "        [0.0226, 0.0174, 0.0237],\n",
      "        [0.0281, 0.0266, 0.0187],\n",
      "        [0.0275, 0.0266, 0.0187],\n",
      "        [0.0257, 0.0356, 0.0245],\n",
      "        [0.0331, 0.0270, 0.0170],\n",
      "        [0.0294, 0.0282, 0.0146],\n",
      "        [0.0379, 0.0258, 0.0199],\n",
      "        [0.0249, 0.0230, 0.0238],\n",
      "        [0.0223, 0.0206, 0.0274],\n",
      "        [0.0246, 0.0305, 0.0284],\n",
      "        [0.0260, 0.0311, 0.0218],\n",
      "        [0.0251, 0.0304, 0.0202],\n",
      "        [0.0227, 0.0298, 0.0230],\n",
      "        [0.0231, 0.0314, 0.0177],\n",
      "        [0.0259, 0.0262, 0.0183],\n",
      "        [0.0296, 0.0359, 0.0193],\n",
      "        [0.0254, 0.0255, 0.0192],\n",
      "        [0.0253, 0.0281, 0.0244],\n",
      "        [0.0216, 0.0234, 0.0198],\n",
      "        [0.0272, 0.0285, 0.0396],\n",
      "        [0.0271, 0.0238, 0.0322],\n",
      "        [0.0307, 0.0209, 0.0390],\n",
      "        [0.0201, 0.0212, 0.0432],\n",
      "        [0.0285, 0.0198, 0.0323],\n",
      "        [0.0214, 0.0186, 0.0371],\n",
      "        [0.0217, 0.0244, 0.0376],\n",
      "        [0.0185, 0.0208, 0.0276],\n",
      "        [0.0188, 0.0141, 0.0372],\n",
      "        [0.0228, 0.0263, 0.0244],\n",
      "        [0.0239, 0.0262, 0.0309],\n",
      "        [0.0169, 0.0212, 0.0307],\n",
      "        [0.0222, 0.0300, 0.0259],\n",
      "        [0.0238, 0.0202, 0.0232],\n",
      "        [0.0264, 0.0264, 0.0203]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.1925, -0.2498,  0.1771],\n",
      "        [ 0.0387,  0.2751,  0.3086],\n",
      "        [ 0.0534, -0.1277,  0.1997],\n",
      "        [ 0.0565,  0.0021,  0.2612],\n",
      "        [ 0.0238, -0.0486,  0.3848],\n",
      "        [-0.0235,  0.0889,  0.4226],\n",
      "        [-0.1113, -0.3450,  0.3691],\n",
      "        [ 0.1736, -0.2266, -0.0272],\n",
      "        [ 0.0385, -0.1747,  0.1467],\n",
      "        [-0.1831, -0.2900,  0.5674],\n",
      "        [ 0.0399, -0.3066,  0.3098],\n",
      "        [-0.0176, -0.1770,  0.2520],\n",
      "        [ 0.0531, -0.2213,  0.4067],\n",
      "        [-0.1449, -0.0202,  0.3447],\n",
      "        [-0.1990,  0.0054,  0.3562],\n",
      "        [-0.1431, -0.1429,  0.2854],\n",
      "        [-0.0025, -0.1567,  0.3230],\n",
      "        [-0.1560, -0.0213,  0.4236],\n",
      "        [-0.2153, -0.2295,  0.2612],\n",
      "        [-0.0533, -0.1688,  0.2155],\n",
      "        [ 0.0844, -0.0838,  0.4324],\n",
      "        [-0.1937, -0.1974,  0.5571],\n",
      "        [ 0.2537, -0.0196,  0.4731],\n",
      "        [-0.0108, -0.3469,  0.4966],\n",
      "        [ 0.1604, -0.2108,  0.5225],\n",
      "        [-0.1172, -0.2029,  0.4753],\n",
      "        [-0.1111, -0.3191,  0.4202],\n",
      "        [ 0.1459, -0.2583,  0.3762],\n",
      "        [ 0.1440, -0.3328,  0.3472],\n",
      "        [ 0.3408,  0.1487,  0.3701],\n",
      "        [ 0.2216, -0.1863,  0.0331],\n",
      "        [ 0.2096, -0.1105,  0.1241],\n",
      "        [ 0.2101, -0.3206,  0.0536],\n",
      "        [-0.0543, -0.3376,  0.2428],\n",
      "        [ 0.1515, -0.2325, -0.2686],\n",
      "        [ 0.1327,  0.1832, -0.1782],\n",
      "        [-0.0213, -0.1775,  0.2321],\n",
      "        [-0.1418, -0.0182,  0.3835],\n",
      "        [ 0.0333, -0.0135, -0.0131],\n",
      "        [ 0.2367,  0.0270,  0.0986],\n",
      "        [ 0.1823,  0.0020,  0.1542],\n",
      "        [-0.0632, -0.3293,  0.4790],\n",
      "        [ 0.0687, -0.0478,  0.3726],\n",
      "        [-0.2241,  0.0583,  0.4666],\n",
      "        [-0.0869, -0.0469,  0.3115],\n",
      "        [ 0.1587, -0.1588,  0.2747],\n",
      "        [ 0.1464, -0.0159,  0.4373],\n",
      "        [ 0.3066,  0.1181,  0.2460],\n",
      "        [-0.1674, -0.1820,  0.2742],\n",
      "        [-0.1633, -0.2537,  0.2864],\n",
      "        [-0.0046, -0.2798,  0.2073],\n",
      "        [-0.0648, -0.3179,  0.3496],\n",
      "        [-0.2085,  0.0558,  0.1476],\n",
      "        [-0.3552,  0.0818,  0.1617],\n",
      "        [-0.0980, -0.1388,  0.0779],\n",
      "        [-0.1389,  0.3789,  0.1624],\n",
      "        [-0.1641,  0.0977,  0.1194],\n",
      "        [ 0.0872,  0.1848, -0.0541],\n",
      "        [ 0.2124,  0.0927, -0.0581],\n",
      "        [-0.2683, -0.1654,  0.4143],\n",
      "        [-0.1138,  0.0815,  0.3142],\n",
      "        [-0.1100,  0.1450,  0.3105],\n",
      "        [-0.0078,  0.0290,  0.3928],\n",
      "        [-0.0316,  0.0818,  0.4622],\n",
      "        [-0.1758, -0.2639, -0.0074],\n",
      "        [-0.2080,  0.1240,  0.2100],\n",
      "        [-0.0714,  0.2864,  0.1473],\n",
      "        [-0.0190,  0.3403,  0.2468],\n",
      "        [-0.1799,  0.2350,  0.4385],\n",
      "        [-0.2578,  0.2534,  0.3464],\n",
      "        [-0.1438,  0.2725, -0.2368],\n",
      "        [-0.2273,  0.2729,  0.2233],\n",
      "        [-0.2161,  0.0550,  0.0751],\n",
      "        [-0.1794,  0.0562,  0.2603]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0166, 0.0110, 0.0123],\n",
      "        [0.0142, 0.0185, 0.0140],\n",
      "        [0.0144, 0.0124, 0.0125],\n",
      "        [0.0144, 0.0141, 0.0133],\n",
      "        [0.0140, 0.0134, 0.0151],\n",
      "        [0.0133, 0.0154, 0.0157],\n",
      "        [0.0122, 0.0100, 0.0149],\n",
      "        [0.0163, 0.0112, 0.0100],\n",
      "        [0.0142, 0.0118, 0.0119],\n",
      "        [0.0114, 0.0105, 0.0181],\n",
      "        [0.0142, 0.0104, 0.0140],\n",
      "        [0.0134, 0.0118, 0.0132],\n",
      "        [0.0144, 0.0113, 0.0154],\n",
      "        [0.0118, 0.0138, 0.0145],\n",
      "        [0.0112, 0.0142, 0.0147],\n",
      "        [0.0118, 0.0122, 0.0137],\n",
      "        [0.0136, 0.0120, 0.0142],\n",
      "        [0.0117, 0.0138, 0.0157],\n",
      "        [0.0110, 0.0112, 0.0133],\n",
      "        [0.0129, 0.0119, 0.0127],\n",
      "        [0.0149, 0.0129, 0.0158],\n",
      "        [0.0112, 0.0116, 0.0179],\n",
      "        [0.0176, 0.0138, 0.0165],\n",
      "        [0.0135, 0.0100, 0.0169],\n",
      "        [0.0160, 0.0114, 0.0173],\n",
      "        [0.0121, 0.0115, 0.0165],\n",
      "        [0.0122, 0.0102, 0.0156],\n",
      "        [0.0158, 0.0109, 0.0150],\n",
      "        [0.0158, 0.0101, 0.0145],\n",
      "        [0.0192, 0.0163, 0.0149],\n",
      "        [0.0170, 0.0117, 0.0106],\n",
      "        [0.0168, 0.0126, 0.0116],\n",
      "        [0.0168, 0.0102, 0.0108],\n",
      "        [0.0129, 0.0100, 0.0131],\n",
      "        [0.0159, 0.0112, 0.0079],\n",
      "        [0.0156, 0.0169, 0.0086],\n",
      "        [0.0134, 0.0118, 0.0130],\n",
      "        [0.0118, 0.0138, 0.0151],\n",
      "        [0.0141, 0.0139, 0.0101],\n",
      "        [0.0173, 0.0145, 0.0113],\n",
      "        [0.0164, 0.0141, 0.0120],\n",
      "        [0.0128, 0.0101, 0.0166],\n",
      "        [0.0146, 0.0134, 0.0149],\n",
      "        [0.0109, 0.0149, 0.0164],\n",
      "        [0.0125, 0.0134, 0.0140],\n",
      "        [0.0160, 0.0120, 0.0135],\n",
      "        [0.0158, 0.0139, 0.0159],\n",
      "        [0.0186, 0.0159, 0.0131],\n",
      "        [0.0116, 0.0117, 0.0135],\n",
      "        [0.0116, 0.0109, 0.0137],\n",
      "        [0.0136, 0.0107, 0.0126],\n",
      "        [0.0128, 0.0103, 0.0146],\n",
      "        [0.0111, 0.0149, 0.0119],\n",
      "        [0.0096, 0.0153, 0.0121],\n",
      "        [0.0124, 0.0123, 0.0111],\n",
      "        [0.0119, 0.0206, 0.0121],\n",
      "        [0.0116, 0.0155, 0.0116],\n",
      "        [0.0149, 0.0170, 0.0097],\n",
      "        [0.0169, 0.0154, 0.0097],\n",
      "        [0.0104, 0.0119, 0.0155],\n",
      "        [0.0122, 0.0153, 0.0141],\n",
      "        [0.0122, 0.0163, 0.0140],\n",
      "        [0.0135, 0.0145, 0.0152],\n",
      "        [0.0132, 0.0153, 0.0163],\n",
      "        [0.0115, 0.0108, 0.0102],\n",
      "        [0.0111, 0.0159, 0.0127],\n",
      "        [0.0127, 0.0188, 0.0119],\n",
      "        [0.0134, 0.0198, 0.0131],\n",
      "        [0.0114, 0.0178, 0.0159],\n",
      "        [0.0106, 0.0181, 0.0145],\n",
      "        [0.0118, 0.0185, 0.0081],\n",
      "        [0.0109, 0.0185, 0.0128],\n",
      "        [0.0110, 0.0149, 0.0111],\n",
      "        [0.0114, 0.0149, 0.0133]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.1500, -0.1268,  0.1306],\n",
      "        [ 0.1564,  0.1203,  0.1626],\n",
      "        [ 0.1444,  0.0853, -0.1299],\n",
      "        [-0.0271, -0.1467,  0.4302],\n",
      "        [-0.2385, -0.2321,  0.2091],\n",
      "        [-0.1516, -0.2546,  0.5571],\n",
      "        [-0.0654, -0.1862,  0.2341],\n",
      "        [-0.1059,  0.1846,  0.3584],\n",
      "        [-0.0370,  0.1398,  0.4202],\n",
      "        [-0.1664,  0.0988,  0.4858],\n",
      "        [-0.0726,  0.1642,  0.5547],\n",
      "        [-0.1215,  0.1208,  0.6216],\n",
      "        [ 0.0933, -0.0080,  0.3855],\n",
      "        [ 0.1514,  0.2366,  0.0734],\n",
      "        [-0.0431,  0.1685,  0.1422],\n",
      "        [ 0.1204,  0.0754,  0.0687],\n",
      "        [ 0.1638,  0.1475,  0.1912],\n",
      "        [-0.0355,  0.0842,  0.3267],\n",
      "        [ 0.0127, -0.0516,  0.1080],\n",
      "        [ 0.1103,  0.3574,  0.2556],\n",
      "        [ 0.0672,  0.1888, -0.1487],\n",
      "        [ 0.0939,  0.3523,  0.3591]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0520, 0.0369, 0.0390],\n",
      "        [0.0523, 0.0472, 0.0403],\n",
      "        [0.0517, 0.0456, 0.0301],\n",
      "        [0.0435, 0.0361, 0.0526],\n",
      "        [0.0352, 0.0332, 0.0422],\n",
      "        [0.0385, 0.0324, 0.0597],\n",
      "        [0.0419, 0.0347, 0.0432],\n",
      "        [0.0403, 0.0503, 0.0490],\n",
      "        [0.0431, 0.0481, 0.0521],\n",
      "        [0.0379, 0.0462, 0.0556],\n",
      "        [0.0416, 0.0493, 0.0596],\n",
      "        [0.0396, 0.0472, 0.0637],\n",
      "        [0.0491, 0.0415, 0.0503],\n",
      "        [0.0521, 0.0530, 0.0368],\n",
      "        [0.0428, 0.0495, 0.0395],\n",
      "        [0.0504, 0.0451, 0.0367],\n",
      "        [0.0527, 0.0485, 0.0414],\n",
      "        [0.0432, 0.0455, 0.0475],\n",
      "        [0.0453, 0.0397, 0.0381],\n",
      "        [0.0499, 0.0598, 0.0442],\n",
      "        [0.0478, 0.0505, 0.0295],\n",
      "        [0.0491, 0.0595, 0.0490]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0456, -0.1132, -0.0305],\n",
      "        [-0.0708,  0.0986,  0.0165],\n",
      "        [-0.0677,  0.2012, -0.0887],\n",
      "        [-0.1334,  0.1113, -0.1819],\n",
      "        [-0.0049,  0.0735, -0.1655],\n",
      "        [ 0.0410,  0.2355, -0.1447],\n",
      "        [ 0.1254, -0.0249, -0.2188],\n",
      "        [ 0.0504, -0.1677,  0.2170],\n",
      "        [-0.1636, -0.1918, -0.0353],\n",
      "        [ 0.0768,  0.0565, -0.2993],\n",
      "        [-0.0740, -0.0724, -0.0947],\n",
      "        [ 0.0010, -0.0682,  0.0332],\n",
      "        [-0.1492,  0.1593, -0.0305],\n",
      "        [-0.2888,  0.0204,  0.0446],\n",
      "        [-0.2634,  0.0740, -0.0126],\n",
      "        [-0.1345,  0.1349,  0.2534],\n",
      "        [-0.2537,  0.0897,  0.1267],\n",
      "        [-0.3215,  0.0473,  0.1390],\n",
      "        [-0.2256,  0.1978, -0.0110],\n",
      "        [-0.0980,  0.3164, -0.0781],\n",
      "        [-0.0552,  0.0470, -0.0728],\n",
      "        [ 0.1147,  0.3167, -0.0566]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0471, 0.0375, 0.0451],\n",
      "        [0.0459, 0.0464, 0.0473],\n",
      "        [0.0460, 0.0514, 0.0426],\n",
      "        [0.0431, 0.0469, 0.0388],\n",
      "        [0.0490, 0.0452, 0.0394],\n",
      "        [0.0513, 0.0531, 0.0402],\n",
      "        [0.0558, 0.0410, 0.0374],\n",
      "        [0.0518, 0.0355, 0.0578],\n",
      "        [0.0418, 0.0347, 0.0449],\n",
      "        [0.0532, 0.0444, 0.0345],\n",
      "        [0.0457, 0.0391, 0.0423],\n",
      "        [0.0493, 0.0392, 0.0481],\n",
      "        [0.0424, 0.0493, 0.0451],\n",
      "        [0.0369, 0.0428, 0.0486],\n",
      "        [0.0378, 0.0452, 0.0459],\n",
      "        [0.0430, 0.0481, 0.0599],\n",
      "        [0.0382, 0.0459, 0.0528],\n",
      "        [0.0357, 0.0440, 0.0534],\n",
      "        [0.0393, 0.0511, 0.0460],\n",
      "        [0.0446, 0.0576, 0.0430],\n",
      "        [0.0466, 0.0440, 0.0432],\n",
      "        [0.0552, 0.0576, 0.0439]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.1519, -0.0338, -0.1660],\n",
      "        [ 0.3010,  0.0102, -0.2097],\n",
      "        [ 0.0182, -0.2216,  0.0956],\n",
      "        [ 0.0839,  0.1382, -0.0469],\n",
      "        [-0.0707,  0.0578,  0.1088],\n",
      "        [ 0.2529,  0.2271,  0.3511],\n",
      "        [ 0.1189, -0.1016,  0.1971],\n",
      "        [-0.0325,  0.0757,  0.1754],\n",
      "        [ 0.1548,  0.3186,  0.1025],\n",
      "        [ 0.1680,  0.2081,  0.1188],\n",
      "        [ 0.2881,  0.1165,  0.2515],\n",
      "        [ 0.0792,  0.2341,  0.4475],\n",
      "        [-0.1925,  0.2415,  0.4780],\n",
      "        [-0.2393,  0.0571,  0.4429],\n",
      "        [-0.1365,  0.2347,  0.3379],\n",
      "        [-0.2057,  0.3479,  0.3547],\n",
      "        [ 0.1583,  0.3020,  0.0695],\n",
      "        [ 0.2568,  0.4412,  0.2961],\n",
      "        [ 0.2686,  0.2585,  0.1058],\n",
      "        [ 0.4136,  0.2418,  0.2051]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0522, 0.0408, 0.0346],\n",
      "        [0.0606, 0.0426, 0.0331],\n",
      "        [0.0457, 0.0338, 0.0449],\n",
      "        [0.0488, 0.0484, 0.0390],\n",
      "        [0.0418, 0.0447, 0.0455],\n",
      "        [0.0578, 0.0529, 0.0580],\n",
      "        [0.0505, 0.0381, 0.0497],\n",
      "        [0.0434, 0.0455, 0.0486],\n",
      "        [0.0524, 0.0580, 0.0452],\n",
      "        [0.0531, 0.0519, 0.0460],\n",
      "        [0.0598, 0.0474, 0.0525],\n",
      "        [0.0486, 0.0533, 0.0638],\n",
      "        [0.0370, 0.0537, 0.0659],\n",
      "        [0.0353, 0.0447, 0.0635],\n",
      "        [0.0392, 0.0533, 0.0572],\n",
      "        [0.0366, 0.0598, 0.0582],\n",
      "        [0.0526, 0.0571, 0.0438],\n",
      "        [0.0580, 0.0656, 0.0549],\n",
      "        [0.0587, 0.0546, 0.0454],\n",
      "        [0.0679, 0.0537, 0.0501]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1405, -0.1450, -0.0913],\n",
      "        [ 0.1926,  0.0591,  0.0503],\n",
      "        [ 0.0887,  0.1387, -0.0208],\n",
      "        [ 0.1040,  0.3188,  0.3352],\n",
      "        [ 0.0754,  0.2744,  0.3730],\n",
      "        [ 0.0481,  0.3167,  0.3967],\n",
      "        [-0.1304,  0.1863,  0.3313],\n",
      "        [-0.1742,  0.2681,  0.4692],\n",
      "        [-0.1722,  0.2266,  0.1431],\n",
      "        [ 0.1467,  0.7065,  0.3406],\n",
      "        [ 0.1332,  0.2115,  0.0600],\n",
      "        [ 0.1544,  0.5386,  0.3806]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0699, 0.0545, 0.0594],\n",
      "        [0.0975, 0.0668, 0.0685],\n",
      "        [0.0878, 0.0723, 0.0638],\n",
      "        [0.0892, 0.0866, 0.0911],\n",
      "        [0.0867, 0.0828, 0.0945],\n",
      "        [0.0844, 0.0864, 0.0969],\n",
      "        [0.0706, 0.0759, 0.0907],\n",
      "        [0.0676, 0.0823, 0.1041],\n",
      "        [0.0677, 0.0790, 0.0751],\n",
      "        [0.0931, 0.1277, 0.0916],\n",
      "        [0.0919, 0.0778, 0.0692],\n",
      "        [0.0938, 0.1078, 0.0953]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 6.5491e-02, -2.8320e-01, -2.3059e-01],\n",
      "        [ 1.7871e-01,  1.6235e-01, -3.6230e-01],\n",
      "        [-4.9255e-02,  6.8604e-02,  2.8183e-02],\n",
      "        [ 1.2573e-02,  2.0703e-01, -4.8401e-02],\n",
      "        [-1.0596e-01,  2.3450e-01,  2.3767e-01],\n",
      "        [ 1.5228e-02,  4.3091e-01, -3.8239e-02],\n",
      "        [-1.2524e-01,  3.2739e-01,  2.7368e-01],\n",
      "        [-2.0557e-01,  1.5125e-01,  1.1267e-01],\n",
      "        [-1.4465e-01,  2.4460e-02, -2.1896e-03],\n",
      "        [-1.5735e-01,  2.9639e-01,  9.8190e-03],\n",
      "        [-4.0863e-02,  4.0924e-02,  4.9774e-02],\n",
      "        [-8.8318e-02,  4.7089e-02,  3.4644e-01],\n",
      "        [-1.7346e-01,  1.2756e-01,  4.5190e-01],\n",
      "        [-1.3965e-01,  9.2468e-02,  4.4775e-01],\n",
      "        [-2.8778e-02,  2.9858e-01,  3.0396e-01],\n",
      "        [-1.0010e-01,  2.7490e-01,  2.8540e-01],\n",
      "        [-3.1567e-01, -1.7053e-01,  5.2783e-01],\n",
      "        [-2.5928e-01, -1.8176e-01,  5.6836e-01],\n",
      "        [-3.1909e-01, -1.9043e-01,  4.9243e-01],\n",
      "        [-8.6731e-02, -6.3095e-03,  2.3328e-01],\n",
      "        [ 9.9487e-02, -1.1938e-01,  4.2651e-01],\n",
      "        [ 1.1909e-02, -7.9590e-02,  4.6509e-01],\n",
      "        [ 1.2390e-01, -2.1338e-01,  4.8218e-01],\n",
      "        [-6.3721e-02, -6.1846e-04,  2.7539e-01],\n",
      "        [-1.6821e-01,  3.5461e-02,  1.7883e-01],\n",
      "        [-3.9771e-01,  6.4148e-02,  4.9536e-01],\n",
      "        [ 2.2156e-02, -2.0432e-02,  3.6621e-01],\n",
      "        [-1.6187e-01, -1.8066e-01,  3.0298e-01],\n",
      "        [-1.0431e-01, -2.7832e-01,  4.5874e-01],\n",
      "        [-1.7090e-01, -3.1445e-01,  4.4141e-01],\n",
      "        [-2.7417e-01, -6.7505e-02,  2.2791e-01],\n",
      "        [-2.2705e-01, -1.2189e-01,  3.2910e-01],\n",
      "        [-1.3428e-01, -3.5815e-01,  3.2202e-01],\n",
      "        [ 1.4801e-03, -4.0588e-02,  2.2644e-01],\n",
      "        [ 1.0818e-02, -4.8950e-02,  2.8857e-01],\n",
      "        [ 2.6886e-02, -1.0712e-02,  2.3035e-01],\n",
      "        [ 5.6091e-02,  2.0767e-02,  3.1079e-01],\n",
      "        [ 5.9891e-03, -3.6694e-01,  6.1377e-01],\n",
      "        [-2.2839e-01, -5.2295e-01,  6.3965e-01],\n",
      "        [-3.1592e-01, -3.7427e-01,  5.1465e-01],\n",
      "        [-1.6309e-01, -3.2983e-01,  3.0933e-01],\n",
      "        [-1.4954e-01, -2.7612e-01,  1.4771e-01],\n",
      "        [ 1.1375e-02, -1.9873e-01,  5.4297e-01],\n",
      "        [-1.1401e-01, -8.8928e-02,  5.5029e-01],\n",
      "        [ 7.0801e-02, -3.5492e-02,  5.1025e-01],\n",
      "        [ 2.1521e-01,  2.5391e-02,  4.0674e-01],\n",
      "        [ 2.2937e-01, -1.1853e-01,  1.3794e-01],\n",
      "        [-1.1147e-02,  1.0901e-01,  4.9194e-01],\n",
      "        [ 8.9233e-02,  1.0944e-01,  2.6172e-01],\n",
      "        [-2.5220e-01,  1.1902e-01,  7.4577e-03],\n",
      "        [-3.7378e-01,  2.3413e-01,  2.1594e-01],\n",
      "        [-3.1616e-01,  3.3447e-01,  2.0410e-01],\n",
      "        [-1.8274e-01,  3.8550e-01,  2.5317e-01],\n",
      "        [-1.4709e-01,  2.6099e-01,  2.5806e-01],\n",
      "        [-4.0723e-01,  4.6844e-03, -2.1423e-02],\n",
      "        [-3.6450e-01,  1.0824e-03,  2.6367e-01],\n",
      "        [-4.4287e-01,  7.5798e-03,  2.2852e-01],\n",
      "        [-3.1958e-01,  3.8281e-01, -5.6343e-03],\n",
      "        [-2.3596e-01,  3.5181e-01, -7.6050e-02],\n",
      "        [-3.3984e-01,  1.7120e-02,  1.8250e-01],\n",
      "        [-1.2164e-01,  8.2153e-02, -7.0251e-02],\n",
      "        [-2.2058e-01, -3.8116e-02,  4.9896e-02],\n",
      "        [-2.5464e-01, -1.3904e-01,  4.7058e-02],\n",
      "        [ 1.0095e-01, -3.4058e-01,  8.2153e-02],\n",
      "        [-3.7720e-02, -4.3640e-03, -8.7708e-02],\n",
      "        [ 2.4307e-02,  2.9370e-01, -6.6711e-02],\n",
      "        [ 5.5878e-02,  2.5342e-01,  4.8889e-02],\n",
      "        [ 8.7524e-02,  2.3792e-01,  1.1664e-01],\n",
      "        [ 1.7090e-01,  4.3365e-02,  4.9530e-02],\n",
      "        [ 3.8403e-01, -9.2712e-02,  9.6130e-02],\n",
      "        [ 2.8394e-01,  1.2482e-01, -5.9692e-02],\n",
      "        [ 2.4731e-01, -1.2286e-01,  1.4417e-01]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0160, 0.0102, 0.0086],\n",
      "        [0.0179, 0.0159, 0.0075],\n",
      "        [0.0142, 0.0144, 0.0111],\n",
      "        [0.0151, 0.0166, 0.0103],\n",
      "        [0.0135, 0.0170, 0.0137],\n",
      "        [0.0152, 0.0208, 0.0104],\n",
      "        [0.0132, 0.0187, 0.0142],\n",
      "        [0.0122, 0.0157, 0.0121],\n",
      "        [0.0129, 0.0138, 0.0108],\n",
      "        [0.0128, 0.0181, 0.0109],\n",
      "        [0.0144, 0.0140, 0.0113],\n",
      "        [0.0137, 0.0141, 0.0153],\n",
      "        [0.0126, 0.0153, 0.0170],\n",
      "        [0.0130, 0.0148, 0.0169],\n",
      "        [0.0145, 0.0182, 0.0146],\n",
      "        [0.0135, 0.0177, 0.0144],\n",
      "        [0.0109, 0.0114, 0.0183],\n",
      "        [0.0115, 0.0112, 0.0191],\n",
      "        [0.0109, 0.0111, 0.0177],\n",
      "        [0.0137, 0.0134, 0.0136],\n",
      "        [0.0165, 0.0120, 0.0165],\n",
      "        [0.0151, 0.0125, 0.0172],\n",
      "        [0.0169, 0.0109, 0.0175],\n",
      "        [0.0140, 0.0135, 0.0142],\n",
      "        [0.0126, 0.0140, 0.0129],\n",
      "        [0.0100, 0.0144, 0.0177],\n",
      "        [0.0153, 0.0132, 0.0156],\n",
      "        [0.0127, 0.0113, 0.0146],\n",
      "        [0.0135, 0.0102, 0.0171],\n",
      "        [0.0126, 0.0098, 0.0168],\n",
      "        [0.0114, 0.0126, 0.0136],\n",
      "        [0.0119, 0.0119, 0.0150],\n",
      "        [0.0131, 0.0094, 0.0149],\n",
      "        [0.0150, 0.0129, 0.0135],\n",
      "        [0.0151, 0.0128, 0.0144],\n",
      "        [0.0154, 0.0133, 0.0136],\n",
      "        [0.0158, 0.0138, 0.0147],\n",
      "        [0.0150, 0.0093, 0.0200],\n",
      "        [0.0119, 0.0080, 0.0205],\n",
      "        [0.0109, 0.0093, 0.0181],\n",
      "        [0.0127, 0.0097, 0.0147],\n",
      "        [0.0129, 0.0102, 0.0125],\n",
      "        [0.0151, 0.0110, 0.0186],\n",
      "        [0.0133, 0.0123, 0.0187],\n",
      "        [0.0160, 0.0130, 0.0180],\n",
      "        [0.0185, 0.0138, 0.0162],\n",
      "        [0.0188, 0.0120, 0.0124],\n",
      "        [0.0148, 0.0150, 0.0177],\n",
      "        [0.0163, 0.0150, 0.0140],\n",
      "        [0.0116, 0.0152, 0.0109],\n",
      "        [0.0103, 0.0170, 0.0134],\n",
      "        [0.0109, 0.0188, 0.0132],\n",
      "        [0.0125, 0.0198, 0.0139],\n",
      "        [0.0129, 0.0175, 0.0140],\n",
      "        [0.0099, 0.0135, 0.0106],\n",
      "        [0.0104, 0.0135, 0.0141],\n",
      "        [0.0096, 0.0136, 0.0136],\n",
      "        [0.0109, 0.0198, 0.0107],\n",
      "        [0.0118, 0.0192, 0.0100],\n",
      "        [0.0106, 0.0137, 0.0130],\n",
      "        [0.0132, 0.0146, 0.0101],\n",
      "        [0.0120, 0.0130, 0.0114],\n",
      "        [0.0116, 0.0117, 0.0113],\n",
      "        [0.0165, 0.0096, 0.0117],\n",
      "        [0.0144, 0.0134, 0.0099],\n",
      "        [0.0153, 0.0181, 0.0101],\n",
      "        [0.0158, 0.0174, 0.0113],\n",
      "        [0.0163, 0.0171, 0.0121],\n",
      "        [0.0177, 0.0141, 0.0113],\n",
      "        [0.0219, 0.0123, 0.0119],\n",
      "        [0.0199, 0.0153, 0.0102],\n",
      "        [0.0191, 0.0119, 0.0125]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.2600, -0.1842,  0.1180],\n",
      "        [ 0.3767,  0.2988, -0.1554],\n",
      "        [ 0.1164,  0.0807,  0.0828],\n",
      "        [ 0.0807,  0.2869, -0.0986],\n",
      "        [ 0.1353,  0.1154, -0.2695],\n",
      "        [ 0.2474,  0.0218,  0.0906],\n",
      "        [ 0.1808,  0.0515, -0.0456],\n",
      "        [ 0.1354, -0.0251, -0.0306],\n",
      "        [ 0.1070,  0.1427, -0.0552],\n",
      "        [-0.1438, -0.0439,  0.3071],\n",
      "        [-0.0192,  0.0168,  0.3833],\n",
      "        [-0.0876, -0.1738,  0.4761],\n",
      "        [-0.1765, -0.1599,  0.3696],\n",
      "        [-0.3296, -0.2014,  0.5718],\n",
      "        [-0.1106, -0.2355,  0.4155],\n",
      "        [-0.2803, -0.3247,  0.6143],\n",
      "        [-0.2522, -0.3643,  0.3926],\n",
      "        [-0.2321, -0.3313,  0.5020],\n",
      "        [-0.2915, -0.6079,  0.4612],\n",
      "        [-0.1919,  0.0094,  0.4346],\n",
      "        [-0.3479, -0.1200,  0.6372],\n",
      "        [-0.2056, -0.0253,  0.4673],\n",
      "        [-0.3372, -0.0190,  0.5098],\n",
      "        [-0.1241, -0.0520,  0.4746],\n",
      "        [-0.2069, -0.0134,  0.5088],\n",
      "        [-0.1152,  0.1276,  0.4702],\n",
      "        [-0.2590,  0.1054,  0.5020],\n",
      "        [-0.1636, -0.0911,  0.5679],\n",
      "        [-0.1241, -0.0626,  0.6079],\n",
      "        [-0.3022, -0.0324,  0.5674],\n",
      "        [-0.0399, -0.0879,  0.5146],\n",
      "        [ 0.1207, -0.0353,  0.3677],\n",
      "        [-0.0631,  0.1307,  0.4885],\n",
      "        [-0.0965, -0.0355,  0.2788],\n",
      "        [-0.1920, -0.3945,  0.3396],\n",
      "        [-0.0399, -0.3127,  0.2047],\n",
      "        [ 0.0179, -0.2698,  0.1243],\n",
      "        [ 0.2250,  0.1046, -0.0576],\n",
      "        [ 0.1941,  0.0219,  0.0602],\n",
      "        [ 0.0747,  0.1052,  0.0397]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0338, 0.0218, 0.0201],\n",
      "        [0.0381, 0.0354, 0.0153],\n",
      "        [0.0293, 0.0284, 0.0194],\n",
      "        [0.0283, 0.0349, 0.0162],\n",
      "        [0.0299, 0.0294, 0.0137],\n",
      "        [0.0334, 0.0268, 0.0196],\n",
      "        [0.0313, 0.0276, 0.0171],\n",
      "        [0.0299, 0.0256, 0.0173],\n",
      "        [0.0291, 0.0302, 0.0169],\n",
      "        [0.0226, 0.0251, 0.0243],\n",
      "        [0.0256, 0.0267, 0.0262],\n",
      "        [0.0239, 0.0220, 0.0288],\n",
      "        [0.0219, 0.0223, 0.0259],\n",
      "        [0.0188, 0.0214, 0.0317],\n",
      "        [0.0234, 0.0207, 0.0271],\n",
      "        [0.0197, 0.0190, 0.0331],\n",
      "        [0.0203, 0.0182, 0.0265],\n",
      "        [0.0207, 0.0188, 0.0296],\n",
      "        [0.0195, 0.0143, 0.0284],\n",
      "        [0.0215, 0.0265, 0.0276],\n",
      "        [0.0184, 0.0233, 0.0338],\n",
      "        [0.0213, 0.0256, 0.0285],\n",
      "        [0.0186, 0.0257, 0.0298],\n",
      "        [0.0231, 0.0249, 0.0288],\n",
      "        [0.0212, 0.0259, 0.0298],\n",
      "        [0.0233, 0.0298, 0.0286],\n",
      "        [0.0202, 0.0291, 0.0296],\n",
      "        [0.0222, 0.0239, 0.0316],\n",
      "        [0.0231, 0.0246, 0.0329],\n",
      "        [0.0193, 0.0254, 0.0316],\n",
      "        [0.0251, 0.0240, 0.0299],\n",
      "        [0.0294, 0.0253, 0.0258],\n",
      "        [0.0245, 0.0299, 0.0292],\n",
      "        [0.0237, 0.0253, 0.0236],\n",
      "        [0.0215, 0.0177, 0.0251],\n",
      "        [0.0251, 0.0192, 0.0220],\n",
      "        [0.0266, 0.0200, 0.0202],\n",
      "        [0.0327, 0.0291, 0.0169],\n",
      "        [0.0317, 0.0268, 0.0190],\n",
      "        [0.0281, 0.0291, 0.0186]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.2573,  0.1191, -0.0568],\n",
      "        [ 0.2129,  0.2216,  0.1713],\n",
      "        [ 0.1803,  0.1100,  0.0555],\n",
      "        [ 0.0336,  0.3035,  0.3567],\n",
      "        [-0.0810,  0.0599,  0.4036],\n",
      "        [-0.0382,  0.3899,  0.5010],\n",
      "        [ 0.1292,  0.0635,  0.3550],\n",
      "        [-0.0485,  0.3992,  0.2996],\n",
      "        [-0.0189,  0.2839,  0.1780],\n",
      "        [-0.0206,  0.1896,  0.3479],\n",
      "        [ 0.0687,  0.1279,  0.2896],\n",
      "        [ 0.3096,  0.0814, -0.0435],\n",
      "        [ 0.2144, -0.0142, -0.0531],\n",
      "        [-0.2483, -0.2549,  0.1232],\n",
      "        [-0.1725, -0.1958,  0.4167],\n",
      "        [ 0.0511, -0.1276,  0.2404],\n",
      "        [-0.2001, -0.1901,  0.3044],\n",
      "        [ 0.0039, -0.1670,  0.5625],\n",
      "        [-0.3091, -0.1237,  0.4924],\n",
      "        [-0.1814, -0.0193,  0.3674],\n",
      "        [-0.4519, -0.1071,  0.2164],\n",
      "        [-0.3062, -0.0508,  0.2578],\n",
      "        [-0.1764, -0.0522,  0.2942],\n",
      "        [-0.1631, -0.0051,  0.4983],\n",
      "        [-0.2722,  0.1013,  0.2510],\n",
      "        [-0.1997,  0.0044,  0.2512],\n",
      "        [-0.2057, -0.0742,  0.4761],\n",
      "        [-0.2411, -0.0854,  0.3872],\n",
      "        [-0.1705,  0.1033,  0.4333],\n",
      "        [-0.1541,  0.2202,  0.3865],\n",
      "        [-0.4185,  0.2351,  0.2881],\n",
      "        [-0.2646,  0.1173, -0.0293],\n",
      "        [-0.1654, -0.0407,  0.2690],\n",
      "        [-0.1801,  0.0042, -0.1398],\n",
      "        [-0.1465, -0.0204,  0.1364],\n",
      "        [-0.0972, -0.1516,  0.3770],\n",
      "        [ 0.0225, -0.1738, -0.0033],\n",
      "        [ 0.2844,  0.1142, -0.0276],\n",
      "        [ 0.3259, -0.0873, -0.2271],\n",
      "        [ 0.0787,  0.1744,  0.1998],\n",
      "        [ 0.1484,  0.1389,  0.2037],\n",
      "        [ 0.1719,  0.1407,  0.2433],\n",
      "        [ 0.0011,  0.0599,  0.2292],\n",
      "        [ 0.2896,  0.3508,  0.1456],\n",
      "        [ 0.0971, -0.1208,  0.1904],\n",
      "        [ 0.1511,  0.3191,  0.4072],\n",
      "        [ 0.0671, -0.2805,  0.2537],\n",
      "        [ 0.2103,  0.1481,  0.0969],\n",
      "        [ 0.2834,  0.4238,  0.0908],\n",
      "        [ 0.3015,  0.2595,  0.0462],\n",
      "        [ 0.2401,  0.0889,  0.1023],\n",
      "        [ 0.1438,  0.0953,  0.2189],\n",
      "        [ 0.1687, -0.1153,  0.3247],\n",
      "        [ 0.0540, -0.2153,  0.2727],\n",
      "        [-0.0718, -0.0343,  0.3787],\n",
      "        [ 0.0162, -0.1571,  0.4639],\n",
      "        [ 0.2502,  0.0396,  0.3657],\n",
      "        [-0.1650, -0.0878,  0.4880],\n",
      "        [-0.0142,  0.1171,  0.2474],\n",
      "        [-0.1614, -0.0251,  0.2195],\n",
      "        [ 0.1043,  0.1937,  0.3975],\n",
      "        [-0.1884, -0.0466,  0.2517],\n",
      "        [-0.0637, -0.1875,  0.6401],\n",
      "        [-0.2722,  0.1089,  0.5273],\n",
      "        [-0.0374,  0.3267,  0.4646],\n",
      "        [ 0.0590,  0.0542,  0.3735],\n",
      "        [ 0.0917,  0.2347,  0.3867],\n",
      "        [ 0.1866,  0.0075,  0.1779],\n",
      "        [ 0.0685,  0.0467,  0.2515],\n",
      "        [ 0.0227, -0.1102,  0.3240],\n",
      "        [ 0.1129,  0.1647,  0.4907],\n",
      "        [ 0.0827,  0.1310,  0.4060],\n",
      "        [ 0.2374,  0.2598,  0.5874],\n",
      "        [ 0.2156,  0.3362,  0.3267],\n",
      "        [ 0.2246,  0.0408,  0.5874],\n",
      "        [ 0.1947, -0.0124,  0.3770],\n",
      "        [-0.0429, -0.3396,  0.3718],\n",
      "        [ 0.4668,  0.0519,  0.3169],\n",
      "        [ 0.2588, -0.0616,  0.0817],\n",
      "        [ 0.3250,  0.2881,  0.2487]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0156, 0.0132, 0.0088],\n",
      "        [0.0149, 0.0146, 0.0111],\n",
      "        [0.0144, 0.0131, 0.0099],\n",
      "        [0.0125, 0.0159, 0.0133],\n",
      "        [0.0111, 0.0124, 0.0140],\n",
      "        [0.0116, 0.0173, 0.0154],\n",
      "        [0.0137, 0.0125, 0.0133],\n",
      "        [0.0115, 0.0174, 0.0126],\n",
      "        [0.0118, 0.0155, 0.0112],\n",
      "        [0.0118, 0.0141, 0.0132],\n",
      "        [0.0129, 0.0133, 0.0125],\n",
      "        [0.0164, 0.0127, 0.0089],\n",
      "        [0.0149, 0.0115, 0.0089],\n",
      "        [0.0094, 0.0091, 0.0106],\n",
      "        [0.0101, 0.0096, 0.0142],\n",
      "        [0.0127, 0.0103, 0.0119],\n",
      "        [0.0099, 0.0097, 0.0127],\n",
      "        [0.0121, 0.0099, 0.0164],\n",
      "        [0.0088, 0.0103, 0.0153],\n",
      "        [0.0100, 0.0115, 0.0135],\n",
      "        [0.0077, 0.0105, 0.0116],\n",
      "        [0.0089, 0.0111, 0.0121],\n",
      "        [0.0101, 0.0111, 0.0125],\n",
      "        [0.0102, 0.0116, 0.0154],\n",
      "        [0.0092, 0.0129, 0.0120],\n",
      "        [0.0099, 0.0117, 0.0120],\n",
      "        [0.0098, 0.0109, 0.0150],\n",
      "        [0.0095, 0.0107, 0.0137],\n",
      "        [0.0102, 0.0130, 0.0144],\n",
      "        [0.0103, 0.0146, 0.0137],\n",
      "        [0.0079, 0.0148, 0.0125],\n",
      "        [0.0092, 0.0132, 0.0091],\n",
      "        [0.0102, 0.0112, 0.0122],\n",
      "        [0.0101, 0.0117, 0.0081],\n",
      "        [0.0104, 0.0115, 0.0107],\n",
      "        [0.0109, 0.0101, 0.0136],\n",
      "        [0.0123, 0.0098, 0.0093],\n",
      "        [0.0160, 0.0131, 0.0091],\n",
      "        [0.0167, 0.0107, 0.0074],\n",
      "        [0.0130, 0.0139, 0.0114],\n",
      "        [0.0140, 0.0134, 0.0114],\n",
      "        [0.0143, 0.0135, 0.0119],\n",
      "        [0.0121, 0.0124, 0.0117],\n",
      "        [0.0161, 0.0166, 0.0108],\n",
      "        [0.0133, 0.0104, 0.0113],\n",
      "        [0.0140, 0.0161, 0.0140],\n",
      "        [0.0129, 0.0088, 0.0120],\n",
      "        [0.0149, 0.0136, 0.0103],\n",
      "        [0.0160, 0.0179, 0.0102],\n",
      "        [0.0163, 0.0152, 0.0098],\n",
      "        [0.0153, 0.0128, 0.0103],\n",
      "        [0.0139, 0.0129, 0.0116],\n",
      "        [0.0143, 0.0104, 0.0129],\n",
      "        [0.0127, 0.0094, 0.0123],\n",
      "        [0.0112, 0.0113, 0.0136],\n",
      "        [0.0122, 0.0100, 0.0148],\n",
      "        [0.0155, 0.0122, 0.0135],\n",
      "        [0.0102, 0.0107, 0.0152],\n",
      "        [0.0119, 0.0132, 0.0120],\n",
      "        [0.0102, 0.0114, 0.0116],\n",
      "        [0.0134, 0.0142, 0.0139],\n",
      "        [0.0100, 0.0112, 0.0120],\n",
      "        [0.0113, 0.0097, 0.0177],\n",
      "        [0.0092, 0.0130, 0.0158],\n",
      "        [0.0116, 0.0162, 0.0149],\n",
      "        [0.0128, 0.0124, 0.0136],\n",
      "        [0.0132, 0.0148, 0.0137],\n",
      "        [0.0145, 0.0118, 0.0112],\n",
      "        [0.0129, 0.0123, 0.0120],\n",
      "        [0.0123, 0.0105, 0.0129],\n",
      "        [0.0135, 0.0138, 0.0153],\n",
      "        [0.0131, 0.0133, 0.0140],\n",
      "        [0.0153, 0.0152, 0.0168],\n",
      "        [0.0149, 0.0164, 0.0129],\n",
      "        [0.0151, 0.0122, 0.0168],\n",
      "        [0.0146, 0.0116, 0.0136],\n",
      "        [0.0115, 0.0083, 0.0135],\n",
      "        [0.0192, 0.0123, 0.0128],\n",
      "        [0.0156, 0.0110, 0.0101],\n",
      "        [0.0167, 0.0156, 0.0120]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.2472, -0.2319,  0.1921],\n",
      "        [ 0.1124,  0.1116, -0.1243],\n",
      "        [ 0.0333, -0.0033, -0.0866],\n",
      "        [ 0.1635, -0.1788,  0.0820],\n",
      "        [-0.1852, -0.1912, -0.0463],\n",
      "        [-0.1959, -0.1455,  0.1226],\n",
      "        [-0.0253, -0.2202,  0.2600],\n",
      "        [-0.0255,  0.0429,  0.0581],\n",
      "        [-0.0850, -0.0360,  0.2170],\n",
      "        [-0.0662, -0.0405,  0.3379],\n",
      "        [-0.2374,  0.1209,  0.4326],\n",
      "        [-0.2588,  0.2269,  0.6523],\n",
      "        [-0.2460,  0.2793,  0.3247],\n",
      "        [-0.0895,  0.1196,  0.2930],\n",
      "        [-0.1752,  0.0859,  0.2688],\n",
      "        [-0.2771,  0.0651,  0.4685],\n",
      "        [-0.3667, -0.0639,  0.5127],\n",
      "        [-0.1366,  0.1305,  0.1152],\n",
      "        [-0.1692, -0.0109,  0.0797],\n",
      "        [-0.1122, -0.0395,  0.0285],\n",
      "        [-0.2028, -0.2815,  0.0415],\n",
      "        [ 0.2793,  0.1516, -0.2800],\n",
      "        [ 0.0604, -0.2252,  0.2372],\n",
      "        [-0.1179, -0.1371,  0.6250],\n",
      "        [ 0.1426,  0.0059,  0.6299],\n",
      "        [ 0.2092, -0.0048,  0.4873],\n",
      "        [ 0.0638,  0.1431,  0.6182],\n",
      "        [ 0.0799, -0.0221,  0.7549],\n",
      "        [ 0.0184, -0.1515,  0.5103],\n",
      "        [ 0.3530,  0.2834,  0.4219],\n",
      "        [ 0.1309, -0.0533,  0.4231],\n",
      "        [ 0.1516, -0.0203,  0.2869],\n",
      "        [ 0.2294, -0.0442,  0.0401],\n",
      "        [ 0.2241,  0.0124,  0.2871],\n",
      "        [ 0.1143, -0.0221,  0.2469],\n",
      "        [ 0.0537, -0.1195, -0.0278],\n",
      "        [ 0.0426, -0.0387,  0.0847],\n",
      "        [ 0.0148, -0.0303,  0.1484],\n",
      "        [-0.0283, -0.1167,  0.0760],\n",
      "        [ 0.0448,  0.2423,  0.0435],\n",
      "        [ 0.1242,  0.0740, -0.0916],\n",
      "        [ 0.2015,  0.2064,  0.1752]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0300, 0.0187, 0.0221],\n",
      "        [0.0262, 0.0264, 0.0161],\n",
      "        [0.0242, 0.0236, 0.0168],\n",
      "        [0.0276, 0.0198, 0.0198],\n",
      "        [0.0195, 0.0195, 0.0174],\n",
      "        [0.0193, 0.0204, 0.0206],\n",
      "        [0.0228, 0.0190, 0.0237],\n",
      "        [0.0228, 0.0247, 0.0194],\n",
      "        [0.0215, 0.0228, 0.0227],\n",
      "        [0.0219, 0.0227, 0.0256],\n",
      "        [0.0185, 0.0267, 0.0282],\n",
      "        [0.0181, 0.0297, 0.0351],\n",
      "        [0.0183, 0.0313, 0.0253],\n",
      "        [0.0214, 0.0267, 0.0245],\n",
      "        [0.0197, 0.0258, 0.0239],\n",
      "        [0.0177, 0.0252, 0.0292],\n",
      "        [0.0162, 0.0222, 0.0305],\n",
      "        [0.0204, 0.0269, 0.0205],\n",
      "        [0.0198, 0.0234, 0.0198],\n",
      "        [0.0209, 0.0227, 0.0188],\n",
      "        [0.0191, 0.0178, 0.0190],\n",
      "        [0.0309, 0.0275, 0.0138],\n",
      "        [0.0249, 0.0189, 0.0231],\n",
      "        [0.0208, 0.0206, 0.0341],\n",
      "        [0.0270, 0.0238, 0.0343],\n",
      "        [0.0289, 0.0235, 0.0297],\n",
      "        [0.0250, 0.0273, 0.0339],\n",
      "        [0.0254, 0.0231, 0.0388],\n",
      "        [0.0238, 0.0203, 0.0304],\n",
      "        [0.0333, 0.0314, 0.0278],\n",
      "        [0.0267, 0.0224, 0.0279],\n",
      "        [0.0272, 0.0232, 0.0243],\n",
      "        [0.0294, 0.0226, 0.0190],\n",
      "        [0.0293, 0.0239, 0.0243],\n",
      "        [0.0262, 0.0231, 0.0234],\n",
      "        [0.0247, 0.0210, 0.0178],\n",
      "        [0.0244, 0.0228, 0.0199],\n",
      "        [0.0238, 0.0229, 0.0212],\n",
      "        [0.0228, 0.0210, 0.0197],\n",
      "        [0.0245, 0.0301, 0.0191],\n",
      "        [0.0265, 0.0255, 0.0167],\n",
      "        [0.0286, 0.0291, 0.0218]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 6.5430e-02, -3.0182e-02,  3.7079e-02],\n",
      "        [ 5.1318e-01,  2.0837e-01,  1.0309e-01],\n",
      "        [ 7.8796e-02,  2.5513e-01,  6.8542e-02],\n",
      "        [ 3.2300e-01,  1.2138e-02, -2.2192e-01],\n",
      "        [ 2.9126e-01, -1.0858e-01, -1.0693e-01],\n",
      "        [ 9.7107e-02, -7.5798e-03,  1.3049e-01],\n",
      "        [ 2.0355e-02,  1.5552e-01,  2.0850e-01],\n",
      "        [-1.5930e-01,  2.0386e-01,  3.6621e-01],\n",
      "        [-2.1985e-01,  3.0785e-03,  3.8574e-01],\n",
      "        [-3.6831e-03,  2.2522e-01,  2.0862e-01],\n",
      "        [ 3.6346e-02, -1.3074e-01,  1.5515e-01],\n",
      "        [-1.0498e-01, -6.5422e-03,  4.0942e-01],\n",
      "        [-9.9564e-03,  2.3987e-02,  1.4990e-01],\n",
      "        [ 1.1719e-01, -1.4905e-01,  1.6589e-01],\n",
      "        [ 1.9885e-01, -2.1033e-01,  1.5979e-01],\n",
      "        [-4.1138e-02, -2.0508e-01,  2.6440e-01],\n",
      "        [ 2.4280e-01, -1.2250e-01,  2.0557e-01],\n",
      "        [ 2.6318e-01, -8.4900e-02,  2.0288e-01],\n",
      "        [ 1.2488e-01,  1.0016e-01,  4.4336e-01],\n",
      "        [ 2.0557e-01,  2.6685e-01,  4.3604e-01],\n",
      "        [ 1.9287e-01,  3.5156e-01,  1.6553e-01],\n",
      "        [ 9.6588e-03,  2.1204e-01,  2.8320e-01],\n",
      "        [-2.8809e-01,  2.1643e-01,  1.6434e-02],\n",
      "        [ 1.9043e-01,  1.5918e-01,  1.3855e-01],\n",
      "        [-1.6711e-01,  2.3999e-01, -2.7124e-01],\n",
      "        [ 1.8665e-01,  1.2457e-01,  1.4392e-01],\n",
      "        [ 5.9937e-02,  2.6001e-01, -1.4258e-01],\n",
      "        [ 2.3767e-01,  9.1675e-02,  3.0228e-02],\n",
      "        [ 1.3142e-03, -1.2344e-02,  5.0964e-02],\n",
      "        [ 1.3074e-01, -2.7939e-02,  4.9067e-04]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0322, 0.0299, 0.0296],\n",
      "        [0.0504, 0.0379, 0.0316],\n",
      "        [0.0326, 0.0398, 0.0306],\n",
      "        [0.0416, 0.0312, 0.0229],\n",
      "        [0.0403, 0.0276, 0.0257],\n",
      "        [0.0332, 0.0306, 0.0325],\n",
      "        [0.0307, 0.0360, 0.0352],\n",
      "        [0.0257, 0.0378, 0.0412],\n",
      "        [0.0242, 0.0309, 0.0420],\n",
      "        [0.0300, 0.0386, 0.0352],\n",
      "        [0.0312, 0.0270, 0.0334],\n",
      "        [0.0271, 0.0306, 0.0430],\n",
      "        [0.0298, 0.0316, 0.0332],\n",
      "        [0.0339, 0.0265, 0.0337],\n",
      "        [0.0368, 0.0250, 0.0335],\n",
      "        [0.0289, 0.0251, 0.0372],\n",
      "        [0.0384, 0.0273, 0.0351],\n",
      "        [0.0392, 0.0283, 0.0350],\n",
      "        [0.0341, 0.0341, 0.0445],\n",
      "        [0.0370, 0.0402, 0.0442],\n",
      "        [0.0366, 0.0438, 0.0337],\n",
      "        [0.0304, 0.0381, 0.0379],\n",
      "        [0.0226, 0.0382, 0.0290],\n",
      "        [0.0364, 0.0361, 0.0328],\n",
      "        [0.0255, 0.0392, 0.0218],\n",
      "        [0.0363, 0.0349, 0.0330],\n",
      "        [0.0320, 0.0399, 0.0248],\n",
      "        [0.0382, 0.0338, 0.0294],\n",
      "        [0.0302, 0.0304, 0.0300],\n",
      "        [0.0343, 0.0299, 0.0286]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0416,  0.0088, -0.1018],\n",
      "        [ 0.0567,  0.2559,  0.0541],\n",
      "        [-0.2217,  0.2319,  0.3169],\n",
      "        [-0.2910,  0.3159,  0.2107],\n",
      "        [-0.2452,  0.0585,  0.0925],\n",
      "        [-0.0033,  0.1737,  0.3254],\n",
      "        [-0.0379,  0.2455,  0.2212],\n",
      "        [-0.1547,  0.5283,  0.2935],\n",
      "        [-0.3442,  0.1915,  0.0460],\n",
      "        [-0.2861,  0.1026,  0.2469],\n",
      "        [-0.2832,  0.1655,  0.1649],\n",
      "        [-0.0020,  0.2148, -0.0128],\n",
      "        [-0.0297, -0.0530,  0.0533],\n",
      "        [-0.0688, -0.3066,  0.3005],\n",
      "        [-0.1736, -0.3999,  0.2040],\n",
      "        [-0.2487, -0.4451,  0.2986],\n",
      "        [-0.2947, -0.1622,  0.1301],\n",
      "        [ 0.1997, -0.0265,  0.3716],\n",
      "        [ 0.0767, -0.1249,  0.3052],\n",
      "        [ 0.1054, -0.0804,  0.2742],\n",
      "        [-0.2339, -0.0329,  0.2742],\n",
      "        [ 0.0488,  0.0387,  0.4351],\n",
      "        [-0.3079,  0.1160,  0.5371],\n",
      "        [-0.1663,  0.1024,  0.3494],\n",
      "        [-0.0286, -0.1693,  0.2959],\n",
      "        [ 0.1453,  0.1395,  0.3752],\n",
      "        [ 0.2000,  0.1031,  0.5054],\n",
      "        [-0.0746, -0.0584,  0.3523],\n",
      "        [-0.0378, -0.2065,  0.2686],\n",
      "        [ 0.2546,  0.0721,  0.0169],\n",
      "        [ 0.2122, -0.0249,  0.2026],\n",
      "        [ 0.3638, -0.0405,  0.1036]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0339, 0.0300, 0.0221],\n",
      "        [0.0344, 0.0384, 0.0258],\n",
      "        [0.0260, 0.0375, 0.0336],\n",
      "        [0.0243, 0.0408, 0.0302],\n",
      "        [0.0254, 0.0315, 0.0268],\n",
      "        [0.0324, 0.0354, 0.0338],\n",
      "        [0.0313, 0.0380, 0.0305],\n",
      "        [0.0278, 0.0504, 0.0328],\n",
      "        [0.0230, 0.0360, 0.0256],\n",
      "        [0.0244, 0.0330, 0.0313],\n",
      "        [0.0245, 0.0351, 0.0288],\n",
      "        [0.0324, 0.0369, 0.0241],\n",
      "        [0.0316, 0.0282, 0.0258],\n",
      "        [0.0303, 0.0219, 0.0330],\n",
      "        [0.0273, 0.0199, 0.0300],\n",
      "        [0.0253, 0.0190, 0.0330],\n",
      "        [0.0242, 0.0253, 0.0278],\n",
      "        [0.0397, 0.0290, 0.0355],\n",
      "        [0.0351, 0.0262, 0.0332],\n",
      "        [0.0361, 0.0274, 0.0322],\n",
      "        [0.0257, 0.0288, 0.0322],\n",
      "        [0.0341, 0.0309, 0.0378],\n",
      "        [0.0239, 0.0334, 0.0418],\n",
      "        [0.0275, 0.0330, 0.0347],\n",
      "        [0.0316, 0.0251, 0.0329],\n",
      "        [0.0376, 0.0342, 0.0356],\n",
      "        [0.0397, 0.0330, 0.0405],\n",
      "        [0.0302, 0.0280, 0.0348],\n",
      "        [0.0313, 0.0242, 0.0320],\n",
      "        [0.0419, 0.0320, 0.0249],\n",
      "        [0.0402, 0.0290, 0.0300],\n",
      "        [0.0468, 0.0286, 0.0271]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 1.5320e-01,  4.6326e-02,  3.6430e-04],\n",
      "        [ 4.0466e-02,  2.1313e-01,  2.1545e-01],\n",
      "        [-3.2373e-01, -2.4573e-01,  4.1553e-01],\n",
      "        [ 2.4316e-01,  5.1025e-02,  1.9971e-01],\n",
      "        [-6.3477e-02, -8.2947e-02,  1.4490e-01],\n",
      "        [-7.4883e-03,  4.0161e-01,  1.9763e-01],\n",
      "        [ 1.4270e-01,  2.2217e-01, -1.8848e-01],\n",
      "        [ 1.1795e-02,  1.8555e-01, -1.3501e-01],\n",
      "        [-7.3662e-03, -4.8157e-02, -2.6855e-01],\n",
      "        [ 8.9478e-02,  1.2671e-01, -5.9052e-02],\n",
      "        [-1.2169e-02,  2.7563e-01,  1.8201e-01],\n",
      "        [-1.7151e-02,  4.1724e-01,  1.1981e-01],\n",
      "        [-7.0068e-02,  2.7612e-01,  3.5474e-01],\n",
      "        [-1.2366e-01,  2.2327e-01,  3.1006e-01],\n",
      "        [-2.3352e-01,  4.4482e-01,  4.0894e-01],\n",
      "        [-2.4170e-01,  4.0625e-01,  5.5762e-01],\n",
      "        [-1.6833e-01,  4.9658e-01,  4.8145e-01],\n",
      "        [ 9.5596e-03,  1.4355e-01,  5.8643e-01],\n",
      "        [-1.9385e-01, -9.2850e-03,  4.7485e-01],\n",
      "        [-1.9189e-01,  2.1643e-01,  4.5752e-01],\n",
      "        [-4.3762e-02,  2.1997e-01,  2.1692e-01],\n",
      "        [ 1.7914e-02,  1.3110e-01,  4.5239e-01],\n",
      "        [-1.4795e-01,  2.8290e-02,  5.5762e-01],\n",
      "        [ 7.4615e-03,  5.8203e-01,  2.5439e-01],\n",
      "        [-1.0236e-01,  1.8726e-01,  2.9199e-01],\n",
      "        [ 1.4801e-02,  3.0103e-01,  3.9062e-01],\n",
      "        [ 3.3569e-02,  1.9580e-01,  3.5498e-01],\n",
      "        [ 7.0984e-02,  2.0605e-01,  1.9031e-01],\n",
      "        [-7.8918e-02,  1.7444e-01,  2.6880e-01],\n",
      "        [ 1.4015e-02,  2.6147e-01,  1.9482e-01],\n",
      "        [-1.2219e-01, -1.0870e-01, -1.2445e-01],\n",
      "        [ 5.5359e-02,  1.4673e-01,  2.4133e-01],\n",
      "        [-1.6699e-01, -1.7200e-01, -1.0333e-01],\n",
      "        [ 4.8309e-02,  2.1313e-01,  7.1960e-02],\n",
      "        [ 7.8979e-02,  7.1167e-02,  3.2349e-01],\n",
      "        [ 6.9519e-02, -1.5472e-02,  2.6978e-01],\n",
      "        [ 2.1350e-01,  1.5723e-01,  6.0921e-03],\n",
      "        [ 7.9956e-02,  1.7236e-01,  6.1798e-02],\n",
      "        [ 8.9539e-02,  6.6467e-02,  1.5881e-01],\n",
      "        [ 2.5464e-01,  1.5430e-01,  1.2329e-01],\n",
      "        [ 3.2397e-01,  8.4534e-02,  1.6528e-01],\n",
      "        [ 3.3472e-01,  1.0779e-01,  2.4561e-01],\n",
      "        [ 2.9980e-01,  4.5898e-01,  1.7334e-01],\n",
      "        [ 1.0742e-01,  2.0129e-01,  8.6914e-02],\n",
      "        [ 1.0364e-01,  3.1567e-01,  4.7119e-01],\n",
      "        [-2.6581e-02,  3.9453e-01,  7.8430e-02],\n",
      "        [ 5.1117e-02,  2.5879e-01,  1.6748e-01],\n",
      "        [-3.3844e-02,  2.6709e-01,  2.0227e-01],\n",
      "        [-1.6895e-01,  6.2439e-02,  1.0461e-01],\n",
      "        [-5.2673e-02,  4.2755e-02,  1.1206e-01],\n",
      "        [-7.6538e-02,  2.3962e-01,  1.9360e-01],\n",
      "        [-2.6807e-01,  3.1592e-01,  3.5059e-01],\n",
      "        [-4.0918e-01,  1.9299e-01,  6.2207e-01],\n",
      "        [-2.1851e-01,  1.5588e-01,  3.4302e-01],\n",
      "        [ 4.2725e-03,  3.0322e-01,  1.2726e-02],\n",
      "        [-4.4746e-03,  1.5063e-01,  1.7993e-01],\n",
      "        [-8.5815e-02, -2.2083e-01,  5.4550e-04],\n",
      "        [ 1.2402e-01,  1.6638e-01,  1.0278e-01],\n",
      "        [-4.8431e-02, -9.8389e-02,  1.7932e-01],\n",
      "        [ 1.1890e-01,  1.3855e-02,  2.6855e-01]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0194, 0.0145, 0.0132],\n",
      "        [0.0173, 0.0172, 0.0164],\n",
      "        [0.0120, 0.0108, 0.0201],\n",
      "        [0.0212, 0.0146, 0.0162],\n",
      "        [0.0156, 0.0128, 0.0153],\n",
      "        [0.0165, 0.0207, 0.0161],\n",
      "        [0.0192, 0.0173, 0.0110],\n",
      "        [0.0168, 0.0167, 0.0116],\n",
      "        [0.0165, 0.0132, 0.0101],\n",
      "        [0.0182, 0.0157, 0.0125],\n",
      "        [0.0164, 0.0183, 0.0159],\n",
      "        [0.0163, 0.0211, 0.0149],\n",
      "        [0.0155, 0.0183, 0.0189],\n",
      "        [0.0147, 0.0173, 0.0181],\n",
      "        [0.0132, 0.0216, 0.0199],\n",
      "        [0.0130, 0.0208, 0.0231],\n",
      "        [0.0140, 0.0228, 0.0214],\n",
      "        [0.0168, 0.0160, 0.0238],\n",
      "        [0.0137, 0.0137, 0.0213],\n",
      "        [0.0137, 0.0172, 0.0209],\n",
      "        [0.0159, 0.0173, 0.0164],\n",
      "        [0.0169, 0.0158, 0.0208],\n",
      "        [0.0143, 0.0143, 0.0231],\n",
      "        [0.0167, 0.0248, 0.0171],\n",
      "        [0.0150, 0.0167, 0.0177],\n",
      "        [0.0169, 0.0188, 0.0196],\n",
      "        [0.0172, 0.0169, 0.0189],\n",
      "        [0.0178, 0.0170, 0.0160],\n",
      "        [0.0154, 0.0165, 0.0173],\n",
      "        [0.0168, 0.0180, 0.0161],\n",
      "        [0.0147, 0.0124, 0.0117],\n",
      "        [0.0176, 0.0161, 0.0169],\n",
      "        [0.0141, 0.0117, 0.0119],\n",
      "        [0.0174, 0.0172, 0.0142],\n",
      "        [0.0180, 0.0149, 0.0183],\n",
      "        [0.0178, 0.0137, 0.0173],\n",
      "        [0.0206, 0.0162, 0.0133],\n",
      "        [0.0180, 0.0165, 0.0141],\n",
      "        [0.0182, 0.0148, 0.0155],\n",
      "        [0.0214, 0.0162, 0.0150],\n",
      "        [0.0230, 0.0151, 0.0156],\n",
      "        [0.0232, 0.0155, 0.0169],\n",
      "        [0.0224, 0.0220, 0.0157],\n",
      "        [0.0185, 0.0170, 0.0144],\n",
      "        [0.0184, 0.0190, 0.0212],\n",
      "        [0.0162, 0.0206, 0.0143],\n",
      "        [0.0175, 0.0180, 0.0157],\n",
      "        [0.0161, 0.0181, 0.0162],\n",
      "        [0.0140, 0.0148, 0.0147],\n",
      "        [0.0158, 0.0145, 0.0148],\n",
      "        [0.0154, 0.0176, 0.0161],\n",
      "        [0.0127, 0.0190, 0.0188],\n",
      "        [0.0110, 0.0168, 0.0247],\n",
      "        [0.0134, 0.0162, 0.0186],\n",
      "        [0.0167, 0.0188, 0.0134],\n",
      "        [0.0165, 0.0161, 0.0158],\n",
      "        [0.0153, 0.0111, 0.0132],\n",
      "        [0.0188, 0.0164, 0.0147],\n",
      "        [0.0158, 0.0126, 0.0158],\n",
      "        [0.0187, 0.0141, 0.0173]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.1797, -0.0199, -0.0986],\n",
      "        [ 0.3323,  0.3005,  0.0139],\n",
      "        [ 0.2542,  0.1829,  0.0533],\n",
      "        [ 0.3511,  0.3198,  0.0384],\n",
      "        [ 0.1367,  0.1523, -0.0313],\n",
      "        [ 0.1935,  0.1450, -0.2126],\n",
      "        [ 0.1757,  0.0652, -0.2039],\n",
      "        [ 0.3604,  0.2625, -0.2725],\n",
      "        [ 0.1721,  0.0952, -0.0997],\n",
      "        [ 0.2983,  0.3213, -0.0323],\n",
      "        [ 0.2527,  0.6187, -0.1973],\n",
      "        [ 0.0174,  0.4497, -0.0567],\n",
      "        [ 0.2939,  0.4548, -0.5107],\n",
      "        [ 0.2467,  0.6489,  0.0787],\n",
      "        [ 0.1033,  0.3713, -0.2001],\n",
      "        [ 0.2380,  0.3308,  0.1312]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0594, 0.0449, 0.0618],\n",
      "        [0.0693, 0.0619, 0.0692],\n",
      "        [0.0641, 0.0550, 0.0720],\n",
      "        [0.0706, 0.0631, 0.0709],\n",
      "        [0.0570, 0.0533, 0.0662],\n",
      "        [0.0603, 0.0529, 0.0552],\n",
      "        [0.0592, 0.0489, 0.0557],\n",
      "        [0.0712, 0.0596, 0.0520],\n",
      "        [0.0590, 0.0504, 0.0618],\n",
      "        [0.0670, 0.0632, 0.0661],\n",
      "        [0.0640, 0.0850, 0.0561],\n",
      "        [0.0505, 0.0718, 0.0645],\n",
      "        [0.0667, 0.0722, 0.0410],\n",
      "        [0.0636, 0.0876, 0.0739],\n",
      "        [0.0551, 0.0664, 0.0559],\n",
      "        [0.0630, 0.0638, 0.0778]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.1663, -0.1267, -0.0781],\n",
      "        [ 0.0659,  0.3035, -0.1534],\n",
      "        [ 0.2551,  0.1180,  0.0493],\n",
      "        [ 0.3640,  0.2900, -0.0881],\n",
      "        [ 0.3521,  0.1019,  0.1488],\n",
      "        [ 0.3330,  0.3359,  0.2510],\n",
      "        [ 0.2729,  0.0112, -0.0241],\n",
      "        [ 0.1772,  0.4255,  0.3616],\n",
      "        [ 0.2937, -0.1536,  0.0324],\n",
      "        [ 0.1781,  0.2749,  0.2959],\n",
      "        [ 0.2812, -0.0560,  0.1956],\n",
      "        [ 0.1353,  0.2072,  0.2822],\n",
      "        [ 0.1823,  0.1305,  0.1273],\n",
      "        [ 0.2130,  0.1827,  0.3025],\n",
      "        [ 0.1622,  0.2490,  0.2683],\n",
      "        [ 0.2705,  0.1476,  0.0765],\n",
      "        [ 0.3130,  0.0503,  0.0320],\n",
      "        [ 0.1427,  0.1699,  0.4153],\n",
      "        [-0.0617, -0.0209,  0.4414],\n",
      "        [-0.1082, -0.0938,  0.4944],\n",
      "        [ 0.0809,  0.0727,  0.5996],\n",
      "        [ 0.0149,  0.0033,  0.4580],\n",
      "        [-0.1500, -0.0062,  0.5146],\n",
      "        [ 0.0732,  0.0670,  0.4377],\n",
      "        [ 0.2235, -0.1665,  0.5132],\n",
      "        [ 0.2041, -0.0247,  0.2847],\n",
      "        [ 0.2268,  0.0502,  0.3628],\n",
      "        [ 0.3298,  0.3662,  0.2356],\n",
      "        [ 0.0978,  0.1884,  0.4265],\n",
      "        [ 0.0759,  0.1990,  0.6177],\n",
      "        [ 0.1532,  0.1544,  0.2371],\n",
      "        [ 0.0947, -0.0169,  0.4221],\n",
      "        [ 0.1199,  0.0679,  0.5366],\n",
      "        [ 0.1115, -0.1801,  0.5591],\n",
      "        [ 0.2629,  0.0113,  0.4783],\n",
      "        [ 0.2098, -0.2362,  0.5215],\n",
      "        [ 0.1077,  0.0698,  0.1189],\n",
      "        [-0.1102, -0.0585,  0.1847],\n",
      "        [-0.0183,  0.0871,  0.3250],\n",
      "        [-0.1234,  0.2073,  0.2617],\n",
      "        [ 0.1605, -0.0298,  0.1591],\n",
      "        [ 0.2336,  0.2729,  0.2581],\n",
      "        [ 0.1357,  0.2433,  0.4707],\n",
      "        [-0.0238, -0.0717,  0.3691],\n",
      "        [ 0.0305,  0.0058,  0.3076],\n",
      "        [ 0.1636,  0.2079,  0.2443],\n",
      "        [ 0.1249,  0.0928,  0.1403],\n",
      "        [ 0.2544,  0.4668,  0.1971],\n",
      "        [ 0.1947,  0.1600,  0.1451],\n",
      "        [ 0.1891,  0.3652,  0.1721]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0202, 0.0157, 0.0137],\n",
      "        [0.0183, 0.0241, 0.0127],\n",
      "        [0.0221, 0.0201, 0.0156],\n",
      "        [0.0246, 0.0238, 0.0136],\n",
      "        [0.0243, 0.0197, 0.0172],\n",
      "        [0.0239, 0.0249, 0.0191],\n",
      "        [0.0225, 0.0180, 0.0145],\n",
      "        [0.0204, 0.0273, 0.0213],\n",
      "        [0.0229, 0.0153, 0.0154],\n",
      "        [0.0204, 0.0235, 0.0200],\n",
      "        [0.0227, 0.0168, 0.0181],\n",
      "        [0.0196, 0.0219, 0.0197],\n",
      "        [0.0205, 0.0203, 0.0169],\n",
      "        [0.0212, 0.0214, 0.0201],\n",
      "        [0.0201, 0.0229, 0.0194],\n",
      "        [0.0224, 0.0206, 0.0160],\n",
      "        [0.0234, 0.0187, 0.0153],\n",
      "        [0.0197, 0.0211, 0.0225],\n",
      "        [0.0161, 0.0175, 0.0231],\n",
      "        [0.0154, 0.0162, 0.0244],\n",
      "        [0.0185, 0.0192, 0.0271],\n",
      "        [0.0174, 0.0179, 0.0235],\n",
      "        [0.0147, 0.0177, 0.0249],\n",
      "        [0.0184, 0.0191, 0.0230],\n",
      "        [0.0214, 0.0151, 0.0248],\n",
      "        [0.0210, 0.0174, 0.0198],\n",
      "        [0.0215, 0.0187, 0.0214],\n",
      "        [0.0238, 0.0257, 0.0188],\n",
      "        [0.0189, 0.0215, 0.0228],\n",
      "        [0.0184, 0.0217, 0.0276],\n",
      "        [0.0199, 0.0208, 0.0188],\n",
      "        [0.0188, 0.0175, 0.0227],\n",
      "        [0.0193, 0.0191, 0.0254],\n",
      "        [0.0191, 0.0149, 0.0260],\n",
      "        [0.0222, 0.0180, 0.0240],\n",
      "        [0.0211, 0.0141, 0.0250],\n",
      "        [0.0190, 0.0191, 0.0167],\n",
      "        [0.0153, 0.0168, 0.0179],\n",
      "        [0.0168, 0.0194, 0.0206],\n",
      "        [0.0151, 0.0219, 0.0193],\n",
      "        [0.0201, 0.0173, 0.0174],\n",
      "        [0.0216, 0.0234, 0.0192],\n",
      "        [0.0196, 0.0227, 0.0238],\n",
      "        [0.0167, 0.0166, 0.0215],\n",
      "        [0.0176, 0.0179, 0.0202],\n",
      "        [0.0201, 0.0219, 0.0190],\n",
      "        [0.0194, 0.0195, 0.0171],\n",
      "        [0.0220, 0.0284, 0.0181],\n",
      "        [0.0208, 0.0209, 0.0172],\n",
      "        [0.0207, 0.0257, 0.0177]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.1576, -0.1533,  0.0089],\n",
      "        [ 0.3848,  0.3069, -0.0336],\n",
      "        [ 0.0861,  0.3750, -0.1895],\n",
      "        [ 0.3225,  0.3308,  0.0294],\n",
      "        [ 0.2502, -0.1523, -0.0273],\n",
      "        [ 0.0039,  0.0657,  0.1543],\n",
      "        [-0.0078,  0.1248,  0.0899],\n",
      "        [-0.1378,  0.0637,  0.1461],\n",
      "        [-0.0512, -0.3069,  0.0702],\n",
      "        [ 0.2029, -0.0760, -0.1793],\n",
      "        [ 0.1344, -0.0903, -0.0264],\n",
      "        [ 0.1543,  0.1675,  0.3496],\n",
      "        [ 0.2360,  0.3342,  0.2568],\n",
      "        [ 0.0309, -0.1004,  0.2295],\n",
      "        [ 0.0156,  0.0676,  0.1630],\n",
      "        [ 0.0366,  0.0891,  0.2717],\n",
      "        [-0.0620, -0.1396,  0.2708],\n",
      "        [ 0.1713,  0.1072,  0.2668],\n",
      "        [ 0.1438, -0.0054,  0.1725],\n",
      "        [ 0.2661,  0.0328,  0.1770]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0516, 0.0400, 0.0447],\n",
      "        [0.0648, 0.0634, 0.0428],\n",
      "        [0.0480, 0.0679, 0.0367],\n",
      "        [0.0609, 0.0649, 0.0457],\n",
      "        [0.0566, 0.0401, 0.0431],\n",
      "        [0.0443, 0.0498, 0.0517],\n",
      "        [0.0437, 0.0529, 0.0485],\n",
      "        [0.0384, 0.0497, 0.0513],\n",
      "        [0.0419, 0.0344, 0.0475],\n",
      "        [0.0540, 0.0432, 0.0370],\n",
      "        [0.0504, 0.0426, 0.0432],\n",
      "        [0.0514, 0.0552, 0.0629],\n",
      "        [0.0558, 0.0652, 0.0573],\n",
      "        [0.0455, 0.0422, 0.0558],\n",
      "        [0.0448, 0.0500, 0.0522],\n",
      "        [0.0457, 0.0510, 0.0582],\n",
      "        [0.0414, 0.0406, 0.0581],\n",
      "        [0.0523, 0.0520, 0.0579],\n",
      "        [0.0509, 0.0464, 0.0527],\n",
      "        [0.0575, 0.0482, 0.0529]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0942, -0.2386,  0.1309],\n",
      "        [ 0.3706,  0.5156, -0.0414],\n",
      "        [ 0.1750,  0.1296,  0.0156],\n",
      "        [ 0.3267, -0.0042,  0.0917],\n",
      "        [ 0.3591, -0.0284, -0.0547],\n",
      "        [ 0.4250,  0.2246,  0.0321],\n",
      "        [ 0.4512,  0.1364, -0.2581],\n",
      "        [ 0.3147,  0.1801,  0.3831],\n",
      "        [ 0.1088,  0.0433,  0.3330],\n",
      "        [-0.0456,  0.1106,  0.5190],\n",
      "        [ 0.1918,  0.1357,  0.1854],\n",
      "        [ 0.3516,  0.3694,  0.3472],\n",
      "        [ 0.3411,  0.0723,  0.1124],\n",
      "        [ 0.0264,  0.1486,  0.4805],\n",
      "        [ 0.0113,  0.0196,  0.1746],\n",
      "        [-0.0307,  0.2510,  0.1080],\n",
      "        [-0.0012,  0.0447,  0.0191],\n",
      "        [ 0.2700,  0.2520,  0.3472],\n",
      "        [ 0.2681,  0.2019,  0.4365],\n",
      "        [ 0.0785,  0.1981,  0.3235],\n",
      "        [ 0.0656,  0.2786,  0.3000],\n",
      "        [ 0.0620,  0.2419,  0.2063],\n",
      "        [ 0.1003,  0.1499,  0.0939],\n",
      "        [ 0.4839,  0.2942,  0.0959],\n",
      "        [ 0.4238,  0.2482, -0.1448],\n",
      "        [ 0.4651,  0.3696,  0.2242],\n",
      "        [ 0.2708, -0.0023,  0.2418],\n",
      "        [ 0.1436,  0.1615,  0.1375],\n",
      "        [ 0.1637,  0.2549,  0.0854],\n",
      "        [ 0.2144,  0.0787,  0.1873],\n",
      "        [-0.1145,  0.1732,  0.1987],\n",
      "        [ 0.0111,  0.2900,  0.1418],\n",
      "        [ 0.0334,  0.3171,  0.2668],\n",
      "        [ 0.0360,  0.5308,  0.2173],\n",
      "        [-0.0450,  0.0910,  0.3613],\n",
      "        [ 0.0869,  0.1076,  0.0422],\n",
      "        [ 0.3022,  0.1755,  0.3586],\n",
      "        [ 0.1951,  0.0174,  0.1161],\n",
      "        [-0.0800,  0.3059,  0.1171],\n",
      "        [ 0.1157, -0.0212,  0.0399],\n",
      "        [-0.0286,  0.1887,  0.4861],\n",
      "        [ 0.0872,  0.4783,  0.1854],\n",
      "        [ 0.0552,  0.1798,  0.2035],\n",
      "        [ 0.0458,  0.0966,  0.2761],\n",
      "        [-0.1718, -0.0714,  0.2466],\n",
      "        [ 0.1199, -0.0616,  0.3772],\n",
      "        [ 0.2810, -0.2498, -0.0699],\n",
      "        [ 0.3306, -0.2859,  0.0935],\n",
      "        [ 0.1869, -0.0228,  0.0382],\n",
      "        [ 0.3223,  0.1467,  0.2939],\n",
      "        [ 0.0701,  0.2070, -0.0111],\n",
      "        [-0.0199,  0.3235,  0.2737],\n",
      "        [-0.0146,  0.3181,  0.3025],\n",
      "        [ 0.1543,  0.2847,  0.2354],\n",
      "        [ 0.0813,  0.2576, -0.0207],\n",
      "        [ 0.1146,  0.0418,  0.2148],\n",
      "        [ 0.1558,  0.0279, -0.0572],\n",
      "        [ 0.5894,  0.3884, -0.0890],\n",
      "        [ 0.3252, -0.0330, -0.0414],\n",
      "        [ 0.4343,  0.0539,  0.1487]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0152, 0.0111, 0.0159],\n",
      "        [0.0201, 0.0237, 0.0133],\n",
      "        [0.0165, 0.0161, 0.0141],\n",
      "        [0.0192, 0.0141, 0.0152],\n",
      "        [0.0199, 0.0137, 0.0132],\n",
      "        [0.0212, 0.0177, 0.0144],\n",
      "        [0.0218, 0.0162, 0.0107],\n",
      "        [0.0190, 0.0169, 0.0204],\n",
      "        [0.0155, 0.0148, 0.0194],\n",
      "        [0.0133, 0.0158, 0.0234],\n",
      "        [0.0168, 0.0162, 0.0167],\n",
      "        [0.0197, 0.0204, 0.0197],\n",
      "        [0.0195, 0.0152, 0.0156],\n",
      "        [0.0142, 0.0164, 0.0225],\n",
      "        [0.0140, 0.0144, 0.0166],\n",
      "        [0.0135, 0.0182, 0.0155],\n",
      "        [0.0139, 0.0148, 0.0142],\n",
      "        [0.0182, 0.0182, 0.0197],\n",
      "        [0.0181, 0.0173, 0.0215],\n",
      "        [0.0150, 0.0172, 0.0192],\n",
      "        [0.0148, 0.0187, 0.0188],\n",
      "        [0.0148, 0.0180, 0.0171],\n",
      "        [0.0153, 0.0164, 0.0153],\n",
      "        [0.0225, 0.0190, 0.0153],\n",
      "        [0.0212, 0.0181, 0.0120],\n",
      "        [0.0221, 0.0204, 0.0174],\n",
      "        [0.0182, 0.0141, 0.0177],\n",
      "        [0.0160, 0.0166, 0.0160],\n",
      "        [0.0163, 0.0182, 0.0151],\n",
      "        [0.0172, 0.0153, 0.0168],\n",
      "        [0.0124, 0.0168, 0.0170],\n",
      "        [0.0140, 0.0189, 0.0160],\n",
      "        [0.0144, 0.0194, 0.0182],\n",
      "        [0.0144, 0.0240, 0.0173],\n",
      "        [0.0133, 0.0155, 0.0200],\n",
      "        [0.0151, 0.0157, 0.0145],\n",
      "        [0.0188, 0.0168, 0.0199],\n",
      "        [0.0169, 0.0144, 0.0156],\n",
      "        [0.0128, 0.0192, 0.0156],\n",
      "        [0.0156, 0.0138, 0.0145],\n",
      "        [0.0135, 0.0171, 0.0226],\n",
      "        [0.0151, 0.0228, 0.0167],\n",
      "        [0.0147, 0.0169, 0.0170],\n",
      "        [0.0145, 0.0156, 0.0183],\n",
      "        [0.0117, 0.0132, 0.0178],\n",
      "        [0.0156, 0.0133, 0.0203],\n",
      "        [0.0184, 0.0110, 0.0130],\n",
      "        [0.0193, 0.0106, 0.0153],\n",
      "        [0.0167, 0.0138, 0.0145],\n",
      "        [0.0191, 0.0164, 0.0187],\n",
      "        [0.0149, 0.0174, 0.0137],\n",
      "        [0.0136, 0.0195, 0.0183],\n",
      "        [0.0137, 0.0194, 0.0188],\n",
      "        [0.0162, 0.0188, 0.0176],\n",
      "        [0.0150, 0.0183, 0.0136],\n",
      "        [0.0156, 0.0147, 0.0172],\n",
      "        [0.0162, 0.0145, 0.0131],\n",
      "        [0.0250, 0.0208, 0.0127],\n",
      "        [0.0192, 0.0137, 0.0133],\n",
      "        [0.0214, 0.0149, 0.0161]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0367, -0.1252,  0.0117],\n",
      "        [ 0.3909,  0.1628, -0.2439],\n",
      "        [ 0.1029, -0.0388, -0.0713],\n",
      "        [ 0.2360,  0.0237, -0.0128],\n",
      "        [ 0.0186,  0.1121, -0.0365],\n",
      "        [ 0.1542,  0.2267, -0.1111],\n",
      "        [ 0.1740,  0.0792,  0.0255],\n",
      "        [-0.0615,  0.1917,  0.0351],\n",
      "        [-0.0601, -0.0869,  0.0420],\n",
      "        [-0.0299,  0.0793, -0.0108],\n",
      "        [ 0.0960, -0.1074,  0.1158],\n",
      "        [ 0.0186,  0.1084,  0.1543]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0732, 0.0693, 0.0847],\n",
      "        [0.1123, 0.0925, 0.0656],\n",
      "        [0.0842, 0.0756, 0.0779],\n",
      "        [0.0962, 0.0805, 0.0826],\n",
      "        [0.0774, 0.0879, 0.0806],\n",
      "        [0.0886, 0.0986, 0.0749],\n",
      "        [0.0904, 0.0851, 0.0858],\n",
      "        [0.0715, 0.0952, 0.0866],\n",
      "        [0.0715, 0.0721, 0.0873],\n",
      "        [0.0737, 0.0851, 0.0827],\n",
      "        [0.0836, 0.0706, 0.0939],\n",
      "        [0.0774, 0.0876, 0.0976]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0869, -0.0694, -0.1064],\n",
      "        [ 0.4006, -0.2615, -0.1273],\n",
      "        [ 0.0743,  0.2744, -0.2498],\n",
      "        [ 0.1932, -0.0112,  0.1791],\n",
      "        [-0.1906,  0.0201, -0.0555],\n",
      "        [-0.1814,  0.1466,  0.3394],\n",
      "        [-0.0432,  0.0229,  0.0128],\n",
      "        [-0.0429,  0.2462,  0.2010],\n",
      "        [ 0.0503,  0.3171, -0.2144],\n",
      "        [ 0.2222,  0.3137, -0.3152],\n",
      "        [-0.0515,  0.1931, -0.1925],\n",
      "        [ 0.0903,  0.1971,  0.0012],\n",
      "        [-0.0142,  0.1511, -0.1237],\n",
      "        [-0.0252,  0.0218, -0.0054],\n",
      "        [ 0.1311, -0.0265,  0.0537],\n",
      "        [ 0.3330,  0.2842,  0.0925],\n",
      "        [ 0.0800, -0.0602, -0.1196],\n",
      "        [-0.2163,  0.0499,  0.1860],\n",
      "        [-0.0757,  0.2241,  0.4993],\n",
      "        [-0.3154, -0.0638,  0.4121],\n",
      "        [-0.3228, -0.0904,  0.6382],\n",
      "        [-0.0533, -0.1871,  0.2443],\n",
      "        [-0.0781, -0.2947,  0.1453],\n",
      "        [-0.1322, -0.1886,  0.2372],\n",
      "        [ 0.0339, -0.5464,  0.1451],\n",
      "        [ 0.1346, -0.4055,  0.1583],\n",
      "        [-0.0257, -0.4526,  0.3625],\n",
      "        [-0.0117, -0.4419,  0.2893],\n",
      "        [-0.1098, -0.5845,  0.1864],\n",
      "        [-0.2169, -0.3684,  0.6689],\n",
      "        [-0.1816,  0.0615,  0.5151],\n",
      "        [-0.3418, -0.2062,  0.4087],\n",
      "        [-0.0425, -0.3154,  0.4460],\n",
      "        [-0.3103, -0.2654,  0.4077],\n",
      "        [-0.2439, -0.1036,  0.1301],\n",
      "        [-0.2294, -0.3540,  0.2905],\n",
      "        [-0.0964,  0.0712,  0.5366],\n",
      "        [-0.2756, -0.2119,  0.5654],\n",
      "        [-0.0030, -0.1958,  0.5469],\n",
      "        [-0.2532, -0.0137,  0.4265],\n",
      "        [-0.2874,  0.2874,  0.5156],\n",
      "        [-0.1907, -0.1716,  0.5835],\n",
      "        [-0.0015,  0.0305,  0.5386],\n",
      "        [-0.3188, -0.4082,  0.1342],\n",
      "        [ 0.0374, -0.0578,  0.3455],\n",
      "        [-0.0211, -0.1692,  0.1411],\n",
      "        [-0.1561, -0.2996,  0.2249],\n",
      "        [-0.0956, -0.3298,  0.0464],\n",
      "        [-0.1228, -0.1489,  0.2832],\n",
      "        [-0.0667, -0.0599,  0.3022],\n",
      "        [-0.0204, -0.0586,  0.3655],\n",
      "        [-0.1301, -0.2091,  0.4668],\n",
      "        [-0.0243, -0.2169,  0.1172],\n",
      "        [ 0.2023,  0.0729,  0.0838],\n",
      "        [ 0.1844,  0.1123, -0.1195],\n",
      "        [ 0.2761, -0.0249,  0.0675]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0202, 0.0177, 0.0126],\n",
      "        [0.0277, 0.0146, 0.0123],\n",
      "        [0.0200, 0.0249, 0.0109],\n",
      "        [0.0225, 0.0188, 0.0168],\n",
      "        [0.0153, 0.0193, 0.0133],\n",
      "        [0.0155, 0.0220, 0.0197],\n",
      "        [0.0178, 0.0194, 0.0142],\n",
      "        [0.0178, 0.0243, 0.0171],\n",
      "        [0.0195, 0.0260, 0.0113],\n",
      "        [0.0232, 0.0260, 0.0102],\n",
      "        [0.0176, 0.0230, 0.0116],\n",
      "        [0.0203, 0.0231, 0.0140],\n",
      "        [0.0183, 0.0221, 0.0124],\n",
      "        [0.0181, 0.0194, 0.0139],\n",
      "        [0.0211, 0.0185, 0.0148],\n",
      "        [0.0259, 0.0252, 0.0154],\n",
      "        [0.0201, 0.0179, 0.0124],\n",
      "        [0.0149, 0.0199, 0.0169],\n",
      "        [0.0172, 0.0237, 0.0231],\n",
      "        [0.0135, 0.0178, 0.0212],\n",
      "        [0.0134, 0.0173, 0.0265],\n",
      "        [0.0176, 0.0157, 0.0179],\n",
      "        [0.0172, 0.0141, 0.0162],\n",
      "        [0.0163, 0.0157, 0.0178],\n",
      "        [0.0192, 0.0110, 0.0162],\n",
      "        [0.0212, 0.0126, 0.0164],\n",
      "        [0.0181, 0.0121, 0.0201],\n",
      "        [0.0183, 0.0122, 0.0187],\n",
      "        [0.0166, 0.0106, 0.0169],\n",
      "        [0.0149, 0.0131, 0.0274],\n",
      "        [0.0155, 0.0202, 0.0235],\n",
      "        [0.0132, 0.0154, 0.0211],\n",
      "        [0.0178, 0.0138, 0.0219],\n",
      "        [0.0136, 0.0145, 0.0211],\n",
      "        [0.0145, 0.0171, 0.0160],\n",
      "        [0.0148, 0.0133, 0.0187],\n",
      "        [0.0168, 0.0204, 0.0240],\n",
      "        [0.0141, 0.0153, 0.0247],\n",
      "        [0.0185, 0.0156, 0.0242],\n",
      "        [0.0144, 0.0187, 0.0215],\n",
      "        [0.0139, 0.0253, 0.0235],\n",
      "        [0.0153, 0.0160, 0.0251],\n",
      "        [0.0185, 0.0195, 0.0240],\n",
      "        [0.0135, 0.0126, 0.0160],\n",
      "        [0.0193, 0.0179, 0.0198],\n",
      "        [0.0182, 0.0160, 0.0161],\n",
      "        [0.0159, 0.0140, 0.0175],\n",
      "        [0.0169, 0.0136, 0.0147],\n",
      "        [0.0164, 0.0163, 0.0186],\n",
      "        [0.0173, 0.0179, 0.0190],\n",
      "        [0.0182, 0.0179, 0.0202],\n",
      "        [0.0163, 0.0154, 0.0224],\n",
      "        [0.0181, 0.0153, 0.0158],\n",
      "        [0.0227, 0.0204, 0.0152],\n",
      "        [0.0223, 0.0212, 0.0124],\n",
      "        [0.0245, 0.0185, 0.0150]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 2.6962e-02, -3.6279e-01,  9.0942e-03],\n",
      "        [ 4.5068e-01,  3.8159e-01,  5.0598e-02],\n",
      "        [ 1.5710e-01,  1.8066e-01, -1.4575e-01],\n",
      "        [ 4.4800e-01,  3.4229e-01,  4.8126e-02],\n",
      "        [-1.2421e-01,  2.3303e-01,  9.8705e-05],\n",
      "        [ 2.5864e-02,  4.1528e-01, -1.9073e-03],\n",
      "        [-3.4576e-02,  1.0468e-01,  2.1655e-01],\n",
      "        [ 1.7981e-01,  1.5552e-01,  7.2144e-02],\n",
      "        [-1.1511e-01,  2.2876e-01, -1.3647e-01],\n",
      "        [ 2.8760e-01,  3.4790e-01,  2.0801e-01],\n",
      "        [ 1.0736e-01,  1.3135e-01, -1.9287e-02],\n",
      "        [ 2.4463e-01,  3.8965e-01,  3.4082e-01]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0733, 0.0460, 0.0790],\n",
      "        [0.1119, 0.0969, 0.0823],\n",
      "        [0.0835, 0.0793, 0.0676],\n",
      "        [0.1117, 0.0932, 0.0821],\n",
      "        [0.0630, 0.0836, 0.0782],\n",
      "        [0.0732, 0.1002, 0.0781],\n",
      "        [0.0689, 0.0735, 0.0972],\n",
      "        [0.0854, 0.0773, 0.0840],\n",
      "        [0.0636, 0.0832, 0.0683],\n",
      "        [0.0951, 0.0938, 0.0963],\n",
      "        [0.0794, 0.0755, 0.0768],\n",
      "        [0.0911, 0.0977, 0.1100]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0060, -0.0585, -0.0353],\n",
      "        [ 0.1022,  0.4463, -0.0499],\n",
      "        [ 0.1027,  0.0055,  0.1295],\n",
      "        [ 0.1464,  0.4443,  0.0125],\n",
      "        [ 0.0281,  0.0363,  0.3062],\n",
      "        [ 0.0518,  0.2847,  0.4236],\n",
      "        [ 0.0100,  0.1199,  0.3835],\n",
      "        [-0.1353,  0.2227,  0.4463],\n",
      "        [-0.1373,  0.2988,  0.4556],\n",
      "        [-0.1519,  0.3242,  0.3462],\n",
      "        [-0.0735, -0.0534,  0.1619],\n",
      "        [ 0.1902,  0.4309, -0.1356],\n",
      "        [-0.3835,  0.0441,  0.1113],\n",
      "        [ 0.0886,  0.4763,  0.1632],\n",
      "        [-0.2634,  0.0569,  0.0359],\n",
      "        [-0.4214,  0.3542,  0.2327],\n",
      "        [-0.4675,  0.0211,  0.2081],\n",
      "        [-0.0099,  0.3630,  0.0199],\n",
      "        [-0.4636,  0.1348, -0.1599],\n",
      "        [-0.3884,  0.4241,  0.1600],\n",
      "        [-0.2610,  0.2102,  0.3889],\n",
      "        [-0.3909,  0.1775,  0.2416],\n",
      "        [-0.1261, -0.2206,  0.1963],\n",
      "        [ 0.0640,  0.2213, -0.0646],\n",
      "        [-0.0205, -0.0779, -0.0093],\n",
      "        [ 0.0331, -0.1027, -0.1202],\n",
      "        [-0.0210, -0.1305,  0.2458],\n",
      "        [ 0.0239,  0.0131,  0.2241],\n",
      "        [ 0.0384,  0.2561,  0.1039],\n",
      "        [ 0.0150,  0.3269,  0.2087],\n",
      "        [-0.0524, -0.0522,  0.3025],\n",
      "        [ 0.1630,  0.2708,  0.1088],\n",
      "        [ 0.1710,  0.2361, -0.0886],\n",
      "        [ 0.1418,  0.3013,  0.0213]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0308, 0.0230, 0.0242],\n",
      "        [0.0344, 0.0381, 0.0238],\n",
      "        [0.0344, 0.0245, 0.0285],\n",
      "        [0.0359, 0.0380, 0.0253],\n",
      "        [0.0319, 0.0253, 0.0340],\n",
      "        [0.0327, 0.0324, 0.0382],\n",
      "        [0.0313, 0.0275, 0.0367],\n",
      "        [0.0271, 0.0304, 0.0391],\n",
      "        [0.0270, 0.0328, 0.0395],\n",
      "        [0.0266, 0.0337, 0.0354],\n",
      "        [0.0288, 0.0231, 0.0294],\n",
      "        [0.0375, 0.0375, 0.0219],\n",
      "        [0.0211, 0.0255, 0.0280],\n",
      "        [0.0339, 0.0392, 0.0295],\n",
      "        [0.0238, 0.0258, 0.0259],\n",
      "        [0.0203, 0.0347, 0.0316],\n",
      "        [0.0194, 0.0249, 0.0308],\n",
      "        [0.0307, 0.0350, 0.0255],\n",
      "        [0.0195, 0.0279, 0.0213],\n",
      "        [0.0210, 0.0372, 0.0294],\n",
      "        [0.0239, 0.0300, 0.0369],\n",
      "        [0.0210, 0.0291, 0.0319],\n",
      "        [0.0273, 0.0195, 0.0305],\n",
      "        [0.0331, 0.0304, 0.0235],\n",
      "        [0.0304, 0.0225, 0.0248],\n",
      "        [0.0320, 0.0220, 0.0222],\n",
      "        [0.0303, 0.0214, 0.0320],\n",
      "        [0.0317, 0.0247, 0.0313],\n",
      "        [0.0322, 0.0315, 0.0278],\n",
      "        [0.0315, 0.0338, 0.0308],\n",
      "        [0.0294, 0.0231, 0.0339],\n",
      "        [0.0365, 0.0319, 0.0279],\n",
      "        [0.0368, 0.0309, 0.0229],\n",
      "        [0.0357, 0.0329, 0.0256]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0750, -0.2474,  0.0293],\n",
      "        [ 0.4277,  0.1907,  0.0309],\n",
      "        [ 0.1907,  0.3020,  0.3101],\n",
      "        [ 0.4255,  0.5845,  0.2169],\n",
      "        [ 0.1483,  0.3230,  0.1544],\n",
      "        [ 0.3220,  0.2141,  0.0068],\n",
      "        [ 0.2676,  0.0761,  0.0962],\n",
      "        [ 0.3240,  0.1471, -0.0190],\n",
      "        [ 0.3679,  0.1715,  0.0470],\n",
      "        [ 0.1792,  0.1243,  0.1787],\n",
      "        [ 0.0942,  0.1738,  0.1797],\n",
      "        [-0.0379, -0.0571,  0.2218],\n",
      "        [ 0.0093,  0.2014,  0.4397],\n",
      "        [-0.0041,  0.3054,  0.2368],\n",
      "        [-0.1167,  0.1660,  0.2551],\n",
      "        [-0.1868,  0.0699,  0.2502],\n",
      "        [-0.1000,  0.1168,  0.0182],\n",
      "        [ 0.1240,  0.0409,  0.2849],\n",
      "        [-0.1047, -0.0220,  0.1659],\n",
      "        [ 0.3245,  0.1467,  0.2815]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0462, 0.0331, 0.0432],\n",
      "        [0.0657, 0.0513, 0.0432],\n",
      "        [0.0519, 0.0573, 0.0572],\n",
      "        [0.0656, 0.0760, 0.0521],\n",
      "        [0.0497, 0.0586, 0.0489],\n",
      "        [0.0592, 0.0525, 0.0422],\n",
      "        [0.0560, 0.0457, 0.0461],\n",
      "        [0.0593, 0.0491, 0.0411],\n",
      "        [0.0619, 0.0503, 0.0439],\n",
      "        [0.0513, 0.0480, 0.0501],\n",
      "        [0.0471, 0.0504, 0.0502],\n",
      "        [0.0413, 0.0400, 0.0523],\n",
      "        [0.0433, 0.0518, 0.0651],\n",
      "        [0.0427, 0.0575, 0.0531],\n",
      "        [0.0381, 0.0501, 0.0541],\n",
      "        [0.0356, 0.0455, 0.0538],\n",
      "        [0.0388, 0.0477, 0.0427],\n",
      "        [0.0485, 0.0442, 0.0557],\n",
      "        [0.0386, 0.0415, 0.0495],\n",
      "        [0.0593, 0.0491, 0.0555]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.2529,  0.0313, -0.0941],\n",
      "        [ 0.4482,  0.0759, -0.2380],\n",
      "        [ 0.1710,  0.0729, -0.1641],\n",
      "        [ 0.0411,  0.1191,  0.2253],\n",
      "        [-0.0920,  0.1459,  0.0567],\n",
      "        [ 0.0435,  0.0645,  0.0423],\n",
      "        [ 0.1454, -0.3833, -0.0307],\n",
      "        [ 0.1592,  0.0206,  0.0053],\n",
      "        [ 0.3252, -0.0684, -0.2922],\n",
      "        [-0.0710,  0.0781,  0.0722],\n",
      "        [ 0.1178,  0.1500,  0.3235],\n",
      "        [-0.0071,  0.0833,  0.3464],\n",
      "        [-0.0393, -0.0245,  0.2280],\n",
      "        [ 0.0790,  0.1272,  0.2771],\n",
      "        [-0.1635,  0.3347,  0.2839],\n",
      "        [-0.1368,  0.0431,  0.3545],\n",
      "        [-0.2252, -0.0649,  0.3967],\n",
      "        [-0.2346, -0.0284,  0.2013],\n",
      "        [-0.1827, -0.0353, -0.0239],\n",
      "        [ 0.2566,  0.3423,  0.2258],\n",
      "        [ 0.2515,  0.0917, -0.3335],\n",
      "        [ 0.2455,  0.0788,  0.0703],\n",
      "        [ 0.0210,  0.0507, -0.0146],\n",
      "        [ 0.1368,  0.0873,  0.0114],\n",
      "        [ 0.0997,  0.1593, -0.3074],\n",
      "        [ 0.3176,  0.2927, -0.0670],\n",
      "        [-0.1860,  0.0218, -0.1266],\n",
      "        [-0.1203,  0.0127,  0.2573],\n",
      "        [-0.0460, -0.1882,  0.2778],\n",
      "        [-0.1199, -0.2100,  0.1388],\n",
      "        [-0.1528, -0.1022, -0.2347],\n",
      "        [ 0.0608,  0.2230,  0.2078],\n",
      "        [ 0.1602,  0.1331, -0.1202],\n",
      "        [ 0.1121,  0.3208, -0.0814],\n",
      "        [ 0.0846,  0.1665, -0.2207],\n",
      "        [ 0.1333,  0.2708, -0.1362],\n",
      "        [ 0.0621, -0.1433, -0.0991],\n",
      "        [ 0.0244,  0.1771,  0.2888],\n",
      "        [-0.1765, -0.1237,  0.4541],\n",
      "        [-0.1550,  0.0263,  0.1953],\n",
      "        [-0.0221,  0.1558,  0.2466],\n",
      "        [-0.1237,  0.0549,  0.6265],\n",
      "        [-0.0747, -0.0229,  0.3914],\n",
      "        [-0.0637,  0.0995,  0.2705],\n",
      "        [-0.0886,  0.0418, -0.2174],\n",
      "        [ 0.0670,  0.4380,  0.3391],\n",
      "        [-0.0287, -0.0114,  0.0341],\n",
      "        [-0.1049,  0.5869,  0.0473],\n",
      "        [-0.0042,  0.2734, -0.1201],\n",
      "        [ 0.0298,  0.1407,  0.1312],\n",
      "        [ 0.1752,  0.0097, -0.1924],\n",
      "        [ 0.2581,  0.3276,  0.0513],\n",
      "        [ 0.2437,  0.1826,  0.0540],\n",
      "        [ 0.0554,  0.3748,  0.2605],\n",
      "        [ 0.0574,  0.2849,  0.3877],\n",
      "        [ 0.0130,  0.2524,  0.4414],\n",
      "        [ 0.2290, -0.0697,  0.0948],\n",
      "        [ 0.0379,  0.4041,  0.1892],\n",
      "        [ 0.2347,  0.0823, -0.1527],\n",
      "        [ 0.0111,  0.5093,  0.0962]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0203, 0.0152, 0.0135],\n",
      "        [0.0247, 0.0159, 0.0117],\n",
      "        [0.0187, 0.0158, 0.0126],\n",
      "        [0.0164, 0.0166, 0.0186],\n",
      "        [0.0144, 0.0170, 0.0157],\n",
      "        [0.0165, 0.0157, 0.0155],\n",
      "        [0.0182, 0.0100, 0.0144],\n",
      "        [0.0185, 0.0150, 0.0150],\n",
      "        [0.0219, 0.0137, 0.0111],\n",
      "        [0.0147, 0.0159, 0.0160],\n",
      "        [0.0178, 0.0171, 0.0206],\n",
      "        [0.0157, 0.0160, 0.0211],\n",
      "        [0.0152, 0.0144, 0.0187],\n",
      "        [0.0171, 0.0167, 0.0196],\n",
      "        [0.0134, 0.0206, 0.0198],\n",
      "        [0.0138, 0.0154, 0.0212],\n",
      "        [0.0126, 0.0138, 0.0221],\n",
      "        [0.0125, 0.0143, 0.0182],\n",
      "        [0.0132, 0.0142, 0.0145],\n",
      "        [0.0204, 0.0207, 0.0187],\n",
      "        [0.0203, 0.0161, 0.0107],\n",
      "        [0.0202, 0.0159, 0.0160],\n",
      "        [0.0161, 0.0155, 0.0147],\n",
      "        [0.0181, 0.0161, 0.0151],\n",
      "        [0.0174, 0.0172, 0.0109],\n",
      "        [0.0217, 0.0197, 0.0139],\n",
      "        [0.0131, 0.0150, 0.0131],\n",
      "        [0.0140, 0.0149, 0.0193],\n",
      "        [0.0151, 0.0122, 0.0197],\n",
      "        [0.0140, 0.0119, 0.0171],\n",
      "        [0.0135, 0.0133, 0.0118],\n",
      "        [0.0168, 0.0184, 0.0183],\n",
      "        [0.0185, 0.0168, 0.0132],\n",
      "        [0.0177, 0.0203, 0.0137],\n",
      "        [0.0172, 0.0174, 0.0119],\n",
      "        [0.0180, 0.0193, 0.0130],\n",
      "        [0.0168, 0.0127, 0.0135],\n",
      "        [0.0162, 0.0175, 0.0199],\n",
      "        [0.0132, 0.0130, 0.0234],\n",
      "        [0.0135, 0.0151, 0.0181],\n",
      "        [0.0154, 0.0172, 0.0191],\n",
      "        [0.0139, 0.0155, 0.0278],\n",
      "        [0.0146, 0.0144, 0.0220],\n",
      "        [0.0148, 0.0163, 0.0195],\n",
      "        [0.0144, 0.0153, 0.0120],\n",
      "        [0.0169, 0.0228, 0.0209],\n",
      "        [0.0153, 0.0145, 0.0154],\n",
      "        [0.0142, 0.0265, 0.0156],\n",
      "        [0.0157, 0.0193, 0.0132],\n",
      "        [0.0163, 0.0169, 0.0170],\n",
      "        [0.0188, 0.0149, 0.0123],\n",
      "        [0.0204, 0.0204, 0.0157],\n",
      "        [0.0201, 0.0177, 0.0157],\n",
      "        [0.0167, 0.0214, 0.0193],\n",
      "        [0.0167, 0.0196, 0.0219],\n",
      "        [0.0160, 0.0189, 0.0231],\n",
      "        [0.0199, 0.0137, 0.0164],\n",
      "        [0.0164, 0.0220, 0.0180],\n",
      "        [0.0200, 0.0160, 0.0128],\n",
      "        [0.0160, 0.0245, 0.0164]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.2681, -0.2974,  0.1068],\n",
      "        [ 0.2913,  0.2478, -0.2207],\n",
      "        [-0.1906, -0.0253,  0.0555],\n",
      "        [ 0.1833,  0.0939,  0.1615],\n",
      "        [-0.1758, -0.1032,  0.1160],\n",
      "        [-0.0263,  0.0892,  0.0354],\n",
      "        [ 0.0545, -0.0556, -0.0026],\n",
      "        [-0.0201,  0.0535, -0.1248],\n",
      "        [ 0.0101,  0.0536, -0.0080],\n",
      "        [ 0.1985,  0.1326,  0.0862],\n",
      "        [ 0.0695,  0.0917,  0.0722],\n",
      "        [ 0.1833,  0.2837,  0.4399],\n",
      "        [-0.0455,  0.1296,  0.3940],\n",
      "        [ 0.2673,  0.7222,  0.2805],\n",
      "        [ 0.2489,  0.2542,  0.2830],\n",
      "        [ 0.0644,  0.7954,  0.3789],\n",
      "        [ 0.2307,  0.2440,  0.0312],\n",
      "        [ 0.0485,  0.3538,  0.2761],\n",
      "        [-0.2064, -0.2219,  0.5190],\n",
      "        [-0.2427,  0.1565,  0.4944],\n",
      "        [-0.3477, -0.1405,  0.5845],\n",
      "        [-0.2167, -0.0797,  0.5654],\n",
      "        [-0.2435, -0.0813,  0.4236],\n",
      "        [-0.1444,  0.0095,  0.6509],\n",
      "        [-0.0196,  0.0862,  0.7378],\n",
      "        [-0.0735, -0.0216,  0.5244],\n",
      "        [ 0.0191,  0.1337,  0.1569],\n",
      "        [-0.0825,  0.0349,  0.1680],\n",
      "        [ 0.0527,  0.0069,  0.2759],\n",
      "        [-0.1119, -0.2722,  0.5239],\n",
      "        [-0.2598, -0.1216,  0.6211],\n",
      "        [-0.0985,  0.4446,  0.3909],\n",
      "        [ 0.3169,  0.1548,  0.0739],\n",
      "        [ 0.0231,  0.7134,  0.2380]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0378, 0.0188, 0.0242],\n",
      "        [0.0387, 0.0324, 0.0174],\n",
      "        [0.0239, 0.0247, 0.0230],\n",
      "        [0.0347, 0.0278, 0.0256],\n",
      "        [0.0242, 0.0229, 0.0244],\n",
      "        [0.0282, 0.0277, 0.0225],\n",
      "        [0.0305, 0.0240, 0.0217],\n",
      "        [0.0284, 0.0267, 0.0192],\n",
      "        [0.0292, 0.0267, 0.0216],\n",
      "        [0.0353, 0.0289, 0.0237],\n",
      "        [0.0310, 0.0278, 0.0234],\n",
      "        [0.0347, 0.0336, 0.0338],\n",
      "        [0.0276, 0.0288, 0.0323],\n",
      "        [0.0378, 0.0521, 0.0288],\n",
      "        [0.0371, 0.0327, 0.0289],\n",
      "        [0.0308, 0.0561, 0.0318],\n",
      "        [0.0364, 0.0323, 0.0224],\n",
      "        [0.0304, 0.0361, 0.0287],\n",
      "        [0.0235, 0.0203, 0.0366],\n",
      "        [0.0227, 0.0296, 0.0357],\n",
      "        [0.0204, 0.0220, 0.0390],\n",
      "        [0.0233, 0.0234, 0.0383],\n",
      "        [0.0227, 0.0234, 0.0332],\n",
      "        [0.0250, 0.0256, 0.0417],\n",
      "        [0.0284, 0.0276, 0.0455],\n",
      "        [0.0269, 0.0248, 0.0367],\n",
      "        [0.0295, 0.0290, 0.0255],\n",
      "        [0.0266, 0.0262, 0.0257],\n",
      "        [0.0305, 0.0255, 0.0286],\n",
      "        [0.0259, 0.0193, 0.0367],\n",
      "        [0.0223, 0.0224, 0.0405],\n",
      "        [0.0262, 0.0395, 0.0322],\n",
      "        [0.0397, 0.0296, 0.0234],\n",
      "        [0.0296, 0.0517, 0.0276]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 1.0406e-01, -2.0337e-01,  1.9373e-01],\n",
      "        [ 3.8989e-01,  3.4473e-01, -1.7500e-03],\n",
      "        [-7.1472e-02,  1.0056e-02, -2.9999e-02],\n",
      "        [ 3.1885e-01,  3.3887e-01, -1.0156e-01],\n",
      "        [-1.8250e-01,  1.1377e-01, -8.0688e-02],\n",
      "        [-1.6251e-02,  3.9868e-01,  1.7896e-01],\n",
      "        [-1.0846e-01,  1.4868e-01,  4.1542e-03],\n",
      "        [ 3.3779e-03,  3.0493e-01,  3.2788e-01],\n",
      "        [ 9.0759e-02,  3.9825e-02,  1.3257e-01],\n",
      "        [-3.2867e-02,  2.5558e-02,  2.6562e-01],\n",
      "        [-1.9702e-01,  1.1810e-01,  7.4902e-01],\n",
      "        [ 3.3740e-01,  2.0532e-01,  3.8232e-01],\n",
      "        [ 1.9385e-01,  1.5894e-01,  3.9941e-01],\n",
      "        [ 2.6520e-02,  2.2864e-01,  4.2017e-01],\n",
      "        [-1.4758e-01,  1.1475e-01,  5.1074e-01],\n",
      "        [-1.1560e-01,  1.1688e-01,  1.5063e-01],\n",
      "        [-5.3467e-02,  1.5991e-01,  2.4268e-01],\n",
      "        [-1.5906e-01,  3.2471e-01,  5.1270e-01],\n",
      "        [ 6.7261e-02,  2.4597e-01,  4.7339e-01],\n",
      "        [-1.1108e-01,  2.8247e-01,  3.0005e-01],\n",
      "        [-2.6443e-02,  1.6699e-01,  4.3140e-01],\n",
      "        [-1.8372e-01,  2.8296e-01,  4.1748e-01],\n",
      "        [-2.0361e-01,  1.1951e-01, -3.2684e-02],\n",
      "        [-7.4219e-02,  3.2227e-01,  1.0602e-01],\n",
      "        [-2.6172e-01,  5.9265e-02,  3.2379e-02],\n",
      "        [ 9.0088e-02, -8.6365e-02,  2.6709e-01],\n",
      "        [-2.9932e-01, -3.9673e-03,  2.0850e-01],\n",
      "        [ 2.1622e-02, -4.6501e-03,  2.9053e-01],\n",
      "        [-9.8633e-02, -3.4022e-04,  3.7402e-01],\n",
      "        [-1.7542e-01,  7.3059e-02,  3.3081e-02],\n",
      "        [ 2.4017e-02,  2.4390e-01,  3.1323e-01],\n",
      "        [-2.9297e-02, -9.1370e-02,  7.1582e-01],\n",
      "        [ 1.5186e-01,  3.5278e-02,  6.1523e-01],\n",
      "        [-1.2482e-02, -1.0577e-01,  5.6787e-01],\n",
      "        [ 1.0095e-01, -2.1375e-01,  3.1909e-01],\n",
      "        [-6.6345e-02,  1.0315e-01,  6.7236e-01],\n",
      "        [ 8.6517e-03, -2.0398e-01,  4.4727e-01],\n",
      "        [-1.2378e-01, -8.4717e-02,  5.9326e-01],\n",
      "        [-1.2225e-01, -3.8892e-01,  6.4893e-01],\n",
      "        [-2.7173e-01, -1.2238e-01,  7.4902e-01],\n",
      "        [-2.4255e-01, -1.9189e-01,  3.4595e-01],\n",
      "        [-1.9275e-01, -4.1565e-02,  4.3237e-01],\n",
      "        [-1.2152e-01, -3.4595e-01,  1.5173e-01],\n",
      "        [-2.8198e-01, -3.9746e-01,  2.7173e-01],\n",
      "        [-2.2070e-01, -3.3716e-01,  8.6121e-02],\n",
      "        [-3.4399e-01,  8.6365e-02,  4.3311e-01],\n",
      "        [ 7.5928e-02, -3.2593e-01, -3.9154e-02],\n",
      "        [ 7.3914e-02,  4.7516e-02,  1.9861e-01],\n",
      "        [-5.8319e-02, -1.2152e-01,  1.0999e-01],\n",
      "        [ 3.9978e-02,  8.9722e-02,  2.2290e-01]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0230, 0.0154, 0.0175],\n",
      "        [0.0306, 0.0266, 0.0144],\n",
      "        [0.0193, 0.0190, 0.0140],\n",
      "        [0.0285, 0.0264, 0.0130],\n",
      "        [0.0173, 0.0211, 0.0133],\n",
      "        [0.0204, 0.0280, 0.0173],\n",
      "        [0.0186, 0.0218, 0.0145],\n",
      "        [0.0208, 0.0255, 0.0200],\n",
      "        [0.0227, 0.0196, 0.0165],\n",
      "        [0.0201, 0.0193, 0.0188],\n",
      "        [0.0170, 0.0212, 0.0305],\n",
      "        [0.0291, 0.0231, 0.0211],\n",
      "        [0.0252, 0.0220, 0.0215],\n",
      "        [0.0213, 0.0237, 0.0220],\n",
      "        [0.0179, 0.0211, 0.0241],\n",
      "        [0.0185, 0.0211, 0.0168],\n",
      "        [0.0197, 0.0221, 0.0184],\n",
      "        [0.0177, 0.0260, 0.0241],\n",
      "        [0.0222, 0.0241, 0.0232],\n",
      "        [0.0186, 0.0249, 0.0195],\n",
      "        [0.0202, 0.0222, 0.0222],\n",
      "        [0.0173, 0.0250, 0.0219],\n",
      "        [0.0169, 0.0212, 0.0140],\n",
      "        [0.0193, 0.0260, 0.0161],\n",
      "        [0.0160, 0.0200, 0.0149],\n",
      "        [0.0227, 0.0173, 0.0189],\n",
      "        [0.0154, 0.0187, 0.0178],\n",
      "        [0.0212, 0.0187, 0.0193],\n",
      "        [0.0188, 0.0188, 0.0210],\n",
      "        [0.0174, 0.0202, 0.0149],\n",
      "        [0.0212, 0.0240, 0.0197],\n",
      "        [0.0202, 0.0172, 0.0295],\n",
      "        [0.0241, 0.0195, 0.0267],\n",
      "        [0.0205, 0.0169, 0.0255],\n",
      "        [0.0229, 0.0152, 0.0199],\n",
      "        [0.0194, 0.0209, 0.0283],\n",
      "        [0.0209, 0.0153, 0.0226],\n",
      "        [0.0183, 0.0173, 0.0261],\n",
      "        [0.0184, 0.0127, 0.0276],\n",
      "        [0.0158, 0.0166, 0.0305],\n",
      "        [0.0163, 0.0155, 0.0204],\n",
      "        [0.0171, 0.0181, 0.0222],\n",
      "        [0.0184, 0.0133, 0.0168],\n",
      "        [0.0156, 0.0126, 0.0190],\n",
      "        [0.0166, 0.0134, 0.0157],\n",
      "        [0.0147, 0.0205, 0.0223],\n",
      "        [0.0224, 0.0136, 0.0139],\n",
      "        [0.0223, 0.0197, 0.0176],\n",
      "        [0.0196, 0.0167, 0.0161],\n",
      "        [0.0216, 0.0206, 0.0180]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.1890, -0.0059, -0.2260],\n",
      "        [ 0.3574,  0.4756,  0.0352],\n",
      "        [ 0.0488, -0.1052,  0.3582],\n",
      "        [ 0.2346, -0.1107,  0.1616],\n",
      "        [-0.0346, -0.5063,  0.2808],\n",
      "        [ 0.2693,  0.2111,  0.0267],\n",
      "        [ 0.2308, -0.0719,  0.1115],\n",
      "        [ 0.2189,  0.2661,  0.1243],\n",
      "        [ 0.0767,  0.0750,  0.0986],\n",
      "        [ 0.3003,  0.4065, -0.0479],\n",
      "        [ 0.1226,  0.1128, -0.0342],\n",
      "        [ 0.0789,  0.3147,  0.2566],\n",
      "        [ 0.0153,  0.3037,  0.3484],\n",
      "        [ 0.1150,  0.3801,  0.3748],\n",
      "        [ 0.2339,  0.1537,  0.3955],\n",
      "        [ 0.1901,  0.2947,  0.4233],\n",
      "        [-0.0182,  0.4814,  0.3660],\n",
      "        [-0.1094,  0.1318,  0.2651],\n",
      "        [ 0.2177, -0.0828,  0.2186],\n",
      "        [ 0.2318,  0.3201,  0.3142],\n",
      "        [ 0.0701,  0.0902,  0.1752],\n",
      "        [ 0.2419,  0.3040,  0.3972]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0470, 0.0377, 0.0293],\n",
      "        [0.0556, 0.0610, 0.0380],\n",
      "        [0.0408, 0.0341, 0.0525],\n",
      "        [0.0492, 0.0339, 0.0431],\n",
      "        [0.0376, 0.0228, 0.0486],\n",
      "        [0.0509, 0.0468, 0.0376],\n",
      "        [0.0490, 0.0353, 0.0410],\n",
      "        [0.0484, 0.0495, 0.0415],\n",
      "        [0.0420, 0.0409, 0.0405],\n",
      "        [0.0525, 0.0569, 0.0349],\n",
      "        [0.0439, 0.0424, 0.0354],\n",
      "        [0.0421, 0.0519, 0.0474],\n",
      "        [0.0395, 0.0514, 0.0519],\n",
      "        [0.0436, 0.0555, 0.0533],\n",
      "        [0.0491, 0.0442, 0.0544],\n",
      "        [0.0470, 0.0509, 0.0560],\n",
      "        [0.0382, 0.0614, 0.0529],\n",
      "        [0.0349, 0.0433, 0.0478],\n",
      "        [0.0483, 0.0349, 0.0456],\n",
      "        [0.0490, 0.0522, 0.0502],\n",
      "        [0.0417, 0.0415, 0.0437],\n",
      "        [0.0496, 0.0514, 0.0545]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0403, -0.1061,  0.1509],\n",
      "        [ 0.2445, -0.1320, -0.1567],\n",
      "        [ 0.0110, -0.0133, -0.2429],\n",
      "        [-0.0082,  0.1868,  0.0565],\n",
      "        [-0.2695,  0.0039,  0.0638],\n",
      "        [ 0.3665, -0.0366, -0.2169],\n",
      "        [-0.2859,  0.0526, -0.0598],\n",
      "        [-0.2378,  0.2935,  0.1305],\n",
      "        [-0.3323,  0.4128,  0.0649],\n",
      "        [ 0.3018,  0.2079, -0.1154],\n",
      "        [-0.2388,  0.1084, -0.0956],\n",
      "        [ 0.3870,  0.3665, -0.1479]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0780, 0.0660, 0.1008],\n",
      "        [0.1037, 0.0643, 0.0741],\n",
      "        [0.0821, 0.0724, 0.0679],\n",
      "        [0.0805, 0.0884, 0.0917],\n",
      "        [0.0620, 0.0737, 0.0923],\n",
      "        [0.1171, 0.0707, 0.0698],\n",
      "        [0.0610, 0.0773, 0.0816],\n",
      "        [0.0640, 0.0984, 0.0988],\n",
      "        [0.0582, 0.1108, 0.0924],\n",
      "        [0.1098, 0.0903, 0.0772],\n",
      "        [0.0639, 0.0817, 0.0787],\n",
      "        [0.1196, 0.1058, 0.0747]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 1.2488e-01, -2.0227e-01, -3.8208e-02],\n",
      "        [ 1.5320e-01,  1.6211e-01,  7.7087e-02],\n",
      "        [-7.2937e-02,  1.8555e-01,  2.7368e-01],\n",
      "        [-1.0461e-01,  1.4014e-01,  3.7354e-01],\n",
      "        [-3.2812e-01,  1.0608e-01,  1.6479e-01],\n",
      "        [ 7.8186e-02,  1.5381e-01,  3.2275e-01],\n",
      "        [-1.7725e-01,  1.4148e-01,  3.5498e-01],\n",
      "        [-7.5134e-02,  1.1035e-01,  1.6003e-01],\n",
      "        [-1.1072e-01,  6.8054e-02,  4.4092e-01],\n",
      "        [ 1.7776e-02,  2.7759e-01,  3.3008e-01],\n",
      "        [-1.7529e-01,  2.6514e-01,  3.4302e-01],\n",
      "        [-2.9419e-01,  2.0447e-01,  3.5986e-01],\n",
      "        [-2.7686e-01, -4.0619e-02,  2.6733e-01],\n",
      "        [-1.2683e-01,  8.3618e-02,  4.6436e-01],\n",
      "        [-8.0688e-02,  1.3806e-01,  3.5767e-01],\n",
      "        [ 3.7670e-04,  1.7004e-01,  3.0005e-01],\n",
      "        [-7.9468e-02,  1.1926e-01,  3.2544e-01],\n",
      "        [ 5.9967e-02,  1.4001e-01,  1.5796e-01],\n",
      "        [ 9.2896e-02,  3.3057e-01,  2.0264e-01],\n",
      "        [ 9.0393e-02,  2.3193e-02,  2.2070e-01],\n",
      "        [ 1.4355e-01,  1.9690e-01,  1.6083e-02],\n",
      "        [ 1.3443e-02,  6.1914e-01,  2.0532e-01],\n",
      "        [ 7.9041e-02,  1.0663e-01, -6.6284e-02],\n",
      "        [ 1.7078e-01,  4.5508e-01,  2.3315e-01]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0485, 0.0285, 0.0311],\n",
      "        [0.0499, 0.0410, 0.0349],\n",
      "        [0.0398, 0.0420, 0.0425],\n",
      "        [0.0385, 0.0402, 0.0470],\n",
      "        [0.0308, 0.0388, 0.0381],\n",
      "        [0.0463, 0.0407, 0.0447],\n",
      "        [0.0358, 0.0402, 0.0461],\n",
      "        [0.0397, 0.0390, 0.0380],\n",
      "        [0.0383, 0.0374, 0.0503],\n",
      "        [0.0435, 0.0461, 0.0450],\n",
      "        [0.0359, 0.0455, 0.0456],\n",
      "        [0.0319, 0.0428, 0.0464],\n",
      "        [0.0324, 0.0335, 0.0423],\n",
      "        [0.0377, 0.0380, 0.0515],\n",
      "        [0.0395, 0.0401, 0.0463],\n",
      "        [0.0428, 0.0414, 0.0437],\n",
      "        [0.0395, 0.0393, 0.0448],\n",
      "        [0.0454, 0.0401, 0.0379],\n",
      "        [0.0470, 0.0486, 0.0396],\n",
      "        [0.0468, 0.0357, 0.0403],\n",
      "        [0.0494, 0.0425, 0.0329],\n",
      "        [0.0434, 0.0648, 0.0397],\n",
      "        [0.0463, 0.0388, 0.0303],\n",
      "        [0.0508, 0.0550, 0.0408]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0123, -0.0163, -0.0590],\n",
      "        [ 0.1558,  0.1295, -0.1597],\n",
      "        [ 0.1658,  0.2942, -0.1215],\n",
      "        [ 0.1146,  0.5649, -0.0036],\n",
      "        [ 0.0846,  0.1323,  0.0402],\n",
      "        [ 0.0077,  0.2424, -0.1696],\n",
      "        [-0.1051, -0.0962, -0.0999],\n",
      "        [-0.0295,  0.2197,  0.3389],\n",
      "        [-0.2362,  0.0692,  0.4119],\n",
      "        [-0.1387,  0.0789,  0.4634],\n",
      "        [ 0.0838, -0.1129,  0.1694],\n",
      "        [ 0.2059,  0.2661,  0.2805],\n",
      "        [ 0.2134,  0.1205, -0.0486],\n",
      "        [ 0.2869,  0.3752,  0.0894]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0660, 0.0588, 0.0607],\n",
      "        [0.0781, 0.0681, 0.0549],\n",
      "        [0.0788, 0.0802, 0.0570],\n",
      "        [0.0749, 0.1052, 0.0642],\n",
      "        [0.0727, 0.0682, 0.0670],\n",
      "        [0.0673, 0.0762, 0.0544],\n",
      "        [0.0601, 0.0543, 0.0583],\n",
      "        [0.0649, 0.0745, 0.0904],\n",
      "        [0.0527, 0.0640, 0.0972],\n",
      "        [0.0581, 0.0647, 0.1024],\n",
      "        [0.0726, 0.0534, 0.0763],\n",
      "        [0.0821, 0.0780, 0.0853],\n",
      "        [0.0827, 0.0674, 0.0613],\n",
      "        [0.0890, 0.0870, 0.0704]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0920, -0.0863, -0.0973],\n",
      "        [-0.2473,  0.4768, -0.2935],\n",
      "        [-0.1555,  0.1553,  0.1201],\n",
      "        [ 0.0536,  0.5986, -0.1589],\n",
      "        [ 0.0148,  0.0762, -0.0221],\n",
      "        [-0.1011,  0.1003, -0.3438],\n",
      "        [ 0.0206,  0.1067, -0.0618],\n",
      "        [ 0.1611,  0.3027, -0.0848],\n",
      "        [-0.1991,  0.0674,  0.1494],\n",
      "        [-0.0368,  0.3020,  0.0561],\n",
      "        [-0.1219,  0.0022,  0.1186],\n",
      "        [-0.1799, -0.0441, -0.0044],\n",
      "        [-0.0555, -0.1216,  0.1411],\n",
      "        [ 0.0912,  0.3792,  0.1069],\n",
      "        [-0.2114,  0.4346,  0.1693],\n",
      "        [-0.1506,  0.4402,  0.1833],\n",
      "        [-0.1344,  0.4280,  0.1477],\n",
      "        [-0.2622,  0.3684,  0.2129],\n",
      "        [-0.2998,  0.0135, -0.0272],\n",
      "        [-0.3975,  0.4124,  0.2003],\n",
      "        [-0.1749,  0.3479,  0.0574],\n",
      "        [-0.2271,  0.3318,  0.1013],\n",
      "        [-0.3162,  0.5620, -0.0139],\n",
      "        [-0.4958,  0.4412,  0.0011],\n",
      "        [-0.2037, -0.0077,  0.1089],\n",
      "        [-0.0308,  0.1306, -0.0634],\n",
      "        [ 0.1152, -0.0251,  0.2048],\n",
      "        [ 0.0790,  0.0362,  0.2390]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0436, 0.0257, 0.0308],\n",
      "        [0.0311, 0.0450, 0.0253],\n",
      "        [0.0341, 0.0327, 0.0383],\n",
      "        [0.0420, 0.0509, 0.0290],\n",
      "        [0.0404, 0.0302, 0.0332],\n",
      "        [0.0359, 0.0309, 0.0241],\n",
      "        [0.0406, 0.0311, 0.0319],\n",
      "        [0.0467, 0.0378, 0.0312],\n",
      "        [0.0326, 0.0299, 0.0394],\n",
      "        [0.0383, 0.0378, 0.0359],\n",
      "        [0.0352, 0.0280, 0.0382],\n",
      "        [0.0332, 0.0268, 0.0338],\n",
      "        [0.0376, 0.0248, 0.0391],\n",
      "        [0.0436, 0.0409, 0.0378],\n",
      "        [0.0322, 0.0432, 0.0402],\n",
      "        [0.0342, 0.0434, 0.0408],\n",
      "        [0.0348, 0.0429, 0.0393],\n",
      "        [0.0306, 0.0404, 0.0420],\n",
      "        [0.0295, 0.0284, 0.0330],\n",
      "        [0.0267, 0.0422, 0.0415],\n",
      "        [0.0334, 0.0396, 0.0359],\n",
      "        [0.0317, 0.0390, 0.0375],\n",
      "        [0.0290, 0.0490, 0.0334],\n",
      "        [0.0242, 0.0435, 0.0340],\n",
      "        [0.0324, 0.0278, 0.0378],\n",
      "        [0.0386, 0.0319, 0.0319],\n",
      "        [0.0446, 0.0273, 0.0417],\n",
      "        [0.0430, 0.0290, 0.0431]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 1.3718e-02, -1.3660e-01, -1.3806e-01],\n",
      "        [ 2.9175e-01,  2.1530e-02,  1.9092e-01],\n",
      "        [ 4.2786e-02, -2.4585e-01,  5.6427e-02],\n",
      "        [ 1.3049e-01, -4.8096e-02,  1.1768e-01],\n",
      "        [ 2.2415e-02,  1.0309e-01, -2.7368e-01],\n",
      "        [-4.9072e-02,  2.2998e-01,  1.2939e-01],\n",
      "        [-2.2168e-01,  1.8262e-01,  1.3049e-01],\n",
      "        [-3.9856e-02,  2.6099e-01,  3.9038e-01],\n",
      "        [-5.6824e-02, -1.1238e-02,  5.2051e-01],\n",
      "        [-6.1607e-03, -5.6427e-02,  2.0972e-01],\n",
      "        [-6.8115e-02,  3.2715e-02,  4.2212e-01],\n",
      "        [-2.2327e-01,  1.2854e-01,  4.2651e-01],\n",
      "        [-7.1533e-02,  1.7969e-01,  9.3262e-01],\n",
      "        [-1.8372e-01,  3.2422e-01,  7.2510e-01],\n",
      "        [-1.2915e-01,  2.4182e-01,  7.9736e-01],\n",
      "        [ 1.1426e-01,  3.6084e-01,  2.4817e-01],\n",
      "        [-1.2489e-02,  1.0126e-01,  1.2817e-01],\n",
      "        [-2.2842e-02,  1.5839e-02,  2.0288e-01],\n",
      "        [-1.9971e-01,  1.8689e-01,  1.7651e-01],\n",
      "        [ 8.9661e-02,  1.4001e-01,  3.3813e-01],\n",
      "        [-3.3325e-02,  2.6587e-01,  5.0098e-01],\n",
      "        [-1.7896e-01,  8.3740e-02,  4.9561e-01],\n",
      "        [-1.9019e-01,  1.2585e-01,  5.7178e-01],\n",
      "        [-1.8115e-01, -3.7445e-02,  4.6167e-01],\n",
      "        [-1.1450e-01, -3.5376e-01,  8.9931e-04],\n",
      "        [-2.6367e-01, -1.1591e-01,  2.3767e-01],\n",
      "        [-1.5247e-01,  3.1494e-01,  1.3647e-01],\n",
      "        [-7.2632e-02,  3.0420e-01,  1.8811e-01],\n",
      "        [-4.6112e-02,  2.3669e-01,  4.7900e-01],\n",
      "        [-1.1938e-01,  3.1689e-01,  2.1472e-01],\n",
      "        [-2.8735e-01, -2.4475e-01,  3.1372e-01],\n",
      "        [ 1.0229e-01,  1.1377e-01,  6.4514e-02],\n",
      "        [-2.2119e-01, -5.5878e-02,  7.5226e-03],\n",
      "        [-3.1396e-01,  1.1310e-01,  3.8422e-02],\n",
      "        [-2.4573e-01,  8.2947e-02, -1.9751e-01],\n",
      "        [-1.0217e-01,  3.0258e-02, -3.6450e-01],\n",
      "        [-1.5625e-01,  9.6313e-02, -1.9324e-01],\n",
      "        [-2.4988e-01,  1.8005e-01, -1.1487e-01],\n",
      "        [-1.6797e-01,  3.8574e-01,  9.8206e-02],\n",
      "        [-5.3711e-02,  2.5781e-01, -3.2788e-01],\n",
      "        [ 1.2347e-01,  2.3975e-01, -2.6929e-01],\n",
      "        [ 9.6497e-02,  5.7159e-02, -2.7100e-01],\n",
      "        [ 1.2744e-01,  2.8247e-01, -1.0022e-01],\n",
      "        [ 1.5454e-01,  1.5698e-01,  1.3171e-01],\n",
      "        [ 1.9238e-01,  1.7615e-01,  2.0557e-01],\n",
      "        [ 2.2632e-01,  1.1389e-01,  1.4429e-01],\n",
      "        [-1.5784e-01,  1.0651e-01,  2.5269e-01],\n",
      "        [ 1.0516e-01, -1.0858e-01,  5.8212e-03],\n",
      "        [-1.6443e-01, -2.7783e-01,  1.8701e-01],\n",
      "        [ 1.6541e-01, -2.6929e-01, -2.1851e-01],\n",
      "        [ 1.6309e-01, -3.2539e-03, -1.6663e-01],\n",
      "        [-7.4158e-02, -6.8665e-02, -1.4014e-01],\n",
      "        [-8.5144e-02,  7.8613e-02, -3.0347e-01],\n",
      "        [-1.4978e-01, -9.1736e-02, -7.2899e-03],\n",
      "        [-2.6807e-01,  5.0684e-01,  7.0129e-02],\n",
      "        [ 4.1626e-02,  3.6230e-01,  8.5022e-02],\n",
      "        [-9.2363e-04,  3.4351e-01, -1.8420e-01],\n",
      "        [-2.1729e-01,  6.4087e-02,  1.0687e-01],\n",
      "        [-2.8027e-01, -2.1057e-02, -3.0957e-01],\n",
      "        [-1.9727e-01,  1.0828e-01,  2.1033e-01],\n",
      "        [-1.1896e-01,  1.8994e-01,  2.5244e-01],\n",
      "        [-1.3806e-01,  4.5776e-01,  3.9014e-01],\n",
      "        [-1.6418e-02,  2.5269e-01, -2.3901e-01],\n",
      "        [-8.7463e-02,  2.9297e-01,  2.0593e-01],\n",
      "        [-2.0642e-01,  2.0178e-01, -2.4817e-01],\n",
      "        [-6.3721e-02,  3.1274e-01,  7.1228e-02],\n",
      "        [ 1.6602e-01,  1.5161e-01,  3.9673e-02],\n",
      "        [-2.4719e-02,  2.1472e-01,  3.3887e-01],\n",
      "        [ 7.0740e-02,  1.8860e-01,  2.3865e-01],\n",
      "        [-9.9426e-02,  2.4341e-01,  1.8951e-02],\n",
      "        [-2.4402e-01,  2.5366e-01,  2.2021e-01],\n",
      "        [-1.7554e-01,  6.8481e-02,  2.2339e-01],\n",
      "        [-1.9763e-01,  1.2720e-01,  1.9727e-01],\n",
      "        [-2.8540e-01,  1.5137e-01,  4.2944e-01],\n",
      "        [-2.4011e-01,  3.4943e-02,  8.7341e-02],\n",
      "        [-2.0349e-01,  4.3106e-03,  4.5435e-01],\n",
      "        [-3.3691e-02,  8.5907e-03,  2.1509e-01],\n",
      "        [ 1.5186e-01,  4.9512e-01,  3.6035e-01],\n",
      "        [-1.3135e-01,  3.0078e-01,  1.1127e-01],\n",
      "        [-1.2024e-01,  4.5239e-01,  7.2632e-02],\n",
      "        [ 6.8604e-02,  3.5742e-01,  2.0386e-01],\n",
      "        [ 9.7473e-02,  4.2603e-01,  2.1362e-01],\n",
      "        [-5.2704e-02,  4.9219e-01, -1.7944e-01],\n",
      "        [-4.1699e-01,  3.1445e-01, -3.1104e-01],\n",
      "        [-2.3376e-01,  3.5254e-01, -3.6890e-01],\n",
      "        [ 2.4231e-01,  4.8364e-01, -9.6558e-02],\n",
      "        [-7.6904e-02,  8.5449e-02, -2.4207e-01],\n",
      "        [ 9.2346e-02,  2.4792e-01,  1.8335e-01]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0122, 0.0084, 0.0085],\n",
      "        [0.0161, 0.0098, 0.0117],\n",
      "        [0.0126, 0.0075, 0.0103],\n",
      "        [0.0137, 0.0092, 0.0109],\n",
      "        [0.0123, 0.0107, 0.0074],\n",
      "        [0.0115, 0.0121, 0.0110],\n",
      "        [0.0097, 0.0116, 0.0111],\n",
      "        [0.0116, 0.0125, 0.0143],\n",
      "        [0.0114, 0.0095, 0.0163],\n",
      "        [0.0120, 0.0091, 0.0120],\n",
      "        [0.0113, 0.0100, 0.0148],\n",
      "        [0.0096, 0.0110, 0.0149],\n",
      "        [0.0112, 0.0115, 0.0247],\n",
      "        [0.0100, 0.0133, 0.0200],\n",
      "        [0.0106, 0.0123, 0.0215],\n",
      "        [0.0135, 0.0138, 0.0124],\n",
      "        [0.0119, 0.0107, 0.0110],\n",
      "        [0.0118, 0.0098, 0.0119],\n",
      "        [0.0099, 0.0116, 0.0116],\n",
      "        [0.0132, 0.0111, 0.0136],\n",
      "        [0.0117, 0.0126, 0.0160],\n",
      "        [0.0101, 0.0105, 0.0159],\n",
      "        [0.0100, 0.0109, 0.0172],\n",
      "        [0.0100, 0.0093, 0.0154],\n",
      "        [0.0107, 0.0068, 0.0097],\n",
      "        [0.0093, 0.0086, 0.0123],\n",
      "        [0.0103, 0.0132, 0.0111],\n",
      "        [0.0112, 0.0131, 0.0117],\n",
      "        [0.0115, 0.0122, 0.0157],\n",
      "        [0.0107, 0.0132, 0.0120],\n",
      "        [0.0090, 0.0075, 0.0133],\n",
      "        [0.0133, 0.0108, 0.0104],\n",
      "        [0.0097, 0.0091, 0.0098],\n",
      "        [0.0088, 0.0108, 0.0101],\n",
      "        [0.0094, 0.0105, 0.0080],\n",
      "        [0.0109, 0.0099, 0.0067],\n",
      "        [0.0103, 0.0106, 0.0080],\n",
      "        [0.0094, 0.0115, 0.0087],\n",
      "        [0.0102, 0.0142, 0.0107],\n",
      "        [0.0114, 0.0125, 0.0070],\n",
      "        [0.0136, 0.0122, 0.0074],\n",
      "        [0.0133, 0.0102, 0.0074],\n",
      "        [0.0137, 0.0128, 0.0088],\n",
      "        [0.0141, 0.0113, 0.0111],\n",
      "        [0.0146, 0.0115, 0.0119],\n",
      "        [0.0151, 0.0108, 0.0112],\n",
      "        [0.0103, 0.0107, 0.0125],\n",
      "        [0.0134, 0.0086, 0.0098],\n",
      "        [0.0102, 0.0073, 0.0117],\n",
      "        [0.0142, 0.0074, 0.0078],\n",
      "        [0.0142, 0.0096, 0.0082],\n",
      "        [0.0112, 0.0090, 0.0084],\n",
      "        [0.0111, 0.0104, 0.0072],\n",
      "        [0.0104, 0.0088, 0.0096],\n",
      "        [0.0092, 0.0160, 0.0104],\n",
      "        [0.0126, 0.0138, 0.0106],\n",
      "        [0.0120, 0.0136, 0.0081],\n",
      "        [0.0097, 0.0103, 0.0108],\n",
      "        [0.0091, 0.0094, 0.0071],\n",
      "        [0.0099, 0.0107, 0.0120],\n",
      "        [0.0107, 0.0117, 0.0125],\n",
      "        [0.0105, 0.0152, 0.0143],\n",
      "        [0.0118, 0.0124, 0.0076],\n",
      "        [0.0110, 0.0129, 0.0119],\n",
      "        [0.0098, 0.0118, 0.0076],\n",
      "        [0.0113, 0.0132, 0.0104],\n",
      "        [0.0142, 0.0112, 0.0101],\n",
      "        [0.0117, 0.0119, 0.0136],\n",
      "        [0.0129, 0.0116, 0.0123],\n",
      "        [0.0109, 0.0123, 0.0099],\n",
      "        [0.0094, 0.0124, 0.0121],\n",
      "        [0.0101, 0.0103, 0.0121],\n",
      "        [0.0099, 0.0109, 0.0118],\n",
      "        [0.0091, 0.0112, 0.0149],\n",
      "        [0.0095, 0.0100, 0.0106],\n",
      "        [0.0098, 0.0097, 0.0153],\n",
      "        [0.0116, 0.0097, 0.0120],\n",
      "        [0.0140, 0.0158, 0.0139],\n",
      "        [0.0106, 0.0130, 0.0108],\n",
      "        [0.0107, 0.0151, 0.0104],\n",
      "        [0.0129, 0.0138, 0.0119],\n",
      "        [0.0133, 0.0148, 0.0120],\n",
      "        [0.0114, 0.0158, 0.0081],\n",
      "        [0.0079, 0.0132, 0.0071],\n",
      "        [0.0095, 0.0137, 0.0067],\n",
      "        [0.0154, 0.0156, 0.0088],\n",
      "        [0.0112, 0.0105, 0.0076],\n",
      "        [0.0132, 0.0124, 0.0117]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-1.0388e-01, -1.3147e-01,  1.2756e-01],\n",
      "        [-7.9407e-02,  2.1194e-02,  2.4548e-01],\n",
      "        [-3.5217e-02, -2.0538e-02, -1.5076e-02],\n",
      "        [ 2.6810e-02,  2.1765e-01,  2.3962e-01],\n",
      "        [-1.1700e-01,  1.3818e-01, -7.5867e-02],\n",
      "        [ 1.6907e-02,  3.4033e-01, -2.0544e-01],\n",
      "        [-2.4060e-01, -7.6050e-02,  1.7715e-02],\n",
      "        [-2.5977e-01, -1.7859e-01,  4.4849e-01],\n",
      "        [-2.0862e-01,  1.6504e-01,  7.9492e-01],\n",
      "        [-2.1008e-01,  5.7465e-02,  9.0234e-01],\n",
      "        [-3.7427e-01,  1.3965e-01,  5.7715e-01],\n",
      "        [-7.4829e-02,  4.1284e-01,  6.6211e-01],\n",
      "        [ 1.1975e-01, -2.2986e-01,  2.6318e-01],\n",
      "        [ 4.1748e-02, -8.2825e-02,  5.5762e-01],\n",
      "        [ 1.0004e-01, -1.4795e-01,  3.8257e-01],\n",
      "        [ 1.5955e-01, -1.6223e-01,  3.9673e-01],\n",
      "        [-7.3181e-02, -4.4036e-04,  5.9375e-01],\n",
      "        [ 1.3269e-01,  9.9716e-03,  6.8311e-01],\n",
      "        [ 4.4159e-02,  8.6121e-02,  6.0547e-01],\n",
      "        [ 1.9821e-02, -6.0822e-02,  3.2007e-01],\n",
      "        [ 1.3867e-01, -5.3040e-02,  4.3994e-01],\n",
      "        [ 3.1079e-01,  4.3365e-02,  2.6611e-01],\n",
      "        [ 9.1324e-03,  3.4332e-02,  4.5312e-01],\n",
      "        [ 9.9640e-03, -2.9564e-03,  3.1543e-01],\n",
      "        [ 1.1041e-01, -8.2825e-02,  6.0107e-01],\n",
      "        [-7.2289e-03, -2.2949e-01,  2.1960e-01],\n",
      "        [-1.5068e-02, -2.7390e-02,  5.0830e-01],\n",
      "        [ 2.1936e-01, -3.5693e-01,  3.4595e-01],\n",
      "        [ 1.4270e-01, -6.0616e-03,  4.1162e-01],\n",
      "        [ 3.3203e-01, -4.8187e-02,  5.0098e-01],\n",
      "        [ 1.4697e-01,  1.1499e-01,  5.8838e-01],\n",
      "        [ 3.6230e-01, -5.9967e-02,  4.4946e-01],\n",
      "        [ 1.4685e-01, -2.7161e-02,  5.4590e-01],\n",
      "        [ 3.1421e-01, -1.7065e-01,  3.1616e-01],\n",
      "        [ 1.7822e-01, -6.1084e-01,  7.3828e-01],\n",
      "        [ 1.5015e-01, -5.0049e-01,  3.8306e-01],\n",
      "        [ 1.6931e-01, -3.8550e-01,  6.1865e-01],\n",
      "        [ 1.5796e-01, -1.5088e-01,  4.1431e-01],\n",
      "        [ 4.0527e-02, -2.1509e-01,  4.9805e-01],\n",
      "        [ 1.2830e-01,  5.4779e-02,  4.9121e-01],\n",
      "        [-8.9600e-02, -3.8428e-01,  3.3032e-01],\n",
      "        [-6.2866e-02, -3.4375e-01,  5.1807e-01],\n",
      "        [ 1.6650e-01, -1.3000e-01,  3.7744e-01],\n",
      "        [ 3.6743e-02,  1.9531e-01,  4.1602e-01],\n",
      "        [ 4.9469e-02,  3.4253e-01,  2.8857e-01],\n",
      "        [-8.4473e-02,  1.7029e-01,  5.3955e-01],\n",
      "        [-1.3696e-01,  1.9150e-03,  6.1475e-01],\n",
      "        [ 7.6965e-02, -2.6428e-02,  4.6802e-01],\n",
      "        [-1.1725e-01, -7.9102e-02,  3.5864e-01],\n",
      "        [ 1.5915e-02,  5.0293e-02,  4.6509e-01],\n",
      "        [-8.5545e-04, -3.4943e-02,  2.4255e-01],\n",
      "        [ 3.3966e-02,  1.7273e-01,  3.9111e-01],\n",
      "        [-6.3904e-02, -2.3181e-01,  2.2961e-01],\n",
      "        [-1.3501e-01,  4.7852e-02,  5.0195e-01],\n",
      "        [-7.2449e-02, -6.9702e-02,  3.0005e-01],\n",
      "        [-1.3831e-01,  1.0658e-02,  4.9854e-01],\n",
      "        [-6.4758e-02,  5.5847e-02,  1.2939e-01],\n",
      "        [-4.4250e-02, -2.0645e-02,  3.1909e-01],\n",
      "        [ 1.1938e-01,  1.7102e-01,  9.9976e-02],\n",
      "        [-3.5278e-02, -1.8164e-01,  5.1331e-02],\n",
      "        [-1.7654e-02, -1.8188e-01,  6.1554e-02],\n",
      "        [-1.4648e-01, -7.0007e-02,  3.5522e-01],\n",
      "        [ 2.0599e-02, -2.8748e-02,  2.2375e-01],\n",
      "        [ 5.6305e-02,  9.2651e-02, -3.5553e-02],\n",
      "        [ 1.0150e-01,  6.3171e-02, -2.2888e-01],\n",
      "        [ 1.1987e-01, -1.5051e-01,  1.4380e-01],\n",
      "        [ 1.7627e-01, -1.7102e-01,  9.0881e-02],\n",
      "        [ 1.7236e-01, -2.4536e-01,  2.3584e-01],\n",
      "        [ 2.5537e-01, -2.7908e-02,  2.8271e-01],\n",
      "        [ 2.8564e-01, -1.5979e-01,  5.9570e-02],\n",
      "        [ 3.1616e-01, -1.1469e-01,  1.2455e-03],\n",
      "        [ 1.8445e-01, -1.1182e-01,  6.2408e-02],\n",
      "        [ 1.4099e-01,  1.1212e-01,  6.2744e-02],\n",
      "        [ 1.8823e-01,  1.1749e-01,  1.6919e-01],\n",
      "        [ 6.7566e-02,  7.9163e-02,  1.3513e-01],\n",
      "        [ 1.0535e-01,  9.9426e-02,  4.8706e-01],\n",
      "        [ 1.0809e-01,  4.4678e-02,  4.6582e-01],\n",
      "        [ 2.0300e-01,  1.3013e-01,  2.0618e-01],\n",
      "        [ 2.0154e-01,  1.0944e-01,  7.2327e-02],\n",
      "        [ 2.6880e-01,  3.0957e-01,  2.3645e-01],\n",
      "        [ 2.0520e-01,  2.0959e-01,  2.5635e-02],\n",
      "        [ 1.6394e-01,  1.8591e-01,  2.1423e-01],\n",
      "        [ 2.1167e-01,  4.3677e-01,  7.7393e-02],\n",
      "        [ 2.0215e-01,  2.5610e-01,  1.1450e-01],\n",
      "        [ 9.0332e-02,  1.0718e-01,  1.7737e-01],\n",
      "        [-7.0557e-02,  9.2468e-02,  4.1846e-01],\n",
      "        [ 8.3130e-02, -6.0913e-02,  1.2402e-01],\n",
      "        [ 3.3350e-01,  3.5980e-02,  4.0619e-02],\n",
      "        [ 2.4072e-01,  1.3525e-01, -5.8289e-02],\n",
      "        [ 3.2642e-01,  5.3986e-02,  1.1725e-01]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0093, 0.0097, 0.0090],\n",
      "        [0.0095, 0.0113, 0.0101],\n",
      "        [0.0099, 0.0108, 0.0078],\n",
      "        [0.0106, 0.0138, 0.0101],\n",
      "        [0.0091, 0.0127, 0.0073],\n",
      "        [0.0105, 0.0156, 0.0065],\n",
      "        [0.0081, 0.0103, 0.0081],\n",
      "        [0.0079, 0.0093, 0.0124],\n",
      "        [0.0083, 0.0131, 0.0175],\n",
      "        [0.0083, 0.0117, 0.0195],\n",
      "        [0.0071, 0.0127, 0.0141],\n",
      "        [0.0095, 0.0167, 0.0154],\n",
      "        [0.0116, 0.0088, 0.0103],\n",
      "        [0.0107, 0.0102, 0.0138],\n",
      "        [0.0114, 0.0095, 0.0116],\n",
      "        [0.0121, 0.0094, 0.0118],\n",
      "        [0.0096, 0.0111, 0.0144],\n",
      "        [0.0117, 0.0112, 0.0157],\n",
      "        [0.0107, 0.0121, 0.0145],\n",
      "        [0.0105, 0.0104, 0.0109],\n",
      "        [0.0118, 0.0105, 0.0123],\n",
      "        [0.0140, 0.0116, 0.0103],\n",
      "        [0.0104, 0.0114, 0.0125],\n",
      "        [0.0104, 0.0110, 0.0109],\n",
      "        [0.0115, 0.0102, 0.0145],\n",
      "        [0.0102, 0.0088, 0.0099],\n",
      "        [0.0101, 0.0108, 0.0132],\n",
      "        [0.0128, 0.0077, 0.0112],\n",
      "        [0.0119, 0.0110, 0.0120],\n",
      "        [0.0143, 0.0105, 0.0131],\n",
      "        [0.0119, 0.0124, 0.0143],\n",
      "        [0.0148, 0.0104, 0.0124],\n",
      "        [0.0119, 0.0108, 0.0137],\n",
      "        [0.0141, 0.0093, 0.0109],\n",
      "        [0.0123, 0.0060, 0.0166],\n",
      "        [0.0119, 0.0067, 0.0116],\n",
      "        [0.0122, 0.0075, 0.0147],\n",
      "        [0.0120, 0.0095, 0.0120],\n",
      "        [0.0107, 0.0089, 0.0130],\n",
      "        [0.0117, 0.0117, 0.0130],\n",
      "        [0.0094, 0.0075, 0.0110],\n",
      "        [0.0097, 0.0079, 0.0133],\n",
      "        [0.0121, 0.0097, 0.0116],\n",
      "        [0.0107, 0.0135, 0.0120],\n",
      "        [0.0108, 0.0156, 0.0106],\n",
      "        [0.0095, 0.0131, 0.0136],\n",
      "        [0.0090, 0.0111, 0.0147],\n",
      "        [0.0111, 0.0108, 0.0127],\n",
      "        [0.0091, 0.0102, 0.0113],\n",
      "        [0.0104, 0.0116, 0.0126],\n",
      "        [0.0103, 0.0107, 0.0101],\n",
      "        [0.0106, 0.0132, 0.0117],\n",
      "        [0.0096, 0.0088, 0.0100],\n",
      "        [0.0090, 0.0116, 0.0131],\n",
      "        [0.0096, 0.0103, 0.0107],\n",
      "        [0.0089, 0.0112, 0.0131],\n",
      "        [0.0096, 0.0117, 0.0090],\n",
      "        [0.0098, 0.0108, 0.0109],\n",
      "        [0.0116, 0.0131, 0.0088],\n",
      "        [0.0099, 0.0092, 0.0083],\n",
      "        [0.0101, 0.0092, 0.0084],\n",
      "        [0.0089, 0.0103, 0.0113],\n",
      "        [0.0105, 0.0107, 0.0099],\n",
      "        [0.0109, 0.0121, 0.0076],\n",
      "        [0.0114, 0.0118, 0.0063],\n",
      "        [0.0116, 0.0095, 0.0091],\n",
      "        [0.0123, 0.0093, 0.0087],\n",
      "        [0.0122, 0.0087, 0.0100],\n",
      "        [0.0133, 0.0108, 0.0105],\n",
      "        [0.0137, 0.0094, 0.0084],\n",
      "        [0.0141, 0.0099, 0.0079],\n",
      "        [0.0124, 0.0099, 0.0084],\n",
      "        [0.0118, 0.0124, 0.0084],\n",
      "        [0.0124, 0.0124, 0.0094],\n",
      "        [0.0110, 0.0120, 0.0091],\n",
      "        [0.0114, 0.0122, 0.0129],\n",
      "        [0.0115, 0.0116, 0.0126],\n",
      "        [0.0126, 0.0126, 0.0097],\n",
      "        [0.0126, 0.0123, 0.0085],\n",
      "        [0.0135, 0.0151, 0.0100],\n",
      "        [0.0126, 0.0136, 0.0081],\n",
      "        [0.0121, 0.0133, 0.0098],\n",
      "        [0.0127, 0.0171, 0.0086],\n",
      "        [0.0126, 0.0143, 0.0089],\n",
      "        [0.0113, 0.0123, 0.0095],\n",
      "        [0.0096, 0.0121, 0.0120],\n",
      "        [0.0112, 0.0104, 0.0090],\n",
      "        [0.0144, 0.0115, 0.0083],\n",
      "        [0.0131, 0.0127, 0.0075],\n",
      "        [0.0143, 0.0117, 0.0089]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 2.4719e-02, -1.8591e-01,  1.1664e-01],\n",
      "        [ 7.3059e-02,  3.1641e-01,  1.5564e-01],\n",
      "        [-2.8564e-01, -5.8960e-02,  1.8506e-01],\n",
      "        [ 1.4258e-01,  4.0332e-01, -1.2169e-02],\n",
      "        [ 1.1292e-01, -1.1865e-01,  3.1143e-02],\n",
      "        [ 2.1271e-02,  1.5662e-01,  9.5154e-02],\n",
      "        [ 1.0048e-02,  3.0249e-01,  3.2812e-01],\n",
      "        [ 8.1665e-02,  2.0251e-01,  1.9727e-01],\n",
      "        [-1.3940e-01, -6.7505e-02,  1.3016e-02],\n",
      "        [ 2.2986e-01, -2.1692e-01, -1.4307e-01],\n",
      "        [ 1.5297e-02,  1.7563e-02, -1.3403e-01],\n",
      "        [ 1.8445e-01,  2.7002e-01,  9.0485e-03],\n",
      "        [ 2.9495e-02,  3.2544e-01, -1.6528e-01],\n",
      "        [ 1.4966e-01,  1.7249e-01,  1.2299e-01],\n",
      "        [ 5.2612e-02,  5.5176e-02, -8.3618e-02],\n",
      "        [-5.5115e-02,  1.6296e-01,  6.7810e-02],\n",
      "        [-2.7637e-01,  1.4429e-01,  2.0227e-01],\n",
      "        [-2.5635e-01,  8.2336e-02,  6.2073e-02],\n",
      "        [-1.9421e-01,  2.6807e-01, -1.9373e-01],\n",
      "        [-2.0605e-01,  1.4832e-01,  1.3123e-01],\n",
      "        [ 2.1393e-02,  1.9080e-01, -1.3245e-01],\n",
      "        [ 6.4880e-02, -3.6646e-01,  1.5161e-01],\n",
      "        [-4.9774e-02,  4.8248e-02,  2.0496e-01],\n",
      "        [ 1.0663e-01, -7.9224e-02, -4.2603e-02],\n",
      "        [-1.3290e-02, -2.9888e-03,  1.2512e-01],\n",
      "        [-1.0370e-01, -4.8004e-02,  1.9714e-01],\n",
      "        [-5.4565e-02, -1.1792e-01,  1.4966e-01],\n",
      "        [-9.2285e-02,  1.3074e-01,  1.9995e-01],\n",
      "        [ 4.0588e-02,  9.7473e-02,  5.3345e-02],\n",
      "        [-2.0776e-01,  9.6436e-02,  8.5449e-02],\n",
      "        [-9.3384e-03,  1.1163e-01,  2.3169e-01],\n",
      "        [ 6.3232e-02,  1.7593e-02,  1.1957e-01],\n",
      "        [-9.3201e-02,  3.7988e-01,  1.6382e-01],\n",
      "        [ 6.3843e-02,  3.6597e-01,  6.3721e-01],\n",
      "        [-1.2195e-01,  3.3203e-02,  3.9575e-01],\n",
      "        [ 1.5572e-02,  5.3906e-01,  1.4990e-01],\n",
      "        [-1.2488e-01,  9.4421e-02,  3.8281e-01],\n",
      "        [-2.9907e-02,  1.2854e-01,  3.4729e-02],\n",
      "        [ 4.9255e-02,  4.5654e-02,  4.8798e-02],\n",
      "        [ 1.8323e-01, -4.1290e-02, -4.7333e-02],\n",
      "        [-5.8868e-02, -9.6619e-02,  1.5796e-01],\n",
      "        [-5.2063e-02,  1.1926e-01,  2.2607e-01],\n",
      "        [ 2.1191e-01, -5.8533e-02,  2.9907e-01],\n",
      "        [ 1.1090e-01,  7.9773e-02,  1.6748e-01],\n",
      "        [ 2.2705e-01,  1.0277e-02,  3.2684e-02],\n",
      "        [ 1.6785e-02,  1.6797e-01,  7.9529e-02],\n",
      "        [-9.5764e-02, -4.7638e-02,  1.6980e-01],\n",
      "        [-1.6870e-01,  8.8623e-02,  3.4180e-01],\n",
      "        [-1.1859e-01, -1.3977e-01,  3.5449e-01],\n",
      "        [-5.9814e-02,  2.7271e-01,  1.3306e-01],\n",
      "        [ 1.1230e-01,  1.2360e-01,  3.1299e-01],\n",
      "        [ 1.6589e-01,  1.8616e-01,  2.7319e-01],\n",
      "        [ 9.1309e-02, -4.2114e-02, -6.0516e-02],\n",
      "        [ 1.7603e-01,  8.8623e-02,  1.3062e-01],\n",
      "        [ 1.2372e-01, -4.2023e-02, -5.0446e-02],\n",
      "        [ 1.8762e-01,  2.1545e-01,  3.2544e-01],\n",
      "        [ 2.5452e-02,  2.1216e-01,  3.5303e-01],\n",
      "        [-8.3557e-02,  2.5317e-01,  2.8345e-01],\n",
      "        [-4.5020e-01,  2.7222e-01,  2.4255e-01],\n",
      "        [ 1.5015e-01,  3.5962e-01,  6.1768e-01],\n",
      "        [-1.0242e-01,  5.9479e-02,  1.5759e-01],\n",
      "        [ 2.2021e-01,  8.3740e-02,  1.3477e-01],\n",
      "        [-1.9608e-02,  4.4727e-01,  2.7759e-01],\n",
      "        [-9.2392e-03,  9.2957e-02,  1.5710e-01],\n",
      "        [-2.6074e-01, -6.8237e-02,  1.7700e-01],\n",
      "        [ 2.1094e-01,  2.5928e-01, -6.0120e-03],\n",
      "        [ 2.1545e-01,  4.0723e-01, -1.9507e-01],\n",
      "        [ 1.1676e-01,  4.7681e-01, -2.2327e-01],\n",
      "        [ 1.6650e-01,  1.0394e-01, -1.4062e-01],\n",
      "        [ 8.2153e-02,  6.7932e-02,  1.9934e-01],\n",
      "        [ 1.6333e-01,  1.6586e-02, -9.1400e-03],\n",
      "        [-2.1289e-01,  1.5332e-01,  1.6577e-01],\n",
      "        [-1.6284e-01,  1.9226e-01,  3.4363e-02],\n",
      "        [-1.1237e-01,  3.3325e-01,  9.9670e-02],\n",
      "        [-1.8604e-01,  5.0476e-02, -2.9633e-02],\n",
      "        [ 2.1375e-01, -1.3025e-01, -4.8798e-02],\n",
      "        [ 1.1023e-01,  8.6594e-03,  2.6587e-01],\n",
      "        [-1.0919e-01,  4.9072e-02,  1.6443e-01],\n",
      "        [-6.0394e-02, -1.8631e-02,  8.4106e-02],\n",
      "        [-7.7820e-02, -5.8136e-02,  1.8628e-01],\n",
      "        [ 6.7444e-02,  7.6355e-02,  3.5736e-02],\n",
      "        [ 1.7188e-01,  1.2347e-01,  6.4325e-04],\n",
      "        [-9.0742e-04,  8.7891e-02,  2.0300e-01],\n",
      "        [-1.0117e-02,  3.5919e-02,  2.4915e-01],\n",
      "        [ 1.5894e-01,  1.8726e-01,  2.4597e-01],\n",
      "        [ 5.1392e-02,  4.1553e-01,  1.7700e-01],\n",
      "        [-2.5537e-01,  1.2537e-01,  2.4976e-01],\n",
      "        [ 3.1104e-01,  2.6831e-01,  5.9570e-01],\n",
      "        [-5.5420e-02, -1.4417e-01,  4.2188e-01],\n",
      "        [ 2.3340e-01,  1.6260e-01,  7.2693e-02],\n",
      "        [ 2.8515e-03,  2.1387e-01,  3.3374e-01],\n",
      "        [ 1.3953e-01, -6.9031e-02,  1.3538e-01],\n",
      "        [-7.6828e-03, -2.1680e-01,  1.3306e-01],\n",
      "        [ 2.2900e-01,  1.3171e-01, -6.9771e-03],\n",
      "        [ 9.4666e-02,  3.3936e-01,  3.7476e-02],\n",
      "        [ 1.2201e-01,  2.6245e-01, -1.6333e-01],\n",
      "        [-5.0140e-02,  2.6001e-01,  1.3269e-01],\n",
      "        [ 6.0547e-02,  2.6221e-01,  1.2421e-01],\n",
      "        [-1.9275e-01,  4.5532e-01,  3.1494e-01],\n",
      "        [-8.2581e-02,  5.0244e-01,  4.6967e-02],\n",
      "        [-1.2256e-01,  7.7271e-02,  1.5320e-01],\n",
      "        [-1.9928e-02,  1.1304e-01,  1.6833e-01],\n",
      "        [ 8.0688e-02, -4.4281e-02,  3.1909e-01],\n",
      "        [-4.3945e-02,  7.4524e-02,  3.2422e-01],\n",
      "        [ 9.0942e-02,  7.2083e-02,  4.3506e-01],\n",
      "        [ 8.9844e-02,  3.6182e-01,  8.6487e-02],\n",
      "        [-2.7002e-01,  2.8076e-01,  2.0740e-01],\n",
      "        [ 1.8115e-01,  2.2888e-01,  6.1475e-01],\n",
      "        [-1.6211e-01, -1.5393e-01,  4.1406e-01],\n",
      "        [ 1.5564e-01,  2.0459e-01,  1.6052e-01],\n",
      "        [-1.7737e-01,  4.4067e-01,  2.8687e-01],\n",
      "        [-6.2286e-02,  1.6650e-01,  2.9761e-01],\n",
      "        [-1.7261e-01, -6.4453e-02,  4.2212e-01],\n",
      "        [ 1.9983e-01,  2.3853e-01,  3.6377e-02],\n",
      "        [ 2.9102e-01,  4.3359e-01, -1.4050e-01],\n",
      "        [ 1.6870e-01,  2.8418e-01, -1.6931e-01],\n",
      "        [ 1.5491e-01,  1.5405e-01, -1.6797e-01],\n",
      "        [-1.3086e-01,  1.1432e-01,  1.7517e-01],\n",
      "        [ 1.6553e-01,  1.5161e-01, -3.0411e-02],\n",
      "        [-2.1741e-01,  1.9116e-01,  2.0056e-01],\n",
      "        [-6.9519e-02,  2.3608e-01,  5.3497e-02],\n",
      "        [-1.1047e-01,  3.2812e-01,  1.3147e-01],\n",
      "        [-6.9923e-03,  1.5662e-01,  9.3079e-03],\n",
      "        [ 2.0312e-01,  1.1536e-01,  9.5520e-02],\n",
      "        [-4.0497e-02,  1.0992e-01,  2.9321e-01],\n",
      "        [-8.1177e-02,  2.3779e-01,  4.2529e-01],\n",
      "        [-7.6416e-02,  2.9028e-01, -5.1141e-05],\n",
      "        [-7.8430e-02,  2.5415e-01,  1.7319e-02],\n",
      "        [ 2.4719e-02,  2.4219e-01, -1.4246e-01],\n",
      "        [ 3.6719e-01,  2.4280e-01, -5.3162e-02],\n",
      "        [-1.0925e-01,  2.3059e-01, -9.8145e-02],\n",
      "        [ 1.8286e-01,  1.5222e-01,  7.2388e-02]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0076, 0.0054, 0.0073],\n",
      "        [0.0080, 0.0089, 0.0076],\n",
      "        [0.0056, 0.0061, 0.0078],\n",
      "        [0.0085, 0.0098, 0.0064],\n",
      "        [0.0083, 0.0058, 0.0067],\n",
      "        [0.0076, 0.0076, 0.0072],\n",
      "        [0.0075, 0.0088, 0.0090],\n",
      "        [0.0080, 0.0080, 0.0079],\n",
      "        [0.0064, 0.0061, 0.0066],\n",
      "        [0.0093, 0.0052, 0.0056],\n",
      "        [0.0075, 0.0066, 0.0057],\n",
      "        [0.0089, 0.0085, 0.0066],\n",
      "        [0.0076, 0.0090, 0.0055],\n",
      "        [0.0086, 0.0077, 0.0074],\n",
      "        [0.0078, 0.0069, 0.0060],\n",
      "        [0.0070, 0.0077, 0.0070],\n",
      "        [0.0056, 0.0075, 0.0080],\n",
      "        [0.0057, 0.0071, 0.0069],\n",
      "        [0.0061, 0.0085, 0.0054],\n",
      "        [0.0060, 0.0076, 0.0074],\n",
      "        [0.0076, 0.0079, 0.0057],\n",
      "        [0.0079, 0.0045, 0.0076],\n",
      "        [0.0070, 0.0068, 0.0080],\n",
      "        [0.0082, 0.0060, 0.0062],\n",
      "        [0.0073, 0.0065, 0.0074],\n",
      "        [0.0067, 0.0062, 0.0079],\n",
      "        [0.0070, 0.0058, 0.0076],\n",
      "        [0.0068, 0.0074, 0.0080],\n",
      "        [0.0077, 0.0072, 0.0069],\n",
      "        [0.0060, 0.0072, 0.0071],\n",
      "        [0.0073, 0.0073, 0.0082],\n",
      "        [0.0079, 0.0066, 0.0073],\n",
      "        [0.0067, 0.0095, 0.0077],\n",
      "        [0.0079, 0.0094, 0.0123],\n",
      "        [0.0066, 0.0067, 0.0097],\n",
      "        [0.0075, 0.0112, 0.0076],\n",
      "        [0.0065, 0.0072, 0.0096],\n",
      "        [0.0072, 0.0074, 0.0067],\n",
      "        [0.0078, 0.0068, 0.0068],\n",
      "        [0.0089, 0.0063, 0.0062],\n",
      "        [0.0070, 0.0059, 0.0076],\n",
      "        [0.0070, 0.0073, 0.0082],\n",
      "        [0.0092, 0.0062, 0.0088],\n",
      "        [0.0083, 0.0071, 0.0077],\n",
      "        [0.0093, 0.0066, 0.0067],\n",
      "        [0.0075, 0.0077, 0.0071],\n",
      "        [0.0067, 0.0062, 0.0077],\n",
      "        [0.0063, 0.0071, 0.0092],\n",
      "        [0.0066, 0.0057, 0.0093],\n",
      "        [0.0070, 0.0086, 0.0074],\n",
      "        [0.0083, 0.0074, 0.0089],\n",
      "        [0.0088, 0.0079, 0.0086],\n",
      "        [0.0081, 0.0063, 0.0061],\n",
      "        [0.0088, 0.0071, 0.0074],\n",
      "        [0.0084, 0.0063, 0.0062],\n",
      "        [0.0089, 0.0081, 0.0090],\n",
      "        [0.0076, 0.0081, 0.0093],\n",
      "        [0.0068, 0.0084, 0.0087],\n",
      "        [0.0047, 0.0086, 0.0083],\n",
      "        [0.0086, 0.0093, 0.0121],\n",
      "        [0.0067, 0.0069, 0.0076],\n",
      "        [0.0092, 0.0071, 0.0075],\n",
      "        [0.0073, 0.0102, 0.0086],\n",
      "        [0.0073, 0.0072, 0.0076],\n",
      "        [0.0057, 0.0061, 0.0078],\n",
      "        [0.0091, 0.0085, 0.0065],\n",
      "        [0.0092, 0.0098, 0.0054],\n",
      "        [0.0083, 0.0105, 0.0052],\n",
      "        [0.0088, 0.0072, 0.0057],\n",
      "        [0.0080, 0.0070, 0.0079],\n",
      "        [0.0087, 0.0066, 0.0065],\n",
      "        [0.0060, 0.0076, 0.0077],\n",
      "        [0.0063, 0.0079, 0.0067],\n",
      "        [0.0066, 0.0091, 0.0072],\n",
      "        [0.0062, 0.0069, 0.0063],\n",
      "        [0.0092, 0.0057, 0.0062],\n",
      "        [0.0083, 0.0066, 0.0085],\n",
      "        [0.0066, 0.0069, 0.0077],\n",
      "        [0.0070, 0.0064, 0.0071],\n",
      "        [0.0069, 0.0062, 0.0079],\n",
      "        [0.0079, 0.0070, 0.0067],\n",
      "        [0.0088, 0.0074, 0.0065],\n",
      "        [0.0074, 0.0071, 0.0080],\n",
      "        [0.0073, 0.0068, 0.0084],\n",
      "        [0.0087, 0.0079, 0.0083],\n",
      "        [0.0078, 0.0099, 0.0078],\n",
      "        [0.0057, 0.0074, 0.0084],\n",
      "        [0.0101, 0.0085, 0.0118],\n",
      "        [0.0070, 0.0056, 0.0099],\n",
      "        [0.0094, 0.0077, 0.0070],\n",
      "        [0.0074, 0.0081, 0.0091],\n",
      "        [0.0085, 0.0061, 0.0075],\n",
      "        [0.0074, 0.0053, 0.0074],\n",
      "        [0.0093, 0.0074, 0.0065],\n",
      "        [0.0081, 0.0092, 0.0068],\n",
      "        [0.0084, 0.0085, 0.0055],\n",
      "        [0.0070, 0.0085, 0.0074],\n",
      "        [0.0079, 0.0085, 0.0074],\n",
      "        [0.0061, 0.0103, 0.0089],\n",
      "        [0.0068, 0.0108, 0.0068],\n",
      "        [0.0066, 0.0070, 0.0076],\n",
      "        [0.0073, 0.0073, 0.0077],\n",
      "        [0.0080, 0.0062, 0.0090],\n",
      "        [0.0071, 0.0070, 0.0090],\n",
      "        [0.0081, 0.0070, 0.0101],\n",
      "        [0.0081, 0.0094, 0.0071],\n",
      "        [0.0057, 0.0086, 0.0080],\n",
      "        [0.0089, 0.0082, 0.0120],\n",
      "        [0.0063, 0.0056, 0.0099],\n",
      "        [0.0087, 0.0080, 0.0076],\n",
      "        [0.0062, 0.0101, 0.0087],\n",
      "        [0.0070, 0.0077, 0.0088],\n",
      "        [0.0062, 0.0061, 0.0099],\n",
      "        [0.0090, 0.0083, 0.0068],\n",
      "        [0.0099, 0.0101, 0.0057],\n",
      "        [0.0088, 0.0087, 0.0055],\n",
      "        [0.0087, 0.0076, 0.0055],\n",
      "        [0.0065, 0.0073, 0.0078],\n",
      "        [0.0087, 0.0076, 0.0063],\n",
      "        [0.0060, 0.0079, 0.0080],\n",
      "        [0.0069, 0.0083, 0.0069],\n",
      "        [0.0066, 0.0091, 0.0074],\n",
      "        [0.0074, 0.0076, 0.0066],\n",
      "        [0.0091, 0.0073, 0.0072],\n",
      "        [0.0071, 0.0073, 0.0087],\n",
      "        [0.0068, 0.0083, 0.0100],\n",
      "        [0.0069, 0.0087, 0.0065],\n",
      "        [0.0069, 0.0084, 0.0066],\n",
      "        [0.0076, 0.0083, 0.0056],\n",
      "        [0.0107, 0.0083, 0.0062],\n",
      "        [0.0066, 0.0082, 0.0059],\n",
      "        [0.0089, 0.0076, 0.0070]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1106,  0.0252, -0.0901],\n",
      "        [ 0.0514,  0.4304,  0.0046],\n",
      "        [-0.0128, -0.1362,  0.3293],\n",
      "        [ 0.0862,  0.2634,  0.2335],\n",
      "        [-0.1477, -0.2382,  0.3188],\n",
      "        [-0.1927, -0.0988,  0.2292],\n",
      "        [-0.2769, -0.2913,  0.1107],\n",
      "        [-0.1278, -0.1964,  0.5439],\n",
      "        [-0.1521,  0.1813,  0.0486],\n",
      "        [ 0.0927,  0.1486,  0.2656],\n",
      "        [ 0.1852,  0.0468, -0.1224],\n",
      "        [ 0.2681,  0.4043,  0.0296],\n",
      "        [-0.2874, -0.0323,  0.1738],\n",
      "        [-0.0184,  0.1677,  0.4524],\n",
      "        [ 0.0269, -0.1157,  0.3521],\n",
      "        [-0.1520,  0.3169,  0.2681],\n",
      "        [-0.1150, -0.0686,  0.0030],\n",
      "        [ 0.0823,  0.2251,  0.3052],\n",
      "        [-0.2725, -0.0946,  0.5234],\n",
      "        [-0.3228,  0.2810,  0.4575],\n",
      "        [-0.4185,  0.2856,  0.2097],\n",
      "        [-0.2448,  0.3911,  0.3442],\n",
      "        [-0.2686,  0.1783,  0.2571],\n",
      "        [-0.2190,  0.3140,  0.4341],\n",
      "        [-0.1329, -0.0294,  0.2590],\n",
      "        [-0.0049,  0.1963,  0.4744],\n",
      "        [-0.1829,  0.0027,  0.2220],\n",
      "        [ 0.0995,  0.2218,  0.4243]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0348, 0.0325, 0.0250],\n",
      "        [0.0409, 0.0487, 0.0275],\n",
      "        [0.0384, 0.0276, 0.0380],\n",
      "        [0.0424, 0.0412, 0.0345],\n",
      "        [0.0335, 0.0250, 0.0376],\n",
      "        [0.0321, 0.0287, 0.0344],\n",
      "        [0.0295, 0.0237, 0.0305],\n",
      "        [0.0342, 0.0260, 0.0471],\n",
      "        [0.0334, 0.0380, 0.0287],\n",
      "        [0.0427, 0.0368, 0.0356],\n",
      "        [0.0468, 0.0332, 0.0242],\n",
      "        [0.0508, 0.0475, 0.0281],\n",
      "        [0.0292, 0.0307, 0.0325],\n",
      "        [0.0382, 0.0375, 0.0430],\n",
      "        [0.0399, 0.0282, 0.0388],\n",
      "        [0.0334, 0.0435, 0.0357],\n",
      "        [0.0347, 0.0296, 0.0274],\n",
      "        [0.0422, 0.0397, 0.0371],\n",
      "        [0.0296, 0.0288, 0.0461],\n",
      "        [0.0282, 0.0420, 0.0432],\n",
      "        [0.0256, 0.0422, 0.0337],\n",
      "        [0.0304, 0.0469, 0.0385],\n",
      "        [0.0297, 0.0379, 0.0353],\n",
      "        [0.0312, 0.0434, 0.0422],\n",
      "        [0.0340, 0.0308, 0.0354],\n",
      "        [0.0387, 0.0385, 0.0439],\n",
      "        [0.0324, 0.0318, 0.0341],\n",
      "        [0.0429, 0.0396, 0.0418]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0578, -0.1009, -0.0620],\n",
      "        [ 0.0659,  0.1979,  0.1781],\n",
      "        [-0.1819, -0.0444,  0.3210],\n",
      "        [-0.0915,  0.3196,  0.0256]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2734, 0.2029, 0.2070],\n",
      "        [0.2756, 0.2734, 0.2632],\n",
      "        [0.2151, 0.2146, 0.3037],\n",
      "        [0.2356, 0.3088, 0.2260]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.1698, -0.0741, -0.0151],\n",
      "        [-0.0614,  0.1693,  0.1158],\n",
      "        [-0.1093, -0.0765, -0.0231],\n",
      "        [-0.1960,  0.0624,  0.1831],\n",
      "        [-0.1394, -0.4780,  0.0425],\n",
      "        [-0.1290, -0.1351, -0.0064],\n",
      "        [-0.0627, -0.4976, -0.0528],\n",
      "        [ 0.2279, -0.4360,  0.0281],\n",
      "        [ 0.0355, -0.4053, -0.0265],\n",
      "        [ 0.0732,  0.0139, -0.2507],\n",
      "        [-0.0615, -0.1998, -0.1533],\n",
      "        [ 0.1362,  0.2457, -0.1456],\n",
      "        [ 0.0885, -0.2615, -0.0742],\n",
      "        [ 0.0917, -0.0298, -0.1753],\n",
      "        [-0.0462,  0.0386,  0.0161],\n",
      "        [-0.0514,  0.1235,  0.2876],\n",
      "        [-0.0764,  0.1205,  0.2472],\n",
      "        [-0.0489, -0.0810,  0.4087],\n",
      "        [-0.2278, -0.1920,  0.1475],\n",
      "        [-0.2157,  0.3513,  0.1324],\n",
      "        [-0.2883, -0.0027,  0.2991],\n",
      "        [-0.2047,  0.4006,  0.0775],\n",
      "        [-0.2710,  0.0812,  0.0863],\n",
      "        [-0.0717,  0.5249,  0.0121]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0519, 0.0385, 0.0386],\n",
      "        [0.0412, 0.0491, 0.0440],\n",
      "        [0.0393, 0.0384, 0.0383],\n",
      "        [0.0360, 0.0442, 0.0471],\n",
      "        [0.0381, 0.0257, 0.0409],\n",
      "        [0.0385, 0.0362, 0.0389],\n",
      "        [0.0412, 0.0252, 0.0372],\n",
      "        [0.0551, 0.0268, 0.0403],\n",
      "        [0.0454, 0.0277, 0.0382],\n",
      "        [0.0472, 0.0421, 0.0305],\n",
      "        [0.0412, 0.0340, 0.0336],\n",
      "        [0.0502, 0.0530, 0.0339],\n",
      "        [0.0479, 0.0320, 0.0364],\n",
      "        [0.0480, 0.0403, 0.0329],\n",
      "        [0.0418, 0.0431, 0.0398],\n",
      "        [0.0416, 0.0469, 0.0522],\n",
      "        [0.0406, 0.0468, 0.0502],\n",
      "        [0.0417, 0.0382, 0.0590],\n",
      "        [0.0349, 0.0342, 0.0454],\n",
      "        [0.0353, 0.0590, 0.0448],\n",
      "        [0.0328, 0.0414, 0.0529],\n",
      "        [0.0357, 0.0620, 0.0424],\n",
      "        [0.0334, 0.0450, 0.0428],\n",
      "        [0.0408, 0.0701, 0.0397]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 6.8604e-02, -1.0742e-01, -7.5745e-02],\n",
      "        [ 1.9922e-01,  3.4204e-01,  1.3474e-02],\n",
      "        [ 2.4634e-01, -4.7852e-02,  2.1155e-01],\n",
      "        [ 1.5234e-01,  6.1096e-02,  6.0333e-02],\n",
      "        [ 1.1725e-01,  3.4943e-03, -1.1401e-01],\n",
      "        [-3.4546e-02,  3.6591e-02,  2.8711e-01],\n",
      "        [-1.6602e-01, -1.2708e-01,  1.3013e-01],\n",
      "        [-2.4506e-02,  3.6108e-01,  3.1830e-02],\n",
      "        [ 4.0588e-02, -2.1729e-01, -2.4414e-01],\n",
      "        [ 1.5784e-01,  6.8848e-02,  2.1741e-01],\n",
      "        [ 9.9411e-03,  1.8701e-01, -1.8347e-01],\n",
      "        [ 8.4167e-02,  2.6514e-01,  1.7151e-02],\n",
      "        [ 4.9805e-01,  8.4534e-02,  1.9421e-01],\n",
      "        [ 1.8433e-01,  5.5695e-02,  5.1367e-01],\n",
      "        [ 2.1606e-01, -3.8452e-02,  4.3896e-01],\n",
      "        [ 2.3303e-01, -1.1719e-01,  5.6885e-01],\n",
      "        [ 3.1519e-01, -3.8643e-03,  3.4570e-01],\n",
      "        [ 1.6016e-01, -9.2712e-02,  3.6548e-01],\n",
      "        [ 2.4609e-01, -3.0197e-02,  5.1367e-01],\n",
      "        [ 2.3206e-01, -3.5059e-01,  5.9180e-01],\n",
      "        [ 2.6611e-01,  1.0315e-02,  3.2983e-01],\n",
      "        [ 4.4238e-01, -1.4062e-01,  2.0056e-01],\n",
      "        [ 2.7808e-01, -2.4585e-01,  1.2360e-01],\n",
      "        [-8.4534e-02, -1.4502e-01,  6.5088e-01],\n",
      "        [-8.0948e-03, -7.0068e-02,  3.0786e-01],\n",
      "        [ 1.7456e-01,  5.9082e-02,  3.7988e-01],\n",
      "        [ 1.3330e-01,  5.6877e-03,  1.4404e-02],\n",
      "        [ 2.8687e-02,  2.4377e-01,  4.4214e-01],\n",
      "        [ 4.2236e-02, -8.3862e-02,  1.6663e-01],\n",
      "        [ 1.1688e-01,  3.3813e-01,  3.5381e-03],\n",
      "        [-1.1914e-01, -7.6050e-02, -3.6224e-02],\n",
      "        [-2.9419e-01,  2.7002e-01,  3.0225e-01],\n",
      "        [-4.8901e-01, -8.0811e-02,  1.8677e-01],\n",
      "        [-6.0883e-02,  3.9136e-01,  2.9248e-01],\n",
      "        [ 3.3508e-02, -3.6816e-01,  3.9014e-01],\n",
      "        [ 8.1909e-02, -1.8213e-01,  3.2129e-01],\n",
      "        [-2.5903e-01, -1.9482e-01,  5.2100e-01],\n",
      "        [-1.2939e-01, -2.4695e-01,  4.3457e-01],\n",
      "        [-4.0942e-01, -4.0698e-01,  2.5293e-01],\n",
      "        [-1.4627e-04, -2.2156e-01,  1.7920e-01],\n",
      "        [-2.1338e-01, -6.6162e-02,  2.5537e-01],\n",
      "        [-1.1505e-01, -3.7231e-01,  2.5122e-01],\n",
      "        [-8.7585e-02, -2.0447e-01,  4.2212e-01],\n",
      "        [-6.3599e-02, -4.4556e-01, -3.0991e-02],\n",
      "        [-1.9885e-01, -1.8042e-01, -1.0876e-01],\n",
      "        [-8.2779e-03, -3.3984e-01, -1.2622e-01],\n",
      "        [-5.3131e-02, -4.2725e-01,  1.8457e-01],\n",
      "        [ 2.7557e-02, -3.0518e-01, -3.7549e-01],\n",
      "        [ 1.7590e-01, -7.7400e-03,  2.3376e-01],\n",
      "        [ 4.1602e-01, -9.5459e-02,  1.0199e-01],\n",
      "        [ 2.7161e-02, -1.7944e-02,  4.4971e-01],\n",
      "        [ 4.7974e-01, -2.4658e-01,  2.6367e-02],\n",
      "        [ 1.9385e-01, -2.7930e-01,  2.8052e-01],\n",
      "        [ 4.8682e-01, -2.0593e-01, -8.7341e-02],\n",
      "        [ 1.6260e-01,  3.2288e-02,  1.1774e-01],\n",
      "        [ 3.4351e-01,  1.1053e-01,  1.2642e-02],\n",
      "        [ 7.7942e-02, -8.3237e-03, -1.0175e-01],\n",
      "        [ 3.8306e-01,  3.0518e-01, -1.1285e-01],\n",
      "        [ 8.4045e-02,  2.4609e-01, -2.0154e-01],\n",
      "        [ 3.3105e-01,  5.0995e-02, -8.4106e-02],\n",
      "        [ 4.4360e-01,  3.7781e-02, -6.7406e-03],\n",
      "        [ 3.2861e-01, -2.3914e-01,  5.6213e-02],\n",
      "        [ 2.2498e-01, -1.2482e-01, -9.5947e-02],\n",
      "        [ 4.3610e-02, -6.4880e-02,  3.8013e-01],\n",
      "        [-1.5778e-02, -1.6821e-01,  2.5928e-01],\n",
      "        [ 2.7295e-01,  1.4124e-01,  1.3403e-01],\n",
      "        [ 9.6802e-02, -2.3766e-03,  2.2241e-01],\n",
      "        [ 3.3521e-01, -1.9678e-01, -1.1981e-01],\n",
      "        [ 2.3889e-01, -1.4221e-01,  2.6562e-01],\n",
      "        [-8.6060e-02, -1.1731e-01,  1.8372e-01],\n",
      "        [ 2.0300e-01, -3.0853e-02,  9.4727e-02],\n",
      "        [ 2.1399e-01,  8.7280e-02,  1.9739e-01],\n",
      "        [ 2.1866e-02, -9.1171e-03,  2.7954e-01],\n",
      "        [ 6.5613e-02,  1.0187e-01,  3.7378e-01],\n",
      "        [ 7.6843e-02, -1.1981e-01,  3.9990e-01],\n",
      "        [ 1.5991e-01, -1.3367e-01,  8.2642e-02],\n",
      "        [ 9.9670e-02, -3.6285e-02,  3.0518e-01],\n",
      "        [ 2.6025e-01, -2.1326e-01,  5.8624e-02],\n",
      "        [ 6.4430e-03, -5.3076e-01,  3.2544e-01],\n",
      "        [ 3.2593e-01, -2.5879e-01,  2.6050e-01],\n",
      "        [ 1.7639e-01, -7.3303e-02,  3.5547e-01],\n",
      "        [ 1.7249e-01,  2.3511e-01,  2.5342e-01],\n",
      "        [-5.4504e-02,  1.4343e-01,  2.0056e-01],\n",
      "        [-7.7148e-02,  2.9126e-01,  2.1814e-01],\n",
      "        [-1.5002e-01,  2.1204e-01,  1.7615e-01],\n",
      "        [ 1.2671e-01,  2.6514e-01,  1.7688e-01],\n",
      "        [-3.3594e-01, -1.8689e-01,  3.5132e-01],\n",
      "        [-2.8857e-01, -1.3452e-01,  4.0845e-01],\n",
      "        [-3.1982e-01, -3.5217e-02, -1.1780e-01],\n",
      "        [-9.3567e-02,  3.5132e-01,  1.3965e-01],\n",
      "        [ 2.4200e-02,  8.5449e-02, -1.2408e-01],\n",
      "        [ 3.4637e-02,  3.3496e-01, -4.8187e-02]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0105, 0.0100, 0.0083],\n",
      "        [0.0120, 0.0156, 0.0091],\n",
      "        [0.0125, 0.0106, 0.0110],\n",
      "        [0.0114, 0.0118, 0.0095],\n",
      "        [0.0110, 0.0111, 0.0080],\n",
      "        [0.0095, 0.0115, 0.0119],\n",
      "        [0.0083, 0.0098, 0.0102],\n",
      "        [0.0096, 0.0159, 0.0092],\n",
      "        [0.0102, 0.0089, 0.0070],\n",
      "        [0.0115, 0.0119, 0.0111],\n",
      "        [0.0099, 0.0134, 0.0074],\n",
      "        [0.0107, 0.0145, 0.0091],\n",
      "        [0.0161, 0.0121, 0.0108],\n",
      "        [0.0118, 0.0117, 0.0149],\n",
      "        [0.0122, 0.0107, 0.0139],\n",
      "        [0.0124, 0.0099, 0.0158],\n",
      "        [0.0134, 0.0110, 0.0126],\n",
      "        [0.0115, 0.0101, 0.0129],\n",
      "        [0.0125, 0.0108, 0.0149],\n",
      "        [0.0124, 0.0078, 0.0161],\n",
      "        [0.0128, 0.0112, 0.0124],\n",
      "        [0.0153, 0.0096, 0.0109],\n",
      "        [0.0129, 0.0087, 0.0101],\n",
      "        [0.0090, 0.0096, 0.0171],\n",
      "        [0.0097, 0.0103, 0.0121],\n",
      "        [0.0117, 0.0118, 0.0131],\n",
      "        [0.0112, 0.0112, 0.0091],\n",
      "        [0.0101, 0.0142, 0.0139],\n",
      "        [0.0102, 0.0102, 0.0106],\n",
      "        [0.0110, 0.0156, 0.0090],\n",
      "        [0.0087, 0.0103, 0.0086],\n",
      "        [0.0073, 0.0145, 0.0121],\n",
      "        [0.0060, 0.0102, 0.0108],\n",
      "        [0.0092, 0.0164, 0.0120],\n",
      "        [0.0101, 0.0077, 0.0132],\n",
      "        [0.0106, 0.0092, 0.0123],\n",
      "        [0.0076, 0.0091, 0.0150],\n",
      "        [0.0086, 0.0087, 0.0138],\n",
      "        [0.0065, 0.0074, 0.0115],\n",
      "        [0.0098, 0.0089, 0.0107],\n",
      "        [0.0079, 0.0104, 0.0115],\n",
      "        [0.0087, 0.0076, 0.0115],\n",
      "        [0.0090, 0.0090, 0.0136],\n",
      "        [0.0092, 0.0071, 0.0087],\n",
      "        [0.0080, 0.0093, 0.0080],\n",
      "        [0.0097, 0.0079, 0.0079],\n",
      "        [0.0093, 0.0072, 0.0107],\n",
      "        [0.0101, 0.0082, 0.0061],\n",
      "        [0.0117, 0.0110, 0.0113],\n",
      "        [0.0149, 0.0101, 0.0099],\n",
      "        [0.0101, 0.0109, 0.0140],\n",
      "        [0.0158, 0.0087, 0.0092],\n",
      "        [0.0119, 0.0084, 0.0118],\n",
      "        [0.0159, 0.0090, 0.0082],\n",
      "        [0.0115, 0.0115, 0.0100],\n",
      "        [0.0138, 0.0124, 0.0090],\n",
      "        [0.0106, 0.0110, 0.0081],\n",
      "        [0.0144, 0.0151, 0.0080],\n",
      "        [0.0107, 0.0142, 0.0073],\n",
      "        [0.0136, 0.0117, 0.0082],\n",
      "        [0.0153, 0.0115, 0.0089],\n",
      "        [0.0136, 0.0087, 0.0094],\n",
      "        [0.0123, 0.0098, 0.0081],\n",
      "        [0.0102, 0.0104, 0.0131],\n",
      "        [0.0096, 0.0094, 0.0116],\n",
      "        [0.0129, 0.0128, 0.0102],\n",
      "        [0.0108, 0.0111, 0.0112],\n",
      "        [0.0137, 0.0091, 0.0079],\n",
      "        [0.0124, 0.0096, 0.0116],\n",
      "        [0.0090, 0.0099, 0.0107],\n",
      "        [0.0120, 0.0108, 0.0098],\n",
      "        [0.0121, 0.0121, 0.0109],\n",
      "        [0.0100, 0.0110, 0.0118],\n",
      "        [0.0105, 0.0123, 0.0130],\n",
      "        [0.0106, 0.0098, 0.0133],\n",
      "        [0.0115, 0.0097, 0.0097],\n",
      "        [0.0108, 0.0107, 0.0121],\n",
      "        [0.0127, 0.0090, 0.0095],\n",
      "        [0.0099, 0.0065, 0.0124],\n",
      "        [0.0136, 0.0086, 0.0116],\n",
      "        [0.0117, 0.0103, 0.0127],\n",
      "        [0.0117, 0.0140, 0.0115],\n",
      "        [0.0093, 0.0128, 0.0109],\n",
      "        [0.0091, 0.0148, 0.0111],\n",
      "        [0.0084, 0.0137, 0.0107],\n",
      "        [0.0111, 0.0145, 0.0107],\n",
      "        [0.0070, 0.0092, 0.0127],\n",
      "        [0.0073, 0.0097, 0.0134],\n",
      "        [0.0071, 0.0107, 0.0079],\n",
      "        [0.0089, 0.0158, 0.0103],\n",
      "        [0.0100, 0.0121, 0.0079],\n",
      "        [0.0101, 0.0155, 0.0085]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0107, -0.1827,  0.0249],\n",
      "        [ 0.2360,  0.2605, -0.2188],\n",
      "        [-0.0109,  0.1642, -0.1249],\n",
      "        [ 0.1542,  0.0422, -0.2705],\n",
      "        [ 0.0890,  0.1023, -0.1401],\n",
      "        [ 0.0018,  0.0508,  0.1135],\n",
      "        [ 0.0675, -0.0739,  0.0720],\n",
      "        [-0.0426,  0.2839,  0.0400],\n",
      "        [ 0.1774,  0.2043,  0.2306],\n",
      "        [-0.0258,  0.3894,  0.0038],\n",
      "        [-0.1777,  0.2235,  0.1588],\n",
      "        [-0.0558,  0.0492, -0.0329],\n",
      "        [-0.1769, -0.0544, -0.0356],\n",
      "        [ 0.2988,  0.2076,  0.0287],\n",
      "        [ 0.0632,  0.0491, -0.0036],\n",
      "        [-0.0476,  0.0698,  0.0387],\n",
      "        [ 0.0436, -0.3362, -0.1564],\n",
      "        [ 0.1493, -0.0899, -0.1951],\n",
      "        [ 0.0535,  0.4551,  0.0818],\n",
      "        [ 0.2173, -0.0325, -0.0110],\n",
      "        [ 0.1434,  0.1122, -0.1986],\n",
      "        [ 0.2537,  0.1716,  0.0940],\n",
      "        [ 0.0656, -0.0540,  0.5166],\n",
      "        [-0.1040, -0.2245,  0.5884],\n",
      "        [-0.0336,  0.3018,  0.4021],\n",
      "        [ 0.5283,  0.5425, -0.0286],\n",
      "        [ 0.2162,  0.4382,  0.1259],\n",
      "        [ 0.0133,  0.4329,  0.4492],\n",
      "        [ 0.0643,  0.4006,  0.4231],\n",
      "        [ 0.1498,  0.2478,  0.4565],\n",
      "        [ 0.0708,  0.0756,  0.1754],\n",
      "        [-0.2522, -0.0507,  0.1425],\n",
      "        [-0.0505, -0.1125,  0.1396],\n",
      "        [-0.3054, -0.1318,  0.1534],\n",
      "        [-0.3213, -0.0273,  0.2866],\n",
      "        [-0.3513, -0.0856,  0.3018],\n",
      "        [-0.1837,  0.1538,  0.3333],\n",
      "        [-0.2457, -0.0858,  0.3345],\n",
      "        [-0.2391, -0.0174,  0.4985],\n",
      "        [-0.2147, -0.1934,  0.4536],\n",
      "        [-0.2676, -0.2139,  0.4412],\n",
      "        [-0.2152,  0.0443,  0.0817],\n",
      "        [-0.1742, -0.1318,  0.0789],\n",
      "        [-0.1245,  0.2007, -0.0262]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0224, 0.0171, 0.0199],\n",
      "        [0.0286, 0.0266, 0.0156],\n",
      "        [0.0224, 0.0242, 0.0171],\n",
      "        [0.0264, 0.0214, 0.0148],\n",
      "        [0.0247, 0.0227, 0.0169],\n",
      "        [0.0227, 0.0216, 0.0218],\n",
      "        [0.0242, 0.0190, 0.0209],\n",
      "        [0.0217, 0.0272, 0.0202],\n",
      "        [0.0270, 0.0251, 0.0245],\n",
      "        [0.0220, 0.0303, 0.0195],\n",
      "        [0.0189, 0.0257, 0.0228],\n",
      "        [0.0214, 0.0215, 0.0188],\n",
      "        [0.0189, 0.0194, 0.0187],\n",
      "        [0.0305, 0.0252, 0.0200],\n",
      "        [0.0241, 0.0215, 0.0193],\n",
      "        [0.0216, 0.0220, 0.0202],\n",
      "        [0.0236, 0.0146, 0.0166],\n",
      "        [0.0263, 0.0187, 0.0160],\n",
      "        [0.0239, 0.0323, 0.0211],\n",
      "        [0.0281, 0.0198, 0.0192],\n",
      "        [0.0261, 0.0229, 0.0159],\n",
      "        [0.0291, 0.0243, 0.0213],\n",
      "        [0.0241, 0.0194, 0.0326],\n",
      "        [0.0204, 0.0164, 0.0350],\n",
      "        [0.0219, 0.0277, 0.0290],\n",
      "        [0.0384, 0.0353, 0.0189],\n",
      "        [0.0281, 0.0318, 0.0220],\n",
      "        [0.0229, 0.0316, 0.0304],\n",
      "        [0.0241, 0.0306, 0.0296],\n",
      "        [0.0263, 0.0263, 0.0307],\n",
      "        [0.0243, 0.0221, 0.0231],\n",
      "        [0.0176, 0.0195, 0.0224],\n",
      "        [0.0215, 0.0183, 0.0223],\n",
      "        [0.0167, 0.0180, 0.0226],\n",
      "        [0.0164, 0.0199, 0.0259],\n",
      "        [0.0159, 0.0188, 0.0263],\n",
      "        [0.0188, 0.0239, 0.0271],\n",
      "        [0.0177, 0.0188, 0.0271],\n",
      "        [0.0178, 0.0202, 0.0320],\n",
      "        [0.0182, 0.0169, 0.0306],\n",
      "        [0.0173, 0.0166, 0.0302],\n",
      "        [0.0182, 0.0214, 0.0211],\n",
      "        [0.0190, 0.0180, 0.0210],\n",
      "        [0.0200, 0.0251, 0.0189]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0343, -0.0973,  0.1527],\n",
      "        [ 0.2512,  0.0927,  0.4600],\n",
      "        [ 0.2888, -0.1230,  0.2277],\n",
      "        [ 0.4937, -0.2935,  0.0181],\n",
      "        [ 0.4526, -0.1945,  0.1437],\n",
      "        [ 0.4187,  0.0321,  0.1073],\n",
      "        [ 0.6206, -0.0585,  0.0924],\n",
      "        [ 0.4680, -0.0788, -0.0745],\n",
      "        [ 0.4812, -0.0637, -0.0433],\n",
      "        [ 0.4092, -0.1713,  0.1700],\n",
      "        [ 0.3479, -0.2532,  0.0081],\n",
      "        [ 0.3992, -0.0516,  0.2571],\n",
      "        [ 0.0503,  0.0190, -0.0101],\n",
      "        [ 0.0459,  0.2047,  0.2180],\n",
      "        [ 0.0466,  0.0328,  0.3118],\n",
      "        [ 0.0253, -0.0125,  0.3818],\n",
      "        [ 0.3613, -0.0014,  0.5254],\n",
      "        [ 0.2454, -0.1076,  0.5361],\n",
      "        [ 0.0844,  0.0705,  0.3110],\n",
      "        [-0.1949, -0.2595,  0.3086],\n",
      "        [-0.0071, -0.0910,  0.3994],\n",
      "        [ 0.1324, -0.2754,  0.2330],\n",
      "        [-0.1604, -0.2162,  0.2000],\n",
      "        [ 0.1141, -0.1331,  0.3142],\n",
      "        [-0.0374, -0.3018,  0.2991],\n",
      "        [-0.0668, -0.2290,  0.2925],\n",
      "        [ 0.0273, -0.2671,  0.2390],\n",
      "        [-0.1606, -0.4316,  0.3152],\n",
      "        [-0.3030, -0.1820,  0.1836],\n",
      "        [-0.1176, -0.2399,  0.0121],\n",
      "        [ 0.1652, -0.3542,  0.1758],\n",
      "        [ 0.4673, -0.1205,  0.0923],\n",
      "        [ 0.0976, -0.2101,  0.3232],\n",
      "        [ 0.2937, -0.0324,  0.3777],\n",
      "        [ 0.2927, -0.0608, -0.0217],\n",
      "        [ 0.5889, -0.1597,  0.1847],\n",
      "        [ 0.1191, -0.1790,  0.2583],\n",
      "        [ 0.0165,  0.1401,  0.3088],\n",
      "        [ 0.1235, -0.0727,  0.2075],\n",
      "        [ 0.2458,  0.0284,  0.2791],\n",
      "        [ 0.1005, -0.1948,  0.0474],\n",
      "        [ 0.1565, -0.2644,  0.2391],\n",
      "        [-0.1307,  0.1654,  0.3779],\n",
      "        [-0.0406, -0.1029,  0.5708],\n",
      "        [-0.0082,  0.0126,  0.4539],\n",
      "        [-0.1142,  0.2396,  0.3682],\n",
      "        [-0.0997,  0.1046,  0.4553],\n",
      "        [-0.0353, -0.0911,  0.4448],\n",
      "        [-0.0929, -0.1606,  0.2654],\n",
      "        [ 0.1810, -0.1954,  0.5015],\n",
      "        [-0.0526,  0.1138,  0.1344],\n",
      "        [-0.0221,  0.1588,  0.2961],\n",
      "        [-0.1282,  0.4546,  0.4546],\n",
      "        [ 0.1519,  0.1061,  0.5728],\n",
      "        [ 0.0761, -0.2207,  0.6079],\n",
      "        [ 0.3979, -0.0189,  0.2798],\n",
      "        [ 0.1510, -0.0084,  0.0493]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0155, 0.0170, 0.0155],\n",
      "        [0.0192, 0.0206, 0.0211],\n",
      "        [0.0200, 0.0166, 0.0167],\n",
      "        [0.0245, 0.0140, 0.0136],\n",
      "        [0.0235, 0.0154, 0.0154],\n",
      "        [0.0228, 0.0194, 0.0148],\n",
      "        [0.0279, 0.0177, 0.0146],\n",
      "        [0.0239, 0.0173, 0.0124],\n",
      "        [0.0242, 0.0176, 0.0128],\n",
      "        [0.0226, 0.0158, 0.0158],\n",
      "        [0.0212, 0.0146, 0.0134],\n",
      "        [0.0223, 0.0178, 0.0172],\n",
      "        [0.0157, 0.0191, 0.0132],\n",
      "        [0.0157, 0.0230, 0.0166],\n",
      "        [0.0157, 0.0194, 0.0182],\n",
      "        [0.0154, 0.0185, 0.0195],\n",
      "        [0.0215, 0.0187, 0.0225],\n",
      "        [0.0191, 0.0168, 0.0228],\n",
      "        [0.0163, 0.0201, 0.0182],\n",
      "        [0.0123, 0.0145, 0.0181],\n",
      "        [0.0149, 0.0171, 0.0199],\n",
      "        [0.0171, 0.0142, 0.0168],\n",
      "        [0.0128, 0.0151, 0.0163],\n",
      "        [0.0168, 0.0164, 0.0182],\n",
      "        [0.0144, 0.0139, 0.0180],\n",
      "        [0.0140, 0.0149, 0.0179],\n",
      "        [0.0154, 0.0144, 0.0169],\n",
      "        [0.0127, 0.0122, 0.0182],\n",
      "        [0.0111, 0.0156, 0.0160],\n",
      "        [0.0133, 0.0148, 0.0135],\n",
      "        [0.0177, 0.0132, 0.0159],\n",
      "        [0.0239, 0.0166, 0.0146],\n",
      "        [0.0165, 0.0152, 0.0184],\n",
      "        [0.0201, 0.0182, 0.0194],\n",
      "        [0.0201, 0.0177, 0.0130],\n",
      "        [0.0270, 0.0160, 0.0160],\n",
      "        [0.0169, 0.0157, 0.0173],\n",
      "        [0.0152, 0.0216, 0.0181],\n",
      "        [0.0170, 0.0174, 0.0164],\n",
      "        [0.0191, 0.0193, 0.0176],\n",
      "        [0.0166, 0.0154, 0.0140],\n",
      "        [0.0175, 0.0144, 0.0169],\n",
      "        [0.0131, 0.0221, 0.0194],\n",
      "        [0.0144, 0.0169, 0.0236],\n",
      "        [0.0149, 0.0190, 0.0210],\n",
      "        [0.0134, 0.0238, 0.0192],\n",
      "        [0.0136, 0.0208, 0.0210],\n",
      "        [0.0145, 0.0171, 0.0208],\n",
      "        [0.0136, 0.0160, 0.0174],\n",
      "        [0.0180, 0.0154, 0.0220],\n",
      "        [0.0142, 0.0210, 0.0152],\n",
      "        [0.0146, 0.0220, 0.0179],\n",
      "        [0.0132, 0.0296, 0.0210],\n",
      "        [0.0174, 0.0209, 0.0236],\n",
      "        [0.0162, 0.0150, 0.0245],\n",
      "        [0.0223, 0.0184, 0.0176],\n",
      "        [0.0174, 0.0186, 0.0140]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.1483, -0.0584, -0.0603],\n",
      "        [ 0.2161,  0.0350,  0.0335],\n",
      "        [ 0.1729, -0.0123,  0.0646],\n",
      "        [ 0.3870, -0.1029, -0.0122],\n",
      "        [ 0.3933,  0.1931,  0.0121],\n",
      "        [ 0.0036,  0.1050, -0.0149],\n",
      "        [-0.0279,  0.2407,  0.0247],\n",
      "        [-0.0886,  0.2876,  0.0394],\n",
      "        [-0.2152,  0.0740,  0.2651],\n",
      "        [-0.2502,  0.3301,  0.2424],\n",
      "        [-0.1809,  0.1338, -0.1295],\n",
      "        [-0.2544,  0.3103, -0.0528],\n",
      "        [-0.3132,  0.3171, -0.0342],\n",
      "        [ 0.0404, -0.0239,  0.1710],\n",
      "        [-0.1779,  0.2229,  0.0171],\n",
      "        [-0.0630,  0.0675,  0.1183],\n",
      "        [ 0.0343,  0.0758,  0.1406],\n",
      "        [ 0.0310, -0.0754,  0.3259],\n",
      "        [ 0.2117, -0.0178,  0.1770],\n",
      "        [-0.0800,  0.0436,  0.3389],\n",
      "        [ 0.0745, -0.1324,  0.2957],\n",
      "        [-0.1235,  0.0370,  0.2954],\n",
      "        [ 0.1019, -0.1208,  0.2595],\n",
      "        [-0.0152,  0.0475,  0.1936]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0474, 0.0358, 0.0347],\n",
      "        [0.0508, 0.0393, 0.0381],\n",
      "        [0.0486, 0.0375, 0.0393],\n",
      "        [0.0602, 0.0343, 0.0364],\n",
      "        [0.0606, 0.0461, 0.0373],\n",
      "        [0.0410, 0.0422, 0.0363],\n",
      "        [0.0398, 0.0483, 0.0378],\n",
      "        [0.0374, 0.0507, 0.0384],\n",
      "        [0.0330, 0.0409, 0.0480],\n",
      "        [0.0318, 0.0529, 0.0470],\n",
      "        [0.0341, 0.0434, 0.0324],\n",
      "        [0.0317, 0.0518, 0.0350],\n",
      "        [0.0299, 0.0522, 0.0356],\n",
      "        [0.0426, 0.0371, 0.0438],\n",
      "        [0.0342, 0.0475, 0.0375],\n",
      "        [0.0384, 0.0406, 0.0415],\n",
      "        [0.0423, 0.0410, 0.0424],\n",
      "        [0.0421, 0.0352, 0.0511],\n",
      "        [0.0505, 0.0373, 0.0440],\n",
      "        [0.0378, 0.0397, 0.0517],\n",
      "        [0.0441, 0.0333, 0.0495],\n",
      "        [0.0361, 0.0394, 0.0495],\n",
      "        [0.0453, 0.0337, 0.0478],\n",
      "        [0.0403, 0.0399, 0.0447]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.2020,  0.0453, -0.0546],\n",
      "        [ 0.1318,  0.0230, -0.1646],\n",
      "        [ 0.0704, -0.3040, -0.0046],\n",
      "        [-0.2148,  0.0251,  0.1666],\n",
      "        [-0.0254, -0.2603,  0.1174],\n",
      "        [-0.0170,  0.0523,  0.0491],\n",
      "        [-0.3943, -0.1908,  0.4517],\n",
      "        [ 0.0635, -0.3325,  0.2076],\n",
      "        [-0.1549, -0.2476,  0.1930],\n",
      "        [-0.0867, -0.0886,  0.0699],\n",
      "        [-0.1687, -0.1126,  0.1899],\n",
      "        [-0.0355,  0.0803,  0.1405],\n",
      "        [ 0.1388,  0.2438,  0.1714],\n",
      "        [-0.1592, -0.0959,  0.2607],\n",
      "        [-0.0347, -0.0870,  0.3577],\n",
      "        [-0.0606,  0.0340,  0.4990],\n",
      "        [ 0.2546, -0.1548,  0.2803],\n",
      "        [ 0.2408, -0.0826,  0.2047],\n",
      "        [ 0.1633, -0.0500,  0.0220],\n",
      "        [ 0.2098, -0.1614,  0.2568],\n",
      "        [ 0.0927, -0.1104,  0.1055],\n",
      "        [ 0.0027, -0.0561,  0.4055],\n",
      "        [-0.0891, -0.0908,  0.2681],\n",
      "        [-0.2412,  0.0228,  0.3242],\n",
      "        [-0.2756,  0.0248,  0.5908],\n",
      "        [-0.1202,  0.0958,  0.1879],\n",
      "        [-0.1775,  0.1130, -0.0223],\n",
      "        [ 0.0498,  0.1925,  0.5742],\n",
      "        [-0.2546,  0.1045,  0.0698],\n",
      "        [-0.1877,  0.2216,  0.2344],\n",
      "        [-0.0599, -0.1508,  0.1473],\n",
      "        [-0.2590, -0.2236,  0.4543],\n",
      "        [-0.1107, -0.2437,  0.1171],\n",
      "        [-0.1111,  0.0869,  0.3875],\n",
      "        [-0.0726, -0.1333,  0.3887],\n",
      "        [-0.0292,  0.0252,  0.0225],\n",
      "        [-0.3237,  0.0804,  0.3447],\n",
      "        [ 0.1797, -0.2991,  0.0778],\n",
      "        [-0.1383, -0.3777, -0.0580],\n",
      "        [-0.1399, -0.1570, -0.0939],\n",
      "        [ 0.0693, -0.1606,  0.0285],\n",
      "        [ 0.1665, -0.1477, -0.2661],\n",
      "        [-0.1008, -0.0439,  0.0965],\n",
      "        [ 0.4666,  0.2025, -0.2522]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0284, 0.0250, 0.0178],\n",
      "        [0.0264, 0.0244, 0.0159],\n",
      "        [0.0249, 0.0176, 0.0187],\n",
      "        [0.0187, 0.0245, 0.0222],\n",
      "        [0.0226, 0.0184, 0.0211],\n",
      "        [0.0228, 0.0252, 0.0197],\n",
      "        [0.0156, 0.0197, 0.0295],\n",
      "        [0.0247, 0.0171, 0.0231],\n",
      "        [0.0198, 0.0186, 0.0228],\n",
      "        [0.0213, 0.0219, 0.0201],\n",
      "        [0.0196, 0.0213, 0.0227],\n",
      "        [0.0224, 0.0259, 0.0216],\n",
      "        [0.0266, 0.0305, 0.0223],\n",
      "        [0.0197, 0.0217, 0.0244],\n",
      "        [0.0224, 0.0219, 0.0268],\n",
      "        [0.0218, 0.0247, 0.0309],\n",
      "        [0.0299, 0.0205, 0.0248],\n",
      "        [0.0295, 0.0220, 0.0230],\n",
      "        [0.0273, 0.0227, 0.0192],\n",
      "        [0.0286, 0.0203, 0.0243],\n",
      "        [0.0254, 0.0214, 0.0209],\n",
      "        [0.0232, 0.0226, 0.0282],\n",
      "        [0.0212, 0.0218, 0.0245],\n",
      "        [0.0182, 0.0244, 0.0260],\n",
      "        [0.0176, 0.0245, 0.0339],\n",
      "        [0.0205, 0.0263, 0.0227],\n",
      "        [0.0194, 0.0267, 0.0184],\n",
      "        [0.0244, 0.0289, 0.0333],\n",
      "        [0.0180, 0.0265, 0.0201],\n",
      "        [0.0192, 0.0298, 0.0237],\n",
      "        [0.0218, 0.0205, 0.0217],\n",
      "        [0.0179, 0.0191, 0.0296],\n",
      "        [0.0207, 0.0187, 0.0211],\n",
      "        [0.0207, 0.0260, 0.0276],\n",
      "        [0.0215, 0.0209, 0.0277],\n",
      "        [0.0225, 0.0245, 0.0192],\n",
      "        [0.0168, 0.0259, 0.0265],\n",
      "        [0.0277, 0.0177, 0.0203],\n",
      "        [0.0202, 0.0164, 0.0177],\n",
      "        [0.0201, 0.0204, 0.0171],\n",
      "        [0.0248, 0.0203, 0.0193],\n",
      "        [0.0274, 0.0206, 0.0144],\n",
      "        [0.0209, 0.0229, 0.0207],\n",
      "        [0.0369, 0.0292, 0.0146]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.1392, -0.1848,  0.0798],\n",
      "        [-0.0765, -0.0555, -0.4407],\n",
      "        [-0.1803, -0.0085, -0.0566],\n",
      "        [-0.2327, -0.0556, -0.0478],\n",
      "        [-0.2366, -0.2747, -0.0278],\n",
      "        [-0.0579, -0.1584, -0.2299],\n",
      "        [-0.0170, -0.2549, -0.2111],\n",
      "        [-0.3794, -0.2177,  0.1168],\n",
      "        [-0.1108,  0.0040,  0.4368],\n",
      "        [-0.3035, -0.1719,  0.3032],\n",
      "        [-0.1771, -0.2654,  0.3247],\n",
      "        [-0.1613, -0.1649,  0.2605],\n",
      "        [ 0.0680, -0.4426, -0.1560],\n",
      "        [-0.1263, -0.2930,  0.0892],\n",
      "        [-0.1866, -0.2106,  0.0162],\n",
      "        [-0.0418, -0.3669,  0.1648],\n",
      "        [-0.0858, -0.4038,  0.2744],\n",
      "        [-0.1023, -0.2103,  0.0824],\n",
      "        [-0.0845, -0.4856,  0.1498],\n",
      "        [-0.3494, -0.2314, -0.1251],\n",
      "        [-0.3384, -0.3450,  0.2177],\n",
      "        [-0.2610,  0.2249,  0.1713],\n",
      "        [-0.4465, -0.2328,  0.1975],\n",
      "        [-0.2163,  0.3713,  0.2668],\n",
      "        [-0.3040,  0.1736,  0.4880],\n",
      "        [-0.2474,  0.2090,  0.4880],\n",
      "        [-0.3960,  0.0081,  0.5132],\n",
      "        [-0.2930, -0.0960,  0.4746],\n",
      "        [-0.1835,  0.1236,  0.5396],\n",
      "        [-0.1500,  0.0595,  0.7661],\n",
      "        [-0.2122, -0.0034,  0.8701],\n",
      "        [-0.3179,  0.1497,  0.9619],\n",
      "        [-0.2969,  0.0411,  0.8687],\n",
      "        [-0.1427, -0.3330,  0.5420],\n",
      "        [-0.3291, -0.4580,  0.8901],\n",
      "        [-0.0408, -0.7349,  0.4006],\n",
      "        [-0.1914, -0.7363,  0.6636],\n",
      "        [-0.1098, -0.6787,  0.5771],\n",
      "        [-0.1810, -0.1097,  0.5649],\n",
      "        [-0.1313,  0.1030,  0.4661],\n",
      "        [-0.2629,  0.1823,  0.5322],\n",
      "        [-0.1674,  0.0112,  0.4573],\n",
      "        [-0.0452,  0.1736,  0.4270],\n",
      "        [-0.0998, -0.0399,  0.2651],\n",
      "        [-0.1940,  0.0560,  0.3396],\n",
      "        [-0.0272,  0.1603,  0.2335],\n",
      "        [-0.2886, -0.0726,  0.2600],\n",
      "        [ 0.0504,  0.0586,  0.1057],\n",
      "        [ 0.0098,  0.1206,  0.0599],\n",
      "        [ 0.1882,  0.1274,  0.0351]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0269, 0.0182, 0.0154],\n",
      "        [0.0217, 0.0207, 0.0092],\n",
      "        [0.0195, 0.0217, 0.0135],\n",
      "        [0.0185, 0.0207, 0.0136],\n",
      "        [0.0185, 0.0166, 0.0138],\n",
      "        [0.0221, 0.0187, 0.0113],\n",
      "        [0.0230, 0.0169, 0.0115],\n",
      "        [0.0160, 0.0176, 0.0160],\n",
      "        [0.0210, 0.0219, 0.0220],\n",
      "        [0.0173, 0.0184, 0.0193],\n",
      "        [0.0196, 0.0168, 0.0197],\n",
      "        [0.0199, 0.0185, 0.0185],\n",
      "        [0.0251, 0.0140, 0.0122],\n",
      "        [0.0206, 0.0163, 0.0156],\n",
      "        [0.0194, 0.0177, 0.0145],\n",
      "        [0.0224, 0.0151, 0.0168],\n",
      "        [0.0215, 0.0146, 0.0187],\n",
      "        [0.0211, 0.0177, 0.0155],\n",
      "        [0.0215, 0.0135, 0.0165],\n",
      "        [0.0165, 0.0173, 0.0126],\n",
      "        [0.0167, 0.0155, 0.0177],\n",
      "        [0.0180, 0.0274, 0.0169],\n",
      "        [0.0150, 0.0173, 0.0173],\n",
      "        [0.0189, 0.0317, 0.0186],\n",
      "        [0.0173, 0.0260, 0.0232],\n",
      "        [0.0183, 0.0269, 0.0232],\n",
      "        [0.0158, 0.0220, 0.0238],\n",
      "        [0.0175, 0.0199, 0.0229],\n",
      "        [0.0195, 0.0247, 0.0244],\n",
      "        [0.0201, 0.0232, 0.0306],\n",
      "        [0.0189, 0.0218, 0.0340],\n",
      "        [0.0170, 0.0254, 0.0372],\n",
      "        [0.0174, 0.0228, 0.0339],\n",
      "        [0.0203, 0.0157, 0.0245],\n",
      "        [0.0168, 0.0138, 0.0347],\n",
      "        [0.0225, 0.0105, 0.0212],\n",
      "        [0.0193, 0.0105, 0.0276],\n",
      "        [0.0210, 0.0111, 0.0253],\n",
      "        [0.0195, 0.0196, 0.0250],\n",
      "        [0.0205, 0.0242, 0.0227],\n",
      "        [0.0180, 0.0262, 0.0242],\n",
      "        [0.0198, 0.0221, 0.0225],\n",
      "        [0.0224, 0.0260, 0.0218],\n",
      "        [0.0212, 0.0210, 0.0186],\n",
      "        [0.0193, 0.0231, 0.0200],\n",
      "        [0.0228, 0.0257, 0.0180],\n",
      "        [0.0175, 0.0203, 0.0185],\n",
      "        [0.0246, 0.0232, 0.0158],\n",
      "        [0.0236, 0.0247, 0.0151],\n",
      "        [0.0283, 0.0248, 0.0147]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.1107, -0.1039,  0.0173],\n",
      "        [ 0.0229, -0.0033,  0.1198],\n",
      "        [-0.0406, -0.2407,  0.1588],\n",
      "        [ 0.0080, -0.0165,  0.3813],\n",
      "        [-0.0647, -0.0646,  0.4480],\n",
      "        [ 0.1083,  0.2186,  0.4504],\n",
      "        [-0.1984, -0.0848,  0.3496],\n",
      "        [-0.0103,  0.1373,  0.3196],\n",
      "        [-0.2307, -0.2842,  0.3525],\n",
      "        [-0.2805, -0.2004,  0.2742],\n",
      "        [-0.3401, -0.3601,  0.3323],\n",
      "        [-0.0123, -0.2559,  0.4822],\n",
      "        [-0.1486, -0.3489,  0.5977],\n",
      "        [ 0.0078,  0.1149,  0.5469],\n",
      "        [-0.2839, -0.4021,  0.6943],\n",
      "        [-0.4058,  0.0869,  0.2817],\n",
      "        [-0.2015,  0.0201,  0.0979],\n",
      "        [-0.1125,  0.1305,  0.0839],\n",
      "        [-0.2332, -0.0152,  0.3787],\n",
      "        [ 0.1129,  0.2003,  0.0692]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0616, 0.0476, 0.0363],\n",
      "        [0.0564, 0.0527, 0.0402],\n",
      "        [0.0530, 0.0416, 0.0418],\n",
      "        [0.0556, 0.0520, 0.0522],\n",
      "        [0.0517, 0.0496, 0.0558],\n",
      "        [0.0615, 0.0658, 0.0559],\n",
      "        [0.0452, 0.0486, 0.0506],\n",
      "        [0.0546, 0.0607, 0.0491],\n",
      "        [0.0438, 0.0398, 0.0507],\n",
      "        [0.0417, 0.0433, 0.0469],\n",
      "        [0.0392, 0.0369, 0.0497],\n",
      "        [0.0545, 0.0409, 0.0577],\n",
      "        [0.0475, 0.0373, 0.0648],\n",
      "        [0.0556, 0.0593, 0.0616],\n",
      "        [0.0415, 0.0354, 0.0714],\n",
      "        [0.0367, 0.0577, 0.0472],\n",
      "        [0.0451, 0.0540, 0.0393],\n",
      "        [0.0493, 0.0602, 0.0388],\n",
      "        [0.0437, 0.0521, 0.0521],\n",
      "        [0.0617, 0.0646, 0.0382]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0473, -0.2314,  0.1976],\n",
      "        [ 0.3201,  0.0720,  0.0033],\n",
      "        [-0.0590, -0.1392,  0.1128],\n",
      "        [ 0.2035, -0.1461, -0.0638],\n",
      "        [ 0.0806,  0.0833,  0.0171],\n",
      "        [-0.0436,  0.3853,  0.2130],\n",
      "        [-0.0366,  0.2335, -0.1816],\n",
      "        [ 0.1432,  0.2878,  0.0468],\n",
      "        [ 0.1798,  0.1849, -0.1512],\n",
      "        [ 0.2639,  0.1615,  0.1202]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0854, 0.0712, 0.1171],\n",
      "        [0.1234, 0.0965, 0.0965],\n",
      "        [0.0845, 0.0781, 0.1076],\n",
      "        [0.1099, 0.0776, 0.0902],\n",
      "        [0.0972, 0.0976, 0.0978],\n",
      "        [0.0858, 0.1321, 0.1190],\n",
      "        [0.0864, 0.1135, 0.0801],\n",
      "        [0.1034, 0.1198, 0.1007],\n",
      "        [0.1073, 0.1080, 0.0826],\n",
      "        [0.1167, 0.1055, 0.1085]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0380, -0.0790,  0.1724],\n",
      "        [ 0.2201,  0.4580,  0.1359],\n",
      "        [-0.0801,  0.0481,  0.2238],\n",
      "        [ 0.2144, -0.0662,  0.1536],\n",
      "        [ 0.1753, -0.3484,  0.3259],\n",
      "        [ 0.2520,  0.0626,  0.2024],\n",
      "        [ 0.2732,  0.1287,  0.4902],\n",
      "        [ 0.2069,  0.1647,  0.1923],\n",
      "        [ 0.0809, -0.0234,  0.2661],\n",
      "        [ 0.2115,  0.1935,  0.2472],\n",
      "        [ 0.0140, -0.0901,  0.2583],\n",
      "        [ 0.1898,  0.0167,  0.1696],\n",
      "        [ 0.0238, -0.0556,  0.1478],\n",
      "        [ 0.0125,  0.3445,  0.4202],\n",
      "        [-0.0183, -0.0159,  0.0116],\n",
      "        [ 0.1858,  0.2832,  0.0777]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0570, 0.0532, 0.0593],\n",
      "        [0.0684, 0.0910, 0.0572],\n",
      "        [0.0506, 0.0604, 0.0624],\n",
      "        [0.0679, 0.0539, 0.0582],\n",
      "        [0.0654, 0.0406, 0.0692],\n",
      "        [0.0706, 0.0613, 0.0611],\n",
      "        [0.0721, 0.0655, 0.0815],\n",
      "        [0.0674, 0.0679, 0.0605],\n",
      "        [0.0595, 0.0562, 0.0651],\n",
      "        [0.0677, 0.0699, 0.0639],\n",
      "        [0.0556, 0.0526, 0.0646],\n",
      "        [0.0663, 0.0585, 0.0591],\n",
      "        [0.0562, 0.0544, 0.0578],\n",
      "        [0.0555, 0.0812, 0.0759],\n",
      "        [0.0538, 0.0567, 0.0505],\n",
      "        [0.0660, 0.0765, 0.0539]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0923, -0.2444, -0.0064],\n",
      "        [ 0.1434, -0.0422, -0.0622],\n",
      "        [ 0.0804, -0.1783,  0.1096],\n",
      "        [ 0.2891,  0.0461, -0.1433],\n",
      "        [ 0.0899, -0.1526, -0.0337],\n",
      "        [ 0.0331,  0.3066, -0.1074],\n",
      "        [-0.0726,  0.0034,  0.0575],\n",
      "        [ 0.0900,  0.2791,  0.1083],\n",
      "        [ 0.2227, -0.2211, -0.2571],\n",
      "        [ 0.2954, -0.0065, -0.2607],\n",
      "        [ 0.1735, -0.1422,  0.0760],\n",
      "        [ 0.1249, -0.1274,  0.1035],\n",
      "        [-0.1501,  0.0729,  0.4836],\n",
      "        [-0.1964, -0.0405,  0.3428],\n",
      "        [-0.0433, -0.2179,  0.3394],\n",
      "        [-0.1852,  0.0248,  0.3677],\n",
      "        [-0.1292, -0.2595,  0.4871],\n",
      "        [-0.0773, -0.2253,  0.5581],\n",
      "        [-0.3284, -0.2073,  0.4526],\n",
      "        [-0.2177, -0.2866,  0.5469],\n",
      "        [-0.2318, -0.1285,  0.5693],\n",
      "        [-0.3647,  0.0325,  0.4534],\n",
      "        [-0.2430, -0.0205,  0.5654],\n",
      "        [-0.3066,  0.2517,  0.4614],\n",
      "        [-0.2537, -0.1885,  0.2791],\n",
      "        [ 0.0924, -0.0244,  0.1089],\n",
      "        [ 0.1174, -0.2054,  0.1813],\n",
      "        [ 0.2455,  0.2010,  0.1754]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0394, 0.0293, 0.0278],\n",
      "        [0.0415, 0.0359, 0.0263],\n",
      "        [0.0390, 0.0313, 0.0312],\n",
      "        [0.0480, 0.0392, 0.0242],\n",
      "        [0.0393, 0.0321, 0.0271],\n",
      "        [0.0371, 0.0508, 0.0251],\n",
      "        [0.0334, 0.0375, 0.0296],\n",
      "        [0.0393, 0.0494, 0.0312],\n",
      "        [0.0449, 0.0300, 0.0216],\n",
      "        [0.0483, 0.0372, 0.0215],\n",
      "        [0.0428, 0.0324, 0.0302],\n",
      "        [0.0407, 0.0329, 0.0310],\n",
      "        [0.0309, 0.0403, 0.0454],\n",
      "        [0.0295, 0.0359, 0.0394],\n",
      "        [0.0344, 0.0301, 0.0393],\n",
      "        [0.0299, 0.0384, 0.0404],\n",
      "        [0.0316, 0.0289, 0.0455],\n",
      "        [0.0333, 0.0299, 0.0489],\n",
      "        [0.0259, 0.0304, 0.0440],\n",
      "        [0.0289, 0.0281, 0.0483],\n",
      "        [0.0285, 0.0329, 0.0494],\n",
      "        [0.0249, 0.0386, 0.0440],\n",
      "        [0.0282, 0.0367, 0.0492],\n",
      "        [0.0265, 0.0481, 0.0444],\n",
      "        [0.0279, 0.0310, 0.0370],\n",
      "        [0.0394, 0.0365, 0.0312],\n",
      "        [0.0404, 0.0305, 0.0335],\n",
      "        [0.0459, 0.0457, 0.0333]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.1388, -0.0309, -0.1094],\n",
      "        [ 0.1868,  0.4202,  0.2512],\n",
      "        [ 0.0781, -0.5562,  0.4526],\n",
      "        [ 0.0720, -0.4915,  0.3638],\n",
      "        [ 0.1969, -0.4812,  0.3616],\n",
      "        [ 0.4941, -0.0170,  0.1271],\n",
      "        [ 0.2395, -0.1251,  0.2338],\n",
      "        [ 0.2303,  0.1399,  0.2729],\n",
      "        [ 0.5244,  0.2742,  0.1870],\n",
      "        [ 0.5317,  0.3406,  0.0760],\n",
      "        [ 0.2810, -0.0124,  0.1860],\n",
      "        [ 0.0424,  0.1120,  0.2314],\n",
      "        [ 0.2357, -0.1547,  0.3347],\n",
      "        [ 0.3315, -0.0060,  0.1172],\n",
      "        [ 0.3865, -0.0111,  0.1653],\n",
      "        [ 0.1661,  0.1564,  0.3232],\n",
      "        [ 0.1996,  0.3767,  0.3447],\n",
      "        [ 0.0959,  0.2573,  0.1803],\n",
      "        [ 0.2168, -0.0640,  0.2561],\n",
      "        [ 0.2517,  0.3210,  0.2102],\n",
      "        [ 0.1422,  0.0729, -0.1148],\n",
      "        [ 0.3225,  0.4875,  0.1665],\n",
      "        [ 0.3245,  0.2542,  0.1015],\n",
      "        [ 0.0234,  0.2212,  0.2134],\n",
      "        [-0.0990,  0.1039,  0.2146],\n",
      "        [ 0.0099,  0.0933,  0.4758],\n",
      "        [-0.0435,  0.0535,  0.3564],\n",
      "        [-0.0292,  0.3665,  0.3269],\n",
      "        [-0.1531,  0.2734,  0.1886],\n",
      "        [ 0.1193,  0.4460,  0.1643],\n",
      "        [-0.1808,  0.0895,  0.4451],\n",
      "        [-0.0979,  0.0872,  0.0690],\n",
      "        [-0.0803,  0.0344,  0.0727],\n",
      "        [-0.1316,  0.1176,  0.3618],\n",
      "        [ 0.0146,  0.2300,  0.3521],\n",
      "        [ 0.1095,  0.0767,  0.5571],\n",
      "        [-0.0903, -0.1164,  0.5938],\n",
      "        [-0.1013,  0.0788,  0.3176],\n",
      "        [ 0.2223,  0.2274,  0.4607],\n",
      "        [ 0.1381,  0.1300,  0.6870],\n",
      "        [ 0.0592,  0.1333,  0.5396],\n",
      "        [ 0.0293, -0.0462,  0.5825],\n",
      "        [-0.0674,  0.0921,  0.6006],\n",
      "        [-0.1992,  0.0922,  0.1948],\n",
      "        [-0.0878,  0.1647,  0.4155],\n",
      "        [-0.1931, -0.1251,  0.3220],\n",
      "        [-0.2502,  0.1554,  0.3684],\n",
      "        [-0.1938,  0.3301,  0.0855],\n",
      "        [-0.0091,  0.2656, -0.4417],\n",
      "        [ 0.2020,  0.4597, -0.2070],\n",
      "        [ 0.1411,  0.2346, -0.2834],\n",
      "        [ 0.1899,  0.3687, -0.1869]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0197, 0.0163, 0.0132],\n",
      "        [0.0207, 0.0255, 0.0190],\n",
      "        [0.0186, 0.0096, 0.0232],\n",
      "        [0.0184, 0.0103, 0.0212],\n",
      "        [0.0209, 0.0104, 0.0211],\n",
      "        [0.0281, 0.0165, 0.0167],\n",
      "        [0.0218, 0.0148, 0.0186],\n",
      "        [0.0216, 0.0193, 0.0194],\n",
      "        [0.0290, 0.0221, 0.0178],\n",
      "        [0.0292, 0.0236, 0.0159],\n",
      "        [0.0228, 0.0166, 0.0177],\n",
      "        [0.0179, 0.0188, 0.0186],\n",
      "        [0.0217, 0.0144, 0.0206],\n",
      "        [0.0239, 0.0167, 0.0166],\n",
      "        [0.0253, 0.0166, 0.0174],\n",
      "        [0.0203, 0.0196, 0.0204],\n",
      "        [0.0210, 0.0245, 0.0208],\n",
      "        [0.0189, 0.0217, 0.0177],\n",
      "        [0.0213, 0.0157, 0.0190],\n",
      "        [0.0221, 0.0231, 0.0182],\n",
      "        [0.0198, 0.0181, 0.0131],\n",
      "        [0.0237, 0.0273, 0.0174],\n",
      "        [0.0238, 0.0216, 0.0163],\n",
      "        [0.0176, 0.0209, 0.0182],\n",
      "        [0.0156, 0.0186, 0.0183],\n",
      "        [0.0173, 0.0184, 0.0237],\n",
      "        [0.0164, 0.0177, 0.0211],\n",
      "        [0.0167, 0.0242, 0.0204],\n",
      "        [0.0147, 0.0220, 0.0178],\n",
      "        [0.0193, 0.0262, 0.0174],\n",
      "        [0.0143, 0.0184, 0.0230],\n",
      "        [0.0156, 0.0183, 0.0158],\n",
      "        [0.0158, 0.0174, 0.0159],\n",
      "        [0.0151, 0.0189, 0.0211],\n",
      "        [0.0174, 0.0211, 0.0210],\n",
      "        [0.0192, 0.0181, 0.0257],\n",
      "        [0.0157, 0.0149, 0.0267],\n",
      "        [0.0155, 0.0182, 0.0202],\n",
      "        [0.0215, 0.0211, 0.0234],\n",
      "        [0.0197, 0.0191, 0.0293],\n",
      "        [0.0182, 0.0192, 0.0253],\n",
      "        [0.0177, 0.0160, 0.0264],\n",
      "        [0.0161, 0.0184, 0.0269],\n",
      "        [0.0141, 0.0184, 0.0179],\n",
      "        [0.0157, 0.0198, 0.0223],\n",
      "        [0.0142, 0.0148, 0.0203],\n",
      "        [0.0134, 0.0196, 0.0213],\n",
      "        [0.0141, 0.0233, 0.0161],\n",
      "        [0.0170, 0.0219, 0.0095],\n",
      "        [0.0210, 0.0266, 0.0120],\n",
      "        [0.0198, 0.0212, 0.0111],\n",
      "        [0.0208, 0.0243, 0.0122]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0013, -0.0729,  0.0473],\n",
      "        [ 0.3225,  0.2101,  0.0399],\n",
      "        [ 0.0711,  0.0245,  0.0097],\n",
      "        [ 0.0240,  0.0109, -0.0605],\n",
      "        [-0.0221,  0.2053, -0.1489],\n",
      "        [-0.0970,  0.3008,  0.0440],\n",
      "        [-0.1185,  0.0565, -0.0328],\n",
      "        [-0.0482,  0.4402,  0.1749],\n",
      "        [-0.2037,  0.1315, -0.0383],\n",
      "        [-0.2089,  0.1659,  0.1438],\n",
      "        [-0.2397,  0.1390,  0.0594],\n",
      "        [-0.2827, -0.0149,  0.2517],\n",
      "        [-0.2908,  0.1655, -0.0035],\n",
      "        [-0.0163,  0.3103,  0.2340],\n",
      "        [-0.1324,  0.3142,  0.3811],\n",
      "        [-0.0913,  0.0635,  0.2235],\n",
      "        [-0.1265, -0.0281,  0.4814],\n",
      "        [-0.0140, -0.0271,  0.3677],\n",
      "        [-0.0345, -0.1588,  0.0608],\n",
      "        [ 0.1320,  0.2693,  0.2529],\n",
      "        [-0.2311,  0.1260,  0.3350],\n",
      "        [-0.2817, -0.0801,  0.2452],\n",
      "        [-0.2220, -0.1133,  0.4204],\n",
      "        [-0.1223,  0.0619,  0.4277],\n",
      "        [-0.1831,  0.0185,  0.0748],\n",
      "        [-0.0529,  0.3154,  0.2460],\n",
      "        [-0.1197,  0.2151,  0.0757],\n",
      "        [ 0.0990,  0.4875,  0.1010]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0386, 0.0289, 0.0316],\n",
      "        [0.0534, 0.0383, 0.0313],\n",
      "        [0.0415, 0.0318, 0.0304],\n",
      "        [0.0396, 0.0314, 0.0283],\n",
      "        [0.0378, 0.0381, 0.0259],\n",
      "        [0.0351, 0.0420, 0.0314],\n",
      "        [0.0343, 0.0329, 0.0291],\n",
      "        [0.0368, 0.0482, 0.0358],\n",
      "        [0.0315, 0.0354, 0.0290],\n",
      "        [0.0314, 0.0367, 0.0347],\n",
      "        [0.0304, 0.0357, 0.0319],\n",
      "        [0.0291, 0.0306, 0.0387],\n",
      "        [0.0289, 0.0367, 0.0300],\n",
      "        [0.0380, 0.0424, 0.0380],\n",
      "        [0.0338, 0.0425, 0.0440],\n",
      "        [0.0353, 0.0331, 0.0376],\n",
      "        [0.0341, 0.0302, 0.0487],\n",
      "        [0.0381, 0.0302, 0.0435],\n",
      "        [0.0373, 0.0265, 0.0320],\n",
      "        [0.0441, 0.0406, 0.0388],\n",
      "        [0.0307, 0.0352, 0.0421],\n",
      "        [0.0292, 0.0287, 0.0385],\n",
      "        [0.0310, 0.0277, 0.0458],\n",
      "        [0.0342, 0.0330, 0.0461],\n",
      "        [0.0322, 0.0316, 0.0324],\n",
      "        [0.0367, 0.0426, 0.0385],\n",
      "        [0.0343, 0.0385, 0.0325],\n",
      "        [0.0427, 0.0506, 0.0333]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 2.5928e-01,  2.9648e-02, -2.3901e-01],\n",
      "        [ 2.1460e-01,  5.0629e-02, -3.3521e-01],\n",
      "        [ 1.4075e-01,  2.0715e-01,  7.9773e-02],\n",
      "        [ 2.4622e-01,  7.3608e-02,  5.5969e-02],\n",
      "        [ 2.1570e-01,  1.5344e-01,  2.0789e-01],\n",
      "        [ 2.7173e-01,  2.0361e-01,  1.1911e-03],\n",
      "        [ 4.0698e-01,  3.2776e-02, -1.1884e-01],\n",
      "        [ 1.3318e-01,  2.0361e-01,  2.3880e-02],\n",
      "        [ 1.0638e-01, -1.6467e-01,  8.0688e-02],\n",
      "        [-2.3254e-02,  3.4131e-01,  1.8347e-01],\n",
      "        [ 2.5879e-01, -1.7786e-01,  2.6587e-01],\n",
      "        [ 9.6375e-02,  3.9941e-01, -1.2769e-01],\n",
      "        [ 3.3496e-01, -2.3572e-01,  1.5259e-01],\n",
      "        [ 2.3010e-01,  7.7332e-02,  1.2561e-01],\n",
      "        [ 5.8044e-02, -1.8713e-01,  1.0059e-01],\n",
      "        [ 7.2571e-02,  2.0825e-01,  2.3376e-01],\n",
      "        [ 2.8564e-02,  6.1768e-02,  4.4067e-01],\n",
      "        [-8.3008e-02, -8.5083e-02,  5.3760e-01],\n",
      "        [-5.6671e-02, -2.5269e-01,  3.4546e-01],\n",
      "        [ 7.4463e-02,  3.8075e-04,  1.9348e-02],\n",
      "        [ 6.5369e-02, -1.4880e-01,  2.1204e-01],\n",
      "        [-2.4292e-01, -2.1667e-02,  1.3574e-01],\n",
      "        [-3.5187e-02, -1.7334e-01,  3.9648e-01],\n",
      "        [-8.1055e-02,  2.0642e-01,  5.3467e-01],\n",
      "        [-1.5735e-01, -7.4585e-02,  6.1768e-01],\n",
      "        [-2.0471e-01,  2.7441e-01,  3.9478e-01],\n",
      "        [ 4.6387e-03,  1.1456e-01,  1.5112e-01],\n",
      "        [ 2.6855e-01,  1.3013e-01, -3.7537e-03],\n",
      "        [ 1.3525e-01,  1.7261e-01,  2.3218e-01],\n",
      "        [ 2.7515e-01,  3.0591e-01,  9.4604e-02]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0386, 0.0319, 0.0218],\n",
      "        [0.0369, 0.0326, 0.0198],\n",
      "        [0.0343, 0.0381, 0.0300],\n",
      "        [0.0381, 0.0334, 0.0293],\n",
      "        [0.0369, 0.0361, 0.0341],\n",
      "        [0.0391, 0.0380, 0.0278],\n",
      "        [0.0447, 0.0320, 0.0246],\n",
      "        [0.0340, 0.0380, 0.0284],\n",
      "        [0.0331, 0.0263, 0.0301],\n",
      "        [0.0291, 0.0436, 0.0333],\n",
      "        [0.0386, 0.0259, 0.0362],\n",
      "        [0.0328, 0.0462, 0.0244],\n",
      "        [0.0416, 0.0245, 0.0323],\n",
      "        [0.0375, 0.0335, 0.0314],\n",
      "        [0.0316, 0.0257, 0.0307],\n",
      "        [0.0320, 0.0382, 0.0350],\n",
      "        [0.0306, 0.0330, 0.0431],\n",
      "        [0.0274, 0.0285, 0.0475],\n",
      "        [0.0281, 0.0241, 0.0392],\n",
      "        [0.0321, 0.0310, 0.0283],\n",
      "        [0.0318, 0.0267, 0.0343],\n",
      "        [0.0233, 0.0303, 0.0318],\n",
      "        [0.0287, 0.0260, 0.0412],\n",
      "        [0.0275, 0.0381, 0.0473],\n",
      "        [0.0254, 0.0288, 0.0514],\n",
      "        [0.0243, 0.0408, 0.0412],\n",
      "        [0.0299, 0.0347, 0.0323],\n",
      "        [0.0389, 0.0353, 0.0276],\n",
      "        [0.0341, 0.0368, 0.0350],\n",
      "        [0.0392, 0.0421, 0.0305]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.2463,  0.0662, -0.0476],\n",
      "        [ 0.1925,  0.3826, -0.1098],\n",
      "        [ 0.0865, -0.0056,  0.0489],\n",
      "        [-0.0542,  0.3064,  0.1996],\n",
      "        [ 0.1388, -0.0643,  0.0718],\n",
      "        [ 0.0660,  0.0281, -0.0835],\n",
      "        [ 0.1195,  0.1896, -0.0642],\n",
      "        [ 0.1239,  0.3423, -0.0347],\n",
      "        [ 0.1322,  0.3513, -0.0197],\n",
      "        [ 0.2476,  0.6260, -0.0559],\n",
      "        [ 0.3953,  0.3220, -0.0189],\n",
      "        [ 0.4187,  0.3828, -0.1508],\n",
      "        [-0.0483, -0.0208,  0.0523],\n",
      "        [ 0.1072, -0.2466,  0.2186],\n",
      "        [ 0.2354, -0.2280,  0.1537],\n",
      "        [ 0.2430, -0.3997,  0.3606],\n",
      "        [ 0.0381, -0.4417,  0.3052],\n",
      "        [-0.1793, -0.3406,  0.3762],\n",
      "        [ 0.1226,  0.1061,  0.2437],\n",
      "        [-0.1777,  0.0208,  0.1637],\n",
      "        [-0.1411, -0.2432,  0.1819],\n",
      "        [-0.1626,  0.0025,  0.3867],\n",
      "        [-0.0409, -0.1102,  0.2365],\n",
      "        [ 0.1785,  0.2019,  0.0007],\n",
      "        [-0.1087,  0.0881,  0.1656],\n",
      "        [ 0.0557,  0.4084, -0.1179]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0446, 0.0370, 0.0329],\n",
      "        [0.0422, 0.0509, 0.0309],\n",
      "        [0.0380, 0.0345, 0.0363],\n",
      "        [0.0330, 0.0471, 0.0421],\n",
      "        [0.0400, 0.0325, 0.0371],\n",
      "        [0.0372, 0.0357, 0.0318],\n",
      "        [0.0392, 0.0419, 0.0324],\n",
      "        [0.0394, 0.0489, 0.0334],\n",
      "        [0.0398, 0.0493, 0.0338],\n",
      "        [0.0446, 0.0649, 0.0327],\n",
      "        [0.0517, 0.0479, 0.0339],\n",
      "        [0.0529, 0.0509, 0.0297],\n",
      "        [0.0332, 0.0340, 0.0364],\n",
      "        [0.0388, 0.0271, 0.0430],\n",
      "        [0.0441, 0.0276, 0.0403],\n",
      "        [0.0444, 0.0233, 0.0495],\n",
      "        [0.0362, 0.0223, 0.0469],\n",
      "        [0.0291, 0.0247, 0.0503],\n",
      "        [0.0394, 0.0386, 0.0441],\n",
      "        [0.0292, 0.0354, 0.0407],\n",
      "        [0.0302, 0.0272, 0.0414],\n",
      "        [0.0296, 0.0348, 0.0508],\n",
      "        [0.0334, 0.0311, 0.0437],\n",
      "        [0.0417, 0.0424, 0.0345],\n",
      "        [0.0312, 0.0379, 0.0408],\n",
      "        [0.0368, 0.0522, 0.0307]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.1959, -0.2617,  0.0987],\n",
      "        [ 0.4456,  0.0897,  0.2803],\n",
      "        [ 0.0847,  0.1089, -0.0816],\n",
      "        [ 0.2512,  0.2556, -0.1571],\n",
      "        [ 0.0118, -0.0470,  0.0608],\n",
      "        [ 0.1932,  0.1203,  0.1750]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.1649, 0.1212, 0.1709],\n",
      "        [0.2117, 0.1722, 0.2050],\n",
      "        [0.1476, 0.1755, 0.1427],\n",
      "        [0.1742, 0.2032, 0.1323],\n",
      "        [0.1371, 0.1501, 0.1646],\n",
      "        [0.1644, 0.1776, 0.1844]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0651, -0.2048, -0.2710],\n",
      "        [ 0.0577, -0.0723,  0.1901],\n",
      "        [-0.1400,  0.2205,  0.0989],\n",
      "        [ 0.1764,  0.2786,  0.2795],\n",
      "        [ 0.3281,  0.2183, -0.1865],\n",
      "        [-0.0875,  0.1520,  0.1289],\n",
      "        [ 0.1267,  0.1200,  0.0253],\n",
      "        [ 0.0640,  0.1266, -0.0059],\n",
      "        [ 0.1051,  0.2465,  0.0087],\n",
      "        [-0.0128,  0.2170,  0.1313],\n",
      "        [ 0.0770,  0.2722, -0.0907],\n",
      "        [ 0.0839,  0.1946,  0.2517]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0730, 0.0581, 0.0599],\n",
      "        [0.0826, 0.0663, 0.0950],\n",
      "        [0.0677, 0.0888, 0.0867],\n",
      "        [0.0930, 0.0942, 0.1039],\n",
      "        [0.1082, 0.0886, 0.0652],\n",
      "        [0.0714, 0.0829, 0.0894],\n",
      "        [0.0884, 0.0804, 0.0805],\n",
      "        [0.0831, 0.0809, 0.0781],\n",
      "        [0.0866, 0.0912, 0.0792],\n",
      "        [0.0769, 0.0886, 0.0895],\n",
      "        [0.0842, 0.0936, 0.0717],\n",
      "        [0.0848, 0.0865, 0.1010]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 6.8970e-03,  2.2263e-02, -1.7297e-01],\n",
      "        [ 2.0959e-01, -3.4839e-01,  8.2520e-02],\n",
      "        [-4.6814e-02, -1.4087e-01,  8.9294e-02],\n",
      "        [-5.5817e-02, -3.7939e-01,  1.4050e-01],\n",
      "        [ 1.1688e-01, -2.8271e-01, -2.0813e-02],\n",
      "        [ 1.3745e-01, -1.4725e-02, -8.7891e-02],\n",
      "        [ 1.8127e-01, -4.5563e-02, -2.5055e-02],\n",
      "        [ 2.4323e-02,  1.2976e-01, -1.0284e-02],\n",
      "        [ 9.5337e-02, -1.2622e-01,  6.4148e-02],\n",
      "        [ 6.6589e-02,  2.2729e-01,  1.7834e-01],\n",
      "        [ 9.8389e-02, -1.1804e-01,  2.4963e-01],\n",
      "        [ 3.3374e-01,  2.7637e-01,  1.9873e-01],\n",
      "        [ 1.0565e-01, -1.1194e-01,  5.7343e-02],\n",
      "        [ 1.9104e-01,  2.6196e-01,  7.1655e-02],\n",
      "        [-1.1316e-01,  2.1265e-01,  1.6162e-01],\n",
      "        [-2.6459e-02, -8.1787e-03,  1.7688e-01],\n",
      "        [-1.7432e-01, -1.5735e-01,  3.8916e-01],\n",
      "        [-9.1309e-02, -4.4495e-02,  4.5142e-01],\n",
      "        [-3.1567e-01, -2.8589e-01,  1.7798e-01],\n",
      "        [-2.5558e-02, -6.5369e-02,  3.8647e-01],\n",
      "        [-2.3584e-01, -2.3047e-01,  2.6318e-01],\n",
      "        [ 1.0548e-03,  6.6345e-02,  4.3164e-01],\n",
      "        [ 1.3268e-02, -1.0303e-01,  4.6191e-01],\n",
      "        [-4.1914e-04, -1.2122e-01,  4.5020e-01],\n",
      "        [-2.5955e-02, -1.3916e-01,  3.6816e-01],\n",
      "        [ 9.8450e-02,  2.3547e-01,  5.0439e-01],\n",
      "        [ 5.9753e-02,  1.1725e-01,  3.6230e-01],\n",
      "        [ 3.8239e-02,  2.6782e-01,  3.4521e-01],\n",
      "        [-4.2908e-02, -3.7861e-04,  3.5986e-01],\n",
      "        [-2.6245e-01,  4.3549e-02,  6.0010e-01],\n",
      "        [-1.8579e-01, -2.2937e-01,  2.9443e-01],\n",
      "        [-2.1655e-01, -7.8430e-02,  3.8477e-01],\n",
      "        [-3.0347e-01, -2.2034e-01,  1.5674e-01],\n",
      "        [-2.4341e-01, -1.9653e-02,  4.1284e-01],\n",
      "        [-1.9531e-01,  1.0834e-01,  4.5435e-01],\n",
      "        [-1.5369e-01, -5.0598e-02,  5.3809e-01],\n",
      "        [-1.5222e-01,  1.4673e-01,  2.4719e-01],\n",
      "        [-9.0576e-02,  6.7383e-02,  3.6255e-01],\n",
      "        [-8.8318e-02, -1.2561e-01,  3.1372e-01],\n",
      "        [-3.0121e-02, -2.0105e-01,  2.1729e-01],\n",
      "        [ 5.5908e-02, -1.8860e-01,  9.3384e-02],\n",
      "        [ 3.6835e-02,  1.4648e-01,  1.4502e-01],\n",
      "        [ 9.4543e-02, -9.2651e-02,  9.9121e-02],\n",
      "        [ 1.1340e-01,  1.6693e-02,  8.9233e-02],\n",
      "        [ 1.9324e-01, -2.1826e-01, -1.5552e-01],\n",
      "        [ 1.4124e-01, -1.9409e-01, -3.8910e-02],\n",
      "        [ 1.2866e-01, -3.3765e-01, -1.0126e-01],\n",
      "        [ 2.7002e-01,  2.0239e-01, -6.6772e-02],\n",
      "        [ 2.9175e-01, -1.9702e-01, -5.3253e-02],\n",
      "        [ 7.5745e-02,  5.5008e-03, -1.4026e-01],\n",
      "        [ 1.4807e-01,  8.1253e-03,  9.6313e-02],\n",
      "        [ 7.7576e-02, -4.6875e-02,  1.6809e-01],\n",
      "        [-2.1591e-03, -1.5234e-01,  3.5620e-01],\n",
      "        [ 6.0425e-02,  2.1912e-01,  8.2214e-02],\n",
      "        [-4.5410e-02, -1.7151e-01,  1.9104e-01],\n",
      "        [ 3.3264e-02,  1.4744e-03, -3.4882e-02],\n",
      "        [-8.1726e-02,  7.7744e-03,  3.8037e-01],\n",
      "        [-1.2192e-02, -7.6355e-02,  2.2107e-01],\n",
      "        [ 4.5074e-02, -8.8562e-02,  4.8438e-01],\n",
      "        [ 4.3121e-02,  5.9296e-02,  4.2334e-01],\n",
      "        [ 1.0571e-01, -5.4718e-02,  2.0032e-01],\n",
      "        [ 1.0632e-01,  5.5908e-02,  3.0151e-01],\n",
      "        [ 5.5481e-02,  9.4604e-03,  3.4576e-02],\n",
      "        [ 7.3792e-02, -1.9739e-01,  1.2842e-01],\n",
      "        [-2.1680e-01,  1.0254e-02,  3.2275e-01],\n",
      "        [-1.7358e-01,  7.5745e-02,  1.8372e-01],\n",
      "        [-1.5259e-01,  3.6792e-01,  4.1748e-01],\n",
      "        [-2.5342e-01,  1.4795e-01,  3.6670e-01],\n",
      "        [-2.5464e-01, -1.8921e-01,  1.7249e-01],\n",
      "        [ 1.5735e-01,  4.2456e-01,  2.6221e-01],\n",
      "        [ 1.2213e-01, -4.8553e-02,  1.5027e-01],\n",
      "        [ 8.9539e-02,  2.2253e-01, -3.0807e-02],\n",
      "        [ 3.1274e-01,  1.0944e-01, -1.3428e-01],\n",
      "        [ 2.1399e-01,  1.8811e-01,  1.5518e-02],\n",
      "        [ 1.5198e-01,  2.8809e-01,  5.8167e-02],\n",
      "        [ 2.8784e-01,  2.8345e-01,  1.9702e-01],\n",
      "        [ 1.7920e-01,  1.1696e-02, -1.0767e-01],\n",
      "        [ 2.2229e-01, -2.3499e-03,  2.1252e-01],\n",
      "        [ 1.6443e-01, -2.9932e-01,  2.8320e-02],\n",
      "        [ 2.1802e-01, -6.7749e-02,  3.2544e-01],\n",
      "        [-1.0706e-01, -2.9248e-01,  5.5054e-02],\n",
      "        [ 3.0060e-02, -1.7242e-02,  9.6741e-02],\n",
      "        [-1.0880e-02, -2.1338e-01,  1.0492e-01],\n",
      "        [-7.4097e-02, -1.8835e-01,  4.9561e-01],\n",
      "        [ 2.6489e-02, -2.7441e-01,  2.1240e-01],\n",
      "        [-4.8431e-02, -1.2537e-01,  2.2778e-01],\n",
      "        [-4.1077e-02,  6.9427e-03,  4.5868e-02],\n",
      "        [-9.6069e-02, -7.7820e-02,  1.4917e-01],\n",
      "        [-2.3657e-01, -2.4670e-01,  4.3579e-01],\n",
      "        [-3.7842e-01, -1.2115e-02,  4.9512e-01],\n",
      "        [-3.8599e-01, -1.4795e-01,  4.3433e-01],\n",
      "        [-3.4595e-01, -2.4585e-01,  4.7705e-01],\n",
      "        [-2.6172e-01, -2.3718e-01,  6.0107e-01],\n",
      "        [-2.0593e-01, -1.8530e-01,  7.3877e-01],\n",
      "        [-3.4009e-01, -1.2964e-01,  7.9346e-01],\n",
      "        [ 9.4666e-02, -3.6316e-02,  5.2002e-01],\n",
      "        [-1.5735e-01,  2.1448e-01,  5.8008e-01],\n",
      "        [ 1.5540e-01,  1.2280e-01,  2.2754e-01],\n",
      "        [-9.6375e-02, -2.5070e-02,  3.7427e-01],\n",
      "        [ 1.3306e-02, -7.0496e-02,  6.2012e-01],\n",
      "        [-1.5283e-01, -1.8311e-01,  4.4336e-01],\n",
      "        [-8.5876e-02,  7.3608e-02,  1.6809e-01],\n",
      "        [ 3.0594e-02, -1.0730e-01,  2.3816e-01],\n",
      "        [ 2.0850e-01,  1.2292e-01,  7.2384e-04],\n",
      "        [ 1.9226e-01, -4.2755e-02, -2.5055e-02],\n",
      "        [ 1.2805e-01,  2.8711e-01,  1.3037e-01]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0094, 0.0098, 0.0062],\n",
      "        [0.0115, 0.0068, 0.0080],\n",
      "        [0.0089, 0.0083, 0.0080],\n",
      "        [0.0088, 0.0066, 0.0085],\n",
      "        [0.0105, 0.0072, 0.0072],\n",
      "        [0.0107, 0.0094, 0.0067],\n",
      "        [0.0112, 0.0092, 0.0072],\n",
      "        [0.0096, 0.0109, 0.0073],\n",
      "        [0.0103, 0.0085, 0.0078],\n",
      "        [0.0100, 0.0120, 0.0088],\n",
      "        [0.0103, 0.0085, 0.0094],\n",
      "        [0.0130, 0.0126, 0.0090],\n",
      "        [0.0104, 0.0086, 0.0078],\n",
      "        [0.0113, 0.0125, 0.0079],\n",
      "        [0.0083, 0.0119, 0.0086],\n",
      "        [0.0091, 0.0095, 0.0088],\n",
      "        [0.0078, 0.0082, 0.0109],\n",
      "        [0.0085, 0.0092, 0.0116],\n",
      "        [0.0068, 0.0072, 0.0088],\n",
      "        [0.0091, 0.0090, 0.0108],\n",
      "        [0.0074, 0.0076, 0.0096],\n",
      "        [0.0093, 0.0102, 0.0113],\n",
      "        [0.0095, 0.0086, 0.0117],\n",
      "        [0.0093, 0.0085, 0.0115],\n",
      "        [0.0091, 0.0083, 0.0106],\n",
      "        [0.0103, 0.0121, 0.0122],\n",
      "        [0.0099, 0.0108, 0.0106],\n",
      "        [0.0097, 0.0125, 0.0104],\n",
      "        [0.0089, 0.0096, 0.0105],\n",
      "        [0.0072, 0.0100, 0.0134],\n",
      "        [0.0078, 0.0076, 0.0099],\n",
      "        [0.0075, 0.0089, 0.0108],\n",
      "        [0.0069, 0.0077, 0.0086],\n",
      "        [0.0073, 0.0094, 0.0111],\n",
      "        [0.0077, 0.0107, 0.0116],\n",
      "        [0.0080, 0.0091, 0.0126],\n",
      "        [0.0080, 0.0111, 0.0094],\n",
      "        [0.0085, 0.0103, 0.0106],\n",
      "        [0.0086, 0.0085, 0.0101],\n",
      "        [0.0091, 0.0078, 0.0091],\n",
      "        [0.0099, 0.0079, 0.0081],\n",
      "        [0.0097, 0.0111, 0.0085],\n",
      "        [0.0103, 0.0087, 0.0081],\n",
      "        [0.0105, 0.0097, 0.0080],\n",
      "        [0.0113, 0.0077, 0.0063],\n",
      "        [0.0108, 0.0079, 0.0071],\n",
      "        [0.0106, 0.0068, 0.0066],\n",
      "        [0.0122, 0.0117, 0.0069],\n",
      "        [0.0125, 0.0079, 0.0070],\n",
      "        [0.0101, 0.0096, 0.0064],\n",
      "        [0.0108, 0.0097, 0.0081],\n",
      "        [0.0101, 0.0091, 0.0087],\n",
      "        [0.0093, 0.0082, 0.0105],\n",
      "        [0.0099, 0.0119, 0.0080],\n",
      "        [0.0089, 0.0081, 0.0089],\n",
      "        [0.0097, 0.0096, 0.0071],\n",
      "        [0.0086, 0.0097, 0.0108],\n",
      "        [0.0092, 0.0089, 0.0092],\n",
      "        [0.0098, 0.0088, 0.0119],\n",
      "        [0.0098, 0.0102, 0.0112],\n",
      "        [0.0104, 0.0091, 0.0090],\n",
      "        [0.0104, 0.0101, 0.0099],\n",
      "        [0.0099, 0.0097, 0.0076],\n",
      "        [0.0101, 0.0079, 0.0084],\n",
      "        [0.0075, 0.0097, 0.0102],\n",
      "        [0.0079, 0.0103, 0.0088],\n",
      "        [0.0080, 0.0138, 0.0112],\n",
      "        [0.0072, 0.0111, 0.0106],\n",
      "        [0.0072, 0.0079, 0.0087],\n",
      "        [0.0109, 0.0147, 0.0096],\n",
      "        [0.0106, 0.0091, 0.0085],\n",
      "        [0.0102, 0.0120, 0.0071],\n",
      "        [0.0128, 0.0107, 0.0064],\n",
      "        [0.0116, 0.0116, 0.0075],\n",
      "        [0.0109, 0.0128, 0.0078],\n",
      "        [0.0125, 0.0127, 0.0090],\n",
      "        [0.0112, 0.0097, 0.0066],\n",
      "        [0.0117, 0.0096, 0.0091],\n",
      "        [0.0110, 0.0071, 0.0076],\n",
      "        [0.0116, 0.0090, 0.0102],\n",
      "        [0.0084, 0.0072, 0.0078],\n",
      "        [0.0096, 0.0094, 0.0081],\n",
      "        [0.0092, 0.0077, 0.0082],\n",
      "        [0.0087, 0.0079, 0.0121],\n",
      "        [0.0096, 0.0073, 0.0091],\n",
      "        [0.0089, 0.0085, 0.0092],\n",
      "        [0.0090, 0.0097, 0.0077],\n",
      "        [0.0085, 0.0089, 0.0085],\n",
      "        [0.0074, 0.0075, 0.0114],\n",
      "        [0.0064, 0.0095, 0.0121],\n",
      "        [0.0063, 0.0083, 0.0114],\n",
      "        [0.0066, 0.0075, 0.0119],\n",
      "        [0.0072, 0.0076, 0.0134],\n",
      "        [0.0076, 0.0080, 0.0154],\n",
      "        [0.0066, 0.0084, 0.0163],\n",
      "        [0.0103, 0.0092, 0.0124],\n",
      "        [0.0080, 0.0119, 0.0131],\n",
      "        [0.0109, 0.0108, 0.0092],\n",
      "        [0.0085, 0.0093, 0.0107],\n",
      "        [0.0095, 0.0089, 0.0137],\n",
      "        [0.0080, 0.0080, 0.0115],\n",
      "        [0.0086, 0.0103, 0.0087],\n",
      "        [0.0096, 0.0086, 0.0093],\n",
      "        [0.0115, 0.0108, 0.0074],\n",
      "        [0.0113, 0.0092, 0.0072],\n",
      "        [0.0106, 0.0128, 0.0084]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.1033, -0.0420,  0.1371],\n",
      "        [-0.1428,  0.3198,  0.2415],\n",
      "        [ 0.0127,  0.0130, -0.1124],\n",
      "        [ 0.1549,  0.0515,  0.0020],\n",
      "        [ 0.1958, -0.1110, -0.0287],\n",
      "        [-0.0794,  0.1818,  0.2205],\n",
      "        [-0.1838,  0.4241,  0.1527],\n",
      "        [-0.1351,  0.3218,  0.3530],\n",
      "        [-0.1497,  0.1173,  0.3840],\n",
      "        [ 0.0093,  0.1606,  0.1254],\n",
      "        [ 0.2761,  0.1395,  0.4233],\n",
      "        [ 0.0868, -0.0883,  0.4993],\n",
      "        [-0.1692, -0.0246,  0.3799],\n",
      "        [-0.1653, -0.0992,  0.6118],\n",
      "        [-0.1554, -0.0101,  0.5386],\n",
      "        [-0.0512, -0.0147,  0.4731],\n",
      "        [-0.2246,  0.1879,  0.4924],\n",
      "        [-0.3115,  0.1777,  0.5581],\n",
      "        [-0.1240,  0.3213,  0.6714],\n",
      "        [-0.2456, -0.0032,  0.4436],\n",
      "        [-0.0366,  0.0097,  0.2520],\n",
      "        [-0.0068, -0.0367,  0.1774],\n",
      "        [-0.0430,  0.0388,  0.2634],\n",
      "        [-0.0747, -0.0989,  0.3284],\n",
      "        [ 0.1282, -0.0510,  0.1186],\n",
      "        [ 0.1997, -0.0028,  0.2756],\n",
      "        [ 0.3049, -0.1102,  0.2805],\n",
      "        [ 0.5361,  0.3347,  0.2708],\n",
      "        [ 0.3882, -0.0599, -0.0301],\n",
      "        [ 0.1616, -0.1350,  0.2367],\n",
      "        [ 0.4348, -0.2769, -0.0059],\n",
      "        [ 0.1432,  0.0349,  0.2372],\n",
      "        [-0.1144,  0.0274,  0.3428],\n",
      "        [-0.0609,  0.0090,  0.2952],\n",
      "        [-0.1007, -0.2479,  0.5137],\n",
      "        [ 0.0970, -0.1968,  0.5156],\n",
      "        [-0.1025,  0.0186,  0.1433],\n",
      "        [ 0.0399, -0.1594,  0.1458],\n",
      "        [-0.1592, -0.1591,  0.1804],\n",
      "        [-0.2079, -0.0579,  0.3296],\n",
      "        [-0.1238,  0.2166,  0.2388],\n",
      "        [-0.1004,  0.0087,  0.2644],\n",
      "        [ 0.1483, -0.1013,  0.1099],\n",
      "        [ 0.0041,  0.1154,  0.2448],\n",
      "        [-0.1890,  0.2346,  0.3206],\n",
      "        [-0.2871,  0.0504,  0.1539],\n",
      "        [-0.1741,  0.2483,  0.3420],\n",
      "        [-0.0613,  0.2864,  0.4294],\n",
      "        [-0.0554,  0.3279,  0.3555],\n",
      "        [-0.1225,  0.1351,  0.2460],\n",
      "        [ 0.2360,  0.1128,  0.1835],\n",
      "        [ 0.4038,  0.2075,  0.1007],\n",
      "        [ 0.3530,  0.0640,  0.1260],\n",
      "        [ 0.3982,  0.2771,  0.0585]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0199, 0.0165, 0.0160],\n",
      "        [0.0155, 0.0238, 0.0177],\n",
      "        [0.0181, 0.0175, 0.0124],\n",
      "        [0.0209, 0.0182, 0.0140],\n",
      "        [0.0218, 0.0154, 0.0135],\n",
      "        [0.0165, 0.0207, 0.0174],\n",
      "        [0.0149, 0.0264, 0.0162],\n",
      "        [0.0156, 0.0238, 0.0198],\n",
      "        [0.0154, 0.0194, 0.0204],\n",
      "        [0.0181, 0.0203, 0.0158],\n",
      "        [0.0236, 0.0198, 0.0213],\n",
      "        [0.0195, 0.0158, 0.0229],\n",
      "        [0.0151, 0.0168, 0.0204],\n",
      "        [0.0152, 0.0156, 0.0257],\n",
      "        [0.0153, 0.0171, 0.0238],\n",
      "        [0.0170, 0.0170, 0.0224],\n",
      "        [0.0143, 0.0208, 0.0228],\n",
      "        [0.0131, 0.0206, 0.0243],\n",
      "        [0.0158, 0.0238, 0.0272],\n",
      "        [0.0140, 0.0172, 0.0217],\n",
      "        [0.0173, 0.0174, 0.0179],\n",
      "        [0.0178, 0.0166, 0.0166],\n",
      "        [0.0172, 0.0179, 0.0181],\n",
      "        [0.0166, 0.0156, 0.0193],\n",
      "        [0.0204, 0.0164, 0.0157],\n",
      "        [0.0219, 0.0172, 0.0183],\n",
      "        [0.0243, 0.0154, 0.0184],\n",
      "        [0.0306, 0.0241, 0.0182],\n",
      "        [0.0264, 0.0163, 0.0135],\n",
      "        [0.0210, 0.0151, 0.0176],\n",
      "        [0.0277, 0.0131, 0.0138],\n",
      "        [0.0207, 0.0179, 0.0177],\n",
      "        [0.0160, 0.0177, 0.0196],\n",
      "        [0.0168, 0.0174, 0.0187],\n",
      "        [0.0162, 0.0135, 0.0233],\n",
      "        [0.0197, 0.0142, 0.0233],\n",
      "        [0.0162, 0.0176, 0.0161],\n",
      "        [0.0186, 0.0147, 0.0161],\n",
      "        [0.0153, 0.0147, 0.0167],\n",
      "        [0.0145, 0.0163, 0.0193],\n",
      "        [0.0158, 0.0214, 0.0177],\n",
      "        [0.0162, 0.0174, 0.0181],\n",
      "        [0.0208, 0.0156, 0.0155],\n",
      "        [0.0180, 0.0194, 0.0178],\n",
      "        [0.0148, 0.0218, 0.0192],\n",
      "        [0.0134, 0.0181, 0.0162],\n",
      "        [0.0150, 0.0221, 0.0196],\n",
      "        [0.0168, 0.0230, 0.0214],\n",
      "        [0.0170, 0.0240, 0.0199],\n",
      "        [0.0158, 0.0197, 0.0178],\n",
      "        [0.0227, 0.0193, 0.0167],\n",
      "        [0.0268, 0.0212, 0.0154],\n",
      "        [0.0255, 0.0184, 0.0158],\n",
      "        [0.0267, 0.0228, 0.0148]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 4.2572e-02, -1.3306e-01, -2.4918e-02],\n",
      "        [ 1.3306e-01,  3.5889e-01,  2.5803e-02],\n",
      "        [-7.8125e-02,  1.6174e-01, -1.4819e-01],\n",
      "        [-5.7098e-02,  3.5083e-01,  8.6975e-03],\n",
      "        [-3.2202e-01, -2.8763e-02,  3.9502e-01],\n",
      "        [-1.3342e-01,  5.0879e-01,  7.5439e-02],\n",
      "        [ 1.1703e-02,  6.3293e-02, -2.7046e-03],\n",
      "        [ 2.0691e-01,  1.4392e-01,  6.5117e-03],\n",
      "        [ 3.0716e-02,  7.7026e-02,  1.4734e-01],\n",
      "        [ 1.9214e-01,  3.1470e-01, -1.6830e-02],\n",
      "        [ 3.0029e-02,  1.8652e-01, -1.5297e-02],\n",
      "        [-9.4177e-02,  2.0557e-01,  1.7432e-01],\n",
      "        [-1.8091e-01,  1.0168e-01,  6.3232e-02],\n",
      "        [-1.0748e-03, -3.5797e-02,  1.2537e-01],\n",
      "        [-1.5762e-02,  2.9678e-02,  6.3562e-04],\n",
      "        [ 1.3718e-02, -4.9561e-02,  2.0203e-01],\n",
      "        [-1.1806e-03, -1.1255e-01,  3.0225e-01],\n",
      "        [ 1.9006e-01,  1.1499e-01,  2.9883e-01],\n",
      "        [ 1.7065e-01,  2.8760e-01,  2.7783e-01],\n",
      "        [ 2.3132e-01,  1.4807e-01, -8.6899e-03],\n",
      "        [ 8.6487e-02, -3.0151e-01,  4.2383e-01],\n",
      "        [ 4.8340e-02,  3.1177e-01,  5.2930e-01],\n",
      "        [-9.6008e-02,  1.3000e-01,  5.6494e-01],\n",
      "        [-9.4147e-03,  7.0557e-02,  1.7688e-01],\n",
      "        [-2.8519e-02,  2.3840e-01,  6.4062e-01],\n",
      "        [ 6.5918e-02,  4.7363e-01,  1.3721e-01],\n",
      "        [-9.7595e-02,  2.3706e-01,  5.2930e-01],\n",
      "        [ 1.8896e-01,  4.3701e-01,  2.2430e-02],\n",
      "        [ 1.5649e-01,  1.9641e-01,  7.5012e-02],\n",
      "        [-2.0300e-01, -5.9296e-02,  1.5186e-01],\n",
      "        [-3.7689e-02, -1.2286e-01,  1.3428e-01],\n",
      "        [-1.4153e-03, -1.8921e-01,  1.8481e-01],\n",
      "        [-1.2341e-01,  9.9304e-02,  1.8896e-01],\n",
      "        [-3.1403e-02,  3.2349e-01,  1.2922e-03],\n",
      "        [-1.3843e-01,  2.2656e-01, -1.5366e-02],\n",
      "        [-1.1011e-01,  4.8145e-01, -7.5928e-02],\n",
      "        [ 2.7148e-01,  1.7700e-01, -2.6196e-01],\n",
      "        [ 1.3171e-01,  4.5264e-01,  4.3518e-02]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0269, 0.0194, 0.0219],\n",
      "        [0.0294, 0.0317, 0.0230],\n",
      "        [0.0238, 0.0260, 0.0193],\n",
      "        [0.0244, 0.0314, 0.0226],\n",
      "        [0.0187, 0.0215, 0.0332],\n",
      "        [0.0226, 0.0368, 0.0242],\n",
      "        [0.0261, 0.0236, 0.0223],\n",
      "        [0.0317, 0.0255, 0.0225],\n",
      "        [0.0266, 0.0239, 0.0260],\n",
      "        [0.0312, 0.0303, 0.0220],\n",
      "        [0.0266, 0.0267, 0.0220],\n",
      "        [0.0235, 0.0272, 0.0267],\n",
      "        [0.0215, 0.0245, 0.0239],\n",
      "        [0.0258, 0.0213, 0.0254],\n",
      "        [0.0254, 0.0228, 0.0224],\n",
      "        [0.0262, 0.0211, 0.0274],\n",
      "        [0.0258, 0.0198, 0.0303],\n",
      "        [0.0312, 0.0248, 0.0302],\n",
      "        [0.0306, 0.0295, 0.0296],\n",
      "        [0.0325, 0.0257, 0.0222],\n",
      "        [0.0281, 0.0164, 0.0342],\n",
      "        [0.0271, 0.0302, 0.0380],\n",
      "        [0.0234, 0.0252, 0.0394],\n",
      "        [0.0255, 0.0237, 0.0267],\n",
      "        [0.0251, 0.0281, 0.0425],\n",
      "        [0.0275, 0.0355, 0.0257],\n",
      "        [0.0234, 0.0280, 0.0380],\n",
      "        [0.0312, 0.0342, 0.0229],\n",
      "        [0.0302, 0.0269, 0.0241],\n",
      "        [0.0210, 0.0208, 0.0261],\n",
      "        [0.0248, 0.0196, 0.0256],\n",
      "        [0.0258, 0.0183, 0.0269],\n",
      "        [0.0228, 0.0244, 0.0271],\n",
      "        [0.0250, 0.0306, 0.0224],\n",
      "        [0.0224, 0.0277, 0.0220],\n",
      "        [0.0231, 0.0358, 0.0208],\n",
      "        [0.0338, 0.0264, 0.0172],\n",
      "        [0.0294, 0.0348, 0.0234]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.2966,  0.0520, -0.1421],\n",
      "        [ 0.0820,  0.3374, -0.1060],\n",
      "        [-0.0325, -0.1980,  0.0282],\n",
      "        [-0.1049,  0.0759,  0.1036],\n",
      "        [-0.0720, -0.2240,  0.4258],\n",
      "        [-0.0190,  0.0660,  0.1636],\n",
      "        [ 0.0206, -0.1635,  0.4226],\n",
      "        [-0.0648,  0.5029,  0.6943],\n",
      "        [-0.2732,  0.1663,  0.5396],\n",
      "        [-0.0776,  0.0723,  0.4658],\n",
      "        [ 0.0047, -0.1545,  0.3333],\n",
      "        [ 0.1335,  0.1859,  0.0776],\n",
      "        [ 0.0848, -0.2747,  0.3416],\n",
      "        [-0.0948, -0.0525,  0.2380],\n",
      "        [-0.0453, -0.2908, -0.0802],\n",
      "        [ 0.2021, -0.1582,  0.5610],\n",
      "        [ 0.0807,  0.0551,  0.3962],\n",
      "        [ 0.2235, -0.1635,  0.1837],\n",
      "        [ 0.0343, -0.1241,  0.2283],\n",
      "        [ 0.0901, -0.0573,  0.4119],\n",
      "        [ 0.1055, -0.1240,  0.6685],\n",
      "        [ 0.2954, -0.2006,  0.5674],\n",
      "        [-0.0432, -0.4761,  0.8657],\n",
      "        [ 0.2086,  0.0081,  0.5977],\n",
      "        [-0.0037,  0.1093,  0.5474],\n",
      "        [ 0.0425, -0.0618,  0.2720],\n",
      "        [-0.0263, -0.1743,  0.3726],\n",
      "        [ 0.1876,  0.0798,  0.3049],\n",
      "        [ 0.2268,  0.0679,  0.1144],\n",
      "        [ 0.3271,  0.0568,  0.1930]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0418, 0.0357, 0.0203],\n",
      "        [0.0338, 0.0475, 0.0210],\n",
      "        [0.0301, 0.0278, 0.0240],\n",
      "        [0.0280, 0.0365, 0.0259],\n",
      "        [0.0289, 0.0271, 0.0357],\n",
      "        [0.0305, 0.0362, 0.0275],\n",
      "        [0.0317, 0.0288, 0.0356],\n",
      "        [0.0292, 0.0560, 0.0468],\n",
      "        [0.0237, 0.0400, 0.0400],\n",
      "        [0.0288, 0.0364, 0.0372],\n",
      "        [0.0312, 0.0290, 0.0326],\n",
      "        [0.0356, 0.0408, 0.0252],\n",
      "        [0.0338, 0.0257, 0.0329],\n",
      "        [0.0283, 0.0321, 0.0296],\n",
      "        [0.0297, 0.0253, 0.0216],\n",
      "        [0.0381, 0.0289, 0.0409],\n",
      "        [0.0337, 0.0358, 0.0347],\n",
      "        [0.0389, 0.0288, 0.0280],\n",
      "        [0.0322, 0.0299, 0.0293],\n",
      "        [0.0340, 0.0320, 0.0352],\n",
      "        [0.0346, 0.0299, 0.0456],\n",
      "        [0.0418, 0.0277, 0.0412],\n",
      "        [0.0298, 0.0210, 0.0555],\n",
      "        [0.0383, 0.0341, 0.0424],\n",
      "        [0.0310, 0.0378, 0.0404],\n",
      "        [0.0325, 0.0318, 0.0307],\n",
      "        [0.0303, 0.0284, 0.0339],\n",
      "        [0.0375, 0.0367, 0.0317],\n",
      "        [0.0390, 0.0363, 0.0262],\n",
      "        [0.0432, 0.0359, 0.0283]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.2411, -0.2749,  0.1967],\n",
      "        [ 0.0179,  0.3391,  0.4243],\n",
      "        [-0.2656,  0.0688,  0.0997],\n",
      "        [-0.0680,  0.4116,  0.3647],\n",
      "        [ 0.0569,  0.1949,  0.0355],\n",
      "        [ 0.0693,  0.3228,  0.3762]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.1394, 0.1035, 0.1564],\n",
      "        [0.1807, 0.1913, 0.1964],\n",
      "        [0.1361, 0.1460, 0.1420],\n",
      "        [0.1658, 0.2056, 0.1851],\n",
      "        [0.1879, 0.1655, 0.1331],\n",
      "        [0.1902, 0.1881, 0.1871]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-5.7373e-02, -1.4563e-01, -1.9495e-01],\n",
      "        [-4.1931e-02,  3.3545e-01,  9.4482e-02],\n",
      "        [-8.3435e-02,  1.7761e-01,  2.0935e-01],\n",
      "        [ 8.6121e-02,  1.9836e-01, -9.8450e-02],\n",
      "        [-1.4575e-01, -1.8787e-01,  5.3024e-04],\n",
      "        [-1.5442e-01,  1.8115e-01,  3.8135e-01],\n",
      "        [-2.7417e-01,  2.7930e-01,  1.9989e-02],\n",
      "        [-8.7891e-02,  6.1707e-02,  2.3535e-01],\n",
      "        [-3.6523e-01, -1.1742e-02,  9.1980e-02],\n",
      "        [-1.6235e-01,  1.3489e-01,  2.5488e-01],\n",
      "        [-3.2654e-02, -9.1614e-02,  4.0137e-01],\n",
      "        [-1.3623e-01, -1.6296e-01,  3.5352e-01],\n",
      "        [ 3.5980e-02, -3.2764e-01,  2.8711e-01],\n",
      "        [-1.3025e-01, -1.7290e-03,  3.8745e-01],\n",
      "        [-2.3840e-01, -1.0822e-01,  5.4590e-01],\n",
      "        [-2.4585e-01, -2.0203e-01,  5.2148e-01],\n",
      "        [-7.0679e-02,  3.3386e-02,  2.3132e-01],\n",
      "        [-6.2927e-02,  3.3301e-01,  3.2935e-01],\n",
      "        [ 1.0431e-01,  3.0249e-01,  3.4717e-01],\n",
      "        [-4.0192e-02,  2.1582e-01,  3.6475e-01],\n",
      "        [-6.9031e-02,  3.9185e-01,  3.8940e-01],\n",
      "        [ 1.2018e-01,  2.3035e-01,  2.2388e-01],\n",
      "        [ 1.0107e-01,  6.9397e-02,  4.2114e-01],\n",
      "        [ 8.0994e-02,  3.1319e-03,  2.6221e-01],\n",
      "        [-4.1412e-02,  1.2042e-01,  1.8726e-01],\n",
      "        [ 2.4084e-01,  1.1981e-01,  4.4580e-01],\n",
      "        [-1.8738e-01, -1.3049e-01,  2.5879e-01],\n",
      "        [-6.9153e-02, -6.6528e-02,  3.0542e-01],\n",
      "        [-4.3994e-01, -2.7832e-01,  5.9082e-01],\n",
      "        [-9.1858e-02, -2.2290e-01,  3.6768e-01],\n",
      "        [-2.1924e-01, -1.8152e-01,  5.6104e-01],\n",
      "        [-2.4060e-01,  2.3186e-04,  1.8384e-01],\n",
      "        [-2.5684e-01, -1.6309e-01,  9.8572e-02],\n",
      "        [ 1.1523e-01,  7.1777e-02,  1.2054e-01],\n",
      "        [-2.4097e-01,  7.6599e-02,  1.3672e-01],\n",
      "        [ 7.5150e-03,  1.4209e-01,  2.7832e-01],\n",
      "        [-2.8101e-01,  3.6816e-01,  3.0249e-01],\n",
      "        [-2.7856e-01,  1.5784e-01,  2.3889e-01],\n",
      "        [-2.1057e-01,  1.7053e-01,  5.4474e-02],\n",
      "        [ 1.4458e-02,  4.0381e-01,  2.2473e-01],\n",
      "        [ 2.6810e-02,  3.0670e-03,  1.0699e-01],\n",
      "        [-4.3273e-04,  2.9224e-01,  3.0664e-01]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0245, 0.0190, 0.0149],\n",
      "        [0.0249, 0.0307, 0.0199],\n",
      "        [0.0239, 0.0262, 0.0224],\n",
      "        [0.0283, 0.0268, 0.0164],\n",
      "        [0.0224, 0.0182, 0.0182],\n",
      "        [0.0222, 0.0263, 0.0266],\n",
      "        [0.0197, 0.0291, 0.0185],\n",
      "        [0.0237, 0.0234, 0.0229],\n",
      "        [0.0180, 0.0217, 0.0199],\n",
      "        [0.0220, 0.0251, 0.0234],\n",
      "        [0.0251, 0.0201, 0.0271],\n",
      "        [0.0226, 0.0187, 0.0258],\n",
      "        [0.0269, 0.0158, 0.0242],\n",
      "        [0.0228, 0.0219, 0.0267],\n",
      "        [0.0204, 0.0197, 0.0313],\n",
      "        [0.0203, 0.0179, 0.0306],\n",
      "        [0.0242, 0.0227, 0.0229],\n",
      "        [0.0243, 0.0307, 0.0252],\n",
      "        [0.0288, 0.0297, 0.0257],\n",
      "        [0.0249, 0.0273, 0.0261],\n",
      "        [0.0242, 0.0325, 0.0268],\n",
      "        [0.0292, 0.0277, 0.0227],\n",
      "        [0.0287, 0.0236, 0.0276],\n",
      "        [0.0281, 0.0220, 0.0236],\n",
      "        [0.0249, 0.0248, 0.0219],\n",
      "        [0.0330, 0.0248, 0.0284],\n",
      "        [0.0215, 0.0193, 0.0235],\n",
      "        [0.0242, 0.0206, 0.0246],\n",
      "        [0.0167, 0.0166, 0.0327],\n",
      "        [0.0237, 0.0176, 0.0262],\n",
      "        [0.0208, 0.0183, 0.0318],\n",
      "        [0.0204, 0.0220, 0.0218],\n",
      "        [0.0201, 0.0187, 0.0200],\n",
      "        [0.0291, 0.0236, 0.0205],\n",
      "        [0.0204, 0.0237, 0.0208],\n",
      "        [0.0261, 0.0253, 0.0240],\n",
      "        [0.0196, 0.0317, 0.0246],\n",
      "        [0.0196, 0.0257, 0.0230],\n",
      "        [0.0210, 0.0261, 0.0192],\n",
      "        [0.0263, 0.0329, 0.0227],\n",
      "        [0.0266, 0.0220, 0.0202],\n",
      "        [0.0259, 0.0294, 0.0246]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 2.7271e-01, -5.3131e-02,  1.1646e-01],\n",
      "        [ 9.6497e-02,  2.9663e-01,  4.2432e-01],\n",
      "        [ 1.9507e-01, -3.6106e-03,  3.9844e-01],\n",
      "        [ 8.7402e-02,  3.9014e-01,  5.5225e-01],\n",
      "        [-1.2970e-03, -6.7932e-02,  3.8037e-01],\n",
      "        [-8.9844e-02,  3.9276e-02,  7.3926e-01],\n",
      "        [-1.4954e-01,  7.6408e-03,  4.2041e-01],\n",
      "        [-2.6611e-02,  8.0872e-02,  7.1973e-01],\n",
      "        [-1.8542e-01,  2.7435e-02,  5.3857e-01],\n",
      "        [-2.4841e-01,  4.6906e-02,  5.5615e-01],\n",
      "        [ 1.5686e-02, -2.9810e-01,  5.1855e-01],\n",
      "        [-1.3525e-01,  2.2620e-01,  3.3057e-01],\n",
      "        [-2.2009e-01,  3.8135e-01,  5.6787e-01],\n",
      "        [-3.8550e-01,  1.9629e-01,  4.4727e-01],\n",
      "        [ 2.4323e-02, -7.8003e-02,  2.8839e-02],\n",
      "        [-8.8562e-02,  1.6040e-01,  1.8884e-01],\n",
      "        [ 9.1492e-02, -7.0992e-03,  1.3330e-01],\n",
      "        [ 1.6150e-01,  1.1273e-01,  4.7583e-01],\n",
      "        [-6.3049e-02,  9.7229e-02,  2.2375e-01],\n",
      "        [ 1.0333e-01,  2.5781e-01,  4.0771e-01],\n",
      "        [-7.5928e-02,  1.9507e-01,  3.4399e-01],\n",
      "        [-3.0029e-01,  2.9053e-01,  5.7715e-01],\n",
      "        [-1.5289e-02,  1.2585e-01,  1.4172e-01],\n",
      "        [-6.8604e-02,  3.6499e-01,  3.7842e-01],\n",
      "        [-5.8350e-02,  1.8616e-01,  2.6514e-01],\n",
      "        [-2.7237e-02,  1.8066e-01,  2.5391e-01],\n",
      "        [-2.0081e-01, -3.9093e-02,  1.4807e-01],\n",
      "        [-1.7725e-01,  2.0154e-01,  2.8101e-01],\n",
      "        [-2.5732e-01, -1.1829e-01,  4.6509e-01],\n",
      "        [-3.3228e-01, -1.8408e-01,  3.8623e-01],\n",
      "        [-1.9849e-01,  2.9199e-01,  7.1875e-01],\n",
      "        [-2.4402e-01,  2.8955e-01,  4.9121e-01],\n",
      "        [-3.7476e-01,  2.8223e-01,  4.4458e-01],\n",
      "        [-1.1749e-01,  3.1348e-01,  4.3970e-01],\n",
      "        [-2.2009e-01,  2.8955e-01,  4.1113e-01],\n",
      "        [-2.5024e-01,  1.4368e-01,  7.0862e-02],\n",
      "        [-1.9800e-01, -1.8005e-01,  1.6138e-01],\n",
      "        [ 1.3817e-02,  2.7618e-02,  2.2125e-02],\n",
      "        [ 3.5980e-02,  8.1177e-02, -5.8746e-04],\n",
      "        [ 1.2299e-01,  1.2854e-01,  3.0347e-01]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0354, 0.0208, 0.0192],\n",
      "        [0.0297, 0.0295, 0.0261],\n",
      "        [0.0327, 0.0219, 0.0255],\n",
      "        [0.0294, 0.0324, 0.0297],\n",
      "        [0.0269, 0.0205, 0.0250],\n",
      "        [0.0246, 0.0228, 0.0358],\n",
      "        [0.0232, 0.0221, 0.0260],\n",
      "        [0.0262, 0.0238, 0.0351],\n",
      "        [0.0224, 0.0226, 0.0293],\n",
      "        [0.0210, 0.0230, 0.0298],\n",
      "        [0.0274, 0.0163, 0.0287],\n",
      "        [0.0235, 0.0275, 0.0238],\n",
      "        [0.0216, 0.0321, 0.0302],\n",
      "        [0.0183, 0.0267, 0.0267],\n",
      "        [0.0276, 0.0203, 0.0176],\n",
      "        [0.0247, 0.0258, 0.0206],\n",
      "        [0.0295, 0.0218, 0.0195],\n",
      "        [0.0316, 0.0246, 0.0275],\n",
      "        [0.0253, 0.0242, 0.0214],\n",
      "        [0.0299, 0.0284, 0.0257],\n",
      "        [0.0250, 0.0267, 0.0241],\n",
      "        [0.0200, 0.0293, 0.0305],\n",
      "        [0.0265, 0.0249, 0.0197],\n",
      "        [0.0252, 0.0316, 0.0250],\n",
      "        [0.0254, 0.0264, 0.0223],\n",
      "        [0.0262, 0.0263, 0.0220],\n",
      "        [0.0220, 0.0211, 0.0198],\n",
      "        [0.0226, 0.0268, 0.0226],\n",
      "        [0.0208, 0.0195, 0.0272],\n",
      "        [0.0193, 0.0182, 0.0252],\n",
      "        [0.0221, 0.0294, 0.0351],\n",
      "        [0.0211, 0.0293, 0.0279],\n",
      "        [0.0185, 0.0291, 0.0267],\n",
      "        [0.0239, 0.0300, 0.0265],\n",
      "        [0.0216, 0.0293, 0.0258],\n",
      "        [0.0210, 0.0253, 0.0184],\n",
      "        [0.0221, 0.0183, 0.0201],\n",
      "        [0.0273, 0.0226, 0.0175],\n",
      "        [0.0279, 0.0238, 0.0171],\n",
      "        [0.0305, 0.0250, 0.0232]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0495, -0.0359, -0.1003],\n",
      "        [ 0.1882,  0.2279,  0.1656],\n",
      "        [ 0.0626, -0.0073,  0.0815],\n",
      "        [ 0.1092,  0.2325,  0.3103],\n",
      "        [ 0.0324,  0.0815,  0.0753],\n",
      "        [ 0.2354,  0.1901, -0.0637],\n",
      "        [ 0.1252, -0.0334,  0.1746],\n",
      "        [-0.1066,  0.1372,  0.1776],\n",
      "        [-0.2944,  0.0603,  0.3130],\n",
      "        [-0.1984,  0.0157,  0.1418],\n",
      "        [-0.1154, -0.0677,  0.2369],\n",
      "        [-0.1172, -0.0368,  0.2703],\n",
      "        [-0.0029, -0.2759,  0.0355],\n",
      "        [-0.1729, -0.0062,  0.4946],\n",
      "        [-0.0439,  0.0620,  0.3010],\n",
      "        [-0.0914, -0.0009,  0.1642],\n",
      "        [ 0.0773, -0.0774,  0.1875],\n",
      "        [ 0.0622,  0.0067,  0.0345],\n",
      "        [-0.0840, -0.1830, -0.0770],\n",
      "        [-0.0814,  0.3127,  0.1444],\n",
      "        [-0.1510,  0.0634,  0.3757],\n",
      "        [ 0.0651,  0.2664, -0.0323],\n",
      "        [-0.0552,  0.5601,  0.2788],\n",
      "        [ 0.1531,  0.5596,  0.0993],\n",
      "        [-0.0667,  0.4397,  0.4993],\n",
      "        [ 0.0513,  0.2769,  0.1584],\n",
      "        [ 0.0211,  0.0937,  0.3640],\n",
      "        [-0.0694,  0.3210,  0.1615],\n",
      "        [ 0.0776,  0.0304,  0.0567],\n",
      "        [ 0.1794,  0.1740,  0.2021]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0349, 0.0282, 0.0250],\n",
      "        [0.0402, 0.0367, 0.0327],\n",
      "        [0.0354, 0.0290, 0.0300],\n",
      "        [0.0371, 0.0368, 0.0378],\n",
      "        [0.0344, 0.0317, 0.0298],\n",
      "        [0.0421, 0.0353, 0.0260],\n",
      "        [0.0377, 0.0282, 0.0330],\n",
      "        [0.0299, 0.0335, 0.0331],\n",
      "        [0.0248, 0.0310, 0.0378],\n",
      "        [0.0273, 0.0296, 0.0319],\n",
      "        [0.0296, 0.0273, 0.0351],\n",
      "        [0.0296, 0.0281, 0.0363],\n",
      "        [0.0332, 0.0222, 0.0287],\n",
      "        [0.0280, 0.0290, 0.0454],\n",
      "        [0.0318, 0.0311, 0.0374],\n",
      "        [0.0303, 0.0292, 0.0326],\n",
      "        [0.0359, 0.0270, 0.0334],\n",
      "        [0.0354, 0.0294, 0.0287],\n",
      "        [0.0306, 0.0243, 0.0256],\n",
      "        [0.0307, 0.0399, 0.0320],\n",
      "        [0.0286, 0.0311, 0.0403],\n",
      "        [0.0355, 0.0381, 0.0268],\n",
      "        [0.0315, 0.0511, 0.0366],\n",
      "        [0.0388, 0.0511, 0.0306],\n",
      "        [0.0311, 0.0453, 0.0456],\n",
      "        [0.0350, 0.0385, 0.0324],\n",
      "        [0.0340, 0.0321, 0.0398],\n",
      "        [0.0310, 0.0403, 0.0325],\n",
      "        [0.0359, 0.0301, 0.0293],\n",
      "        [0.0398, 0.0348, 0.0339]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.3838,  0.0285, -0.0878],\n",
      "        [ 0.1068,  0.2227, -0.1200],\n",
      "        [-0.0953,  0.1141,  0.0214],\n",
      "        [-0.0124, -0.4128,  0.3225],\n",
      "        [-0.1820, -0.1654,  0.1050],\n",
      "        [ 0.4458, -0.3579,  0.0586],\n",
      "        [-0.0199, -0.3110, -0.0803],\n",
      "        [ 0.1060, -0.1650,  0.2322],\n",
      "        [-0.1467, -0.2113,  0.1908],\n",
      "        [ 0.0884,  0.0399,  0.3940],\n",
      "        [-0.0160, -0.3198,  0.2554],\n",
      "        [ 0.2629, -0.0113,  0.0839],\n",
      "        [-0.0726,  0.0900,  0.2761],\n",
      "        [-0.1672, -0.1283,  0.3606],\n",
      "        [-0.1528,  0.0512,  0.3237],\n",
      "        [ 0.0027, -0.3140,  0.6108],\n",
      "        [ 0.0690,  0.1112,  0.4810],\n",
      "        [-0.2732, -0.2336,  0.6777],\n",
      "        [-0.1116,  0.0187,  0.5493],\n",
      "        [-0.1664, -0.0697,  0.4490],\n",
      "        [-0.3689, -0.0044,  0.4309],\n",
      "        [ 0.0939,  0.0950,  0.4526],\n",
      "        [-0.0505, -0.4111,  0.6826],\n",
      "        [-0.1980, -0.4431,  0.7349],\n",
      "        [ 0.0413, -0.2438,  0.4146],\n",
      "        [-0.2385, -0.3213,  0.6973],\n",
      "        [-0.2003, -0.3848,  0.5728],\n",
      "        [ 0.0210, -0.2505,  0.4307],\n",
      "        [ 0.0989, -0.0887,  0.5859],\n",
      "        [-0.0208,  0.0324,  0.5293],\n",
      "        [-0.0021,  0.0341,  0.5029],\n",
      "        [-0.1004, -0.0924,  0.5103],\n",
      "        [-0.0496, -0.0184,  0.2661],\n",
      "        [ 0.1737, -0.0065,  0.3281],\n",
      "        [ 0.1740, -0.1454,  0.1469],\n",
      "        [ 0.2211, -0.1479,  0.3638],\n",
      "        [ 0.1107, -0.0664,  0.3655],\n",
      "        [ 0.0607, -0.3855,  0.4272],\n",
      "        [ 0.0362, -0.0887,  0.3972],\n",
      "        [ 0.1415,  0.0669,  0.4404],\n",
      "        [-0.1782, -0.0619,  0.4607],\n",
      "        [-0.0428,  0.1863,  0.2903],\n",
      "        [-0.1022,  0.0309,  0.3015],\n",
      "        [-0.0855,  0.0359,  0.3953],\n",
      "        [-0.0197, -0.0394,  0.4790],\n",
      "        [-0.0112, -0.0606,  0.5806],\n",
      "        [ 0.0260, -0.1355,  0.2703],\n",
      "        [-0.0515, -0.0622,  0.2189],\n",
      "        [-0.0639, -0.0779,  0.3662],\n",
      "        [-0.2064, -0.1475,  0.5005],\n",
      "        [-0.0613, -0.2285,  0.3401],\n",
      "        [ 0.1610, -0.1414,  0.4573],\n",
      "        [ 0.3450, -0.1373,  0.2676],\n",
      "        [ 0.2832,  0.3127,  0.3135],\n",
      "        [ 0.0779, -0.1103,  0.2639],\n",
      "        [ 0.2406,  0.2062,  0.3083]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0257, 0.0199, 0.0112],\n",
      "        [0.0195, 0.0242, 0.0108],\n",
      "        [0.0159, 0.0217, 0.0125],\n",
      "        [0.0173, 0.0128, 0.0169],\n",
      "        [0.0146, 0.0164, 0.0136],\n",
      "        [0.0273, 0.0135, 0.0130],\n",
      "        [0.0172, 0.0142, 0.0113],\n",
      "        [0.0195, 0.0164, 0.0154],\n",
      "        [0.0151, 0.0157, 0.0148],\n",
      "        [0.0191, 0.0201, 0.0181],\n",
      "        [0.0172, 0.0141, 0.0158],\n",
      "        [0.0228, 0.0191, 0.0133],\n",
      "        [0.0163, 0.0212, 0.0161],\n",
      "        [0.0148, 0.0170, 0.0175],\n",
      "        [0.0150, 0.0204, 0.0169],\n",
      "        [0.0176, 0.0141, 0.0225],\n",
      "        [0.0188, 0.0216, 0.0198],\n",
      "        [0.0133, 0.0153, 0.0241],\n",
      "        [0.0157, 0.0197, 0.0212],\n",
      "        [0.0148, 0.0181, 0.0192],\n",
      "        [0.0121, 0.0193, 0.0188],\n",
      "        [0.0192, 0.0213, 0.0192],\n",
      "        [0.0166, 0.0128, 0.0242],\n",
      "        [0.0144, 0.0124, 0.0255],\n",
      "        [0.0182, 0.0152, 0.0185],\n",
      "        [0.0138, 0.0140, 0.0246],\n",
      "        [0.0143, 0.0132, 0.0217],\n",
      "        [0.0179, 0.0151, 0.0188],\n",
      "        [0.0193, 0.0177, 0.0220],\n",
      "        [0.0172, 0.0200, 0.0208],\n",
      "        [0.0175, 0.0200, 0.0202],\n",
      "        [0.0158, 0.0176, 0.0204],\n",
      "        [0.0167, 0.0190, 0.0160],\n",
      "        [0.0208, 0.0192, 0.0170],\n",
      "        [0.0208, 0.0167, 0.0142],\n",
      "        [0.0219, 0.0167, 0.0176],\n",
      "        [0.0196, 0.0181, 0.0176],\n",
      "        [0.0186, 0.0132, 0.0188],\n",
      "        [0.0182, 0.0177, 0.0182],\n",
      "        [0.0202, 0.0207, 0.0190],\n",
      "        [0.0146, 0.0182, 0.0194],\n",
      "        [0.0168, 0.0233, 0.0164],\n",
      "        [0.0158, 0.0200, 0.0165],\n",
      "        [0.0161, 0.0201, 0.0182],\n",
      "        [0.0172, 0.0186, 0.0197],\n",
      "        [0.0173, 0.0182, 0.0219],\n",
      "        [0.0180, 0.0169, 0.0160],\n",
      "        [0.0166, 0.0182, 0.0152],\n",
      "        [0.0164, 0.0179, 0.0177],\n",
      "        [0.0143, 0.0167, 0.0202],\n",
      "        [0.0165, 0.0154, 0.0172],\n",
      "        [0.0206, 0.0168, 0.0193],\n",
      "        [0.0247, 0.0169, 0.0160],\n",
      "        [0.0233, 0.0265, 0.0167],\n",
      "        [0.0189, 0.0173, 0.0159],\n",
      "        [0.0223, 0.0238, 0.0166]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 2.5244e-01, -1.9080e-01, -5.4962e-02],\n",
      "        [ 1.7041e-01,  1.0510e-01, -2.9517e-01],\n",
      "        [-2.4429e-02, -8.7769e-02, -2.5415e-01],\n",
      "        [ 2.0862e-01,  9.5337e-02, -1.8787e-01],\n",
      "        [ 7.1289e-02,  1.5979e-01, -4.3677e-01],\n",
      "        [ 3.4619e-01,  3.9624e-01, -3.3423e-01],\n",
      "        [ 1.7676e-01,  2.6782e-01, -3.6450e-01],\n",
      "        [ 1.7749e-01,  4.8657e-01, -3.8818e-02],\n",
      "        [ 9.8022e-02,  3.3618e-01, -1.9080e-01],\n",
      "        [ 3.8599e-01,  6.3867e-01,  8.7662e-03],\n",
      "        [ 2.0081e-02,  3.1860e-01, -5.6458e-02],\n",
      "        [ 1.2671e-01,  2.6611e-01, -1.3635e-01],\n",
      "        [ 3.4454e-02, -1.1406e-02,  1.6174e-01],\n",
      "        [ 4.9782e-04, -1.7737e-01,  1.5344e-01],\n",
      "        [-5.3635e-03,  1.2170e-01,  2.0361e-01],\n",
      "        [-8.0322e-02, -1.0504e-01,  1.8811e-01],\n",
      "        [-1.4697e-01,  3.5571e-01,  3.4607e-02],\n",
      "        [-2.8491e-01,  3.3838e-01,  2.2168e-01],\n",
      "        [-2.5977e-01,  4.3896e-01,  1.3831e-01],\n",
      "        [-2.4829e-01,  3.8501e-01,  9.3628e-02],\n",
      "        [-8.4900e-02,  1.6687e-01,  1.7944e-01],\n",
      "        [-2.7222e-01,  1.9714e-01,  6.7529e-01],\n",
      "        [-8.9478e-02,  2.9419e-01,  2.9297e-01],\n",
      "        [-6.3904e-02,  4.5410e-01, -3.1592e-01],\n",
      "        [-6.6162e-02,  3.5083e-01,  2.9297e-02],\n",
      "        [-2.9175e-01,  1.0583e-01,  3.5815e-01],\n",
      "        [ 1.0229e-01,  3.0640e-02,  1.5674e-01],\n",
      "        [ 4.2578e-01,  4.1187e-01,  4.0169e-03],\n",
      "        [ 6.7810e-02,  1.4478e-01,  1.1084e-01],\n",
      "        [ 4.1040e-01,  4.5117e-01, -7.8186e-02]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0404, 0.0215, 0.0303],\n",
      "        [0.0372, 0.0290, 0.0239],\n",
      "        [0.0307, 0.0239, 0.0249],\n",
      "        [0.0387, 0.0287, 0.0266],\n",
      "        [0.0338, 0.0306, 0.0207],\n",
      "        [0.0444, 0.0388, 0.0230],\n",
      "        [0.0375, 0.0341, 0.0223],\n",
      "        [0.0375, 0.0424, 0.0309],\n",
      "        [0.0347, 0.0365, 0.0265],\n",
      "        [0.0462, 0.0494, 0.0324],\n",
      "        [0.0320, 0.0359, 0.0303],\n",
      "        [0.0357, 0.0340, 0.0280],\n",
      "        [0.0325, 0.0258, 0.0377],\n",
      "        [0.0314, 0.0218, 0.0374],\n",
      "        [0.0312, 0.0294, 0.0393],\n",
      "        [0.0290, 0.0235, 0.0387],\n",
      "        [0.0271, 0.0372, 0.0332],\n",
      "        [0.0236, 0.0366, 0.0400],\n",
      "        [0.0242, 0.0404, 0.0368],\n",
      "        [0.0245, 0.0383, 0.0352],\n",
      "        [0.0289, 0.0308, 0.0384],\n",
      "        [0.0239, 0.0318, 0.0630],\n",
      "        [0.0287, 0.0350, 0.0430],\n",
      "        [0.0295, 0.0411, 0.0234],\n",
      "        [0.0294, 0.0370, 0.0330],\n",
      "        [0.0235, 0.0290, 0.0459],\n",
      "        [0.0348, 0.0269, 0.0375],\n",
      "        [0.0481, 0.0394, 0.0322],\n",
      "        [0.0336, 0.0302, 0.0359],\n",
      "        [0.0474, 0.0410, 0.0297]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0742, -0.2314, -0.1569],\n",
      "        [ 0.1399,  0.2490,  0.0452],\n",
      "        [ 0.0955,  0.1189, -0.1214],\n",
      "        [ 0.2942,  0.1351,  0.0646]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2054, 0.1826, 0.2218],\n",
      "        [0.2544, 0.2952, 0.2715],\n",
      "        [0.2434, 0.2590, 0.2297],\n",
      "        [0.2969, 0.2634, 0.2769]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 5.8472e-02,  1.5405e-01, -8.0139e-02],\n",
      "        [ 2.1985e-01, -1.7410e-02, -2.1655e-01],\n",
      "        [-1.9250e-01,  3.8727e-02, -5.6152e-02],\n",
      "        [-1.7532e-02,  2.2192e-01,  9.3628e-02],\n",
      "        [-9.9609e-02,  1.6565e-01,  1.1224e-01],\n",
      "        [ 5.5428e-03,  3.5181e-01, -9.8877e-02],\n",
      "        [ 1.1731e-01,  3.6353e-01,  3.0542e-01],\n",
      "        [ 5.5298e-02,  2.4072e-01,  3.3667e-01],\n",
      "        [-2.0683e-04,  1.7761e-01,  4.5630e-01],\n",
      "        [ 8.4534e-02,  2.1997e-01,  4.0381e-01],\n",
      "        [ 1.9257e-02,  2.4158e-01,  2.7686e-01],\n",
      "        [ 3.1738e-01,  5.0879e-01,  2.0874e-01],\n",
      "        [-2.8656e-02,  3.5327e-01,  8.5388e-02],\n",
      "        [ 1.5149e-01,  3.1274e-01,  2.8906e-01]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0715, 0.0651, 0.0556],\n",
      "        [0.0840, 0.0548, 0.0485],\n",
      "        [0.0557, 0.0580, 0.0569],\n",
      "        [0.0663, 0.0696, 0.0662],\n",
      "        [0.0611, 0.0659, 0.0674],\n",
      "        [0.0678, 0.0793, 0.0545],\n",
      "        [0.0759, 0.0803, 0.0817],\n",
      "        [0.0713, 0.0710, 0.0844],\n",
      "        [0.0674, 0.0667, 0.0950],\n",
      "        [0.0734, 0.0695, 0.0901],\n",
      "        [0.0688, 0.0710, 0.0795],\n",
      "        [0.0927, 0.0928, 0.0742],\n",
      "        [0.0656, 0.0795, 0.0656],\n",
      "        [0.0785, 0.0763, 0.0804]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0310, -0.1395, -0.1499],\n",
      "        [ 0.3201, -0.0015, -0.3792],\n",
      "        [ 0.0891, -0.3098,  0.0724],\n",
      "        [-0.1147, -0.1109,  0.1681],\n",
      "        [-0.0953, -0.1048,  0.2554],\n",
      "        [-0.0358,  0.1359, -0.0801],\n",
      "        [-0.2598, -0.1394,  0.0147],\n",
      "        [ 0.2147,  0.2308, -0.0545],\n",
      "        [ 0.0958, -0.2213,  0.0931],\n",
      "        [ 0.4275,  0.3555,  0.1196],\n",
      "        [ 0.1718, -0.0608,  0.2573],\n",
      "        [ 0.1149, -0.0296,  0.5444],\n",
      "        [ 0.0195, -0.0620,  0.4917],\n",
      "        [-0.2115, -0.1030,  0.3840],\n",
      "        [-0.1917,  0.0054,  0.1444],\n",
      "        [-0.1508, -0.0431,  0.1456],\n",
      "        [ 0.0285, -0.0429,  0.1371],\n",
      "        [ 0.0177, -0.0313,  0.1342],\n",
      "        [ 0.0039, -0.3430, -0.1639],\n",
      "        [-0.0251, -0.2428, -0.3225],\n",
      "        [-0.0133, -0.2170, -0.1810],\n",
      "        [-0.1803, -0.1959,  0.1100],\n",
      "        [-0.0959,  0.1431,  0.1654],\n",
      "        [-0.0898, -0.1730,  0.3240],\n",
      "        [ 0.1044, -0.0461,  0.4646],\n",
      "        [ 0.2041, -0.2102,  0.0978],\n",
      "        [ 0.2605,  0.1293,  0.1786],\n",
      "        [ 0.1248, -0.1134, -0.0062],\n",
      "        [-0.0455, -0.1915,  0.2793],\n",
      "        [ 0.0696, -0.0016, -0.1093],\n",
      "        [-0.1283, -0.3074,  0.1313],\n",
      "        [-0.0328, -0.2678,  0.2001],\n",
      "        [-0.0378, -0.1862,  0.5283],\n",
      "        [-0.0819, -0.0184,  0.4900],\n",
      "        [-0.0712, -0.1004,  0.5908],\n",
      "        [-0.2013,  0.1451,  0.4382],\n",
      "        [-0.2795, -0.3186,  0.2593],\n",
      "        [ 0.1020, -0.1509,  0.1743],\n",
      "        [-0.0992, -0.1027, -0.1505],\n",
      "        [-0.1698, -0.2111,  0.2250],\n",
      "        [-0.1935, -0.1116,  0.0638],\n",
      "        [-0.2349, -0.1150,  0.2407],\n",
      "        [-0.0598, -0.1057,  0.1053],\n",
      "        [-0.1164, -0.1729,  0.2217],\n",
      "        [ 0.0110,  0.2123,  0.1126],\n",
      "        [-0.1691, -0.0801,  0.2084],\n",
      "        [-0.2151,  0.0640, -0.0398],\n",
      "        [ 0.1703,  0.1334, -0.0137],\n",
      "        [-0.0385,  0.0777, -0.1134],\n",
      "        [ 0.0506,  0.0483,  0.1339],\n",
      "        [ 0.1631,  0.0883,  0.2012],\n",
      "        [-0.0268, -0.0575,  0.2661],\n",
      "        [ 0.1064,  0.0164,  0.0673],\n",
      "        [-0.0460, -0.0067,  0.4121],\n",
      "        [-0.1558, -0.1216,  0.3459],\n",
      "        [-0.0892, -0.2325,  0.3184],\n",
      "        [-0.1392,  0.1709,  0.4880],\n",
      "        [ 0.0461,  0.1007,  0.2781],\n",
      "        [ 0.0087,  0.0529,  0.3508],\n",
      "        [-0.3159,  0.0740,  0.2734],\n",
      "        [-0.2365,  0.2014,  0.4001],\n",
      "        [-0.3708, -0.0891,  0.4062],\n",
      "        [-0.2971, -0.1364,  0.1879],\n",
      "        [-0.0307, -0.0106,  0.3423],\n",
      "        [-0.0599, -0.3096,  0.2046],\n",
      "        [-0.0114, -0.1331,  0.2664],\n",
      "        [-0.2208, -0.1903,  0.7275],\n",
      "        [ 0.1654, -0.1164,  0.3943],\n",
      "        [-0.0389,  0.0914,  0.2739],\n",
      "        [-0.0204, -0.0909,  0.2393],\n",
      "        [-0.2190, -0.0754,  0.3479],\n",
      "        [ 0.0418, -0.1025,  0.3013],\n",
      "        [ 0.0042, -0.0459,  0.4702],\n",
      "        [ 0.0009, -0.1533,  0.5132],\n",
      "        [ 0.0798, -0.2235,  0.1449],\n",
      "        [ 0.3623,  0.0491,  0.2135],\n",
      "        [ 0.2390, -0.0960,  0.0426],\n",
      "        [ 0.2976, -0.0669,  0.2949]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0126, 0.0118, 0.0088],\n",
      "        [0.0178, 0.0135, 0.0070],\n",
      "        [0.0142, 0.0099, 0.0110],\n",
      "        [0.0116, 0.0121, 0.0121],\n",
      "        [0.0118, 0.0122, 0.0132],\n",
      "        [0.0125, 0.0155, 0.0095],\n",
      "        [0.0100, 0.0118, 0.0104],\n",
      "        [0.0161, 0.0171, 0.0097],\n",
      "        [0.0143, 0.0109, 0.0113],\n",
      "        [0.0199, 0.0193, 0.0116],\n",
      "        [0.0154, 0.0128, 0.0133],\n",
      "        [0.0145, 0.0132, 0.0177],\n",
      "        [0.0132, 0.0127, 0.0168],\n",
      "        [0.0105, 0.0122, 0.0151],\n",
      "        [0.0107, 0.0136, 0.0119],\n",
      "        [0.0111, 0.0130, 0.0119],\n",
      "        [0.0133, 0.0130, 0.0118],\n",
      "        [0.0132, 0.0131, 0.0117],\n",
      "        [0.0130, 0.0096, 0.0087],\n",
      "        [0.0126, 0.0106, 0.0074],\n",
      "        [0.0128, 0.0109, 0.0086],\n",
      "        [0.0108, 0.0111, 0.0115],\n",
      "        [0.0118, 0.0156, 0.0121],\n",
      "        [0.0118, 0.0114, 0.0142],\n",
      "        [0.0144, 0.0129, 0.0163],\n",
      "        [0.0159, 0.0110, 0.0113],\n",
      "        [0.0168, 0.0154, 0.0123],\n",
      "        [0.0147, 0.0121, 0.0102],\n",
      "        [0.0124, 0.0112, 0.0136],\n",
      "        [0.0139, 0.0135, 0.0092],\n",
      "        [0.0114, 0.0100, 0.0117],\n",
      "        [0.0125, 0.0104, 0.0125],\n",
      "        [0.0125, 0.0113, 0.0174],\n",
      "        [0.0119, 0.0133, 0.0168],\n",
      "        [0.0121, 0.0123, 0.0185],\n",
      "        [0.0106, 0.0157, 0.0159],\n",
      "        [0.0098, 0.0099, 0.0133],\n",
      "        [0.0143, 0.0117, 0.0122],\n",
      "        [0.0117, 0.0122, 0.0088],\n",
      "        [0.0109, 0.0110, 0.0128],\n",
      "        [0.0107, 0.0121, 0.0109],\n",
      "        [0.0102, 0.0121, 0.0131],\n",
      "        [0.0122, 0.0122, 0.0114],\n",
      "        [0.0115, 0.0114, 0.0128],\n",
      "        [0.0131, 0.0168, 0.0115],\n",
      "        [0.0109, 0.0125, 0.0126],\n",
      "        [0.0104, 0.0144, 0.0099],\n",
      "        [0.0154, 0.0155, 0.0101],\n",
      "        [0.0125, 0.0146, 0.0092],\n",
      "        [0.0136, 0.0142, 0.0117],\n",
      "        [0.0152, 0.0148, 0.0126],\n",
      "        [0.0126, 0.0128, 0.0134],\n",
      "        [0.0144, 0.0138, 0.0110],\n",
      "        [0.0124, 0.0135, 0.0155],\n",
      "        [0.0111, 0.0120, 0.0145],\n",
      "        [0.0118, 0.0107, 0.0141],\n",
      "        [0.0113, 0.0161, 0.0167],\n",
      "        [0.0136, 0.0150, 0.0135],\n",
      "        [0.0131, 0.0143, 0.0146],\n",
      "        [0.0094, 0.0146, 0.0135],\n",
      "        [0.0102, 0.0166, 0.0153],\n",
      "        [0.0089, 0.0124, 0.0154],\n",
      "        [0.0096, 0.0118, 0.0124],\n",
      "        [0.0126, 0.0134, 0.0144],\n",
      "        [0.0122, 0.0099, 0.0126],\n",
      "        [0.0128, 0.0119, 0.0134],\n",
      "        [0.0104, 0.0112, 0.0212],\n",
      "        [0.0153, 0.0121, 0.0152],\n",
      "        [0.0125, 0.0148, 0.0135],\n",
      "        [0.0127, 0.0124, 0.0130],\n",
      "        [0.0104, 0.0126, 0.0145],\n",
      "        [0.0135, 0.0122, 0.0139],\n",
      "        [0.0130, 0.0129, 0.0164],\n",
      "        [0.0130, 0.0116, 0.0171],\n",
      "        [0.0140, 0.0108, 0.0119],\n",
      "        [0.0186, 0.0142, 0.0127],\n",
      "        [0.0164, 0.0123, 0.0107],\n",
      "        [0.0174, 0.0127, 0.0138]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0180, -0.1654,  0.2433],\n",
      "        [ 0.1070,  0.3259,  0.0095],\n",
      "        [-0.0878,  0.2152, -0.0309],\n",
      "        [-0.0422,  0.0875, -0.0179],\n",
      "        [ 0.0940, -0.0865,  0.2212],\n",
      "        [ 0.0170,  0.3511,  0.1194],\n",
      "        [-0.0699,  0.4910,  0.3696],\n",
      "        [-0.0614,  0.3521,  0.2861],\n",
      "        [ 0.0701,  0.1432,  0.1472],\n",
      "        [ 0.1681,  0.0640,  0.2019],\n",
      "        [ 0.1610, -0.0419,  0.1193],\n",
      "        [-0.1388, -0.1782,  0.5269],\n",
      "        [-0.0037, -0.0826,  0.4094],\n",
      "        [-0.1456,  0.2261,  0.2373],\n",
      "        [ 0.0209,  0.2206,  0.1356],\n",
      "        [ 0.0720,  0.1027,  0.2527],\n",
      "        [ 0.2776,  0.0859, -0.1048],\n",
      "        [ 0.4597,  0.1758, -0.0316],\n",
      "        [ 0.1549,  0.0166,  0.0230],\n",
      "        [ 0.3206, -0.0281,  0.0493]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0469, 0.0372, 0.0537],\n",
      "        [0.0513, 0.0608, 0.0425],\n",
      "        [0.0422, 0.0544, 0.0408],\n",
      "        [0.0442, 0.0479, 0.0414],\n",
      "        [0.0506, 0.0403, 0.0526],\n",
      "        [0.0468, 0.0624, 0.0475],\n",
      "        [0.0430, 0.0717, 0.0609],\n",
      "        [0.0433, 0.0624, 0.0561],\n",
      "        [0.0494, 0.0507, 0.0488],\n",
      "        [0.0545, 0.0468, 0.0515],\n",
      "        [0.0541, 0.0421, 0.0475],\n",
      "        [0.0401, 0.0367, 0.0714],\n",
      "        [0.0459, 0.0404, 0.0634],\n",
      "        [0.0398, 0.0550, 0.0534],\n",
      "        [0.0470, 0.0547, 0.0482],\n",
      "        [0.0495, 0.0486, 0.0542],\n",
      "        [0.0608, 0.0479, 0.0379],\n",
      "        [0.0730, 0.0523, 0.0408],\n",
      "        [0.0538, 0.0446, 0.0431],\n",
      "        [0.0635, 0.0427, 0.0442]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0639, -0.2393, -0.0459],\n",
      "        [ 0.0753,  0.1030,  0.0136],\n",
      "        [-0.0575, -0.1322, -0.0178],\n",
      "        [ 0.0542, -0.0310, -0.1986],\n",
      "        [-0.0680, -0.1984,  0.0606],\n",
      "        [-0.1287,  0.3271,  0.0499],\n",
      "        [-0.1437, -0.0846,  0.0818],\n",
      "        [-0.0391,  0.1034,  0.0967],\n",
      "        [-0.0412,  0.0191,  0.1274],\n",
      "        [ 0.1776, -0.0231,  0.2333],\n",
      "        [-0.3374, -0.0319, -0.1804],\n",
      "        [-0.0657,  0.3982,  0.0719],\n",
      "        [-0.2986,  0.0467,  0.0096],\n",
      "        [-0.3713,  0.0018,  0.0645],\n",
      "        [-0.3044, -0.4783,  0.0823],\n",
      "        [-0.3171, -0.0586,  0.2052],\n",
      "        [-0.0804,  0.3245,  0.1093],\n",
      "        [-0.3936,  0.0644,  0.2852],\n",
      "        [-0.1881, -0.1022,  0.1660],\n",
      "        [ 0.0685,  0.4160, -0.0841],\n",
      "        [ 0.1460,  0.1356,  0.0287],\n",
      "        [ 0.0458,  0.3840,  0.2773]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0528, 0.0335, 0.0404],\n",
      "        [0.0534, 0.0471, 0.0428],\n",
      "        [0.0468, 0.0373, 0.0415],\n",
      "        [0.0523, 0.0412, 0.0347],\n",
      "        [0.0463, 0.0349, 0.0449],\n",
      "        [0.0435, 0.0590, 0.0444],\n",
      "        [0.0429, 0.0390, 0.0459],\n",
      "        [0.0476, 0.0471, 0.0465],\n",
      "        [0.0475, 0.0433, 0.0480],\n",
      "        [0.0592, 0.0415, 0.0533],\n",
      "        [0.0354, 0.0412, 0.0353],\n",
      "        [0.0464, 0.0633, 0.0454],\n",
      "        [0.0367, 0.0446, 0.0427],\n",
      "        [0.0342, 0.0426, 0.0451],\n",
      "        [0.0365, 0.0264, 0.0459],\n",
      "        [0.0361, 0.0401, 0.0519],\n",
      "        [0.0457, 0.0588, 0.0471],\n",
      "        [0.0334, 0.0453, 0.0562],\n",
      "        [0.0410, 0.0384, 0.0499],\n",
      "        [0.0530, 0.0645, 0.0388],\n",
      "        [0.0573, 0.0487, 0.0435],\n",
      "        [0.0518, 0.0624, 0.0558]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0549,  0.1715, -0.0850],\n",
      "        [-0.0942,  0.2174, -0.3105],\n",
      "        [ 0.0199, -0.0868, -0.0363],\n",
      "        [ 0.0990,  0.1209,  0.0402],\n",
      "        [ 0.0747,  0.0173, -0.3770],\n",
      "        [-0.0392,  0.0701, -0.1786],\n",
      "        [ 0.2563,  0.0435, -0.1523],\n",
      "        [-0.2067,  0.1837,  0.3887],\n",
      "        [ 0.2129, -0.1801, -0.0711],\n",
      "        [ 0.0712,  0.2094,  0.1417],\n",
      "        [ 0.0551, -0.0152,  0.1071],\n",
      "        [ 0.0815,  0.0510,  0.0117],\n",
      "        [-0.1231, -0.1382,  0.1466],\n",
      "        [-0.3003, -0.2856,  0.1578],\n",
      "        [-0.3953,  0.0399,  0.0966],\n",
      "        [-0.3052, -0.0933,  0.1420],\n",
      "        [-0.5015, -0.0914,  0.2046],\n",
      "        [-0.2593,  0.0934,  0.5503],\n",
      "        [-0.2240, -0.1606,  0.5234],\n",
      "        [-0.0659, -0.1936,  0.2229],\n",
      "        [ 0.0921, -0.2177,  0.2166],\n",
      "        [-0.1510,  0.1515,  0.4375],\n",
      "        [-0.2266,  0.1637,  0.5024],\n",
      "        [-0.1849,  0.1294,  0.5142],\n",
      "        [-0.1481,  0.1169,  0.4158],\n",
      "        [-0.1506,  0.0624,  0.2527],\n",
      "        [-0.3064, -0.1870,  0.0956],\n",
      "        [-0.2378,  0.0959,  0.1836],\n",
      "        [-0.0191, -0.0817,  0.0906],\n",
      "        [ 0.1100,  0.0439,  0.1395]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0342, 0.0388, 0.0258],\n",
      "        [0.0329, 0.0407, 0.0206],\n",
      "        [0.0369, 0.0300, 0.0270],\n",
      "        [0.0399, 0.0370, 0.0292],\n",
      "        [0.0390, 0.0333, 0.0192],\n",
      "        [0.0348, 0.0351, 0.0235],\n",
      "        [0.0467, 0.0342, 0.0241],\n",
      "        [0.0294, 0.0393, 0.0414],\n",
      "        [0.0447, 0.0273, 0.0261],\n",
      "        [0.0388, 0.0404, 0.0323],\n",
      "        [0.0382, 0.0323, 0.0312],\n",
      "        [0.0392, 0.0345, 0.0284],\n",
      "        [0.0320, 0.0285, 0.0325],\n",
      "        [0.0268, 0.0246, 0.0328],\n",
      "        [0.0243, 0.0341, 0.0309],\n",
      "        [0.0266, 0.0298, 0.0323],\n",
      "        [0.0219, 0.0299, 0.0344],\n",
      "        [0.0279, 0.0359, 0.0486],\n",
      "        [0.0289, 0.0279, 0.0473],\n",
      "        [0.0338, 0.0270, 0.0350],\n",
      "        [0.0396, 0.0263, 0.0348],\n",
      "        [0.0311, 0.0381, 0.0434],\n",
      "        [0.0288, 0.0386, 0.0463],\n",
      "        [0.0300, 0.0373, 0.0469],\n",
      "        [0.0312, 0.0368, 0.0425],\n",
      "        [0.0311, 0.0349, 0.0361],\n",
      "        [0.0266, 0.0272, 0.0309],\n",
      "        [0.0285, 0.0360, 0.0337],\n",
      "        [0.0355, 0.0302, 0.0307],\n",
      "        [0.0404, 0.0342, 0.0322]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 1.5308e-01, -6.5063e-02,  6.5857e-02],\n",
      "        [ 5.1636e-02,  1.1383e-02,  1.0181e-01],\n",
      "        [-1.6589e-01,  5.4789e-04,  3.6206e-01],\n",
      "        [-3.7628e-02, -2.6108e-02,  7.2937e-02],\n",
      "        [-1.9775e-01,  3.0444e-01,  1.6553e-01],\n",
      "        [ 8.4900e-02,  3.8013e-01,  1.3794e-01],\n",
      "        [-1.8631e-02,  4.6362e-01,  2.1277e-01],\n",
      "        [-4.0222e-02,  6.0449e-01,  4.9390e-01],\n",
      "        [-3.2104e-01, -4.0009e-02,  2.7417e-01],\n",
      "        [-1.9507e-01,  1.8555e-01,  4.3384e-01],\n",
      "        [-1.9727e-01,  3.0347e-01, -1.4758e-01],\n",
      "        [-3.6572e-01,  2.9053e-01,  3.2983e-01],\n",
      "        [-4.4385e-01,  1.4661e-01,  3.3667e-01],\n",
      "        [-1.2103e-01,  2.0703e-01,  3.3813e-01],\n",
      "        [-2.1313e-01,  1.7773e-01,  5.1660e-01],\n",
      "        [-2.7856e-01,  1.8506e-01,  4.9951e-01],\n",
      "        [-1.9714e-01,  1.0602e-01,  4.4873e-01],\n",
      "        [-2.7979e-01, -5.9265e-02,  4.1211e-01],\n",
      "        [-2.1008e-01, -5.1422e-02,  4.9170e-01],\n",
      "        [-2.3340e-01,  3.0472e-02,  1.6589e-01],\n",
      "        [-3.0591e-01,  2.9011e-03,  2.8052e-01],\n",
      "        [-1.4673e-01, -7.0251e-02,  3.5815e-01],\n",
      "        [-2.5488e-01,  1.3147e-01,  3.6792e-01],\n",
      "        [ 9.3506e-02,  6.8665e-02,  1.4099e-01],\n",
      "        [-3.8379e-01, -8.1558e-03,  3.3618e-01],\n",
      "        [-9.4971e-02, -1.2474e-02,  4.7925e-01],\n",
      "        [-4.1595e-02, -1.1426e-01,  3.2104e-01],\n",
      "        [ 2.6611e-01,  3.3887e-01,  2.4915e-01],\n",
      "        [ 2.1265e-01, -3.9703e-02,  8.7023e-04],\n",
      "        [ 3.8477e-01,  2.6978e-01,  1.8530e-01]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0428, 0.0271, 0.0265],\n",
      "        [0.0386, 0.0293, 0.0275],\n",
      "        [0.0311, 0.0290, 0.0357],\n",
      "        [0.0353, 0.0282, 0.0267],\n",
      "        [0.0301, 0.0393, 0.0293],\n",
      "        [0.0399, 0.0423, 0.0285],\n",
      "        [0.0360, 0.0461, 0.0307],\n",
      "        [0.0352, 0.0530, 0.0407],\n",
      "        [0.0266, 0.0278, 0.0327],\n",
      "        [0.0302, 0.0349, 0.0383],\n",
      "        [0.0301, 0.0392, 0.0214],\n",
      "        [0.0255, 0.0387, 0.0345],\n",
      "        [0.0235, 0.0335, 0.0348],\n",
      "        [0.0325, 0.0356, 0.0348],\n",
      "        [0.0296, 0.0346, 0.0417],\n",
      "        [0.0278, 0.0349, 0.0409],\n",
      "        [0.0301, 0.0322, 0.0389],\n",
      "        [0.0278, 0.0273, 0.0375],\n",
      "        [0.0298, 0.0275, 0.0406],\n",
      "        [0.0291, 0.0299, 0.0293],\n",
      "        [0.0270, 0.0290, 0.0329],\n",
      "        [0.0317, 0.0270, 0.0356],\n",
      "        [0.0284, 0.0330, 0.0359],\n",
      "        [0.0403, 0.0310, 0.0286],\n",
      "        [0.0250, 0.0287, 0.0348],\n",
      "        [0.0334, 0.0286, 0.0401],\n",
      "        [0.0352, 0.0258, 0.0342],\n",
      "        [0.0479, 0.0406, 0.0319],\n",
      "        [0.0454, 0.0278, 0.0249],\n",
      "        [0.0539, 0.0379, 0.0299]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.2118,  0.0836, -0.0264],\n",
      "        [ 0.1553,  0.3513,  0.1716],\n",
      "        [-0.0688, -0.1292,  0.3274],\n",
      "        [ 0.0272,  0.0815,  0.2676],\n",
      "        [ 0.1235, -0.0999,  0.0447],\n",
      "        [ 0.3547,  0.2397, -0.1403],\n",
      "        [ 0.2632, -0.1168,  0.0496],\n",
      "        [ 0.2050, -0.0015,  0.0316],\n",
      "        [ 0.1719, -0.0934,  0.0432],\n",
      "        [-0.0801,  0.1783,  0.2113],\n",
      "        [-0.0630, -0.0106,  0.2598],\n",
      "        [ 0.1389,  0.1004,  0.6157],\n",
      "        [ 0.1976,  0.2257,  0.6650],\n",
      "        [ 0.0544,  0.2133,  0.6782],\n",
      "        [-0.1799, -0.2466,  0.3328],\n",
      "        [ 0.0610,  0.0596,  0.7080],\n",
      "        [-0.0463,  0.1000,  0.3491],\n",
      "        [ 0.0801, -0.0588,  0.2966],\n",
      "        [-0.1185, -0.0017,  0.2322],\n",
      "        [-0.2166, -0.2250,  0.4192],\n",
      "        [-0.1744,  0.0662,  0.5015],\n",
      "        [ 0.1155,  0.3230,  0.2345],\n",
      "        [-0.1151,  0.3115,  0.3232],\n",
      "        [-0.0510,  0.0604,  0.2292],\n",
      "        [-0.1125, -0.0522,  0.0036],\n",
      "        [-0.0168, -0.1583,  0.4446],\n",
      "        [-0.1138, -0.3193,  0.2361],\n",
      "        [ 0.1548, -0.1254,  0.3274],\n",
      "        [ 0.0328, -0.1096,  0.3242],\n",
      "        [ 0.2607, -0.1066,  0.0139],\n",
      "        [ 0.1749, -0.0817,  0.0609],\n",
      "        [ 0.1885, -0.0069,  0.3247],\n",
      "        [-0.0687, -0.0490,  0.2031],\n",
      "        [ 0.0081, -0.0880,  0.1942],\n",
      "        [-0.2881, -0.2878,  0.4058],\n",
      "        [-0.1547,  0.0202,  0.4258],\n",
      "        [-0.1197, -0.1671,  0.0907],\n",
      "        [-0.1289,  0.1771,  0.3577]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0314, 0.0282, 0.0192],\n",
      "        [0.0297, 0.0368, 0.0234],\n",
      "        [0.0237, 0.0228, 0.0273],\n",
      "        [0.0261, 0.0281, 0.0257],\n",
      "        [0.0288, 0.0234, 0.0206],\n",
      "        [0.0363, 0.0329, 0.0171],\n",
      "        [0.0331, 0.0230, 0.0207],\n",
      "        [0.0312, 0.0259, 0.0203],\n",
      "        [0.0302, 0.0236, 0.0206],\n",
      "        [0.0235, 0.0310, 0.0243],\n",
      "        [0.0239, 0.0256, 0.0255],\n",
      "        [0.0292, 0.0287, 0.0364],\n",
      "        [0.0310, 0.0325, 0.0383],\n",
      "        [0.0268, 0.0321, 0.0388],\n",
      "        [0.0212, 0.0202, 0.0275],\n",
      "        [0.0270, 0.0275, 0.0400],\n",
      "        [0.0243, 0.0286, 0.0279],\n",
      "        [0.0275, 0.0244, 0.0265],\n",
      "        [0.0226, 0.0259, 0.0249],\n",
      "        [0.0205, 0.0207, 0.0299],\n",
      "        [0.0213, 0.0277, 0.0325],\n",
      "        [0.0285, 0.0358, 0.0249],\n",
      "        [0.0227, 0.0354, 0.0272],\n",
      "        [0.0242, 0.0275, 0.0248],\n",
      "        [0.0227, 0.0246, 0.0198],\n",
      "        [0.0250, 0.0221, 0.0307],\n",
      "        [0.0227, 0.0188, 0.0249],\n",
      "        [0.0297, 0.0228, 0.0273],\n",
      "        [0.0263, 0.0232, 0.0272],\n",
      "        [0.0330, 0.0233, 0.0200],\n",
      "        [0.0303, 0.0239, 0.0209],\n",
      "        [0.0307, 0.0257, 0.0273],\n",
      "        [0.0237, 0.0247, 0.0241],\n",
      "        [0.0256, 0.0237, 0.0239],\n",
      "        [0.0191, 0.0194, 0.0296],\n",
      "        [0.0218, 0.0264, 0.0301],\n",
      "        [0.0226, 0.0219, 0.0216],\n",
      "        [0.0224, 0.0309, 0.0282]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 1.5564e-02, -7.4327e-05,  4.9957e-02],\n",
      "        [ 2.3303e-01,  5.6738e-01, -1.1890e-01],\n",
      "        [ 3.4943e-02,  3.3789e-01,  1.2476e-01],\n",
      "        [-9.3018e-02,  3.3057e-01,  1.2354e-01],\n",
      "        [ 4.0131e-02,  1.8384e-01, -1.9928e-02],\n",
      "        [ 3.8037e-01,  1.6602e-01, -2.6672e-02],\n",
      "        [ 3.6816e-01,  1.2396e-01, -3.0014e-02],\n",
      "        [ 2.1375e-01,  1.5063e-01,  2.7295e-01],\n",
      "        [ 2.4915e-01,  2.7417e-01,  1.8323e-01],\n",
      "        [ 8.3679e-02,  2.9712e-01,  8.7769e-02],\n",
      "        [-5.0385e-02, -2.8149e-01,  1.6016e-01],\n",
      "        [ 7.0251e-02,  4.5380e-02, -1.9058e-02],\n",
      "        [-3.1403e-02, -1.6870e-01, -1.7847e-01],\n",
      "        [ 1.7896e-01,  1.3092e-02,  8.5815e-02],\n",
      "        [ 4.2511e-02, -1.0773e-01, -2.5317e-01],\n",
      "        [ 2.0972e-01,  1.4526e-01, -1.9299e-01],\n",
      "        [ 5.7892e-02,  1.0925e-01, -1.4185e-01],\n",
      "        [ 9.9915e-02,  1.2744e-01, -9.6802e-02]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.0497, 0.0479, 0.0578],\n",
      "        [0.0618, 0.0845, 0.0488],\n",
      "        [0.0508, 0.0672, 0.0623],\n",
      "        [0.0446, 0.0667, 0.0622],\n",
      "        [0.0510, 0.0576, 0.0539],\n",
      "        [0.0717, 0.0566, 0.0535],\n",
      "        [0.0708, 0.0542, 0.0533],\n",
      "        [0.0607, 0.0557, 0.0722],\n",
      "        [0.0629, 0.0630, 0.0660],\n",
      "        [0.0533, 0.0645, 0.0600],\n",
      "        [0.0466, 0.0362, 0.0645],\n",
      "        [0.0526, 0.0502, 0.0539],\n",
      "        [0.0475, 0.0405, 0.0460],\n",
      "        [0.0586, 0.0486, 0.0599],\n",
      "        [0.0511, 0.0431, 0.0427],\n",
      "        [0.0604, 0.0555, 0.0453],\n",
      "        [0.0519, 0.0535, 0.0477],\n",
      "        [0.0541, 0.0544, 0.0499]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1926, -0.0560, -0.0823],\n",
      "        [ 0.2754,  0.4514,  0.0966],\n",
      "        [ 0.1401,  0.1389, -0.0467],\n",
      "        [ 0.2598,  0.3425, -0.0372]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.1798, 0.1864, 0.2338],\n",
      "        [0.2871, 0.3096, 0.2795],\n",
      "        [0.2507, 0.2264, 0.2423],\n",
      "        [0.2825, 0.2776, 0.2446]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Predicted output sizes\n",
      "torch.Size([100, 132, 3])\n",
      "Batch moves size\n",
      "torch.Size([100, 132, 3])\n",
      "Back-prop\n",
      "End back-prop\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0:SHIFT 1:RIGHTARC 2:LEFTARC\n",
    "moves = [0, 1, 2]\n",
    "\n",
    "\n",
    "#creiamo un oggetto Dependencies per salvare le dependencies\n",
    "class Dependencies(object):\n",
    "    def __init__(self,n):\n",
    "        self.n = n\n",
    "        self.heads = [None] * (n+1)\n",
    "        self.arcs = []\n",
    "    \n",
    "    def add_arc(self, head, child):\n",
    "        child=child\n",
    "        self.heads[child]=head\n",
    "        self.arcs.append((head,child))\n",
    "\n",
    "    def contains(self,head,child):\n",
    "        child=child\n",
    "        if self.heads[child]==head:\n",
    "            return True\n",
    "        else: return False\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "class Oracle(object):\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        #BERT encoder\n",
    "        encoder_name = \"dbmdz/bert-base-italian-xxl-cased\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(encoder_name)\n",
    "        self.encoder = AutoModel.from_pretrained(encoder_name)\n",
    "\n",
    "        #LSTM oracle\n",
    "        input_size = 3840  \n",
    "        hidden_size = 64\n",
    "        num_layers = 1\n",
    "        output_size = 3  \n",
    "        self.model = torch.nn.LSTM(input_size,hidden_size,num_layers,batch_first=True,bidirectional=False,proj_size=output_size)\n",
    "        self.model.half()\n",
    "\n",
    "        #Oracle critenion and optimazation\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "    \n",
    "    def tokens(self,words,lemmas):\n",
    "        words_token=[102]\n",
    "        for i in range(0,len(lemmas)):\n",
    "            word_token=self.tokenizer.convert_tokens_to_ids(words[i])\n",
    "            lemma_token=self.tokenizer.convert_tokens_to_ids(lemmas[i])\n",
    "            if(word_token!=101):\n",
    "                words_token.append(word_token)\n",
    "            else:\n",
    "                words_token.append(lemma_token)\n",
    "        words_token.append(103)\n",
    "        return words_token\n",
    "    \n",
    "    def encode(self,words,lemmas):\n",
    "        words_token=self.tokens(words,lemmas)\n",
    "        #max_length = 64  # Example max length ????\n",
    "        padded_input_ids = words_token\n",
    "        input_tensor = torch.tensor([padded_input_ids])\n",
    "        with torch.no_grad():\n",
    "            outputs = self.encoder(input_tensor)\n",
    "        return outputs.last_hidden_state\n",
    "    \n",
    "    #prende i batches dalla cartella, e allena il modello\n",
    "    def train_on_batches(self):\n",
    "        files = os.listdir(\"data/batches\")\n",
    "        for i in range(0,len(files)):\n",
    "            if(i==0):\n",
    "                \n",
    "                print(\"Loadind \"+str(i))\n",
    "                batch_features,batch_moves=torch.load(f\"data/batches/{files[i]}\") \n",
    "                print(\"Batch features sizes\")\n",
    "                predicted_output, _ = self.model(batch_features)\n",
    "                predicted_output= unpack_sequence(predicted_output)\n",
    "                for el in predicted_output:\n",
    "                    print(\"prima \"+str(el))\n",
    "                    el = torch.nn.Softmax(dim=0)(el)  \n",
    "                    print(\"dopo \"+str(el))\n",
    "                print(\"Predicted output sizes\")\n",
    "                predicted_output = torch.nn.utils.rnn.pad_sequence(predicted_output, batch_first=True)\n",
    "                #print(predicted_output)\n",
    "                print(predicted_output.size())\n",
    "\n",
    "\n",
    "                print(\"Batch moves size\")\n",
    "                batch_moves, _ = torch.nn.utils.rnn.pad_packed_sequence(batch_moves, batch_first=True)\n",
    "                #print(batch_moves)\n",
    "                print(batch_moves.size())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                loss = self.criterion(predicted_output, batch_moves)\n",
    "\n",
    "                #backprop\n",
    "                print(\"Back-prop\")\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                print(\"End back-prop\")\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    def score(features):\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class Parser(object):\n",
    "    model=Oracle()\n",
    "    \n",
    "    #applica la mossa andando ad aggiornare lo stack e l'indice del buffer  \n",
    "    def transition(self,move, stack, i, dependencies):\n",
    "        match move:\n",
    "            case 0:\n",
    "                stack.append(i)\n",
    "                return stack,i+1,dependencies\n",
    "            case 1:\n",
    "                dependencies.add_arc(stack[-2], stack.pop())\n",
    "                return stack,i,dependencies\n",
    "            case 2:\n",
    "                dependencies.add_arc(stack[-1], stack[-2])\n",
    "                stack.pop(-2)\n",
    "                return stack,i,dependencies\n",
    "            case _:\n",
    "                raise \"Wrong Move\"\n",
    "\n",
    "               #ritorna le mosse possibili che si possono applicare        \n",
    "    def get_valid_moves(i, n, stack_depth):\n",
    "        moves = []\n",
    "        if i <= n:\n",
    "            moves.append(0)\n",
    "        if stack_depth >= 2:\n",
    "            moves.append(1)\n",
    "            moves.append(2)\n",
    "        return moves\n",
    "\n",
    "    def parsing(self,words,tags):\n",
    "        if(len(words)!=len(tags)):\n",
    "            raise \"Wrong tag len\"\n",
    "        n=len(words)\n",
    "        deps=Dependencies(n)\n",
    "        stack=[0]\n",
    "        i_buffer=1\n",
    "        moves=self.get_valid_moves(i_buffer,n,len(stack))\n",
    "        while moves:\n",
    "            features = ['FeaturesDaScegliere']\n",
    "            scores = self.model.score(features)\n",
    "            next_move = max(moves, key=lambda move: scores[move])\n",
    "            stack,i_buffer,deps = self.transition(next_move, stack, i_buffer, deps)\n",
    "            moves = self.get_valid_moves(i,n,len(stack))\n",
    "        return deps\n",
    "    \n",
    "    #sceglie la mossa migliore da eseguire nel simulate_parse\n",
    "    def check_best(self,heads,stack,buffer,deps,i):\n",
    "        move=-1\n",
    "        if(len(stack)>=2):\n",
    "            children_list=[]\n",
    "            for child,head in enumerate(heads):\n",
    "                if head == stack[-1]:\n",
    "                    children_list.append(child)\n",
    "            if(((heads[stack[-1]])==(stack[-2])) and all([deps.contains(stack[-1],child) for child in children_list])):\n",
    "                move=1\n",
    "            if(heads[stack[-2]]==stack[-1]):\n",
    "                move=2\n",
    "        if(i<=len(buffer) and move==-1):\n",
    "            move=0\n",
    "        elif(i>len(buffer) and move==-1):\n",
    "            move=None\n",
    "        return move\n",
    "    \n",
    "    #fa reverse engineering, dato lo stato finale ricostruisce lo stack, buffer e le mosse\n",
    "    def simulate_parse(self,heads,buffer):\n",
    "        deps=Dependencies(len(buffer))\n",
    "        stack=[0]\n",
    "        moves=[]\n",
    "        buffers=[]\n",
    "        stacks=[]\n",
    "        i=1\n",
    "        best_move=self.check_best(heads,stack,buffer,deps,i)\n",
    "        while best_move!=None:\n",
    "            buffers.append(i)\n",
    "            stacks.append(stack[:])\n",
    "            moves.append(best_move)\n",
    "            stack,i,deps=self.transition(best_move,stack,i,deps)\n",
    "            best_move=self.check_best(heads,stack,buffer,deps,i)\n",
    "        if(i>len(buffer)):\n",
    "            return stacks,buffers,moves\n",
    "        else: return None \n",
    "\n",
    "    #prende gli ultimi tre elementi dello stack\n",
    "    def get_stack_context(self,list):\n",
    "        depth=len(list)\n",
    "\n",
    "        if depth >= 3:\n",
    "            return [list[-1], list[-2], list[-3]]\n",
    "        \n",
    "        elif depth >= 2:\n",
    "\n",
    "            return [list[-1], list[-2], -1]\n",
    "        \n",
    "        elif depth == 1:\n",
    "            return [list[-1], -1 , -1]\n",
    "        else:\n",
    "            return [-1, -1, -1]\n",
    "\n",
    "    def get_buffer_context(self,index,len_phrase):\n",
    "    #prende gli ultimi due elementi dell buffer\n",
    "        if(index==len_phrase):\n",
    "            return [index,-1]\n",
    "        elif(index>len_phrase):\n",
    "            return [-1,-1]\n",
    "        else: return [index,index+1]  \n",
    "\n",
    "    def flatten_embedded_features(self,matrix):\n",
    "        flat_list = torch.tensor([])\n",
    "        for row in matrix:\n",
    "            flat_list=torch.cat((flat_list,row))\n",
    "        return flat_list\n",
    "\n",
    "    def encode_moves(self,heads,phrase,phrases_lemma):\n",
    "        embeddings = self.model.encode(phrase,phrases_lemma)\n",
    "        stacks,buffers,moves=self.simulate_parse(heads,phrase)\n",
    "        root_embeding=torch.tensor(np.ones(768))\n",
    "        empty_embedding=torch.tensor(np.zeros(768))\n",
    "        embedded_features=[]\n",
    "        for i in range(0,len(stacks)):\n",
    "            stack_feature=self.get_stack_context(stacks[i])\n",
    "            for j,el in enumerate(stack_feature):\n",
    "                if(el>=1):\n",
    "                    stack_feature[j]=embeddings[0][el]\n",
    "                elif(el==0):\n",
    "                    stack_feature[j]=root_embeding\n",
    "                else:\n",
    "                    stack_feature[j]=empty_embedding\n",
    "            buffer_feature=self.get_buffer_context(buffers[i],len(phrase))\n",
    "            for j,el in enumerate(buffer_feature):\n",
    "                if(el>=1):\n",
    "                    buffer_feature[j]=embeddings[0][el]\n",
    "                else:\n",
    "                    buffer_feature[j]=empty_embedding\n",
    "\n",
    "            embedded_features.append(self.flatten_embedded_features(stack_feature+buffer_feature).to(torch.float16))#.to(torch.float16)\n",
    "\n",
    "        expanded_moves=[]\n",
    "        for move in moves:\n",
    "            if(move==0): expanded_moves.append(torch.tensor([1,0,0]).to(torch.float16))\n",
    "            if(move==1): expanded_moves.append(torch.tensor([0,1,0]).to(torch.float16))\n",
    "            if(move==2): expanded_moves.append(torch.tensor([0,0,1]).to(torch.float16))\n",
    "\n",
    "        return embedded_features,expanded_moves\n",
    "    \n",
    "    def create_batches(self,batch_size,dataset):\n",
    "\n",
    "        #prende il dataset e per ogni frase genera il batch corrispettivo, genererà n=batch-size file    \n",
    "        batch_feature=[]\n",
    "        batch_moves=[]\n",
    "\n",
    "        index_batch=0\n",
    "        for i,sent in enumerate(dataset):     \n",
    "            if(i<1000):\n",
    "                heads=[-1]\n",
    "                words=[]\n",
    "                lemmas=[]\n",
    "\n",
    "                wrong_sent=0\n",
    "                for token in sent:\n",
    "                    if(token.head is None): wrong_sent=1\n",
    "                    if(token.form is None): wrong_sent=1\n",
    "                    if(token.lemma is None): wrong_sent=1\n",
    "\n",
    "                    heads.append(int(token.head))\n",
    "                    words.append(token.form)\n",
    "                    lemmas.append(token.lemma)\n",
    "                \n",
    "                if(wrong_sent==0):\n",
    "                    sent_features,sent_moves = self.encode_moves(heads,words,lemmas)\n",
    "                    sent_features=torch.stack(sent_features,dim=0)\n",
    "                    sent_moves=torch.stack(sent_moves)\n",
    "                    batch_feature.append(sent_features)\n",
    "                    batch_moves.append(sent_moves)\n",
    "                \n",
    "\n",
    "                if(len(batch_moves)==batch_size): \n",
    "                    #print(sent_moves)\n",
    "                    #print(index_batch)\n",
    "                    packed_features=pack_sequence(batch_feature,enforce_sorted=False)\n",
    "                    packed_moves=pack_sequence(batch_moves,enforce_sorted=False)\n",
    "\n",
    "\n",
    "                    torch.save((packed_features,packed_moves), f\"data/batches/tensor{index_batch}.pt\")\n",
    "                    index_batch+=1\n",
    "                    batch_feature=[]\n",
    "                    batch_moves=[]\n",
    "\n",
    "\n",
    "#DA FARE:\n",
    "#1. Salvare batch da 50-100 frasi su file dati, ossia per ogni frase gli stati con relativi stack,buffer e move. \n",
    "#2. Importare batch per batch come nell'esempio di chat gpt.\n",
    "#3. Per ogni batch fare forward e back-prop di adam optimizer come nell'esempio di chat_gpt.\n",
    "\n",
    "\n",
    "parser = Parser()  \n",
    "phrase = \"book me the morning flight\".split()\n",
    "phrase2 = \"Book the flight Houston\".split()\n",
    "heads=[-1,0,1,5,5,1]\n",
    "heads2=[-1,0,3,1,3]\n",
    "stack=[0]\n",
    "parser= Parser()\n",
    "sstack,buffer,moves= parser.simulate_parse(heads,phrase)\n",
    "sstack2,buffer2,moves2= parser.simulate_parse(heads2,phrase2)\n",
    "\n",
    "\n",
    "#p1,m1=parser.encode_moves(heads,phrase,phrase)\n",
    "#p2,m2=parser.encode_moves(heads2,phrase2,phrase2)\n",
    "#print(m2)\n",
    "#torch.set_printoptions(profile=\"full\")\n",
    "#p1 = torch.stack(p1, dim=0)\n",
    "#p2 = torch.stack(p2, dim=0)\n",
    "#print(p1)\n",
    "#print(p2)\n",
    "#input=pack_sequence([p1, p2])\n",
    "\n",
    "#input_size = 3840  # Each element in the sequence is a vector of size 2\n",
    "#hidden_size = 64\n",
    "#num_layers = 1\n",
    "#output_size = 3  # Example output size\n",
    "#model = torch.nn.LSTM(input_size,hidden_size,num_layers,batch_first=True,bidirectional=False,proj_size=output_size)\n",
    "#model.half()\n",
    "#\n",
    "#output = model(input)\n",
    "#print(output)\n",
    "#print(\"OUTPUT\")\n",
    "#print(unpack_sequence(output[0]))\n",
    "\n",
    "\n",
    "oracle=Oracle()\n",
    "#parser.create_batches(100,train_prepocesed)\n",
    "oracle.train_on_batches()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
