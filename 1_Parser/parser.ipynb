{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libs.corpus import openConllu, check_projectivity\n",
    "import pyconll\n",
    "import pyconll.util\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pack_sequence, unpack_sequence\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pyconll.load_from_file('data/it_isdt-ud-train.conllu')\n",
    "train_prepocesed=[]\n",
    "for i,sent in enumerate(train):        \n",
    "    sentence_preprocesed=[]\n",
    "    for j,token in enumerate(sent):\n",
    "        if(token.head is not None):\n",
    "            sentence_preprocesed.append(token)\n",
    "    train_prepocesed.append(sentence_preprocesed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0:SHIFT 1:RIGHTARC 2:LEFTARC\n",
    "moves = [0, 1, 2]\n",
    "\n",
    "\n",
    "#creiamo un oggetto Dependencies per salvare le dependencies\n",
    "class Dependencies(object):\n",
    "    def __init__(self,n):\n",
    "        self.n = n\n",
    "        self.heads = [None] * (n+1)\n",
    "        self.arcs = []\n",
    "    \n",
    "    def get_heads(self):\n",
    "        return self.heads\n",
    "    \n",
    "    def add_arc(self, head, child):\n",
    "        child=child\n",
    "        self.heads[child]=head\n",
    "        self.arcs.append((head,child))\n",
    "\n",
    "    def contains(self,head,child):\n",
    "        child=child\n",
    "        if self.heads[child]==head:\n",
    "            return True\n",
    "        else: return False\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "class Oracle(object):\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        #BERT encoder\n",
    "        encoder_name = \"dbmdz/bert-base-italian-xxl-cased\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(encoder_name)\n",
    "        self.encoder = AutoModel.from_pretrained(encoder_name)\n",
    "\n",
    "        #LSTM oracle\n",
    "        input_size = 3840  \n",
    "        hidden_size = 64\n",
    "        num_layers = 1\n",
    "        output_size = 3  \n",
    "        self.model = torch.nn.LSTM(input_size,hidden_size,num_layers,batch_first=True,bidirectional=False,proj_size=output_size)\n",
    "        self.model.half()\n",
    "\n",
    "        #Oracle critenion and optimazation\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "    \n",
    "    def tokens(self,words,lemmas):\n",
    "        words_token=[102]\n",
    "        for i in range(0,len(lemmas)):\n",
    "            word_token=self.tokenizer.convert_tokens_to_ids(words[i])\n",
    "            lemma_token=self.tokenizer.convert_tokens_to_ids(lemmas[i])\n",
    "            if(word_token!=101):\n",
    "                words_token.append(word_token)\n",
    "            else:\n",
    "                words_token.append(lemma_token)\n",
    "        words_token.append(103)\n",
    "        return words_token\n",
    "    \n",
    "    def encode(self,words,lemmas):\n",
    "        words_token=self.tokens(words,lemmas)\n",
    "        #max_length = 64  # Example max length ????\n",
    "        padded_input_ids = words_token\n",
    "        input_tensor = torch.tensor([padded_input_ids])\n",
    "        with torch.no_grad():\n",
    "            outputs = self.encoder(input_tensor)\n",
    "        return outputs.last_hidden_state\n",
    "    \n",
    "    #prende i batches dalla cartella, e allena il modello\n",
    "    def train_on_batches(self):\n",
    "        files = os.listdir(\"data/batches\")\n",
    "        for i in range(0,len(files)):\n",
    "            if(i==0):\n",
    "                \n",
    "                print(\"Loadind \"+str(i))\n",
    "                batch_features,batch_moves=torch.load(f\"data/batches/{files[i]}\") \n",
    "                print(\"Batch features sizes\")\n",
    "                predicted_output, _ = self.model(batch_features)\n",
    "                predicted_output= unpack_sequence(predicted_output)\n",
    "                for el in predicted_output:\n",
    "                    print(\"prima \"+str(el))\n",
    "                    el = torch.nn.Softmax(dim=1)(el)  \n",
    "                    print(\"dopo \"+str(el))\n",
    "                print(\"Predicted output sizes\")\n",
    "                predicted_output = torch.nn.utils.rnn.pad_sequence(predicted_output, batch_first=True)\n",
    "                print(predicted_output.size())\n",
    "\n",
    "                print(\"Batch moves size\")\n",
    "                batch_moves, _ = torch.nn.utils.rnn.pad_packed_sequence(batch_moves, batch_first=True)\n",
    "                print(batch_moves.size())\n",
    "\n",
    "                loss = self.criterion(predicted_output, batch_moves)\n",
    "\n",
    "                #backprop\n",
    "                print(\"Start Back-prop\")\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                print(\"End back-prop\")\n",
    "                print(predicted_output)\n",
    "\n",
    "    \n",
    "    def score(self,features):\n",
    "        packed_features=pack_sequence([features],enforce_sorted=False)\n",
    "        predicted_output,_ = self.model(packed_features)\n",
    "        print(\"score features \"+str(packed_features))\n",
    "        print(\"predicted output \"+str(unpack_sequence(predicted_output)))\n",
    "\n",
    "        return predicted_output\n",
    "    #prende gli ultimi tre elementi dello stack\n",
    "    def get_stack_context(self,list):\n",
    "        depth=len(list)\n",
    "\n",
    "        if depth >= 3:\n",
    "            return [list[-1], list[-2], list[-3]]\n",
    "        \n",
    "        elif depth >= 2:\n",
    "\n",
    "            return [list[-1], list[-2], -1]\n",
    "        \n",
    "        elif depth == 1:\n",
    "            return [list[-1], -1 , -1]\n",
    "        else:\n",
    "            return [-1, -1, -1]\n",
    "\n",
    "    #prende gli ultimi due elementi dell buffer\n",
    "    def get_buffer_context(self,index,len_phrase):\n",
    "        if(index==len_phrase):\n",
    "            return [index,-1]\n",
    "        elif(index>len_phrase):\n",
    "            return [-1,-1]\n",
    "        else: return [index,index+1]  \n",
    "\n",
    "    def flatten_embedded_features(self,matrix):\n",
    "        flat_list = torch.tensor([])\n",
    "        for row in matrix:\n",
    "            flat_list=torch.cat((flat_list,row))\n",
    "        return flat_list\n",
    "\n",
    "    def extract_features(self,phrase,phrases_lemma,stacks,buffers):\n",
    "        embeddings = self.encode(phrase,phrases_lemma)\n",
    "        root_embeding=torch.tensor(np.ones(768))\n",
    "        empty_embedding=torch.tensor(np.zeros(768))\n",
    "        embedded_features=[]\n",
    "        for i in range(0,len(stacks)):\n",
    "            stack_feature=self.get_stack_context(stacks[i])\n",
    "            for j,el in enumerate(stack_feature):\n",
    "                if(el>=1):\n",
    "                    stack_feature[j]=embeddings[0][el]\n",
    "                elif(el==0):\n",
    "                    stack_feature[j]=root_embeding\n",
    "                else:\n",
    "                    stack_feature[j]=empty_embedding\n",
    "            buffer_feature=self.get_buffer_context(buffers[i],len(phrase))\n",
    "            for j,el in enumerate(buffer_feature):\n",
    "                if(el>=1):\n",
    "                    buffer_feature[j]=embeddings[0][el]\n",
    "                else:\n",
    "                    buffer_feature[j]=empty_embedding\n",
    "\n",
    "            embedded_features.append(self.flatten_embedded_features(stack_feature+buffer_feature).to(torch.float16))#.to(torch.float16)\n",
    "        return embedded_features\n",
    "\n",
    "\n",
    "\n",
    "class Parser(object):\n",
    "    def __init__(self,oracle):\n",
    "        self.oracle=oracle\n",
    "\n",
    "    #applica la mossa andando ad aggiornare lo stack e l'indice del buffer  \n",
    "    def transition(self,move, stack, i, dependencies):\n",
    "        match move:\n",
    "            case 0:\n",
    "                stack.append(i)\n",
    "                return stack,i+1,dependencies\n",
    "            case 1:\n",
    "                dependencies.add_arc(stack[-2], stack.pop())\n",
    "                return stack,i,dependencies\n",
    "            case 2:\n",
    "                dependencies.add_arc(stack[-1], stack[-2])\n",
    "                stack.pop(-2)\n",
    "                return stack,i,dependencies\n",
    "            case _:\n",
    "                raise \"Wrong Move\"\n",
    "\n",
    "    #ritorna le mosse possibili che si possono applicare        \n",
    "    def get_valid_moves(self,i, n, stack_depth):\n",
    "        moves = []\n",
    "        if i <= n:\n",
    "            moves.append(0)\n",
    "        if stack_depth >= 2:\n",
    "            moves.append(1)\n",
    "            moves.append(2)\n",
    "        return moves\n",
    "\n",
    "    def parsing(self,words,phrases_lemma):\n",
    "        n=len(words)\n",
    "        deps=Dependencies(n)\n",
    "        stack=[0]\n",
    "        i_buffer=1\n",
    "        moves=self.get_valid_moves(i_buffer,n,len(stack))\n",
    "        while moves:\n",
    "            features = self.oracle.extract_features(words,phrases_lemma,[stack],[i_buffer])\n",
    "            features=torch.stack(features)\n",
    "            scores = self.oracle.score(features)\n",
    "            print(\"features  \"+str(features))\n",
    "            print(\"features  dimensione \"+str(features.size()))\n",
    "            print(scores)\n",
    "            next_move = max(moves, key=lambda move: scores[move])\n",
    "            stack,i_buffer,deps = self.transition(next_move, stack, i_buffer, deps)\n",
    "            moves = self.get_valid_moves(i,n,len(stack))\n",
    "        return deps\n",
    "    \n",
    "    #sceglie la mossa migliore da eseguire nel simulate_parse\n",
    "    def check_best(self,heads,stack,buffer,deps,i):\n",
    "        move=-1\n",
    "        if(len(stack)>=2):\n",
    "            children_list=[]\n",
    "            for child,head in enumerate(heads):\n",
    "                if head == stack[-1]:\n",
    "                    children_list.append(child)\n",
    "            if(((heads[stack[-1]])==(stack[-2])) and all([deps.contains(stack[-1],child) for child in children_list])):\n",
    "                move=1\n",
    "            if(heads[stack[-2]]==stack[-1]):\n",
    "                move=2\n",
    "        if(i<=len(buffer) and move==-1):\n",
    "            move=0\n",
    "        elif(i>len(buffer) and move==-1):\n",
    "            move=None\n",
    "        return move\n",
    "    \n",
    "    #fa reverse engineering, dato lo stato finale ricostruisce lo stack, buffer e le mosse\n",
    "    def simulate_parse(self,heads,buffer):\n",
    "        deps=Dependencies(len(buffer))\n",
    "        stack=[0]\n",
    "        moves=[]\n",
    "        buffers=[]\n",
    "        stacks=[]\n",
    "        i=1\n",
    "        best_move=self.check_best(heads,stack,buffer,deps,i)\n",
    "        while best_move!=None:\n",
    "            buffers.append(i)\n",
    "            stacks.append(stack[:])\n",
    "            moves.append(best_move)\n",
    "            stack,i,deps=self.transition(best_move,stack,i,deps)\n",
    "            best_move=self.check_best(heads,stack,buffer,deps,i)\n",
    "        if(i>len(buffer)):\n",
    "            return stacks,buffers,moves\n",
    "        else: return None \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loadind 0\n",
      "Batch features sizes\n",
      "prima tensor([[-0.1899, -0.2262,  0.1254],\n",
      "        [-0.2349, -0.0619, -0.0275],\n",
      "        [-0.0296, -0.0618,  0.0053],\n",
      "        [ 0.1565, -0.3350,  0.0521]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2998, 0.2891, 0.4109],\n",
      "        [0.2925, 0.3477, 0.3599],\n",
      "        [0.3330, 0.3223, 0.3447],\n",
      "        [0.3979, 0.2435, 0.3586]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1422, -0.3765,  0.1070],\n",
      "        [ 0.0461,  0.0300, -0.0256],\n",
      "        [ 0.0962, -0.0557, -0.1694],\n",
      "        [-0.0392, -0.2137, -0.0226],\n",
      "        [ 0.0864, -0.2854,  0.4644],\n",
      "        [ 0.0186, -0.1711,  0.3250],\n",
      "        [-0.0444, -0.0676,  0.0260],\n",
      "        [ 0.2876, -0.2954,  0.1586],\n",
      "        [ 0.1676, -0.2306, -0.2898],\n",
      "        [ 0.3630, -0.2444,  0.1216]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3252, 0.2573, 0.4172],\n",
      "        [0.3430, 0.3376, 0.3193],\n",
      "        [0.3809, 0.3271, 0.2920],\n",
      "        [0.3501, 0.2939, 0.3560],\n",
      "        [0.3176, 0.2190, 0.4634],\n",
      "        [0.3140, 0.2598, 0.4265],\n",
      "        [0.3279, 0.3203, 0.3518],\n",
      "        [0.4104, 0.2290, 0.3606],\n",
      "        [0.4338, 0.2915, 0.2747],\n",
      "        [0.4292, 0.2338, 0.3372]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1899, -0.2262,  0.1254],\n",
      "        [-0.2349, -0.0619, -0.0275],\n",
      "        [-0.0296, -0.0618,  0.0053],\n",
      "        [ 0.1565, -0.3350,  0.0521]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2998, 0.2891, 0.4109],\n",
      "        [0.2925, 0.3477, 0.3599],\n",
      "        [0.3330, 0.3223, 0.3447],\n",
      "        [0.3979, 0.2435, 0.3586]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0327, -0.4084,  0.1261],\n",
      "        [ 0.0402,  0.0152,  0.0184],\n",
      "        [ 0.1678, -0.0529, -0.1050],\n",
      "        [ 0.2869, -0.1013,  0.1447],\n",
      "        [ 0.1337, -0.0142, -0.0923],\n",
      "        [-0.0416, -0.0841,  0.1936],\n",
      "        [ 0.1534, -0.0565,  0.0607],\n",
      "        [ 0.1421, -0.1440,  0.1776],\n",
      "        [ 0.3704, -0.0570, -0.0343],\n",
      "        [-0.0255, -0.0486,  0.1791],\n",
      "        [ 0.0058,  0.0094, -0.0300],\n",
      "        [ 0.0262, -0.1898,  0.2148],\n",
      "        [-0.0628, -0.1582, -0.0191],\n",
      "        [ 0.2091, -0.2087,  0.2822]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3647, 0.2346, 0.4006],\n",
      "        [0.3386, 0.3301, 0.3313],\n",
      "        [0.3901, 0.3127, 0.2969],\n",
      "        [0.3928, 0.2664, 0.3408],\n",
      "        [0.3760, 0.3242, 0.2998],\n",
      "        [0.3103, 0.2974, 0.3926],\n",
      "        [0.3674, 0.2979, 0.3350],\n",
      "        [0.3589, 0.2695, 0.3718],\n",
      "        [0.4312, 0.2812, 0.2876],\n",
      "        [0.3120, 0.3049, 0.3831],\n",
      "        [0.3369, 0.3381, 0.3250],\n",
      "        [0.3318, 0.2673, 0.4006],\n",
      "        [0.3386, 0.3079, 0.3538],\n",
      "        [0.3657, 0.2408, 0.3936]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-3.0713e-01, -1.0559e-01,  1.1176e-01],\n",
      "        [-1.5051e-01,  1.0437e-01, -9.5581e-02],\n",
      "        [-1.0016e-01,  1.1768e-01, -2.6416e-01],\n",
      "        [-2.5195e-01,  1.2610e-01, -1.7529e-01],\n",
      "        [-1.0307e-02,  9.0942e-02, -5.3192e-02],\n",
      "        [ 1.2341e-01, -2.0398e-01, -6.8848e-02],\n",
      "        [ 6.7932e-02,  4.0558e-02, -6.1401e-02],\n",
      "        [-4.2999e-02,  1.2744e-01,  8.3252e-02],\n",
      "        [-8.6914e-02,  2.3108e-01,  2.6413e-02],\n",
      "        [-6.4392e-02,  2.2217e-01,  7.2205e-02],\n",
      "        [ 4.0210e-01,  2.1704e-01,  2.6566e-02],\n",
      "        [ 7.4402e-02,  2.7985e-02,  2.9980e-01],\n",
      "        [-6.0211e-02, -1.4990e-01, -2.6929e-01],\n",
      "        [-4.1040e-01,  7.0801e-02, -1.1029e-01],\n",
      "        [-3.9209e-01,  8.3923e-02,  2.1875e-04],\n",
      "        [-4.0918e-01,  1.2085e-01, -7.5195e-02],\n",
      "        [-7.8796e-02, -7.3608e-02, -2.1399e-01],\n",
      "        [-3.7427e-01,  1.4197e-01, -2.4084e-01],\n",
      "        [-2.0703e-01, -1.6089e-01, -2.2522e-01],\n",
      "        [-3.5083e-01,  1.9409e-02, -1.1246e-02],\n",
      "        [ 9.6375e-02,  1.3977e-01, -5.0781e-01],\n",
      "        [ 9.8083e-02,  2.5024e-01, -6.8665e-02],\n",
      "        [ 6.6162e-02,  2.0035e-02, -3.4363e-02],\n",
      "        [ 8.5022e-02,  1.7151e-01, -5.9601e-02],\n",
      "        [ 1.0852e-01, -1.1896e-01, -1.4172e-01],\n",
      "        [ 1.5491e-01, -1.7688e-01,  7.3242e-02],\n",
      "        [-8.6426e-02, -1.5796e-01, -1.6083e-02],\n",
      "        [ 1.2671e-01, -1.4697e-01,  1.8127e-01],\n",
      "        [ 8.5020e-04, -2.4524e-01, -1.9019e-01],\n",
      "        [-1.4734e-01, -1.2006e-01, -8.3374e-02],\n",
      "        [-1.2061e-01, -5.3345e-02, -7.2327e-02],\n",
      "        [-1.8945e-01, -2.2168e-01, -9.1003e-02],\n",
      "        [-5.0385e-02, -1.0925e-01, -5.3619e-02],\n",
      "        [ 1.6174e-01, -6.9702e-02, -7.3547e-02],\n",
      "        [-1.7383e-01, -5.6305e-02, -1.9485e-02],\n",
      "        [ 1.3025e-01, -1.7859e-01, -2.7686e-01],\n",
      "        [ 7.6721e-02, -3.6743e-02, -2.9199e-01],\n",
      "        [-8.1177e-02, -1.5039e-01, -1.7297e-01],\n",
      "        [-3.7109e-01,  1.4526e-01,  6.1371e-02],\n",
      "        [-1.3013e-01, -6.2500e-02, -9.9426e-02],\n",
      "        [-9.3567e-02, -1.1833e-02, -3.1342e-02],\n",
      "        [-1.1157e-01, -7.7820e-02,  1.0948e-02],\n",
      "        [ 1.2903e-01,  1.2915e-01, -1.3220e-01],\n",
      "        [ 2.4090e-03,  1.4661e-01, -7.1960e-02],\n",
      "        [-2.8214e-02,  9.5459e-02, -5.0934e-02],\n",
      "        [-8.3923e-02,  2.0190e-01, -1.6187e-01],\n",
      "        [ 2.1774e-02,  2.0984e-01, -1.2378e-01],\n",
      "        [ 2.9953e-02, -2.0764e-01, -2.7103e-03],\n",
      "        [ 8.3252e-02, -6.6833e-02, -2.7905e-01],\n",
      "        [-1.5266e-02, -2.0435e-01, -2.6535e-02],\n",
      "        [-3.5425e-01, -5.1910e-02, -2.0898e-01],\n",
      "        [-1.0895e-01,  7.5806e-02, -1.8359e-01],\n",
      "        [-1.5900e-02,  4.2969e-02, -2.8442e-01],\n",
      "        [ 1.6602e-01, -1.0455e-01,  6.1432e-02],\n",
      "        [ 1.9299e-01, -2.4280e-01, -4.4482e-01],\n",
      "        [ 2.1875e-01, -2.0410e-01,  1.0199e-01]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2671, 0.3267, 0.4060],\n",
      "        [0.2988, 0.3855, 0.3157],\n",
      "        [0.3235, 0.4021, 0.2744],\n",
      "        [0.2825, 0.4124, 0.3052],\n",
      "        [0.3264, 0.3611, 0.3125],\n",
      "        [0.3928, 0.2832, 0.3240],\n",
      "        [0.3506, 0.3413, 0.3081],\n",
      "        [0.3013, 0.3572, 0.3418],\n",
      "        [0.2861, 0.3933, 0.3206],\n",
      "        [0.2876, 0.3828, 0.3296],\n",
      "        [0.3972, 0.3301, 0.2727],\n",
      "        [0.3118, 0.2976, 0.3906],\n",
      "        [0.3669, 0.3354, 0.2976],\n",
      "        [0.2520, 0.4077, 0.3403],\n",
      "        [0.2445, 0.3936, 0.3621],\n",
      "        [0.2441, 0.4148, 0.3411],\n",
      "        [0.3474, 0.3491, 0.3035],\n",
      "        [0.2620, 0.4390, 0.2993],\n",
      "        [0.3301, 0.3457, 0.3242],\n",
      "        [0.2595, 0.3760, 0.3645],\n",
      "        [0.3860, 0.4031, 0.2109],\n",
      "        [0.3320, 0.3867, 0.2812],\n",
      "        [0.3499, 0.3340, 0.3164],\n",
      "        [0.3384, 0.3689, 0.2927],\n",
      "        [0.3884, 0.3093, 0.3022],\n",
      "        [0.3789, 0.2720, 0.3491],\n",
      "        [0.3330, 0.3098, 0.3572],\n",
      "        [0.3550, 0.2700, 0.3750],\n",
      "        [0.3835, 0.2998, 0.3167],\n",
      "        [0.3232, 0.3323, 0.3445],\n",
      "        [0.3206, 0.3430, 0.3364],\n",
      "        [0.3254, 0.3152, 0.3591],\n",
      "        [0.3401, 0.3208, 0.3391],\n",
      "        [0.3870, 0.3071, 0.3059],\n",
      "        [0.3037, 0.3418, 0.3545],\n",
      "        [0.4167, 0.3059, 0.2773],\n",
      "        [0.3870, 0.3455, 0.2676],\n",
      "        [0.3516, 0.3279, 0.3206],\n",
      "        [0.2372, 0.3975, 0.3655],\n",
      "        [0.3225, 0.3450, 0.3325],\n",
      "        [0.3176, 0.3445, 0.3379],\n",
      "        [0.3159, 0.3269, 0.3572],\n",
      "        [0.3611, 0.3611, 0.2781],\n",
      "        [0.3242, 0.3745, 0.3010],\n",
      "        [0.3215, 0.3640, 0.3145],\n",
      "        [0.3071, 0.4087, 0.2842],\n",
      "        [0.3257, 0.3931, 0.2815],\n",
      "        [0.3628, 0.2861, 0.3511],\n",
      "        [0.3911, 0.3367, 0.2722],\n",
      "        [0.3550, 0.2939, 0.3511],\n",
      "        [0.2849, 0.3855, 0.3296],\n",
      "        [0.3193, 0.3843, 0.2964],\n",
      "        [0.3540, 0.3755, 0.2705],\n",
      "        [0.3755, 0.2864, 0.3381],\n",
      "        [0.4597, 0.2974, 0.2429],\n",
      "        [0.3928, 0.2573, 0.3496]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1859, -0.0770, -0.0077],\n",
      "        [-0.0682,  0.0250, -0.0090],\n",
      "        [ 0.0087, -0.0783, -0.0097],\n",
      "        [ 0.0187, -0.3030, -0.1576],\n",
      "        [ 0.1259, -0.3770, -0.2581],\n",
      "        [ 0.0293, -0.2421, -0.2225],\n",
      "        [-0.0998,  0.3357, -0.2174],\n",
      "        [-0.1107,  0.0307, -0.2318],\n",
      "        [-0.1013, -0.1432, -0.2522],\n",
      "        [-0.3540, -0.0382, -0.1512],\n",
      "        [-0.0407, -0.0158, -0.2399],\n",
      "        [-0.1825, -0.1234, -0.1455],\n",
      "        [ 0.1699,  0.0543, -0.0808],\n",
      "        [-0.0538,  0.0808,  0.0766],\n",
      "        [ 0.2610,  0.0213, -0.2361],\n",
      "        [ 0.3474, -0.0445, -0.2886],\n",
      "        [ 0.3152,  0.0665, -0.4670],\n",
      "        [ 0.2251,  0.1056, -0.0740],\n",
      "        [ 0.6079, -0.0151, -0.2529],\n",
      "        [ 0.0589,  0.0046, -0.2003],\n",
      "        [ 0.4963,  0.0184, -0.0584],\n",
      "        [ 0.0788,  0.0906,  0.0214],\n",
      "        [ 0.0175,  0.3003, -0.3162],\n",
      "        [ 0.2155, -0.0141, -0.1643],\n",
      "        [ 0.3064,  0.1549, -0.2751],\n",
      "        [ 0.3601,  0.1511, -0.0399],\n",
      "        [ 0.5171,  0.1981, -0.2327],\n",
      "        [ 0.2710, -0.0438, -0.1965],\n",
      "        [ 0.1696, -0.0297, -0.2939],\n",
      "        [ 0.3567, -0.0793,  0.0903],\n",
      "        [ 0.0204,  0.0284, -0.4070],\n",
      "        [ 0.1559,  0.0112, -0.2094],\n",
      "        [-0.1544, -0.1187, -0.1431],\n",
      "        [ 0.0182, -0.0563, -0.0150],\n",
      "        [ 0.0603, -0.0354, -0.1576],\n",
      "        [ 0.0919, -0.2294,  0.0869],\n",
      "        [ 0.0426, -0.2817,  0.1282],\n",
      "        [ 0.0349, -0.3643, -0.0174],\n",
      "        [-0.0859, -0.3765, -0.0093],\n",
      "        [ 0.2096, -0.5449,  0.2351],\n",
      "        [ 0.0554, -0.4805,  0.0326],\n",
      "        [ 0.2175, -0.4526,  0.2048],\n",
      "        [ 0.1776, -0.3196,  0.0387],\n",
      "        [ 0.2388, -0.3679, -0.0109],\n",
      "        [ 0.4043, -0.3696, -0.0917],\n",
      "        [ 0.4126, -0.3003,  0.1694],\n",
      "        [ 0.2759, -0.1120,  0.1909],\n",
      "        [ 0.2944, -0.3130,  0.2247],\n",
      "        [ 0.4099, -0.2961,  0.2101],\n",
      "        [ 0.3467, -0.1448,  0.4795],\n",
      "        [ 0.1980, -0.3176,  0.1526],\n",
      "        [ 0.2612, -0.3237,  0.1797],\n",
      "        [ 0.4563, -0.2069, -0.2028],\n",
      "        [ 0.2581, -0.2856, -0.0583],\n",
      "        [ 0.5459, -0.2864, -0.1998],\n",
      "        [ 0.1891, -0.1405, -0.2406],\n",
      "        [ 0.1230, -0.0284, -0.2284],\n",
      "        [ 0.0402, -0.0204, -0.1202],\n",
      "        [ 0.2162, -0.3491,  0.0698],\n",
      "        [ 0.1842, -0.2377,  0.2996],\n",
      "        [ 0.1582,  0.1160,  0.1287],\n",
      "        [ 0.1282,  0.0160, -0.1653],\n",
      "        [-0.0184,  0.0866, -0.1373],\n",
      "        [ 0.3162,  0.1509, -0.4082],\n",
      "        [ 0.1611, -0.1183,  0.0182],\n",
      "        [ 0.2484, -0.3081,  0.0542],\n",
      "        [ 0.3489, -0.2791, -0.2288],\n",
      "        [ 0.0424, -0.1013, -0.1052],\n",
      "        [ 0.0890, -0.3555, -0.0146],\n",
      "        [ 0.2064, -0.4519,  0.0263],\n",
      "        [ 0.1393, -0.4824, -0.0433],\n",
      "        [ 0.1482, -0.5493, -0.0407],\n",
      "        [ 0.0615, -0.5005, -0.0916],\n",
      "        [ 0.1192, -0.4519,  0.0240]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3020, 0.3369, 0.3611],\n",
      "        [0.3167, 0.3474, 0.3359],\n",
      "        [0.3450, 0.3162, 0.3386],\n",
      "        [0.3901, 0.2827, 0.3271],\n",
      "        [0.4375, 0.2646, 0.2981],\n",
      "        [0.3938, 0.3000, 0.3062],\n",
      "        [0.2913, 0.4500, 0.2588],\n",
      "        [0.3291, 0.3792, 0.2917],\n",
      "        [0.3547, 0.3401, 0.3052],\n",
      "        [0.2781, 0.3813, 0.3406],\n",
      "        [0.3516, 0.3604, 0.2881],\n",
      "        [0.3228, 0.3423, 0.3350],\n",
      "        [0.3748, 0.3337, 0.2915],\n",
      "        [0.3047, 0.3484, 0.3469],\n",
      "        [0.4175, 0.3286, 0.2539],\n",
      "        [0.4534, 0.3064, 0.2401],\n",
      "        [0.4470, 0.3486, 0.2045],\n",
      "        [0.3804, 0.3376, 0.2820],\n",
      "        [0.5103, 0.2737, 0.2158],\n",
      "        [0.3679, 0.3484, 0.2839],\n",
      "        [0.4558, 0.2825, 0.2617],\n",
      "        [0.3384, 0.3423, 0.3193],\n",
      "        [0.3286, 0.4360, 0.2354],\n",
      "        [0.4033, 0.3206, 0.2759],\n",
      "        [0.4136, 0.3555, 0.2312],\n",
      "        [0.4028, 0.3269, 0.2700],\n",
      "        [0.4546, 0.3306, 0.2148],\n",
      "        [0.4243, 0.3098, 0.2659],\n",
      "        [0.4084, 0.3347, 0.2568],\n",
      "        [0.4146, 0.2681, 0.3176],\n",
      "        [0.3760, 0.3789, 0.2451],\n",
      "        [0.3906, 0.3381, 0.2712],\n",
      "        [0.3281, 0.3401, 0.3318],\n",
      "        [0.3455, 0.3206, 0.3340],\n",
      "        [0.3687, 0.3350, 0.2964],\n",
      "        [0.3677, 0.2666, 0.3657],\n",
      "        [0.3555, 0.2571, 0.3875],\n",
      "        [0.3816, 0.2561, 0.3623],\n",
      "        [0.3538, 0.2644, 0.3818],\n",
      "        [0.4006, 0.1884, 0.4109],\n",
      "        [0.3901, 0.2284, 0.3813],\n",
      "        [0.4001, 0.2047, 0.3950],\n",
      "        [0.4036, 0.2454, 0.3511],\n",
      "        [0.4302, 0.2345, 0.3352],\n",
      "        [0.4832, 0.2228, 0.2942],\n",
      "        [0.4397, 0.2156, 0.3447],\n",
      "        [0.3850, 0.2612, 0.3538],\n",
      "        [0.4036, 0.2198, 0.3765],\n",
      "        [0.4324, 0.2135, 0.3540],\n",
      "        [0.3630, 0.2222, 0.4148],\n",
      "        [0.3918, 0.2339, 0.3743],\n",
      "        [0.4033, 0.2247, 0.3718],\n",
      "        [0.4919, 0.2534, 0.2546],\n",
      "        [0.4331, 0.2515, 0.3157],\n",
      "        [0.5239, 0.2279, 0.2484],\n",
      "        [0.4219, 0.3035, 0.2747],\n",
      "        [0.3901, 0.3352, 0.2744],\n",
      "        [0.3582, 0.3369, 0.3049],\n",
      "        [0.4111, 0.2336, 0.3552],\n",
      "        [0.3599, 0.2361, 0.4041],\n",
      "        [0.3413, 0.3271, 0.3313],\n",
      "        [0.3789, 0.3386, 0.2825],\n",
      "        [0.3335, 0.3704, 0.2961],\n",
      "        [0.4287, 0.3635, 0.2078],\n",
      "        [0.3813, 0.2883, 0.3306],\n",
      "        [0.4172, 0.2391, 0.3435],\n",
      "        [0.4773, 0.2546, 0.2678],\n",
      "        [0.3665, 0.3174, 0.3162],\n",
      "        [0.3933, 0.2522, 0.3545],\n",
      "        [0.4250, 0.2201, 0.3550],\n",
      "        [0.4219, 0.2266, 0.3516],\n",
      "        [0.4299, 0.2141, 0.3560],\n",
      "        [0.4119, 0.2347, 0.3533],\n",
      "        [0.4043, 0.2283, 0.3674]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.2076, -0.1627,  0.1469],\n",
      "        [ 0.1023, -0.1137,  0.0385],\n",
      "        [ 0.0710, -0.1831, -0.1300],\n",
      "        [ 0.0075, -0.2051,  0.4194],\n",
      "        [-0.0506, -0.0145,  0.0596],\n",
      "        [-0.0687,  0.2292,  0.2019],\n",
      "        [ 0.0705,  0.0042,  0.0509],\n",
      "        [-0.0643, -0.0670,  0.3264],\n",
      "        [-0.0386,  0.0807,  0.1456],\n",
      "        [-0.1123, -0.0578,  0.2393],\n",
      "        [-0.0804,  0.0472,  0.1113],\n",
      "        [-0.1301,  0.0605,  0.1400],\n",
      "        [ 0.1351,  0.0287, -0.0844],\n",
      "        [ 0.2257, -0.0146,  0.1554],\n",
      "        [-0.0225,  0.1619, -0.3943],\n",
      "        [-0.0081,  0.0012, -0.0049],\n",
      "        [ 0.0688, -0.1766, -0.4414],\n",
      "        [ 0.0942, -0.0510, -0.0428]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2881, 0.3013, 0.4106],\n",
      "        [0.3645, 0.2937, 0.3418],\n",
      "        [0.3855, 0.2991, 0.3154],\n",
      "        [0.3013, 0.2437, 0.4551],\n",
      "        [0.3171, 0.3289, 0.3540],\n",
      "        [0.2734, 0.3682, 0.3584],\n",
      "        [0.3428, 0.3208, 0.3362],\n",
      "        [0.2878, 0.2869, 0.4253],\n",
      "        [0.3003, 0.3384, 0.3611],\n",
      "        [0.2876, 0.3037, 0.4087],\n",
      "        [0.2988, 0.3394, 0.3618],\n",
      "        [0.2842, 0.3438, 0.3721],\n",
      "        [0.3701, 0.3328, 0.2971],\n",
      "        [0.3679, 0.2893, 0.3428],\n",
      "        [0.3457, 0.4158, 0.2384],\n",
      "        [0.3320, 0.3350, 0.3330],\n",
      "        [0.4197, 0.3284, 0.2520],\n",
      "        [0.3655, 0.3159, 0.3186]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1733, -0.1713,  0.1078],\n",
      "        [ 0.0434,  0.0529, -0.1368],\n",
      "        [ 0.1238,  0.0835, -0.0386],\n",
      "        [ 0.0299,  0.1910, -0.0974],\n",
      "        [ 0.0864,  0.2209, -0.3372],\n",
      "        [-0.1504,  0.1152,  0.2039],\n",
      "        [ 0.0266, -0.0580,  0.0129],\n",
      "        [ 0.1215,  0.0774, -0.0374],\n",
      "        [ 0.1829,  0.0233, -0.0887],\n",
      "        [ 0.1384,  0.0101, -0.0832],\n",
      "        [ 0.1582,  0.0949, -0.1045],\n",
      "        [ 0.1172,  0.1349, -0.0085],\n",
      "        [ 0.2496, -0.2050, -0.1840],\n",
      "        [ 0.0177,  0.2859, -0.0599],\n",
      "        [-0.1294, -0.0128,  0.1019],\n",
      "        [-0.3325,  0.0795,  0.3203],\n",
      "        [-0.1251,  0.0259,  0.2476],\n",
      "        [-0.0374,  0.0365,  0.1901],\n",
      "        [-0.0116, -0.1393,  0.0597],\n",
      "        [-0.0459, -0.2397,  0.1625],\n",
      "        [-0.4629,  0.0847, -0.0142],\n",
      "        [-0.1041,  0.1162,  0.0803],\n",
      "        [-0.0466,  0.2433,  0.0148],\n",
      "        [-0.1031, -0.0732,  0.0589],\n",
      "        [ 0.0155, -0.2859, -0.1643],\n",
      "        [ 0.2384, -0.3271, -0.0353],\n",
      "        [ 0.0798, -0.0784, -0.3970],\n",
      "        [-0.0473, -0.0170, -0.1582],\n",
      "        [ 0.1143, -0.1710, -0.3315],\n",
      "        [ 0.0126,  0.0029, -0.3062],\n",
      "        [-0.1659,  0.1396, -0.1798],\n",
      "        [-0.1995, -0.0706,  0.0944],\n",
      "        [-0.0752, -0.2527, -0.0764],\n",
      "        [-0.0842, -0.2455,  0.1186],\n",
      "        [-0.0615, -0.1848, -0.0269],\n",
      "        [ 0.2505, -0.1334,  0.0919],\n",
      "        [ 0.1057,  0.1945, -0.1576],\n",
      "        [-0.1467,  0.2166,  0.1545],\n",
      "        [-0.0688, -0.0986,  0.0393],\n",
      "        [ 0.0364, -0.0471,  0.1633],\n",
      "        [-0.1986,  0.2783, -0.2130],\n",
      "        [-0.2520,  0.4058,  0.0528],\n",
      "        [-0.1166,  0.1511,  0.1650],\n",
      "        [-0.0352,  0.2235,  0.2026],\n",
      "        [ 0.0310,  0.1376,  0.1552],\n",
      "        [ 0.1152,  0.1039,  0.3257],\n",
      "        [ 0.1227,  0.1067,  0.2063],\n",
      "        [ 0.2179,  0.0182,  0.2262],\n",
      "        [ 0.3574,  0.0941, -0.1238],\n",
      "        [ 0.3694,  0.0608, -0.2751],\n",
      "        [ 0.0820,  0.1720, -0.2352],\n",
      "        [ 0.2313,  0.0349, -0.2563],\n",
      "        [ 0.1996, -0.0859, -0.1033],\n",
      "        [ 0.0847, -0.1285, -0.3318],\n",
      "        [ 0.2019, -0.1460, -0.3496],\n",
      "        [ 0.1447, -0.1805, -0.2241],\n",
      "        [-0.2031,  0.1342, -0.3889],\n",
      "        [ 0.0378, -0.0140, -0.0668],\n",
      "        [ 0.0341, -0.0172, -0.3323],\n",
      "        [-0.0561, -0.2729, -0.4333],\n",
      "        [ 0.0412, -0.1425, -0.4636],\n",
      "        [ 0.0137, -0.4211, -0.2737]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3005, 0.3013, 0.3982],\n",
      "        [0.3516, 0.3550, 0.2935],\n",
      "        [0.3557, 0.3418, 0.3025],\n",
      "        [0.3274, 0.3845, 0.2881],\n",
      "        [0.3574, 0.4087, 0.2339],\n",
      "        [0.2681, 0.3496, 0.3821],\n",
      "        [0.3442, 0.3162, 0.3396],\n",
      "        [0.3560, 0.3406, 0.3037],\n",
      "        [0.3826, 0.3262, 0.2915],\n",
      "        [0.3730, 0.3281, 0.2988],\n",
      "        [0.3694, 0.3467, 0.2839],\n",
      "        [0.3450, 0.3511, 0.3042],\n",
      "        [0.4380, 0.2781, 0.2839],\n",
      "        [0.3093, 0.4045, 0.2861],\n",
      "        [0.2954, 0.3320, 0.3723],\n",
      "        [0.2257, 0.3408, 0.4336],\n",
      "        [0.2766, 0.3218, 0.4016],\n",
      "        [0.3000, 0.3232, 0.3767],\n",
      "        [0.3386, 0.2979, 0.3635],\n",
      "        [0.3274, 0.2695, 0.4031],\n",
      "        [0.2328, 0.4026, 0.3647],\n",
      "        [0.2900, 0.3613, 0.3486],\n",
      "        [0.2942, 0.3931, 0.3127],\n",
      "        [0.3120, 0.3213, 0.3667],\n",
      "        [0.3884, 0.2874, 0.3245],\n",
      "        [0.4294, 0.2439, 0.3267],\n",
      "        [0.4041, 0.3450, 0.2510],\n",
      "        [0.3418, 0.3523, 0.3059],\n",
      "        [0.4180, 0.3142, 0.2676],\n",
      "        [0.3679, 0.3645, 0.2676],\n",
      "        [0.2991, 0.4060, 0.2949],\n",
      "        [0.2874, 0.3269, 0.3855],\n",
      "        [0.3525, 0.2952, 0.3521],\n",
      "        [0.3252, 0.2766, 0.3982],\n",
      "        [0.3425, 0.3027, 0.3545],\n",
      "        [0.3945, 0.2688, 0.3367],\n",
      "        [0.3496, 0.3818, 0.2686],\n",
      "        [0.2639, 0.3794, 0.3567],\n",
      "        [0.3242, 0.3147, 0.3611],\n",
      "        [0.3274, 0.3010, 0.3716],\n",
      "        [0.2781, 0.4480, 0.2739],\n",
      "        [0.2333, 0.4504, 0.3164],\n",
      "        [0.2754, 0.3599, 0.3650],\n",
      "        [0.2805, 0.3635, 0.3560],\n",
      "        [0.3081, 0.3428, 0.3489],\n",
      "        [0.3103, 0.3069, 0.3831],\n",
      "        [0.3257, 0.3203, 0.3540],\n",
      "        [0.3538, 0.2896, 0.3567],\n",
      "        [0.4189, 0.3220, 0.2590],\n",
      "        [0.4426, 0.3252, 0.2323],\n",
      "        [0.3542, 0.3877, 0.2581],\n",
      "        [0.4106, 0.3374, 0.2522],\n",
      "        [0.4016, 0.3018, 0.2966],\n",
      "        [0.4053, 0.3274, 0.2673],\n",
      "        [0.4382, 0.3093, 0.2524],\n",
      "        [0.4143, 0.2993, 0.2864],\n",
      "        [0.3093, 0.4336, 0.2571],\n",
      "        [0.3508, 0.3333, 0.3159],\n",
      "        [0.3784, 0.3594, 0.2622],\n",
      "        [0.4014, 0.3232, 0.2754],\n",
      "        [0.4106, 0.3416, 0.2478],\n",
      "        [0.4170, 0.2700, 0.3130]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1053, -0.3711,  0.2976],\n",
      "        [-0.0482,  0.1722,  0.1622],\n",
      "        [ 0.0419,  0.0635, -0.1744],\n",
      "        [ 0.2358, -0.0230, -0.0653],\n",
      "        [ 0.2164, -0.2854, -0.3594],\n",
      "        [-0.0062,  0.1175, -0.2371],\n",
      "        [-0.1061, -0.1805, -0.2849],\n",
      "        [-0.1996,  0.0568, -0.2150],\n",
      "        [-0.0743,  0.0569, -0.1240],\n",
      "        [-0.2786,  0.0759,  0.0565],\n",
      "        [-0.1379, -0.0021,  0.0179],\n",
      "        [-0.1570, -0.0267,  0.0233],\n",
      "        [-0.1158, -0.0839, -0.0780],\n",
      "        [-0.0784,  0.1102,  0.0310],\n",
      "        [-0.1162, -0.0468, -0.0450],\n",
      "        [ 0.1130, -0.1030,  0.0836],\n",
      "        [ 0.0659,  0.0673,  0.1230],\n",
      "        [ 0.1989, -0.1771,  0.1205],\n",
      "        [-0.0991, -0.0886,  0.0156],\n",
      "        [-0.1495,  0.1348, -0.0778],\n",
      "        [-0.0078, -0.3037, -0.1199],\n",
      "        [ 0.0539, -0.2135, -0.2537]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3064, 0.2350, 0.4585],\n",
      "        [0.2874, 0.3582, 0.3545],\n",
      "        [0.3538, 0.3613, 0.2849],\n",
      "        [0.3982, 0.3074, 0.2947],\n",
      "        [0.4614, 0.2793, 0.2593],\n",
      "        [0.3418, 0.3867, 0.2712],\n",
      "        [0.3618, 0.3357, 0.3025],\n",
      "        [0.3052, 0.3943, 0.3005],\n",
      "        [0.3235, 0.3689, 0.3079],\n",
      "        [0.2615, 0.3728, 0.3657],\n",
      "        [0.3018, 0.3457, 0.3525],\n",
      "        [0.2998, 0.3413, 0.3589],\n",
      "        [0.3257, 0.3362, 0.3381],\n",
      "        [0.3010, 0.3633, 0.3357],\n",
      "        [0.3179, 0.3408, 0.3413],\n",
      "        [0.3601, 0.2903, 0.3496],\n",
      "        [0.3267, 0.3271, 0.3459],\n",
      "        [0.3831, 0.2629, 0.3540],\n",
      "        [0.3193, 0.3228, 0.3582],\n",
      "        [0.2939, 0.3904, 0.3157],\n",
      "        [0.3792, 0.2820, 0.3389],\n",
      "        [0.3999, 0.3062, 0.2939]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0717, -0.2169,  0.3057],\n",
      "        [ 0.0022,  0.1187, -0.0511],\n",
      "        [ 0.2656, -0.0462,  0.0659],\n",
      "        [ 0.2708, -0.1910,  0.2964],\n",
      "        [ 0.2588, -0.2056,  0.2106],\n",
      "        [ 0.2417, -0.1034,  0.1754],\n",
      "        [ 0.0793, -0.1841, -0.0520],\n",
      "        [ 0.2952, -0.0509, -0.1180],\n",
      "        [ 0.1642, -0.2111, -0.1968],\n",
      "        [-0.0055, -0.0163,  0.0615],\n",
      "        [ 0.0171, -0.1946, -0.0180],\n",
      "        [ 0.0287, -0.0159,  0.1649],\n",
      "        [ 0.0751, -0.0430, -0.1523],\n",
      "        [ 0.1044,  0.0936,  0.0059],\n",
      "        [ 0.0677, -0.2581, -0.2109],\n",
      "        [ 0.4270, -0.3513, -0.0600]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3010, 0.2603, 0.4390],\n",
      "        [0.3254, 0.3657, 0.3086],\n",
      "        [0.3921, 0.2871, 0.3210],\n",
      "        [0.3765, 0.2373, 0.3862],\n",
      "        [0.3875, 0.2435, 0.3691],\n",
      "        [0.3782, 0.2678, 0.3540],\n",
      "        [0.3779, 0.2905, 0.3315],\n",
      "        [0.4221, 0.2986, 0.2793],\n",
      "        [0.4194, 0.2881, 0.2922],\n",
      "        [0.3269, 0.3235, 0.3496],\n",
      "        [0.3604, 0.2917, 0.3479],\n",
      "        [0.3223, 0.3083, 0.3694],\n",
      "        [0.3723, 0.3308, 0.2966],\n",
      "        [0.3455, 0.3416, 0.3130],\n",
      "        [0.4033, 0.2913, 0.3054],\n",
      "        [0.4822, 0.2214, 0.2964]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1148, -0.1224,  0.2087],\n",
      "        [-0.0322, -0.0930,  0.0287],\n",
      "        [ 0.0593, -0.1504, -0.0437],\n",
      "        [ 0.0692, -0.1993, -0.0051],\n",
      "        [-0.0424, -0.0273, -0.1936],\n",
      "        [-0.0078, -0.0211,  0.1169],\n",
      "        [-0.0284, -0.1849,  0.0631],\n",
      "        [ 0.0851, -0.0769, -0.0436],\n",
      "        [ 0.0483, -0.0947,  0.0740],\n",
      "        [-0.0060,  0.0343, -0.0412],\n",
      "        [ 0.0671,  0.0969, -0.0994],\n",
      "        [-0.0461,  0.2460, -0.0145],\n",
      "        [ 0.1271,  0.1426, -0.2107],\n",
      "        [-0.1114,  0.1180, -0.0185],\n",
      "        [-0.0107,  0.1514, -0.2330],\n",
      "        [-0.1655,  0.1381, -0.1525],\n",
      "        [-0.1393,  0.0154, -0.0830],\n",
      "        [ 0.1158,  0.0695, -0.1796],\n",
      "        [ 0.0718,  0.1682, -0.1754],\n",
      "        [ 0.1281, -0.2321, -0.2532],\n",
      "        [ 0.0287, -0.4788, -0.0976],\n",
      "        [-0.0988, -0.3591,  0.0540],\n",
      "        [-0.1015, -0.1445, -0.1262],\n",
      "        [ 0.0355, -0.0923, -0.2791],\n",
      "        [ 0.1388, -0.1681, -0.2805],\n",
      "        [ 0.1969,  0.0874, -0.1456],\n",
      "        [ 0.1892, -0.0289, -0.1727],\n",
      "        [ 0.2888, -0.0934, -0.0717]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2964, 0.2942, 0.4097],\n",
      "        [0.3330, 0.3132, 0.3538],\n",
      "        [0.3687, 0.2988, 0.3325],\n",
      "        [0.3713, 0.2839, 0.3447],\n",
      "        [0.3479, 0.3530, 0.2991],\n",
      "        [0.3206, 0.3164, 0.3630],\n",
      "        [0.3389, 0.2898, 0.3713],\n",
      "        [0.3665, 0.3115, 0.3220],\n",
      "        [0.3457, 0.2996, 0.3547],\n",
      "        [0.3325, 0.3462, 0.3210],\n",
      "        [0.3477, 0.3582, 0.2942],\n",
      "        [0.2966, 0.3972, 0.3062],\n",
      "        [0.3665, 0.3721, 0.2615],\n",
      "        [0.2981, 0.3750, 0.3271],\n",
      "        [0.3359, 0.3950, 0.2690],\n",
      "        [0.2969, 0.4023, 0.3008],\n",
      "        [0.3101, 0.3618, 0.3281],\n",
      "        [0.3706, 0.3538, 0.2756],\n",
      "        [0.3469, 0.3821, 0.2710],\n",
      "        [0.4202, 0.2930, 0.2869],\n",
      "        [0.4026, 0.2424, 0.3550],\n",
      "        [0.3406, 0.2625, 0.3967],\n",
      "        [0.3408, 0.3264, 0.3325],\n",
      "        [0.3831, 0.3372, 0.2798],\n",
      "        [0.4177, 0.3074, 0.2747],\n",
      "        [0.3838, 0.3440, 0.2725],\n",
      "        [0.3999, 0.3215, 0.2786],\n",
      "        [0.4202, 0.2866, 0.2930]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1790, -0.2174,  0.0694],\n",
      "        [ 0.0880,  0.0032,  0.1810],\n",
      "        [-0.0402,  0.1426, -0.1519],\n",
      "        [ 0.1356,  0.0138, -0.0109],\n",
      "        [-0.0639, -0.1083, -0.4951],\n",
      "        [ 0.1552, -0.2415, -0.0919],\n",
      "        [-0.0487, -0.3130, -0.1838],\n",
      "        [-0.1328,  0.0154,  0.1748],\n",
      "        [ 0.0879,  0.0509,  0.0023],\n",
      "        [ 0.0710,  0.0102,  0.0446],\n",
      "        [ 0.0741,  0.1520,  0.2157],\n",
      "        [-0.0117,  0.1443,  0.2664],\n",
      "        [-0.0311,  0.0612,  0.1602],\n",
      "        [-0.1003,  0.1327,  0.2446],\n",
      "        [ 0.1899, -0.1165, -0.1306],\n",
      "        [ 0.0294, -0.1444,  0.0333],\n",
      "        [-0.0264, -0.3972, -0.2289],\n",
      "        [-0.0134, -0.0963,  0.0049]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3083, 0.2966, 0.3950],\n",
      "        [0.3315, 0.3047, 0.3638],\n",
      "        [0.3232, 0.3879, 0.2891],\n",
      "        [0.3638, 0.3220, 0.3142],\n",
      "        [0.3838, 0.3669, 0.2493],\n",
      "        [0.4075, 0.2742, 0.3184],\n",
      "        [0.3787, 0.2908, 0.3308],\n",
      "        [0.2842, 0.3296, 0.3865],\n",
      "        [0.3469, 0.3345, 0.3186],\n",
      "        [0.3430, 0.3228, 0.3340],\n",
      "        [0.3093, 0.3345, 0.3564],\n",
      "        [0.2866, 0.3350, 0.3784],\n",
      "        [0.3022, 0.3315, 0.3660],\n",
      "        [0.2722, 0.3435, 0.3843],\n",
      "        [0.4062, 0.2991, 0.2947],\n",
      "        [0.3516, 0.2954, 0.3530],\n",
      "        [0.3989, 0.2754, 0.3257],\n",
      "        [0.3403, 0.3132, 0.3464]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 4.2816e-02, -5.7312e-02,  2.2290e-01],\n",
      "        [ 1.1475e-01,  2.3636e-02, -1.6663e-01],\n",
      "        [ 2.4744e-01, -1.9287e-01, -3.5132e-01],\n",
      "        [ 1.5918e-01, -2.2754e-01,  2.2720e-02],\n",
      "        [ 9.9182e-02,  8.2214e-02, -1.0980e-01],\n",
      "        [ 1.2708e-01, -1.3586e-01,  3.2495e-01],\n",
      "        [ 4.0259e-01, -3.0762e-01, -5.7495e-02],\n",
      "        [ 5.1147e-02, -3.9014e-01,  3.2715e-01],\n",
      "        [ 1.9458e-01, -3.0811e-01,  2.9932e-01],\n",
      "        [-2.8610e-03, -4.6021e-01,  4.1260e-01],\n",
      "        [ 8.0627e-02, -1.9153e-01,  6.1133e-01],\n",
      "        [ 1.3428e-01, -1.4758e-01,  4.8315e-01],\n",
      "        [ 1.1664e-01, -2.6294e-01,  4.1431e-01],\n",
      "        [ 2.0544e-01, -1.0675e-01,  3.2446e-01],\n",
      "        [ 4.0985e-02, -1.5182e-02,  1.9836e-01],\n",
      "        [ 1.3757e-01, -1.5881e-01,  1.5771e-01],\n",
      "        [ 2.0898e-01, -1.7505e-01,  4.0710e-02],\n",
      "        [ 2.5436e-02, -5.4718e-02,  3.8916e-01],\n",
      "        [-2.7588e-02, -1.4722e-01,  1.3843e-01],\n",
      "        [ 2.6413e-02, -2.1683e-02,  4.1626e-01],\n",
      "        [ 2.4780e-01, -2.8320e-01,  1.2103e-01],\n",
      "        [-2.0740e-01, -7.0129e-02,  1.0999e-01],\n",
      "        [-9.3933e-02,  1.8005e-02,  4.8828e-01],\n",
      "        [-2.0581e-01, -1.1267e-01,  2.5073e-01],\n",
      "        [-1.3855e-01, -1.0431e-01,  9.4604e-02],\n",
      "        [-6.8115e-02, -1.2622e-01,  7.3242e-02],\n",
      "        [ 2.1094e-01, -1.3708e-01,  1.8323e-01],\n",
      "        [ 1.7993e-01, -1.9580e-01,  8.4900e-02],\n",
      "        [ 1.4014e-01, -2.1899e-01,  5.8655e-02],\n",
      "        [ 9.4238e-02, -5.1575e-02,  6.1798e-02],\n",
      "        [ 2.2192e-01, -1.2537e-01,  1.2703e-02],\n",
      "        [ 2.8906e-01, -4.0092e-03, -6.3477e-02],\n",
      "        [ 2.9614e-01,  2.4451e-01, -6.8481e-02],\n",
      "        [ 7.2168e-01, -8.3008e-03,  7.1777e-02],\n",
      "        [ 5.6055e-01, -4.3854e-02,  8.8318e-02],\n",
      "        [ 4.0430e-01, -3.9429e-02,  8.4717e-02],\n",
      "        [ 4.0186e-01, -1.0242e-01, -1.2830e-01],\n",
      "        [ 1.9788e-01, -1.2408e-01, -1.6064e-01],\n",
      "        [ 2.5342e-01, -2.3212e-03,  1.8420e-01],\n",
      "        [ 3.9478e-01, -6.6101e-02,  2.1204e-01],\n",
      "        [ 2.1399e-01, -5.3833e-02,  2.0520e-01],\n",
      "        [ 2.2168e-01, -2.5391e-01,  3.0411e-02],\n",
      "        [ 4.7095e-01, -5.3406e-02,  1.7065e-01],\n",
      "        [ 1.2323e-01,  9.5398e-02,  1.3892e-01],\n",
      "        [ 1.7859e-01,  8.5083e-02,  6.8665e-02],\n",
      "        [ 1.6357e-01, -1.5442e-01,  1.7456e-01],\n",
      "        [ 1.1841e-01,  1.2608e-03,  2.1948e-01],\n",
      "        [ 5.0903e-02, -3.6499e-02,  2.0325e-01],\n",
      "        [ 5.9479e-02, -5.0995e-02,  1.5527e-01],\n",
      "        [ 3.0273e-01, -5.4504e-02, -2.2339e-02],\n",
      "        [ 2.7686e-01,  1.5100e-01,  3.7354e-02],\n",
      "        [ 2.6514e-01,  1.7273e-01,  1.5459e-03],\n",
      "        [-1.3039e-02,  3.9990e-01, -1.3418e-03],\n",
      "        [ 5.7159e-02,  4.9365e-01, -1.6492e-01],\n",
      "        [ 6.8420e-02,  3.3716e-01, -6.3354e-02],\n",
      "        [ 9.0637e-02,  1.9836e-01,  4.5715e-02],\n",
      "        [ 1.4319e-01,  2.9224e-01,  1.2360e-01],\n",
      "        [ 1.2573e-01,  2.3181e-01,  2.6221e-01],\n",
      "        [ 1.7737e-01,  4.0649e-02,  8.6243e-02],\n",
      "        [ 1.7969e-01, -1.9089e-02,  2.1692e-01],\n",
      "        [ 4.2651e-01,  3.4576e-02,  6.0669e-02],\n",
      "        [-2.3828e-01, -1.4539e-01,  2.2107e-01],\n",
      "        [ 3.4375e-01, -9.3933e-02,  2.5244e-01],\n",
      "        [ 1.4087e-01, -3.3398e-01,  1.8262e-01],\n",
      "        [ 2.8052e-01, -1.6833e-01, -7.3242e-03],\n",
      "        [-1.6899e-03, -2.9224e-01,  5.5481e-02],\n",
      "        [-8.0200e-02, -9.9243e-02, -5.5725e-02],\n",
      "        [-1.5205e-02, -9.5581e-02,  1.2708e-01],\n",
      "        [-1.1017e-01, -3.1201e-01, -1.9150e-02],\n",
      "        [ 2.3193e-02, -1.1719e-01, -4.2053e-02],\n",
      "        [-6.9458e-02, -1.0919e-01,  5.8838e-02],\n",
      "        [ 1.5833e-01, -2.8809e-01,  1.6187e-01],\n",
      "        [-3.4698e-02, -1.0168e-01, -1.9055e-01],\n",
      "        [-1.4977e-02, -1.5434e-02, -1.0449e-01],\n",
      "        [-2.8223e-01,  1.1139e-01,  1.8909e-01],\n",
      "        [ 2.0462e-02, -1.9983e-01,  2.4341e-01],\n",
      "        [ 2.5040e-02, -6.9031e-02,  9.6619e-02],\n",
      "        [-3.2690e-01, -2.4036e-01,  1.1116e-02],\n",
      "        [-3.3984e-01, -7.4158e-02, -1.7512e-04],\n",
      "        [-3.3472e-01, -1.7566e-01,  7.9712e-02],\n",
      "        [-1.6882e-01, -7.3669e-02, -9.3811e-02],\n",
      "        [-8.2092e-02, -9.6191e-02,  6.3965e-02],\n",
      "        [-4.2328e-02, -1.8616e-01,  4.3976e-02],\n",
      "        [-3.2568e-01,  6.9824e-02,  1.0017e-02],\n",
      "        [ 4.9225e-02, -6.7978e-03, -7.4463e-02],\n",
      "        [ 1.8396e-01,  5.1453e-02,  5.3284e-02],\n",
      "        [ 1.0864e-01,  4.2419e-02,  4.0070e-02],\n",
      "        [-2.6794e-02, -7.6050e-02,  1.7310e-01],\n",
      "        [-1.6495e-02, -1.2006e-01,  5.4102e-01],\n",
      "        [-1.2512e-02, -2.2522e-01,  4.4995e-01],\n",
      "        [ 2.7490e-01, -3.6230e-01,  5.0195e-01],\n",
      "        [ 1.9922e-01, -2.2266e-01,  2.8149e-01],\n",
      "        [ 2.8369e-01, -2.1448e-01,  4.5508e-01],\n",
      "        [ 2.9858e-01, -1.2299e-01,  2.4915e-01],\n",
      "        [ 1.4917e-01,  8.6731e-02,  2.6587e-01],\n",
      "        [ 7.3608e-02, -9.0149e-02,  1.7419e-01],\n",
      "        [-1.7932e-01,  9.7107e-02,  2.6172e-01],\n",
      "        [ 1.1377e-01,  1.0095e-01, -8.4076e-03],\n",
      "        [ 2.1814e-01, -9.5825e-02, -2.3804e-01],\n",
      "        [ 2.5977e-01, -1.3684e-01,  7.0679e-02],\n",
      "        [ 2.2742e-01, -3.1525e-02, -1.9958e-01],\n",
      "        [-1.7017e-01, -2.6343e-01, -1.1360e-02],\n",
      "        [ 2.2217e-01, -1.9275e-01, -1.2415e-01],\n",
      "        [ 1.1285e-01, -3.9258e-01,  1.2683e-01],\n",
      "        [-1.8933e-01,  3.4302e-02,  6.9092e-02],\n",
      "        [-1.1688e-01,  1.9702e-01, -1.1322e-01],\n",
      "        [-3.8257e-01,  2.3315e-01, -4.6875e-02],\n",
      "        [-1.0736e-01, -6.2927e-02, -2.0642e-01],\n",
      "        [-1.6357e-02, -6.2103e-02, -5.4779e-02],\n",
      "        [ 3.6548e-01, -4.9866e-02,  5.4810e-02],\n",
      "        [ 2.2754e-01,  7.9407e-02,  3.5278e-02],\n",
      "        [ 2.0264e-01,  7.9102e-02, -5.2185e-02],\n",
      "        [ 1.8823e-01,  6.7663e-04, -1.5198e-01],\n",
      "        [ 1.1951e-01,  1.0828e-01, -1.0986e-01],\n",
      "        [ 5.4962e-02, -3.9307e-02,  1.5572e-02],\n",
      "        [ 9.1919e-02, -1.8237e-01, -1.4380e-01],\n",
      "        [ 1.9238e-01, -1.4368e-01, -2.1790e-01],\n",
      "        [-1.8784e-02, -2.2791e-01,  1.6394e-01],\n",
      "        [-1.0445e-02, -2.2070e-01, -1.6016e-01],\n",
      "        [-6.2805e-02, -1.2976e-01,  2.7563e-01]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3223, 0.2917, 0.3860],\n",
      "        [0.3748, 0.3423, 0.2830],\n",
      "        [0.4558, 0.2935, 0.2505],\n",
      "        [0.3918, 0.2661, 0.3418],\n",
      "        [0.3579, 0.3518, 0.2903],\n",
      "        [0.3347, 0.2573, 0.4080],\n",
      "        [0.4712, 0.2316, 0.2974],\n",
      "        [0.3376, 0.2172, 0.4451],\n",
      "        [0.3682, 0.2228, 0.4089],\n",
      "        [0.3176, 0.2010, 0.4812],\n",
      "        [0.2888, 0.2201, 0.4912],\n",
      "        [0.3152, 0.2378, 0.4468],\n",
      "        [0.3298, 0.2257, 0.4443],\n",
      "        [0.3499, 0.2561, 0.3940],\n",
      "        [0.3210, 0.3035, 0.3757],\n",
      "        [0.3618, 0.2690, 0.3691],\n",
      "        [0.3958, 0.2695, 0.3345],\n",
      "        [0.2974, 0.2747, 0.4280],\n",
      "        [0.3259, 0.2893, 0.3848],\n",
      "        [0.2915, 0.2778, 0.4307],\n",
      "        [0.4050, 0.2382, 0.3567],\n",
      "        [0.2839, 0.3259, 0.3901],\n",
      "        [0.2559, 0.2861, 0.4580],\n",
      "        [0.2720, 0.2986, 0.4294],\n",
      "        [0.3032, 0.3137, 0.3828],\n",
      "        [0.3230, 0.3049, 0.3721],\n",
      "        [0.3733, 0.2637, 0.3630],\n",
      "        [0.3853, 0.2646, 0.3503],\n",
      "        [0.3816, 0.2666, 0.3518],\n",
      "        [0.3530, 0.3052, 0.3418],\n",
      "        [0.3972, 0.2808, 0.3223],\n",
      "        [0.4084, 0.3047, 0.2871],\n",
      "        [0.3782, 0.3591, 0.2627],\n",
      "        [0.4990, 0.2405, 0.2605],\n",
      "        [0.4609, 0.2517, 0.2874],\n",
      "        [0.4224, 0.2710, 0.3069],\n",
      "        [0.4561, 0.2754, 0.2683],\n",
      "        [0.4126, 0.2991, 0.2883],\n",
      "        [0.3694, 0.2859, 0.3447],\n",
      "        [0.4060, 0.2561, 0.3381],\n",
      "        [0.3628, 0.2776, 0.3596],\n",
      "        [0.4087, 0.2539, 0.3374],\n",
      "        [0.4287, 0.2537, 0.3176],\n",
      "        [0.3347, 0.3254, 0.3398],\n",
      "        [0.3562, 0.3245, 0.3191],\n",
      "        [0.3652, 0.2656, 0.3691],\n",
      "        [0.3337, 0.2969, 0.3694],\n",
      "        [0.3245, 0.2974, 0.3779],\n",
      "        [0.3337, 0.2988, 0.3674],\n",
      "        [0.4128, 0.2888, 0.2983],\n",
      "        [0.3748, 0.3303, 0.2949],\n",
      "        [0.3730, 0.3401, 0.2866],\n",
      "        [0.2839, 0.4290, 0.2871],\n",
      "        [0.2986, 0.4622, 0.2391],\n",
      "        [0.3140, 0.4109, 0.2751],\n",
      "        [0.3257, 0.3628, 0.3115],\n",
      "        [0.3184, 0.3694, 0.3123],\n",
      "        [0.3069, 0.3413, 0.3518],\n",
      "        [0.3591, 0.3132, 0.3279],\n",
      "        [0.3499, 0.2869, 0.3633],\n",
      "        [0.4221, 0.2852, 0.2927],\n",
      "        [0.2717, 0.2981, 0.4302],\n",
      "        [0.3909, 0.2524, 0.3567],\n",
      "        [0.3752, 0.2334, 0.3914],\n",
      "        [0.4187, 0.2673, 0.3140],\n",
      "        [0.3562, 0.2664, 0.3772],\n",
      "        [0.3328, 0.3264, 0.3408],\n",
      "        [0.3252, 0.3000, 0.3748],\n",
      "        [0.3433, 0.2805, 0.3760],\n",
      "        [0.3564, 0.3098, 0.3340],\n",
      "        [0.3228, 0.3103, 0.3669],\n",
      "        [0.3782, 0.2421, 0.3796],\n",
      "        [0.3584, 0.3352, 0.3066],\n",
      "        [0.3433, 0.3430, 0.3137],\n",
      "        [0.2449, 0.3630, 0.3923],\n",
      "        [0.3276, 0.2629, 0.4094],\n",
      "        [0.3350, 0.3049, 0.3599],\n",
      "        [0.2864, 0.3123, 0.4014],\n",
      "        [0.2695, 0.3516, 0.3787],\n",
      "        [0.2712, 0.3181, 0.4106],\n",
      "        [0.3147, 0.3462, 0.3391],\n",
      "        [0.3181, 0.3137, 0.3682],\n",
      "        [0.3384, 0.2930, 0.3687],\n",
      "        [0.2576, 0.3823, 0.3601],\n",
      "        [0.3535, 0.3342, 0.3123],\n",
      "        [0.3633, 0.3181, 0.3186],\n",
      "        [0.3484, 0.3262, 0.3254],\n",
      "        [0.3152, 0.3000, 0.3848],\n",
      "        [0.2742, 0.2472, 0.4788],\n",
      "        [0.2944, 0.2380, 0.4675],\n",
      "        [0.3591, 0.1899, 0.4509],\n",
      "        [0.3647, 0.2393, 0.3960],\n",
      "        [0.3579, 0.2174, 0.4248],\n",
      "        [0.3835, 0.2515, 0.3650],\n",
      "        [0.3264, 0.3066, 0.3669],\n",
      "        [0.3384, 0.2874, 0.3743],\n",
      "        [0.2583, 0.3403, 0.4014],\n",
      "        [0.3481, 0.3438, 0.3081],\n",
      "        [0.4229, 0.3091, 0.2681],\n",
      "        [0.3999, 0.2690, 0.3311],\n",
      "        [0.4126, 0.3184, 0.2690],\n",
      "        [0.3245, 0.2954, 0.3801],\n",
      "        [0.4224, 0.2788, 0.2988],\n",
      "        [0.3821, 0.2305, 0.3875],\n",
      "        [0.2820, 0.3528, 0.3652],\n",
      "        [0.2966, 0.4058, 0.2976],\n",
      "        [0.2354, 0.4355, 0.3291],\n",
      "        [0.3389, 0.3542, 0.3069],\n",
      "        [0.3428, 0.3274, 0.3298],\n",
      "        [0.4180, 0.2759, 0.3064],\n",
      "        [0.3721, 0.3208, 0.3071],\n",
      "        [0.3762, 0.3323, 0.2915],\n",
      "        [0.3936, 0.3262, 0.2800],\n",
      "        [0.3591, 0.3552, 0.2856],\n",
      "        [0.3481, 0.3169, 0.3347],\n",
      "        [0.3921, 0.2981, 0.3098],\n",
      "        [0.4204, 0.3005, 0.2791],\n",
      "        [0.3320, 0.2693, 0.3987],\n",
      "        [0.3743, 0.3035, 0.3223],\n",
      "        [0.2996, 0.2803, 0.4202]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1125, -0.2189, -0.0465],\n",
      "        [-0.0952, -0.0912,  0.0233],\n",
      "        [-0.2280, -0.2610,  0.0165],\n",
      "        [-0.1085, -0.0981,  0.1879],\n",
      "        [ 0.1412, -0.2974,  0.0282],\n",
      "        [ 0.0829, -0.4353,  0.3066],\n",
      "        [ 0.1694, -0.1208,  0.3108],\n",
      "        [ 0.0227, -0.0364,  0.1781],\n",
      "        [ 0.1498, -0.1726, -0.2952],\n",
      "        [ 0.2781, -0.1406,  0.0574],\n",
      "        [ 0.0977, -0.0522,  0.4561],\n",
      "        [ 0.1672, -0.2715,  0.2517],\n",
      "        [ 0.3213, -0.2023,  0.0349],\n",
      "        [ 0.1103, -0.1174,  0.1990],\n",
      "        [ 0.3435, -0.0664, -0.0585],\n",
      "        [ 0.2434, -0.1379,  0.0360],\n",
      "        [ 0.1014, -0.0336,  0.1952],\n",
      "        [ 0.0026,  0.0027,  0.1753],\n",
      "        [ 0.2686, -0.1627,  0.1296],\n",
      "        [ 0.0839,  0.1328,  0.2905],\n",
      "        [ 0.1333, -0.0559,  0.3225],\n",
      "        [ 0.1174, -0.1409,  0.4180],\n",
      "        [ 0.1355, -0.2209,  0.0909],\n",
      "        [ 0.0639, -0.1954,  0.0764],\n",
      "        [ 0.1798, -0.1196, -0.0737],\n",
      "        [-0.0687, -0.2491,  0.2759],\n",
      "        [ 0.0953, -0.2927,  0.2590],\n",
      "        [ 0.1013, -0.1510,  0.2600],\n",
      "        [ 0.0638, -0.2200, -0.0988],\n",
      "        [-0.0227, -0.3284,  0.1567],\n",
      "        [ 0.0034, -0.2654, -0.1348],\n",
      "        [-0.0782, -0.1210,  0.1247],\n",
      "        [-0.0530, -0.0413, -0.1692],\n",
      "        [-0.0430, -0.1490,  0.0701],\n",
      "        [-0.0980, -0.2805,  0.0504],\n",
      "        [ 0.2146, -0.3186, -0.0220],\n",
      "        [-0.0751, -0.4458, -0.0009],\n",
      "        [-0.1770, -0.0974,  0.1465],\n",
      "        [-0.1221,  0.3308, -0.1886],\n",
      "        [-0.0560,  0.3379, -0.0533],\n",
      "        [ 0.0559, -0.0693,  0.0682],\n",
      "        [-0.1495,  0.0955,  0.3704],\n",
      "        [-0.2803,  0.3660, -0.3694],\n",
      "        [-0.2040,  0.1810, -0.2751],\n",
      "        [-0.0389, -0.0419, -0.2421],\n",
      "        [-0.0443,  0.0563, -0.0502],\n",
      "        [ 0.1609,  0.0033, -0.1992],\n",
      "        [-0.1300,  0.3044,  0.0347],\n",
      "        [-0.2428,  0.3506, -0.2478],\n",
      "        [-0.1245,  0.2603, -0.2251],\n",
      "        [-0.1193,  0.0175, -0.1359],\n",
      "        [ 0.0085,  0.0190,  0.0343],\n",
      "        [-0.0914,  0.0795,  0.1747],\n",
      "        [ 0.1366,  0.2094,  0.2993],\n",
      "        [ 0.0553, -0.0738,  0.1252],\n",
      "        [ 0.1620,  0.0462,  0.1655],\n",
      "        [ 0.0577,  0.2150,  0.1962],\n",
      "        [ 0.2023,  0.0097,  0.2080],\n",
      "        [ 0.0989,  0.0412,  0.2869],\n",
      "        [ 0.2493,  0.0175,  0.1310],\n",
      "        [ 0.1425,  0.1008,  0.0742],\n",
      "        [-0.0315,  0.1704,  0.4316],\n",
      "        [ 0.0622,  0.0039,  0.4666],\n",
      "        [ 0.1028,  0.1132,  0.4287],\n",
      "        [ 0.2798,  0.1677,  0.3652],\n",
      "        [ 0.1292,  0.0717,  0.3567],\n",
      "        [ 0.1909,  0.1787, -0.0578],\n",
      "        [ 0.2073,  0.0440, -0.2401],\n",
      "        [ 0.2327,  0.1697, -0.2124],\n",
      "        [ 0.1688, -0.0509, -0.2393],\n",
      "        [ 0.1320, -0.1345, -0.3032],\n",
      "        [ 0.1340, -0.1681, -0.1449],\n",
      "        [-0.0113, -0.4521, -0.1926],\n",
      "        [ 0.2284, -0.4253, -0.0972]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3369, 0.3030, 0.3601],\n",
      "        [0.3196, 0.3208, 0.3596],\n",
      "        [0.3081, 0.2981, 0.3936],\n",
      "        [0.2981, 0.3010, 0.4009],\n",
      "        [0.3940, 0.2542, 0.3518],\n",
      "        [0.3513, 0.2092, 0.4395],\n",
      "        [0.3447, 0.2581, 0.3972],\n",
      "        [0.3215, 0.3030, 0.3755],\n",
      "        [0.4229, 0.3062, 0.2710],\n",
      "        [0.4065, 0.2673, 0.3259],\n",
      "        [0.3037, 0.2615, 0.4348],\n",
      "        [0.3660, 0.2360, 0.3982],\n",
      "        [0.4268, 0.2527, 0.3206],\n",
      "        [0.3462, 0.2756, 0.3782],\n",
      "        [0.4287, 0.2844, 0.2869],\n",
      "        [0.4006, 0.2737, 0.3257],\n",
      "        [0.3364, 0.2939, 0.3696],\n",
      "        [0.3137, 0.3137, 0.3728],\n",
      "        [0.3967, 0.2578, 0.3455],\n",
      "        [0.3049, 0.3203, 0.3750],\n",
      "        [0.3293, 0.2727, 0.3979],\n",
      "        [0.3203, 0.2473, 0.4324],\n",
      "        [0.3765, 0.2637, 0.3601],\n",
      "        [0.3591, 0.2771, 0.3638],\n",
      "        [0.3972, 0.2944, 0.3083],\n",
      "        [0.3081, 0.2571, 0.4348],\n",
      "        [0.3501, 0.2375, 0.4124],\n",
      "        [0.3391, 0.2634, 0.3975],\n",
      "        [0.3843, 0.2893, 0.3267],\n",
      "        [0.3408, 0.2512, 0.4080],\n",
      "        [0.3794, 0.2900, 0.3306],\n",
      "        [0.3142, 0.3010, 0.3848],\n",
      "        [0.3445, 0.3486, 0.3069],\n",
      "        [0.3313, 0.2979, 0.3708],\n",
      "        [0.3340, 0.2783, 0.3875],\n",
      "        [0.4209, 0.2469, 0.3323],\n",
      "        [0.3613, 0.2494, 0.3892],\n",
      "        [0.2886, 0.3125, 0.3989],\n",
      "        [0.2849, 0.4482, 0.2666],\n",
      "        [0.2869, 0.4253, 0.2876],\n",
      "        [0.3455, 0.3049, 0.3496],\n",
      "        [0.2524, 0.3228, 0.4248],\n",
      "        [0.2615, 0.4993, 0.2393],\n",
      "        [0.2939, 0.4321, 0.2739],\n",
      "        [0.3555, 0.3545, 0.2900],\n",
      "        [0.3225, 0.3567, 0.3206],\n",
      "        [0.3918, 0.3347, 0.2734],\n",
      "        [0.2686, 0.4148, 0.3167],\n",
      "        [0.2627, 0.4756, 0.2615],\n",
      "        [0.2964, 0.4355, 0.2681],\n",
      "        [0.3196, 0.3662, 0.3142],\n",
      "        [0.3293, 0.3328, 0.3379],\n",
      "        [0.2864, 0.3398, 0.3738],\n",
      "        [0.3074, 0.3308, 0.3618],\n",
      "        [0.3389, 0.2979, 0.3633],\n",
      "        [0.3455, 0.3079, 0.3467],\n",
      "        [0.3013, 0.3525, 0.3459],\n",
      "        [0.3533, 0.2915, 0.3552],\n",
      "        [0.3174, 0.2996, 0.3831],\n",
      "        [0.3728, 0.2959, 0.3313],\n",
      "        [0.3457, 0.3315, 0.3228],\n",
      "        [0.2622, 0.3210, 0.4167],\n",
      "        [0.2905, 0.2742, 0.4353],\n",
      "        [0.2944, 0.2976, 0.4080],\n",
      "        [0.3352, 0.2996, 0.3652],\n",
      "        [0.3125, 0.2952, 0.3923],\n",
      "        [0.3613, 0.3569, 0.2817],\n",
      "        [0.4019, 0.3413, 0.2568],\n",
      "        [0.3877, 0.3640, 0.2484],\n",
      "        [0.4053, 0.3252, 0.2695],\n",
      "        [0.4143, 0.3174, 0.2681],\n",
      "        [0.4006, 0.2961, 0.3032],\n",
      "        [0.4036, 0.2598, 0.3367],\n",
      "        [0.4460, 0.2319, 0.3220]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-2.2632e-01, -1.7871e-01,  4.2908e-02],\n",
      "        [ 4.2038e-03,  1.0785e-01, -4.7272e-02],\n",
      "        [-1.0748e-01, -2.5659e-01, -2.7905e-01],\n",
      "        [-1.8250e-01, -9.3140e-02,  3.8513e-02],\n",
      "        [-1.3660e-01, -3.6133e-01, -2.3987e-01],\n",
      "        [ 1.7920e-01, -3.4521e-01, -3.9185e-02],\n",
      "        [-1.6211e-01, -3.6108e-01, -1.6431e-01],\n",
      "        [-3.3813e-02, -1.5564e-01,  1.4917e-01],\n",
      "        [-2.2046e-01, -1.1322e-01,  9.8083e-02],\n",
      "        [ 2.1680e-01, -3.7109e-01,  4.6768e-03],\n",
      "        [-2.9956e-01, -3.7549e-01,  3.3173e-02],\n",
      "        [ 1.4307e-01, -3.9307e-01, -9.6008e-02],\n",
      "        [ 8.5693e-02, -3.5425e-01, -1.9678e-01],\n",
      "        [ 2.3169e-01, -6.4307e-01,  1.6956e-01],\n",
      "        [ 3.5962e-01, -3.5181e-01, -1.5662e-01],\n",
      "        [ 1.9373e-01,  2.4011e-01, -2.7832e-01],\n",
      "        [ 1.5833e-01, -7.3486e-02,  2.1118e-01],\n",
      "        [ 2.0837e-01, -3.1342e-02, -6.1584e-02],\n",
      "        [ 2.1863e-01,  5.6091e-02, -1.9055e-01],\n",
      "        [ 2.3975e-01, -3.1494e-02, -1.2610e-01],\n",
      "        [-2.9938e-02,  5.3955e-02,  1.1627e-01],\n",
      "        [ 1.9861e-01, -1.6663e-02,  2.2546e-01],\n",
      "        [ 9.1248e-02, -1.7078e-01,  1.1572e-01],\n",
      "        [ 2.5421e-02, -1.2036e-01,  4.0710e-02],\n",
      "        [ 4.7546e-02, -1.6284e-01,  2.8516e-01],\n",
      "        [ 2.7176e-02, -1.2311e-01,  1.7090e-01],\n",
      "        [-1.6235e-01, -2.4414e-01,  2.6367e-01],\n",
      "        [-1.7441e-02, -1.3481e-02,  1.1395e-01],\n",
      "        [ 3.5059e-01, -2.8662e-01,  1.0632e-01],\n",
      "        [ 3.6133e-01, -2.4133e-01,  2.0081e-01],\n",
      "        [ 3.0176e-01, -2.4524e-01,  3.9526e-01],\n",
      "        [ 1.7688e-01, -2.4207e-01,  8.9050e-02],\n",
      "        [-4.8157e-02, -2.6953e-01,  3.7048e-02],\n",
      "        [ 2.8061e-02, -2.5586e-01,  1.1987e-01],\n",
      "        [ 3.6621e-01, -2.5781e-01, -6.8542e-02],\n",
      "        [-3.7207e-01,  1.3428e-01,  2.3560e-01],\n",
      "        [-1.7126e-01,  2.5681e-02,  2.1936e-01],\n",
      "        [-2.3425e-01,  9.9121e-02,  3.0396e-02],\n",
      "        [-1.1053e-01, -2.1130e-01,  1.7212e-01],\n",
      "        [-1.6418e-01,  2.8419e-03,  7.4646e-02],\n",
      "        [ 1.8701e-01, -1.3342e-01,  1.5442e-01],\n",
      "        [ 1.3892e-01, -7.7148e-02,  2.3462e-01],\n",
      "        [ 3.7036e-01,  2.5269e-02,  1.9092e-01],\n",
      "        [ 1.2842e-01, -1.6711e-01,  1.1139e-01],\n",
      "        [-4.4975e-03,  1.2817e-02,  1.1633e-01],\n",
      "        [-9.1370e-02, -2.3636e-02,  9.0088e-02],\n",
      "        [ 2.8244e-02, -1.8591e-01,  1.7017e-01],\n",
      "        [ 1.2436e-02, -3.7048e-02, -3.8457e-04],\n",
      "        [-1.2825e-02, -3.5980e-02,  6.7444e-02],\n",
      "        [ 1.3397e-02, -2.2522e-01,  2.7393e-01],\n",
      "        [-1.3672e-01, -1.3318e-01, -5.7587e-02],\n",
      "        [ 1.4795e-01, -3.7500e-01,  1.9849e-01]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2979, 0.3123, 0.3899],\n",
      "        [0.3269, 0.3625, 0.3105],\n",
      "        [0.3699, 0.3186, 0.3115],\n",
      "        [0.2993, 0.3274, 0.3733],\n",
      "        [0.3704, 0.2957, 0.3340],\n",
      "        [0.4175, 0.2471, 0.3354],\n",
      "        [0.3550, 0.2910, 0.3542],\n",
      "        [0.3240, 0.2869, 0.3892],\n",
      "        [0.2866, 0.3191, 0.3943],\n",
      "        [0.4229, 0.2350, 0.3420],\n",
      "        [0.3010, 0.2791, 0.4199],\n",
      "        [0.4216, 0.2466, 0.3318],\n",
      "        [0.4170, 0.2686, 0.3145],\n",
      "        [0.4243, 0.1769, 0.3987],\n",
      "        [0.4790, 0.2351, 0.2859],\n",
      "        [0.3743, 0.3921, 0.2335],\n",
      "        [0.3513, 0.2786, 0.3704],\n",
      "        [0.3921, 0.3086, 0.2993],\n",
      "        [0.3977, 0.3381, 0.2642],\n",
      "        [0.4072, 0.3105, 0.2825],\n",
      "        [0.3081, 0.3352, 0.3567],\n",
      "        [0.3530, 0.2847, 0.3625],\n",
      "        [0.3579, 0.2754, 0.3667],\n",
      "        [0.3472, 0.3000, 0.3525],\n",
      "        [0.3250, 0.2632, 0.4119],\n",
      "        [0.3318, 0.2854, 0.3831],\n",
      "        [0.2896, 0.2668, 0.4434],\n",
      "        [0.3181, 0.3193, 0.3628],\n",
      "        [0.4326, 0.2288, 0.3389],\n",
      "        [0.4167, 0.2281, 0.3550],\n",
      "        [0.3735, 0.2162, 0.4102],\n",
      "        [0.3887, 0.2556, 0.3560],\n",
      "        [0.3459, 0.2773, 0.3767],\n",
      "        [0.3511, 0.2642, 0.3848],\n",
      "        [0.4580, 0.2454, 0.2966],\n",
      "        [0.2224, 0.3691, 0.4084],\n",
      "        [0.2705, 0.3296, 0.3999],\n",
      "        [0.2703, 0.3774, 0.3523],\n",
      "        [0.3096, 0.2798, 0.4106],\n",
      "        [0.2898, 0.3423, 0.3679],\n",
      "        [0.3713, 0.2695, 0.3594],\n",
      "        [0.3440, 0.2773, 0.3787],\n",
      "        [0.3931, 0.2783, 0.3286],\n",
      "        [0.3667, 0.2729, 0.3606],\n",
      "        [0.3179, 0.3235, 0.3586],\n",
      "        [0.3059, 0.3274, 0.3667],\n",
      "        [0.3379, 0.2727, 0.3894],\n",
      "        [0.3403, 0.3237, 0.3359],\n",
      "        [0.3267, 0.3193, 0.3540],\n",
      "        [0.3242, 0.2554, 0.4207],\n",
      "        [0.3240, 0.3252, 0.3508],\n",
      "        [0.3782, 0.2241, 0.3977]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0263, -0.3105,  0.0994],\n",
      "        [ 0.1165, -0.1385, -0.0080],\n",
      "        [ 0.1111, -0.1243, -0.1410],\n",
      "        [ 0.3193, -0.4397,  0.0873],\n",
      "        [ 0.0557, -0.2563, -0.1305],\n",
      "        [ 0.4197, -0.4333,  0.1733],\n",
      "        [-0.2266, -0.0478,  0.1542],\n",
      "        [ 0.1035, -0.2542,  0.0022],\n",
      "        [ 0.2595, -0.1851, -0.1879],\n",
      "        [ 0.1923,  0.1979, -0.0482],\n",
      "        [ 0.0276,  0.2915, -0.1132],\n",
      "        [ 0.2146,  0.2327,  0.1283],\n",
      "        [-0.1113,  0.4172,  0.0807],\n",
      "        [ 0.0163,  0.0962,  0.0432],\n",
      "        [ 0.0620,  0.0625, -0.1011],\n",
      "        [ 0.1103,  0.0234, -0.1547],\n",
      "        [-0.0356, -0.1492, -0.0637],\n",
      "        [-0.0291, -0.1418, -0.0409],\n",
      "        [-0.0697, -0.0563, -0.0634],\n",
      "        [ 0.2158, -0.2483,  0.1917],\n",
      "        [-0.0102, -0.2124, -0.0438],\n",
      "        [ 0.2209, -0.3164,  0.2197]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3464, 0.2607, 0.3928],\n",
      "        [0.3762, 0.2915, 0.3323],\n",
      "        [0.3894, 0.3079, 0.3027],\n",
      "        [0.4424, 0.2070, 0.3506],\n",
      "        [0.3904, 0.2856, 0.3240],\n",
      "        [0.4529, 0.1930, 0.3540],\n",
      "        [0.2732, 0.3267, 0.3999],\n",
      "        [0.3843, 0.2686, 0.3472],\n",
      "        [0.4385, 0.2812, 0.2803],\n",
      "        [0.3582, 0.3601, 0.2817],\n",
      "        [0.3154, 0.4106, 0.2739],\n",
      "        [0.3406, 0.3469, 0.3125],\n",
      "        [0.2559, 0.4341, 0.3101],\n",
      "        [0.3215, 0.3481, 0.3303],\n",
      "        [0.3508, 0.3511, 0.2981],\n",
      "        [0.3726, 0.3416, 0.2859],\n",
      "        [0.3491, 0.3115, 0.3394],\n",
      "        [0.3469, 0.3101, 0.3430],\n",
      "        [0.3311, 0.3357, 0.3333],\n",
      "        [0.3838, 0.2413, 0.3748],\n",
      "        [0.3591, 0.2935, 0.3474],\n",
      "        [0.3872, 0.2262, 0.3867]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1552, -0.0437,  0.2102],\n",
      "        [-0.0707, -0.1141,  0.0978],\n",
      "        [ 0.0807, -0.1431, -0.2438],\n",
      "        [ 0.1913, -0.2925, -0.0160]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2810, 0.3142, 0.4050],\n",
      "        [0.3184, 0.3049, 0.3767],\n",
      "        [0.3965, 0.3169, 0.2866],\n",
      "        [0.4116, 0.2537, 0.3345]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-2.2717e-01, -1.1493e-01,  3.9771e-01],\n",
      "        [-1.2634e-01, -5.5084e-02, -2.8955e-01],\n",
      "        [-3.3667e-01, -1.8787e-01, -5.9448e-02],\n",
      "        [-1.3672e-01,  3.2898e-02,  2.4307e-02],\n",
      "        [-3.5370e-02, -2.1680e-01,  2.9712e-01],\n",
      "        [ 1.9202e-01, -4.5410e-01,  2.2141e-02],\n",
      "        [ 6.9763e-02, -2.6880e-01, -8.1848e-02],\n",
      "        [-4.8218e-02, -2.4585e-01, -5.2429e-02],\n",
      "        [-4.8004e-02, -1.2646e-01,  2.9126e-01],\n",
      "        [-2.1021e-01, -3.4497e-01,  1.3831e-01],\n",
      "        [-1.0144e-01, -3.3496e-01,  2.0654e-01],\n",
      "        [ 1.1707e-01, -5.0195e-01,  2.1033e-01],\n",
      "        [-4.8523e-02, -1.3989e-01, -5.5923e-03],\n",
      "        [-9.0698e-02, -3.8147e-02, -3.9185e-01],\n",
      "        [-6.8787e-02, -2.0068e-01, -2.1851e-01],\n",
      "        [ 6.7810e-02, -2.6611e-01, -4.5227e-02],\n",
      "        [ 2.1683e-02, -1.5527e-01, -9.2041e-02],\n",
      "        [ 1.6028e-01, -1.5942e-01,  4.6173e-02],\n",
      "        [ 3.6572e-01, -2.1313e-01,  3.0875e-05],\n",
      "        [ 2.7173e-01, -2.2754e-01, -1.3855e-01],\n",
      "        [ 2.8760e-01, -3.7524e-01, -2.3865e-01],\n",
      "        [ 2.0789e-01, -5.5225e-01,  2.0398e-01],\n",
      "        [ 2.5537e-01, -3.5791e-01, -2.1179e-01],\n",
      "        [ 3.1860e-01, -4.0576e-01,  3.1067e-02],\n",
      "        [ 1.4343e-01, -2.1777e-01, -3.1226e-01],\n",
      "        [ 1.9360e-01, -2.1765e-01,  1.7990e-02]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2507, 0.2805, 0.4685],\n",
      "        [0.3420, 0.3674, 0.2905],\n",
      "        [0.2874, 0.3335, 0.3792],\n",
      "        [0.2976, 0.3528, 0.3496],\n",
      "        [0.3098, 0.2583, 0.4319],\n",
      "        [0.4224, 0.2213, 0.3564],\n",
      "        [0.3887, 0.2771, 0.3340],\n",
      "        [0.3550, 0.2915, 0.3535],\n",
      "        [0.3005, 0.2778, 0.4219],\n",
      "        [0.3040, 0.2656, 0.4307],\n",
      "        [0.3171, 0.2512, 0.4316],\n",
      "        [0.3794, 0.2042, 0.4165],\n",
      "        [0.3381, 0.3086, 0.3530],\n",
      "        [0.3579, 0.3772, 0.2649],\n",
      "        [0.3652, 0.3201, 0.3145],\n",
      "        [0.3833, 0.2744, 0.3423],\n",
      "        [0.3662, 0.3069, 0.3269],\n",
      "        [0.3818, 0.2773, 0.3408],\n",
      "        [0.4436, 0.2487, 0.3076],\n",
      "        [0.4404, 0.2673, 0.2922],\n",
      "        [0.4749, 0.2448, 0.2805],\n",
      "        [0.4060, 0.1898, 0.4043],\n",
      "        [0.4612, 0.2498, 0.2891],\n",
      "        [0.4475, 0.2169, 0.3357],\n",
      "        [0.4290, 0.2991, 0.2720],\n",
      "        [0.3997, 0.2649, 0.3354]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.3630, -0.0667,  0.1852],\n",
      "        [ 0.2742, -0.3682,  0.2328],\n",
      "        [ 0.0023, -0.2605,  0.2225],\n",
      "        [ 0.1891, -0.4241,  0.2954],\n",
      "        [-0.1931, -0.2201,  0.3499],\n",
      "        [-0.0302, -0.3691,  0.2142],\n",
      "        [-0.0021, -0.2715,  0.1165],\n",
      "        [-0.0939, -0.3323,  0.1348],\n",
      "        [-0.2632, -0.2666,  0.3000],\n",
      "        [-0.1343, -0.1440,  0.1583],\n",
      "        [-0.2717, -0.1726,  0.2393],\n",
      "        [-0.1887, -0.2292,  0.1986],\n",
      "        [-0.1577, -0.3594, -0.0902],\n",
      "        [ 0.0408, -0.1381,  0.0646],\n",
      "        [ 0.2175, -0.3049, -0.1750],\n",
      "        [-0.1490, -0.1946, -0.0658],\n",
      "        [ 0.2764, -0.1494, -0.0815],\n",
      "        [ 0.1846, -0.2595, -0.0434],\n",
      "        [ 0.2418, -0.1447, -0.1995],\n",
      "        [ 0.0461, -0.0566, -0.0981],\n",
      "        [ 0.2429,  0.0846,  0.0590],\n",
      "        [ 0.0483,  0.1417,  0.0261],\n",
      "        [ 0.1058,  0.1439,  0.1039],\n",
      "        [ 0.1348,  0.1207, -0.0608],\n",
      "        [ 0.2479, -0.1787, -0.2128],\n",
      "        [ 0.0517, -0.2365,  0.0469],\n",
      "        [ 0.2642, -0.1376, -0.1774],\n",
      "        [ 0.0041, -0.1373, -0.1500],\n",
      "        [ 0.2566, -0.1744, -0.3933],\n",
      "        [ 0.0624, -0.1163,  0.0031],\n",
      "        [-0.0491,  0.0383, -0.0578],\n",
      "        [ 0.0744, -0.1193, -0.0931],\n",
      "        [ 0.1901, -0.1807, -0.0928],\n",
      "        [ 0.0598,  0.0776, -0.1847],\n",
      "        [-0.0064,  0.2256, -0.2445],\n",
      "        [ 0.0764,  0.3408, -0.4490],\n",
      "        [-0.1039,  0.4312, -0.2485],\n",
      "        [-0.1008,  0.3750, -0.3589],\n",
      "        [ 0.1011,  0.0463, -0.0741],\n",
      "        [-0.1621,  0.2095, -0.1741],\n",
      "        [-0.0417,  0.0786, -0.0504],\n",
      "        [-0.0625,  0.1592, -0.1785],\n",
      "        [ 0.0463, -0.0335, -0.2991],\n",
      "        [ 0.1226, -0.2271, -0.3684],\n",
      "        [ 0.1892, -0.2327, -0.3037],\n",
      "        [ 0.0694, -0.2139,  0.0593],\n",
      "        [ 0.0181, -0.2729, -0.3523],\n",
      "        [ 0.1595, -0.2717,  0.0671]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2454, 0.3301, 0.4246],\n",
      "        [0.4023, 0.2117, 0.3860],\n",
      "        [0.3315, 0.2549, 0.4133],\n",
      "        [0.3767, 0.2041, 0.4192],\n",
      "        [0.2708, 0.2634, 0.4658],\n",
      "        [0.3345, 0.2384, 0.4272],\n",
      "        [0.3459, 0.2644, 0.3896],\n",
      "        [0.3284, 0.2588, 0.4128],\n",
      "        [0.2664, 0.2656, 0.4680],\n",
      "        [0.3003, 0.2974, 0.4023],\n",
      "        [0.2651, 0.2927, 0.4421],\n",
      "        [0.2913, 0.2798, 0.4290],\n",
      "        [0.3464, 0.2832, 0.3706],\n",
      "        [0.3496, 0.2922, 0.3582],\n",
      "        [0.4409, 0.2615, 0.2976],\n",
      "        [0.3286, 0.3140, 0.3572],\n",
      "        [0.4250, 0.2776, 0.2971],\n",
      "        [0.4102, 0.2632, 0.3267],\n",
      "        [0.4304, 0.2925, 0.2769],\n",
      "        [0.3613, 0.3259, 0.3127],\n",
      "        [0.3723, 0.3179, 0.3098],\n",
      "        [0.3252, 0.3569, 0.3179],\n",
      "        [0.3293, 0.3420, 0.3286],\n",
      "        [0.3560, 0.3511, 0.2927],\n",
      "        [0.4380, 0.2859, 0.2764],\n",
      "        [0.3643, 0.2732, 0.3625],\n",
      "        [0.4324, 0.2893, 0.2781],\n",
      "        [0.3669, 0.3186, 0.3145],\n",
      "        [0.4604, 0.2993, 0.2404],\n",
      "        [0.3599, 0.3010, 0.3391],\n",
      "        [0.3245, 0.3540, 0.3215],\n",
      "        [0.3745, 0.3086, 0.3169],\n",
      "        [0.4092, 0.2825, 0.3083],\n",
      "        [0.3569, 0.3635, 0.2795],\n",
      "        [0.3279, 0.4136, 0.2585],\n",
      "        [0.3455, 0.4502, 0.2043],\n",
      "        [0.2798, 0.4780, 0.2422],\n",
      "        [0.2957, 0.4758, 0.2284],\n",
      "        [0.3589, 0.3398, 0.3013],\n",
      "        [0.2908, 0.4216, 0.2874],\n",
      "        [0.3206, 0.3616, 0.3179],\n",
      "        [0.3186, 0.3977, 0.2837],\n",
      "        [0.3801, 0.3508, 0.2690],\n",
      "        [0.4316, 0.3042, 0.2642],\n",
      "        [0.4412, 0.2893, 0.2695],\n",
      "        [0.3645, 0.2747, 0.3608],\n",
      "        [0.4102, 0.3066, 0.2832],\n",
      "        [0.3904, 0.2537, 0.3560]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-2.6221e-01, -3.0249e-01,  2.0007e-01],\n",
      "        [ 1.8542e-01, -2.2205e-01, -3.0975e-02],\n",
      "        [ 1.7725e-01, -3.5522e-02, -4.0222e-02],\n",
      "        [ 1.3159e-01, -3.1372e-01,  9.3018e-02],\n",
      "        [-7.4768e-02,  1.1749e-01, -1.1700e-01],\n",
      "        [-8.2947e-02,  1.1743e-01,  1.8701e-01],\n",
      "        [-2.0972e-01, -8.7219e-02, -3.6743e-02],\n",
      "        [-2.6660e-01, -4.6631e-02,  3.0249e-01],\n",
      "        [-2.5903e-01, -2.9688e-01,  1.8909e-01],\n",
      "        [-1.0400e-01, -1.5454e-01,  1.7651e-01],\n",
      "        [-4.5061e-05, -1.8753e-02, -1.5381e-01],\n",
      "        [-4.2343e-03,  4.6600e-02,  1.0931e-01],\n",
      "        [ 1.7175e-01, -2.0911e-01, -1.1646e-01],\n",
      "        [-1.9299e-01, -3.3325e-02,  9.9548e-02],\n",
      "        [ 2.9639e-01, -1.0431e-01, -3.3081e-01],\n",
      "        [-1.1786e-01,  7.1228e-02, -1.7395e-01],\n",
      "        [ 1.1938e-01, -3.9825e-02, -2.8125e-01],\n",
      "        [-6.8726e-02, -1.8906e-02, -1.0315e-01],\n",
      "        [ 4.8486e-01, -1.2708e-01, -2.0227e-01],\n",
      "        [ 6.0181e-02, -1.3550e-01,  2.3804e-02],\n",
      "        [ 1.9214e-01, -9.9609e-02, -9.7229e-02],\n",
      "        [-9.2773e-02, -2.7100e-02, -9.8038e-03],\n",
      "        [-2.1411e-01,  1.4270e-01, -1.7480e-01],\n",
      "        [-8.4595e-02,  1.0699e-01,  2.1801e-03],\n",
      "        [-3.8892e-01,  8.9539e-02, -1.1896e-01],\n",
      "        [-1.5979e-01,  1.8445e-01,  2.4036e-01],\n",
      "        [ 1.3403e-01, -9.7595e-02,  5.3955e-02],\n",
      "        [ 5.5573e-02, -2.1851e-01,  8.2153e-02],\n",
      "        [ 3.1189e-02, -1.8726e-01, -1.2733e-02],\n",
      "        [-8.8074e-02, -2.4426e-01, -2.6978e-02],\n",
      "        [ 2.1863e-01,  4.2152e-03, -1.9080e-01],\n",
      "        [ 1.8600e-02, -1.4661e-01, -7.3853e-02],\n",
      "        [-5.2872e-03, -9.3689e-02,  8.5632e-02],\n",
      "        [-8.7524e-02, -3.1445e-01, -3.1152e-01],\n",
      "        [ 3.1403e-02, -1.4185e-01, -3.8269e-02],\n",
      "        [-7.0435e-02, -3.4497e-01,  1.1517e-01],\n",
      "        [-1.6327e-02, -2.8052e-01,  8.1116e-02],\n",
      "        [-7.2083e-02, -2.5439e-01, -2.3575e-02],\n",
      "        [-1.6467e-01, -1.5312e-02,  3.2406e-03],\n",
      "        [-2.5586e-01, -2.3840e-01,  1.1328e-01],\n",
      "        [-2.2766e-01, -3.5156e-01,  3.3301e-01],\n",
      "        [-9.0714e-03,  1.3367e-01, -1.2964e-01],\n",
      "        [-1.8860e-01,  5.3711e-03, -2.0093e-01],\n",
      "        [ 5.6763e-02,  6.5186e-02,  8.1360e-02],\n",
      "        [ 1.7960e-02, -2.9419e-01, -3.0090e-02],\n",
      "        [ 2.6123e-01, -2.4683e-01, -2.9240e-03],\n",
      "        [ 8.4900e-02, -1.1029e-01,  1.0242e-01],\n",
      "        [ 3.1860e-01, -2.7246e-01,  1.4673e-01],\n",
      "        [-2.2903e-02, -2.7686e-01,  3.7183e-01],\n",
      "        [-8.6594e-03, -1.2988e-01,  2.5342e-01],\n",
      "        [ 6.2439e-02, -2.7734e-01,  2.3621e-01],\n",
      "        [ 1.9165e-01, -1.7615e-01,  4.3579e-02],\n",
      "        [ 2.0850e-01, -1.6699e-01,  3.7628e-02],\n",
      "        [ 1.6077e-01, -1.2421e-01, -9.4452e-03],\n",
      "        [ 2.5513e-02, -2.3108e-01, -1.5404e-02],\n",
      "        [ 7.7759e-02, -7.7698e-02,  1.5527e-01],\n",
      "        [ 1.3269e-01, -2.4915e-01,  2.4329e-01],\n",
      "        [ 1.3721e-01, -8.8379e-02, -1.5747e-01],\n",
      "        [ 8.5571e-02, -4.9133e-02, -2.3706e-01],\n",
      "        [-4.9683e-02, -4.0161e-02,  1.0046e-01],\n",
      "        [ 1.1792e-01, -2.0105e-01,  9.0271e-02],\n",
      "        [-6.3354e-02,  1.6016e-01,  1.2231e-01],\n",
      "        [-1.6632e-02, -3.4302e-01,  3.8672e-01],\n",
      "        [ 1.4258e-01, -2.2961e-01,  2.8906e-01],\n",
      "        [-1.5503e-01,  3.0487e-02,  5.1855e-01],\n",
      "        [ 1.4709e-01, -1.1121e-01,  2.6904e-01],\n",
      "        [ 1.0529e-01, -6.7200e-02,  3.6230e-01],\n",
      "        [ 2.7490e-01,  1.2561e-01,  6.2286e-02],\n",
      "        [ 1.1871e-01,  1.2550e-02,  1.6101e-01],\n",
      "        [ 2.1594e-01,  6.7558e-03,  1.3452e-01],\n",
      "        [ 3.0249e-01, -1.0663e-01,  2.6465e-01],\n",
      "        [ 4.6558e-01, -1.6296e-01,  2.0654e-01],\n",
      "        [ 5.4883e-01, -2.9541e-01,  3.8940e-02],\n",
      "        [ 4.1943e-01, -3.2715e-01, -1.2347e-01],\n",
      "        [ 3.0591e-01, -2.7026e-01, -1.3721e-01],\n",
      "        [ 1.1713e-01, -2.7563e-01,  8.7708e-02],\n",
      "        [-1.4294e-01, -3.7793e-01,  1.2903e-01],\n",
      "        [ 2.4976e-01, -1.2952e-01,  7.6294e-02],\n",
      "        [-5.1971e-02,  4.1199e-02,  3.1934e-01],\n",
      "        [-3.9276e-02,  4.5593e-02,  2.3560e-01],\n",
      "        [-8.3923e-02,  8.2581e-02,  2.0105e-01],\n",
      "        [-1.0168e-01,  9.9426e-02,  2.9150e-01],\n",
      "        [-2.7863e-02,  5.4413e-02,  1.9873e-01],\n",
      "        [ 1.2622e-01,  1.8066e-01,  1.9629e-01],\n",
      "        [ 1.3416e-01, -3.6926e-02,  1.1157e-01],\n",
      "        [ 7.2441e-03,  2.3535e-01, -8.4290e-02],\n",
      "        [-5.9174e-02,  7.0923e-02, -1.5894e-01],\n",
      "        [ 3.3887e-01, -1.5125e-01, -6.7322e-02],\n",
      "        [-6.6910e-03, -1.2360e-02,  6.3232e-02],\n",
      "        [ 2.6709e-01, -1.5991e-01, -5.4565e-02],\n",
      "        [ 6.9397e-02, -8.5876e-02,  3.7354e-01],\n",
      "        [ 2.8152e-02,  1.2708e-01,  2.2705e-01],\n",
      "        [ 1.3664e-02, -3.8849e-02,  1.5247e-01],\n",
      "        [ 1.4575e-01,  4.4128e-02,  3.9673e-01],\n",
      "        [ 3.7500e-01, -2.4829e-01,  2.4170e-01],\n",
      "        [ 2.0288e-01, -7.4829e-02,  2.1350e-01],\n",
      "        [ 5.5511e-02, -1.8750e-01,  3.4692e-01],\n",
      "        [-1.0217e-01, -4.3365e-02,  4.3970e-01],\n",
      "        [ 5.1117e-02, -3.9722e-01,  1.9885e-01],\n",
      "        [ 9.3567e-02, -3.4741e-01,  1.3257e-01],\n",
      "        [-3.0322e-01, -2.7930e-01, -8.8623e-02],\n",
      "        [ 6.5979e-02, -3.1616e-01,  7.6538e-02],\n",
      "        [-1.0388e-01, -5.2246e-01, -1.8054e-01],\n",
      "        [ 9.7656e-02, -2.4500e-01,  2.3376e-02]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2817, 0.2708, 0.4475],\n",
      "        [0.4048, 0.2693, 0.3259],\n",
      "        [0.3828, 0.3093, 0.3079],\n",
      "        [0.3843, 0.2461, 0.3696],\n",
      "        [0.3154, 0.3823, 0.3022],\n",
      "        [0.2832, 0.3459, 0.3708],\n",
      "        [0.3013, 0.3406, 0.3582],\n",
      "        [0.2493, 0.3105, 0.4402],\n",
      "        [0.2834, 0.2729, 0.4436],\n",
      "        [0.3054, 0.2903, 0.4043],\n",
      "        [0.3523, 0.3457, 0.3020],\n",
      "        [0.3152, 0.3315, 0.3530],\n",
      "        [0.4111, 0.2808, 0.3081],\n",
      "        [0.2847, 0.3340, 0.3813],\n",
      "        [0.4536, 0.3040, 0.2423],\n",
      "        [0.3171, 0.3831, 0.2998],\n",
      "        [0.3965, 0.3381, 0.2656],\n",
      "        [0.3315, 0.3484, 0.3203],\n",
      "        [0.4890, 0.2651, 0.2460],\n",
      "        [0.3589, 0.2952, 0.3459],\n",
      "        [0.4006, 0.2993, 0.3000],\n",
      "        [0.3171, 0.3386, 0.3445],\n",
      "        [0.2883, 0.4119, 0.2998],\n",
      "        [0.3030, 0.3667, 0.3303],\n",
      "        [0.2549, 0.4114, 0.3340],\n",
      "        [0.2561, 0.3616, 0.3823],\n",
      "        [0.3682, 0.2920, 0.3398],\n",
      "        [0.3589, 0.2727, 0.3684],\n",
      "        [0.3623, 0.2910, 0.3467],\n",
      "        [0.3428, 0.2932, 0.3643],\n",
      "        [0.4048, 0.3267, 0.2688],\n",
      "        [0.3623, 0.3071, 0.3303],\n",
      "        [0.3323, 0.3040, 0.3638],\n",
      "        [0.3853, 0.3069, 0.3079],\n",
      "        [0.3606, 0.3032, 0.3362],\n",
      "        [0.3374, 0.2563, 0.4062],\n",
      "        [0.3484, 0.2676, 0.3840],\n",
      "        [0.3469, 0.2891, 0.3640],\n",
      "        [0.2991, 0.3472, 0.3538],\n",
      "        [0.2886, 0.2937, 0.4175],\n",
      "        [0.2751, 0.2430, 0.4819],\n",
      "        [0.3289, 0.3794, 0.2915],\n",
      "        [0.3123, 0.3792, 0.3086],\n",
      "        [0.3296, 0.3325, 0.3379],\n",
      "        [0.3726, 0.2725, 0.3550],\n",
      "        [0.4221, 0.2539, 0.3240],\n",
      "        [0.3521, 0.2896, 0.3584],\n",
      "        [0.4175, 0.2311, 0.3516],\n",
      "        [0.3069, 0.2379, 0.4553],\n",
      "        [0.3140, 0.2781, 0.4080],\n",
      "        [0.3447, 0.2454, 0.4099],\n",
      "        [0.3914, 0.2710, 0.3376],\n",
      "        [0.3953, 0.2715, 0.3333],\n",
      "        [0.3853, 0.2898, 0.3250],\n",
      "        [0.3657, 0.2830, 0.3511],\n",
      "        [0.3406, 0.2915, 0.3679],\n",
      "        [0.3572, 0.2438, 0.3989],\n",
      "        [0.3933, 0.3140, 0.2930],\n",
      "        [0.3848, 0.3364, 0.2788],\n",
      "        [0.3152, 0.3184, 0.3665],\n",
      "        [0.3704, 0.2693, 0.3604],\n",
      "        [0.2896, 0.3621, 0.3486],\n",
      "        [0.3108, 0.2242, 0.4651],\n",
      "        [0.3513, 0.2421, 0.4067],\n",
      "        [0.2401, 0.2891, 0.4709],\n",
      "        [0.3445, 0.2661, 0.3892],\n",
      "        [0.3191, 0.2686, 0.4126],\n",
      "        [0.3745, 0.3225, 0.3027],\n",
      "        [0.3398, 0.3057, 0.3545],\n",
      "        [0.3660, 0.2969, 0.3374],\n",
      "        [0.3806, 0.2529, 0.3665],\n",
      "        [0.4338, 0.2313, 0.3347],\n",
      "        [0.4924, 0.2117, 0.2959],\n",
      "        [0.4866, 0.2306, 0.2827],\n",
      "        [0.4536, 0.2549, 0.2913],\n",
      "        [0.3779, 0.2551, 0.3669],\n",
      "        [0.3223, 0.2549, 0.4231],\n",
      "        [0.3960, 0.2710, 0.3330],\n",
      "        [0.2820, 0.3093, 0.4087],\n",
      "        [0.2937, 0.3198, 0.3867],\n",
      "        [0.2849, 0.3364, 0.3787],\n",
      "        [0.2700, 0.3301, 0.3999],\n",
      "        [0.2993, 0.3250, 0.3755],\n",
      "        [0.3196, 0.3374, 0.3428],\n",
      "        [0.3545, 0.2988, 0.3467],\n",
      "        [0.3157, 0.3965, 0.2881],\n",
      "        [0.3286, 0.3743, 0.2974],\n",
      "        [0.4387, 0.2688, 0.2922],\n",
      "        [0.3262, 0.3242, 0.3496],\n",
      "        [0.4207, 0.2744, 0.3049],\n",
      "        [0.3113, 0.2666, 0.4221],\n",
      "        [0.3008, 0.3320, 0.3669],\n",
      "        [0.3228, 0.3064, 0.3708],\n",
      "        [0.3137, 0.2832, 0.4031],\n",
      "        [0.4148, 0.2224, 0.3630],\n",
      "        [0.3613, 0.2737, 0.3650],\n",
      "        [0.3203, 0.2512, 0.4287],\n",
      "        [0.2646, 0.2805, 0.4548],\n",
      "        [0.3574, 0.2283, 0.4143],\n",
      "        [0.3728, 0.2397, 0.3875],\n",
      "        [0.3064, 0.3137, 0.3796],\n",
      "        [0.3713, 0.2534, 0.3752],\n",
      "        [0.3870, 0.2546, 0.3584],\n",
      "        [0.3792, 0.2690, 0.3518]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0220, -0.1272,  0.1458],\n",
      "        [ 0.1824, -0.1975,  0.1490],\n",
      "        [ 0.3096, -0.2556, -0.0397],\n",
      "        [ 0.1420, -0.1049,  0.1010],\n",
      "        [ 0.1572, -0.1621,  0.1241],\n",
      "        [ 0.1891, -0.0309,  0.2561],\n",
      "        [ 0.1815, -0.1194,  0.2286],\n",
      "        [ 0.3022, -0.1840,  0.1826],\n",
      "        [ 0.1868, -0.2546,  0.2100],\n",
      "        [ 0.1792, -0.2798,  0.1714],\n",
      "        [ 0.3630, -0.3242,  0.0656],\n",
      "        [ 0.1738, -0.0026,  0.2261],\n",
      "        [ 0.2317,  0.1110,  0.3228],\n",
      "        [-0.0267,  0.1832,  0.1813],\n",
      "        [ 0.2401, -0.1216, -0.0228],\n",
      "        [-0.0809, -0.0809,  0.1465],\n",
      "        [ 0.3125,  0.1532, -0.2023],\n",
      "        [ 0.1678,  0.0192, -0.0466],\n",
      "        [ 0.5059, -0.0777, -0.2751],\n",
      "        [ 0.4622, -0.2006,  0.0870],\n",
      "        [ 0.3074, -0.2072, -0.1606],\n",
      "        [ 0.2649, -0.1534,  0.0503],\n",
      "        [ 0.1935, -0.0968,  0.0505],\n",
      "        [ 0.3123, -0.0950,  0.1154],\n",
      "        [-0.0349,  0.2332,  0.1154],\n",
      "        [ 0.4385, -0.3740, -0.0047],\n",
      "        [ 0.1242,  0.0126,  0.2018],\n",
      "        [ 0.1755, -0.1666,  0.2527],\n",
      "        [ 0.1659,  0.1036,  0.1965],\n",
      "        [ 0.2629, -0.0056,  0.1893],\n",
      "        [ 0.1332, -0.1375,  0.1309],\n",
      "        [ 0.4241, -0.3411,  0.2028],\n",
      "        [ 0.1947, -0.0318,  0.0084],\n",
      "        [ 0.5723, -0.1743,  0.0526],\n",
      "        [ 0.3140, -0.2651,  0.1472],\n",
      "        [ 0.3455, -0.4656,  0.2776],\n",
      "        [ 0.0346, -0.2546,  0.3313],\n",
      "        [-0.0284, -0.2234,  0.1743],\n",
      "        [ 0.2163, -0.3313,  0.3132],\n",
      "        [ 0.1284, -0.0562,  0.1412],\n",
      "        [ 0.0811, -0.1204, -0.0013],\n",
      "        [-0.0912, -0.2421,  0.1093],\n",
      "        [ 0.1954, -0.1009, -0.0401],\n",
      "        [ 0.3108,  0.0831,  0.0582],\n",
      "        [ 0.2247,  0.1617, -0.0802],\n",
      "        [-0.0205,  0.2827, -0.0176],\n",
      "        [ 0.1573,  0.1390, -0.0752],\n",
      "        [ 0.1620,  0.2067,  0.0193],\n",
      "        [-0.1204,  0.2759, -0.1536],\n",
      "        [ 0.0386,  0.1218, -0.3137],\n",
      "        [ 0.3484,  0.0418, -0.1852],\n",
      "        [ 0.2125, -0.0909,  0.0712],\n",
      "        [ 0.4104, -0.2815, -0.3728],\n",
      "        [ 0.1437, -0.1225,  0.0556]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3245, 0.2920, 0.3835],\n",
      "        [0.3772, 0.2581, 0.3647],\n",
      "        [0.4399, 0.2500, 0.3103],\n",
      "        [0.3647, 0.2849, 0.3501],\n",
      "        [0.3711, 0.2698, 0.3591],\n",
      "        [0.3481, 0.2795, 0.3723],\n",
      "        [0.3586, 0.2654, 0.3760],\n",
      "        [0.3997, 0.2457, 0.3545],\n",
      "        [0.3750, 0.2412, 0.3838],\n",
      "        [0.3811, 0.2408, 0.3782],\n",
      "        [0.4453, 0.2240, 0.3308],\n",
      "        [0.3457, 0.2898, 0.3643],\n",
      "        [0.3354, 0.2974, 0.3674],\n",
      "        [0.2886, 0.3560, 0.3552],\n",
      "        [0.4055, 0.2825, 0.3118],\n",
      "        [0.3071, 0.3071, 0.3857],\n",
      "        [0.4082, 0.3479, 0.2439],\n",
      "        [0.3748, 0.3230, 0.3022],\n",
      "        [0.4961, 0.2769, 0.2272],\n",
      "        [0.4541, 0.2340, 0.3120],\n",
      "        [0.4497, 0.2688, 0.2815],\n",
      "        [0.4058, 0.2671, 0.3274],\n",
      "        [0.3823, 0.2861, 0.3315],\n",
      "        [0.4021, 0.2676, 0.3303],\n",
      "        [0.2883, 0.3767, 0.3350],\n",
      "        [0.4795, 0.2128, 0.3079],\n",
      "        [0.3362, 0.3005, 0.3633],\n",
      "        [0.3584, 0.2546, 0.3872],\n",
      "        [0.3367, 0.3164, 0.3472],\n",
      "        [0.3713, 0.2839, 0.3450],\n",
      "        [0.3623, 0.2764, 0.3613],\n",
      "        [0.4412, 0.2052, 0.3535],\n",
      "        [0.3806, 0.3035, 0.3159],\n",
      "        [0.4834, 0.2291, 0.2876],\n",
      "        [0.4155, 0.2328, 0.3516],\n",
      "        [0.4204, 0.1868, 0.3928],\n",
      "        [0.3232, 0.2421, 0.4348],\n",
      "        [0.3281, 0.2700, 0.4019],\n",
      "        [0.3730, 0.2158, 0.4111],\n",
      "        [0.3516, 0.2922, 0.3562],\n",
      "        [0.3652, 0.2986, 0.3362],\n",
      "        [0.3245, 0.2791, 0.3965],\n",
      "        [0.3948, 0.2935, 0.3118],\n",
      "        [0.3887, 0.3096, 0.3020],\n",
      "        [0.3738, 0.3508, 0.2754],\n",
      "        [0.2979, 0.4033, 0.2988],\n",
      "        [0.3604, 0.3540, 0.2856],\n",
      "        [0.3433, 0.3589, 0.2976],\n",
      "        [0.2896, 0.4304, 0.2800],\n",
      "        [0.3584, 0.3896, 0.2520],\n",
      "        [0.4307, 0.3169, 0.2524],\n",
      "        [0.3835, 0.2832, 0.3330],\n",
      "        [0.5107, 0.2559, 0.2334],\n",
      "        [0.3728, 0.2856, 0.3413]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0556,  0.0556,  0.0953],\n",
      "        [ 0.2434, -0.2273,  0.0410],\n",
      "        [ 0.2666, -0.3569,  0.2224],\n",
      "        [ 0.4795, -0.1021,  0.3218],\n",
      "        [ 0.2747,  0.1418,  0.0699],\n",
      "        [ 0.1317,  0.2157,  0.1375],\n",
      "        [ 0.1777, -0.0429, -0.1145],\n",
      "        [ 0.0449, -0.0792, -0.0574],\n",
      "        [ 0.0385, -0.1616,  0.0137],\n",
      "        [ 0.1542, -0.1733,  0.1686],\n",
      "        [-0.0214, -0.2100,  0.1511],\n",
      "        [ 0.1914,  0.0380,  0.2395],\n",
      "        [ 0.1250,  0.2032,  0.2683],\n",
      "        [ 0.1011,  0.1566,  0.0860],\n",
      "        [ 0.0645,  0.1680,  0.3477],\n",
      "        [-0.1102,  0.1832,  0.2417],\n",
      "        [ 0.1479, -0.0584, -0.0320],\n",
      "        [ 0.1776,  0.2063,  0.0931],\n",
      "        [ 0.1602, -0.0366,  0.0746],\n",
      "        [ 0.2207, -0.0183,  0.0540],\n",
      "        [ 0.2983, -0.2236, -0.0425],\n",
      "        [ 0.2654, -0.0795,  0.1350],\n",
      "        [ 0.2021, -0.2715, -0.0102],\n",
      "        [ 0.3215, -0.1207, -0.0814],\n",
      "        [ 0.2239, -0.3694,  0.0545],\n",
      "        [ 0.2747, -0.0930,  0.1838],\n",
      "        [ 0.2908, -0.1859,  0.4856],\n",
      "        [ 0.1626,  0.0841,  0.3538],\n",
      "        [-0.1410,  0.0246,  0.5234],\n",
      "        [-0.1873, -0.0077,  0.3062],\n",
      "        [-0.0182, -0.0768,  0.3601],\n",
      "        [ 0.1606, -0.1484,  0.1753],\n",
      "        [ 0.1818,  0.1425, -0.0137],\n",
      "        [ 0.2457, -0.0731,  0.1991],\n",
      "        [ 0.1118,  0.1331, -0.0873],\n",
      "        [ 0.0667,  0.1561, -0.0607],\n",
      "        [ 0.0166,  0.1013,  0.1168],\n",
      "        [ 0.0628, -0.0223,  0.2280],\n",
      "        [-0.0347, -0.0135,  0.0909],\n",
      "        [ 0.1593, -0.0213,  0.1204],\n",
      "        [ 0.2085, -0.0604,  0.1351],\n",
      "        [ 0.2311, -0.1378,  0.4348],\n",
      "        [ 0.0251, -0.1068,  0.4954],\n",
      "        [ 0.1306, -0.2064,  0.3691],\n",
      "        [ 0.3420, -0.1188,  0.1906],\n",
      "        [ 0.1069,  0.0459,  0.0793],\n",
      "        [ 0.1882, -0.3040,  0.2639],\n",
      "        [ 0.1644,  0.0013, -0.0090],\n",
      "        [ 0.3369, -0.3027,  0.1965],\n",
      "        [ 0.2412, -0.3245,  0.1521],\n",
      "        [ 0.1194, -0.2781,  0.0311],\n",
      "        [ 0.2089, -0.2947,  0.2318]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3289, 0.3289, 0.3423],\n",
      "        [0.4097, 0.2559, 0.3345],\n",
      "        [0.4011, 0.2151, 0.3838],\n",
      "        [0.4143, 0.2317, 0.3540],\n",
      "        [0.3716, 0.3254, 0.3030],\n",
      "        [0.3232, 0.3516, 0.3252],\n",
      "        [0.3923, 0.3147, 0.2930],\n",
      "        [0.3589, 0.3171, 0.3240],\n",
      "        [0.3579, 0.2930, 0.3491],\n",
      "        [0.3657, 0.2634, 0.3708],\n",
      "        [0.3315, 0.2747, 0.3940],\n",
      "        [0.3440, 0.2952, 0.3608],\n",
      "        [0.3091, 0.3342, 0.3567],\n",
      "        [0.3286, 0.3474, 0.3237],\n",
      "        [0.2910, 0.3228, 0.3862],\n",
      "        [0.2659, 0.3564, 0.3779],\n",
      "        [0.3774, 0.3071, 0.3154],\n",
      "        [0.3391, 0.3491, 0.3118],\n",
      "        [0.3650, 0.2998, 0.3352],\n",
      "        [0.3796, 0.2991, 0.3213],\n",
      "        [0.4338, 0.2576, 0.3086],\n",
      "        [0.3867, 0.2739, 0.3394],\n",
      "        [0.4114, 0.2561, 0.3325],\n",
      "        [0.4326, 0.2781, 0.2893],\n",
      "        [0.4172, 0.2306, 0.3523],\n",
      "        [0.3838, 0.2656, 0.3506],\n",
      "        [0.3525, 0.2189, 0.4285],\n",
      "        [0.3188, 0.2949, 0.3862],\n",
      "        [0.2426, 0.2861, 0.4712],\n",
      "        [0.2607, 0.3120, 0.4272],\n",
      "        [0.2939, 0.2771, 0.4290],\n",
      "        [0.3638, 0.2671, 0.3691],\n",
      "        [0.3591, 0.3455, 0.2954],\n",
      "        [0.3730, 0.2712, 0.3560],\n",
      "        [0.3521, 0.3596, 0.2886],\n",
      "        [0.3362, 0.3677, 0.2961],\n",
      "        [0.3132, 0.3408, 0.3462],\n",
      "        [0.3228, 0.2964, 0.3809],\n",
      "        [0.3169, 0.3237, 0.3594],\n",
      "        [0.3577, 0.2986, 0.3440],\n",
      "        [0.3713, 0.2837, 0.3450],\n",
      "        [0.3428, 0.2371, 0.4202],\n",
      "        [0.2876, 0.2520, 0.4602],\n",
      "        [0.3352, 0.2393, 0.4255],\n",
      "        [0.4016, 0.2532, 0.3452],\n",
      "        [0.3433, 0.3230, 0.3340],\n",
      "        [0.3718, 0.2273, 0.4009],\n",
      "        [0.3718, 0.3157, 0.3125],\n",
      "        [0.4172, 0.2201, 0.3625],\n",
      "        [0.4028, 0.2288, 0.3684],\n",
      "        [0.3865, 0.2598, 0.3538],\n",
      "        [0.3806, 0.2300, 0.3894]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-3.5254e-01, -6.6956e-02,  1.8188e-01],\n",
      "        [-1.6553e-01,  2.7271e-01,  3.3374e-01],\n",
      "        [-1.0876e-01,  2.3364e-01,  1.2585e-01],\n",
      "        [-3.4888e-01,  1.5918e-01,  1.9653e-01],\n",
      "        [-2.1167e-01,  2.6782e-01,  6.1865e-01],\n",
      "        [-7.7820e-02,  2.8174e-01,  2.2900e-01],\n",
      "        [ 8.7128e-03,  3.2764e-01,  1.7834e-01],\n",
      "        [-3.3142e-02, -1.0333e-01,  1.1523e-01],\n",
      "        [ 2.5830e-01, -1.7090e-02, -7.4707e-02],\n",
      "        [ 1.2708e-01,  1.0413e-01, -9.7961e-02],\n",
      "        [ 1.8753e-02,  1.2374e-04,  5.8929e-02],\n",
      "        [ 2.3254e-01,  2.3413e-01,  4.8035e-02],\n",
      "        [ 1.1493e-01,  2.5562e-01,  1.0162e-01],\n",
      "        [-1.2585e-01,  1.1627e-01,  1.4490e-01],\n",
      "        [ 1.2073e-01,  1.5610e-02,  8.0109e-04],\n",
      "        [ 5.0537e-02, -1.4746e-01,  1.5527e-01],\n",
      "        [-1.1481e-01, -1.7261e-01, -2.6196e-01],\n",
      "        [ 2.1887e-01, -2.6831e-01,  1.3696e-01]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2477, 0.3296, 0.4226],\n",
      "        [0.2383, 0.3691, 0.3926],\n",
      "        [0.2722, 0.3835, 0.3442],\n",
      "        [0.2279, 0.3789, 0.3933],\n",
      "        [0.2037, 0.3291, 0.4673],\n",
      "        [0.2637, 0.3779, 0.3584],\n",
      "        [0.2808, 0.3865, 0.3328],\n",
      "        [0.3235, 0.3015, 0.3752],\n",
      "        [0.4038, 0.3066, 0.2896],\n",
      "        [0.3604, 0.3521, 0.2876],\n",
      "        [0.3308, 0.3247, 0.3445],\n",
      "        [0.3530, 0.3535, 0.2935],\n",
      "        [0.3186, 0.3669, 0.3145],\n",
      "        [0.2791, 0.3555, 0.3657],\n",
      "        [0.3589, 0.3230, 0.3181],\n",
      "        [0.3413, 0.2800, 0.3789],\n",
      "        [0.3562, 0.3362, 0.3076],\n",
      "        [0.3943, 0.2423, 0.3633]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0149, -0.0278,  0.0687],\n",
      "        [ 0.0086, -0.0772, -0.1134],\n",
      "        [ 0.0195, -0.3621,  0.0504],\n",
      "        [ 0.0034, -0.1361,  0.0164],\n",
      "        [ 0.0758, -0.2397,  0.2158],\n",
      "        [ 0.2727, -0.1713,  0.2871],\n",
      "        [ 0.2244, -0.1159,  0.0641],\n",
      "        [ 0.2812, -0.2180,  0.0528],\n",
      "        [ 0.2295, -0.0774,  0.0887],\n",
      "        [ 0.3013, -0.1302,  0.0034],\n",
      "        [ 0.0926,  0.1032, -0.1221],\n",
      "        [ 0.1359,  0.0605,  0.0646],\n",
      "        [ 0.0746, -0.2656, -0.1180],\n",
      "        [ 0.1959, -0.0734, -0.0219]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3252, 0.3210, 0.3538],\n",
      "        [0.3567, 0.3274, 0.3159],\n",
      "        [0.3684, 0.2515, 0.3799],\n",
      "        [0.3469, 0.3018, 0.3513],\n",
      "        [0.3472, 0.2532, 0.3994],\n",
      "        [0.3765, 0.2416, 0.3821],\n",
      "        [0.3901, 0.2776, 0.3323],\n",
      "        [0.4163, 0.2527, 0.3313],\n",
      "        [0.3840, 0.2825, 0.3335],\n",
      "        [0.4180, 0.2715, 0.3103],\n",
      "        [0.3550, 0.3586, 0.2864],\n",
      "        [0.3499, 0.3245, 0.3257],\n",
      "        [0.3943, 0.2805, 0.3252],\n",
      "        [0.3894, 0.2974, 0.3132]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1144, -0.0442,  0.0914],\n",
      "        [ 0.1593, -0.3530,  0.1002],\n",
      "        [ 0.2460, -0.4934,  0.2059],\n",
      "        [ 0.3652, -0.2954,  0.2957],\n",
      "        [ 0.0182, -0.4543,  0.3235],\n",
      "        [ 0.1118, -0.2512, -0.0277],\n",
      "        [-0.0872, -0.4036,  0.3044],\n",
      "        [ 0.0827, -0.2859,  0.4338],\n",
      "        [ 0.1941, -0.2849,  0.2037],\n",
      "        [ 0.1949, -0.1669, -0.0190],\n",
      "        [ 0.1013, -0.2539,  0.0724],\n",
      "        [ 0.2231, -0.0041, -0.0176],\n",
      "        [-0.0094, -0.2046, -0.1038],\n",
      "        [ 0.0020,  0.0163, -0.0576],\n",
      "        [ 0.1691,  0.0252, -0.3542],\n",
      "        [ 0.1082, -0.0845, -0.0441],\n",
      "        [ 0.5039, -0.3232,  0.0638],\n",
      "        [ 0.2119, -0.1875,  0.0327],\n",
      "        [ 0.2876, -0.2810,  0.1036],\n",
      "        [ 0.1603, -0.2393, -0.1263],\n",
      "        [ 0.3367, -0.4446, -0.1593],\n",
      "        [ 0.2220, -0.2206, -0.0640],\n",
      "        [ 0.2102, -0.3862, -0.0721],\n",
      "        [ 0.1958, -0.2191,  0.0418]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3030, 0.3250, 0.3721],\n",
      "        [0.3936, 0.2357, 0.3708],\n",
      "        [0.4102, 0.1958, 0.3940],\n",
      "        [0.4082, 0.2109, 0.3809],\n",
      "        [0.3354, 0.2091, 0.4553],\n",
      "        [0.3899, 0.2712, 0.3391],\n",
      "        [0.3118, 0.2272, 0.4612],\n",
      "        [0.3213, 0.2223, 0.4565],\n",
      "        [0.3804, 0.2356, 0.3840],\n",
      "        [0.3994, 0.2781, 0.3225],\n",
      "        [0.3743, 0.2622, 0.3635],\n",
      "        [0.3872, 0.3086, 0.3044],\n",
      "        [0.3660, 0.3010, 0.3330],\n",
      "        [0.3381, 0.3430, 0.3186],\n",
      "        [0.4067, 0.3523, 0.2410],\n",
      "        [0.3726, 0.3074, 0.3201],\n",
      "        [0.4805, 0.2101, 0.3093],\n",
      "        [0.3989, 0.2676, 0.3335],\n",
      "        [0.4170, 0.2361, 0.3469],\n",
      "        [0.4131, 0.2769, 0.3101],\n",
      "        [0.4839, 0.2216, 0.2947],\n",
      "        [0.4177, 0.2683, 0.3140],\n",
      "        [0.4338, 0.2390, 0.3271],\n",
      "        [0.3972, 0.2622, 0.3406]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0903,  0.0930,  0.0734],\n",
      "        [ 0.0996, -0.0434, -0.1649],\n",
      "        [ 0.2142, -0.2603,  0.0759],\n",
      "        [ 0.2727, -0.2834,  0.2045],\n",
      "        [ 0.2642, -0.2524,  0.0732],\n",
      "        [ 0.0405, -0.1202,  0.0671],\n",
      "        [-0.0602, -0.1884,  0.0666],\n",
      "        [ 0.0632, -0.1866,  0.1206],\n",
      "        [-0.2705, -0.0396, -0.0437],\n",
      "        [-0.0548, -0.1164,  0.2104],\n",
      "        [ 0.1121, -0.3708, -0.2988],\n",
      "        [ 0.1523, -0.3396,  0.0673]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2959, 0.3555, 0.3486],\n",
      "        [0.3796, 0.3291, 0.2913],\n",
      "        [0.4011, 0.2496, 0.3494],\n",
      "        [0.3989, 0.2286, 0.3726],\n",
      "        [0.4128, 0.2462, 0.3411],\n",
      "        [0.3474, 0.2959, 0.3567],\n",
      "        [0.3318, 0.2917, 0.3765],\n",
      "        [0.3523, 0.2744, 0.3733],\n",
      "        [0.2844, 0.3584, 0.3569],\n",
      "        [0.3083, 0.2898, 0.4019],\n",
      "        [0.4385, 0.2705, 0.2908],\n",
      "        [0.3953, 0.2417, 0.3630]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0687, -0.1938,  0.0415],\n",
      "        [ 0.3535, -0.1398, -0.4272],\n",
      "        [ 0.1378,  0.0735, -0.4609],\n",
      "        [ 0.1586, -0.0863, -0.1063],\n",
      "        [ 0.3821, -0.1764, -0.4722],\n",
      "        [ 0.0508,  0.0699, -0.2487],\n",
      "        [ 0.2242, -0.1842, -0.4001],\n",
      "        [-0.1040,  0.1469, -0.0197],\n",
      "        [-0.0067, -0.0550, -0.2781],\n",
      "        [-0.0136, -0.0955, -0.1506],\n",
      "        [ 0.2190,  0.2000, -0.2917],\n",
      "        [-0.0891, -0.0928, -0.0533],\n",
      "        [ 0.0014, -0.3376, -0.0508],\n",
      "        [ 0.2041, -0.2776, -0.1910],\n",
      "        [ 0.1236, -0.0757, -0.2069],\n",
      "        [ 0.2861,  0.1040, -0.2037],\n",
      "        [ 0.3120, -0.1036, -0.0979],\n",
      "        [ 0.5195, -0.0796, -0.1792],\n",
      "        [ 0.1923, -0.1354, -0.2052],\n",
      "        [ 0.4717, -0.0556, -0.1833],\n",
      "        [ 0.2355,  0.0047, -0.3438],\n",
      "        [ 0.1482,  0.0168,  0.0262],\n",
      "        [ 0.2893, -0.2278, -0.2881],\n",
      "        [ 0.2211, -0.1103, -0.1816],\n",
      "        [ 0.2991,  0.0842, -0.4358],\n",
      "        [ 0.1392, -0.2106, -0.1711],\n",
      "        [ 0.1583, -0.1273, -0.1721],\n",
      "        [ 0.0434, -0.1205, -0.1617],\n",
      "        [-0.1117, -0.0343, -0.0577],\n",
      "        [-0.3748,  0.2473,  0.0666],\n",
      "        [-0.5483, -0.0074,  0.0836],\n",
      "        [-0.4194,  0.1182,  0.0349],\n",
      "        [-0.2903, -0.1074,  0.0826],\n",
      "        [-0.0583,  0.3528,  0.5410],\n",
      "        [ 0.0288,  0.1273,  0.1672],\n",
      "        [ 0.0389,  0.0142,  0.1091],\n",
      "        [ 0.0743, -0.2764, -0.0414],\n",
      "        [-0.0026,  0.1345,  0.2485],\n",
      "        [ 0.2346, -0.1615,  0.0652],\n",
      "        [ 0.0465, -0.0753,  0.2423],\n",
      "        [-0.0912, -0.1608,  0.1247],\n",
      "        [-0.1622, -0.0473,  0.0804],\n",
      "        [-0.0779, -0.1288, -0.1550],\n",
      "        [-0.0865, -0.0175,  0.3049],\n",
      "        [ 0.1848,  0.0739, -0.0789],\n",
      "        [-0.0589, -0.0497,  0.1840],\n",
      "        [-0.1481,  0.1689,  0.1604],\n",
      "        [-0.1459, -0.0499,  0.3662],\n",
      "        [-0.3774, -0.2534,  0.2361],\n",
      "        [-0.0416, -0.0795,  0.1960],\n",
      "        [-0.0201,  0.1481, -0.0039],\n",
      "        [ 0.0263,  0.2030,  0.1727],\n",
      "        [ 0.1193,  0.2179,  0.2637],\n",
      "        [-0.0613,  0.0631,  0.2805],\n",
      "        [-0.0072,  0.0345,  0.2213],\n",
      "        [-0.1091,  0.0798,  0.3271],\n",
      "        [-0.1743, -0.2371,  0.0573],\n",
      "        [-0.0849,  0.0230,  0.4121],\n",
      "        [-0.2450,  0.1675,  0.1075],\n",
      "        [ 0.1863,  0.0354, -0.2319],\n",
      "        [ 0.0675,  0.1469, -0.2021],\n",
      "        [-0.1498,  0.1572,  0.0575],\n",
      "        [ 0.0944,  0.0543, -0.0070],\n",
      "        [ 0.2057, -0.1144, -0.0378],\n",
      "        [ 0.0639, -0.4451, -0.2159],\n",
      "        [ 0.0594, -0.3369,  0.0361]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3335, 0.2942, 0.3723],\n",
      "        [0.4834, 0.2952, 0.2214],\n",
      "        [0.4021, 0.3770, 0.2209],\n",
      "        [0.3921, 0.3069, 0.3008],\n",
      "        [0.5005, 0.2864, 0.2130],\n",
      "        [0.3623, 0.3691, 0.2686],\n",
      "        [0.4546, 0.3020, 0.2434],\n",
      "        [0.2964, 0.3811, 0.3225],\n",
      "        [0.3684, 0.3508, 0.2808],\n",
      "        [0.3579, 0.3298, 0.3123],\n",
      "        [0.3875, 0.3801, 0.2324],\n",
      "        [0.3298, 0.3286, 0.3418],\n",
      "        [0.3757, 0.2676, 0.3567],\n",
      "        [0.4365, 0.2695, 0.2939],\n",
      "        [0.3940, 0.3228, 0.2832],\n",
      "        [0.4087, 0.3408, 0.2505],\n",
      "        [0.4304, 0.2839, 0.2856],\n",
      "        [0.4885, 0.2683, 0.2429],\n",
      "        [0.4180, 0.3013, 0.2808],\n",
      "        [0.4741, 0.2798, 0.2462],\n",
      "        [0.4248, 0.3372, 0.2380],\n",
      "        [0.3621, 0.3174, 0.3206],\n",
      "        [0.4634, 0.2764, 0.2603],\n",
      "        [0.4189, 0.3008, 0.2800],\n",
      "        [0.4375, 0.3528, 0.2097],\n",
      "        [0.4102, 0.2891, 0.3008],\n",
      "        [0.4048, 0.3042, 0.2910],\n",
      "        [0.3755, 0.3186, 0.3059],\n",
      "        [0.3188, 0.3445, 0.3367],\n",
      "        [0.2263, 0.4216, 0.3521],\n",
      "        [0.2174, 0.3735, 0.4092],\n",
      "        [0.2333, 0.3994, 0.3674],\n",
      "        [0.2737, 0.3286, 0.3975],\n",
      "        [0.2310, 0.3484, 0.4207],\n",
      "        [0.3076, 0.3394, 0.3533],\n",
      "        [0.3281, 0.3201, 0.3518],\n",
      "        [0.3853, 0.2715, 0.3433],\n",
      "        [0.2913, 0.3342, 0.3745],\n",
      "        [0.3972, 0.2673, 0.3354],\n",
      "        [0.3225, 0.2854, 0.3921],\n",
      "        [0.3152, 0.2939, 0.3911],\n",
      "        [0.2944, 0.3303, 0.3752],\n",
      "        [0.3477, 0.3303, 0.3218],\n",
      "        [0.2817, 0.3018, 0.4165],\n",
      "        [0.3755, 0.3359, 0.2883],\n",
      "        [0.3044, 0.3074, 0.3882],\n",
      "        [0.2678, 0.3677, 0.3645],\n",
      "        [0.2654, 0.2920, 0.4426],\n",
      "        [0.2512, 0.2844, 0.4641],\n",
      "        [0.3096, 0.2981, 0.3926],\n",
      "        [0.3125, 0.3699, 0.3176],\n",
      "        [0.2983, 0.3562, 0.3455],\n",
      "        [0.3069, 0.3386, 0.3545],\n",
      "        [0.2825, 0.3198, 0.3977],\n",
      "        [0.3030, 0.3159, 0.3809],\n",
      "        [0.2664, 0.3218, 0.4119],\n",
      "        [0.3125, 0.2935, 0.3940],\n",
      "        [0.2661, 0.2964, 0.4375],\n",
      "        [0.2542, 0.3840, 0.3618],\n",
      "        [0.3972, 0.3416, 0.2615],\n",
      "        [0.3513, 0.3804, 0.2683],\n",
      "        [0.2786, 0.3787, 0.3428],\n",
      "        [0.3491, 0.3354, 0.3154],\n",
      "        [0.3984, 0.2893, 0.3123],\n",
      "        [0.4243, 0.2551, 0.3208],\n",
      "        [0.3774, 0.2539, 0.3687]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.1055, -0.2795,  0.2213],\n",
      "        [-0.0027, -0.1715,  0.1221],\n",
      "        [ 0.4585, -0.3591, -0.1350],\n",
      "        [ 0.4458, -0.2732,  0.0991],\n",
      "        [ 0.2778, -0.2379, -0.2477],\n",
      "        [ 0.1858, -0.0698,  0.0632],\n",
      "        [ 0.5005,  0.1025, -0.2012],\n",
      "        [ 0.4683, -0.3149,  0.1660],\n",
      "        [ 0.0559, -0.0681,  0.1323],\n",
      "        [-0.0609, -0.0372,  0.1884],\n",
      "        [ 0.0632, -0.1500, -0.0209],\n",
      "        [-0.0298, -0.1313,  0.3022],\n",
      "        [ 0.0526, -0.1104,  0.1466],\n",
      "        [ 0.0108, -0.1288,  0.0267],\n",
      "        [ 0.1131, -0.1991, -0.2218],\n",
      "        [ 0.0252, -0.3396,  0.0107],\n",
      "        [-0.0113, -0.2090, -0.1620],\n",
      "        [ 0.0435, -0.2959, -0.0312],\n",
      "        [ 0.1492, -0.6509,  0.1575],\n",
      "        [ 0.0950, -0.5088,  0.1849],\n",
      "        [ 0.1692, -0.4426, -0.0066],\n",
      "        [-0.0409, -0.2981,  0.1066],\n",
      "        [ 0.0015, -0.3049,  0.2632],\n",
      "        [ 0.0315, -0.1689, -0.1488],\n",
      "        [-0.1409, -0.2053, -0.1037],\n",
      "        [ 0.0132, -0.1060, -0.0249],\n",
      "        [ 0.1255, -0.3145,  0.2079],\n",
      "        [ 0.0588, -0.5737,  0.1177],\n",
      "        [-0.1080, -0.2761,  0.1544],\n",
      "        [ 0.1150, -0.2878, -0.1104],\n",
      "        [ 0.1020, -0.2363, -0.1652],\n",
      "        [-0.0827, -0.2128,  0.1549],\n",
      "        [ 0.1077, -0.0299, -0.1072],\n",
      "        [ 0.1005, -0.2202,  0.0430],\n",
      "        [-0.0527, -0.0014, -0.0335],\n",
      "        [ 0.0035, -0.0880, -0.1694],\n",
      "        [ 0.0388, -0.2737, -0.2778],\n",
      "        [ 0.1456, -0.2625, -0.0166],\n",
      "        [-0.1654, -0.0346,  0.3267],\n",
      "        [-0.0988, -0.1824,  0.0999],\n",
      "        [-0.2708, -0.2181, -0.1744],\n",
      "        [-0.0624, -0.2571, -0.3096],\n",
      "        [-0.2996, -0.3469, -0.0829],\n",
      "        [ 0.0790, -0.2642,  0.0338]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3567, 0.2427, 0.4006],\n",
      "        [0.3359, 0.2837, 0.3804],\n",
      "        [0.5015, 0.2214, 0.2771],\n",
      "        [0.4558, 0.2220, 0.3223],\n",
      "        [0.4570, 0.2729, 0.2703],\n",
      "        [0.3760, 0.2913, 0.3328],\n",
      "        [0.4614, 0.3098, 0.2288],\n",
      "        [0.4553, 0.2081, 0.3367],\n",
      "        [0.3374, 0.2981, 0.3643],\n",
      "        [0.3025, 0.3096, 0.3879],\n",
      "        [0.3667, 0.2961, 0.3372],\n",
      "        [0.3032, 0.2739, 0.4226],\n",
      "        [0.3391, 0.2881, 0.3726],\n",
      "        [0.3464, 0.3013, 0.3521],\n",
      "        [0.4087, 0.2991, 0.2922],\n",
      "        [0.3730, 0.2590, 0.3677],\n",
      "        [0.3730, 0.3062, 0.3208],\n",
      "        [0.3787, 0.2698, 0.3516],\n",
      "        [0.4070, 0.1829, 0.4104],\n",
      "        [0.3787, 0.2070, 0.4143],\n",
      "        [0.4199, 0.2278, 0.3523],\n",
      "        [0.3411, 0.2637, 0.3953],\n",
      "        [0.3293, 0.2426, 0.4280],\n",
      "        [0.3770, 0.3083, 0.3147],\n",
      "        [0.3362, 0.3152, 0.3489],\n",
      "        [0.3508, 0.3115, 0.3376],\n",
      "        [0.3662, 0.2360, 0.3977],\n",
      "        [0.3857, 0.2050, 0.4092],\n",
      "        [0.3179, 0.2688, 0.4133],\n",
      "        [0.4055, 0.2710, 0.3235],\n",
      "        [0.4036, 0.2876, 0.3088],\n",
      "        [0.3179, 0.2791, 0.4031],\n",
      "        [0.3735, 0.3254, 0.3013],\n",
      "        [0.3745, 0.2717, 0.3535],\n",
      "        [0.3254, 0.3428, 0.3318],\n",
      "        [0.3630, 0.3313, 0.3054],\n",
      "        [0.4065, 0.2974, 0.2961],\n",
      "        [0.3977, 0.2644, 0.3381],\n",
      "        [0.2649, 0.3018, 0.4333],\n",
      "        [0.3186, 0.2930, 0.3884],\n",
      "        [0.3169, 0.3340, 0.3489],\n",
      "        [0.3840, 0.3162, 0.2998],\n",
      "        [0.3130, 0.2983, 0.3887],\n",
      "        [0.3752, 0.2661, 0.3586]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0114, -0.1223, -0.0216],\n",
      "        [ 0.1592, -0.0745, -0.0253],\n",
      "        [ 0.1653,  0.0958, -0.2927],\n",
      "        [ 0.2734, -0.1168,  0.2412],\n",
      "        [-0.0357,  0.1394,  0.0441],\n",
      "        [-0.0762, -0.1005, -0.0347],\n",
      "        [-0.1331, -0.0875,  0.0110],\n",
      "        [ 0.2661, -0.1948,  0.1194],\n",
      "        [ 0.0196, -0.0499, -0.0098],\n",
      "        [ 0.0824, -0.1530, -0.0704],\n",
      "        [ 0.0783, -0.1805,  0.1288],\n",
      "        [ 0.0458, -0.2009,  0.1322],\n",
      "        [ 0.2573, -0.0630,  0.0598],\n",
      "        [ 0.3762,  0.1028, -0.0104],\n",
      "        [ 0.2681,  0.1326,  0.1846],\n",
      "        [ 0.1831,  0.0843, -0.1456],\n",
      "        [ 0.1964,  0.1947,  0.0523],\n",
      "        [ 0.2522,  0.2360, -0.0800],\n",
      "        [ 0.3291,  0.1658, -0.0133],\n",
      "        [ 0.3062, -0.2339,  0.1290],\n",
      "        [ 0.0871, -0.2039, -0.2296],\n",
      "        [ 0.1826, -0.1857,  0.1624],\n",
      "        [ 0.4160, -0.2913, -0.0775],\n",
      "        [ 0.2708, -0.0787,  0.0901],\n",
      "        [ 0.2905, -0.0428, -0.0471],\n",
      "        [ 0.4741, -0.2590,  0.1032],\n",
      "        [ 0.5103, -0.4341,  0.0071],\n",
      "        [ 0.4563, -0.2600, -0.0272],\n",
      "        [ 0.3459, -0.2122,  0.0852],\n",
      "        [ 0.2883, -0.1044,  0.1682],\n",
      "        [ 0.2568, -0.2847,  0.2473],\n",
      "        [ 0.3047, -0.1995,  0.1154],\n",
      "        [ 0.4490, -0.3174, -0.0029],\n",
      "        [ 0.3135, -0.4336,  0.2283],\n",
      "        [ 0.0917, -0.5215, -0.0650],\n",
      "        [ 0.0743, -0.6406,  0.0712],\n",
      "        [ 0.1406, -0.2844, -0.2246],\n",
      "        [-0.0093, -0.3225,  0.0198],\n",
      "        [-0.1967, -0.4692,  0.1082],\n",
      "        [ 0.1459, -0.3357,  0.1486]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3467, 0.3103, 0.3430],\n",
      "        [0.3811, 0.3018, 0.3169],\n",
      "        [0.3899, 0.3635, 0.2466],\n",
      "        [0.3779, 0.2559, 0.3660],\n",
      "        [0.3054, 0.3638, 0.3308],\n",
      "        [0.3313, 0.3232, 0.3452],\n",
      "        [0.3123, 0.3269, 0.3608],\n",
      "        [0.4009, 0.2529, 0.3462],\n",
      "        [0.3445, 0.3213, 0.3345],\n",
      "        [0.3774, 0.2983, 0.3240],\n",
      "        [0.3542, 0.2734, 0.3726],\n",
      "        [0.3481, 0.2722, 0.3796],\n",
      "        [0.3926, 0.2849, 0.3223],\n",
      "        [0.4099, 0.3118, 0.2783],\n",
      "        [0.3579, 0.3127, 0.3293],\n",
      "        [0.3809, 0.3450, 0.2742],\n",
      "        [0.3491, 0.3486, 0.3022],\n",
      "        [0.3701, 0.3643, 0.2656],\n",
      "        [0.3906, 0.3318, 0.2773],\n",
      "        [0.4131, 0.2407, 0.3462],\n",
      "        [0.4038, 0.3020, 0.2942],\n",
      "        [0.3743, 0.2590, 0.3667],\n",
      "        [0.4753, 0.2344, 0.2903],\n",
      "        [0.3938, 0.2776, 0.3286],\n",
      "        [0.4116, 0.2949, 0.2937],\n",
      "        [0.4607, 0.2213, 0.3179],\n",
      "        [0.5015, 0.1951, 0.3032],\n",
      "        [0.4751, 0.2321, 0.2930],\n",
      "        [0.4268, 0.2443, 0.3289],\n",
      "        [0.3904, 0.2637, 0.3462],\n",
      "        [0.3887, 0.2262, 0.3850],\n",
      "        [0.4114, 0.2484, 0.3403],\n",
      "        [0.4758, 0.2212, 0.3030],\n",
      "        [0.4180, 0.1980, 0.3838],\n",
      "        [0.4172, 0.2260, 0.3567],\n",
      "        [0.4023, 0.1968, 0.4009],\n",
      "        [0.4260, 0.2786, 0.2957],\n",
      "        [0.3623, 0.2649, 0.3728],\n",
      "        [0.3208, 0.2443, 0.4351],\n",
      "        [0.3816, 0.2357, 0.3826]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-3.6736e-03,  4.0317e-04,  9.0881e-02],\n",
      "        [-9.9182e-02, -2.8662e-01,  2.1240e-01],\n",
      "        [ 1.8079e-01, -9.8755e-02,  6.1920e-02],\n",
      "        [ 1.1755e-01, -2.5122e-01,  1.7310e-01],\n",
      "        [ 2.2766e-01, -3.5034e-01,  4.4995e-01],\n",
      "        [-7.0114e-03, -3.1860e-01,  3.4717e-01],\n",
      "        [ 1.7200e-01, -4.2017e-01,  4.2816e-02],\n",
      "        [-8.3130e-02, -9.8022e-02,  1.1121e-01],\n",
      "        [-8.3984e-02,  1.3940e-01,  1.5991e-01],\n",
      "        [ 2.7271e-01, -2.3511e-01,  3.2440e-02],\n",
      "        [ 6.4011e-03,  3.6438e-02,  3.1219e-02],\n",
      "        [ 4.9896e-02, -1.9507e-01,  1.5100e-01],\n",
      "        [ 1.5404e-02,  8.5999e-02,  1.0883e-01],\n",
      "        [ 1.3538e-01,  1.1432e-01,  1.6342e-02],\n",
      "        [-1.1188e-01,  1.7920e-01,  2.6831e-01],\n",
      "        [-1.5381e-01,  5.1849e-02,  1.7615e-01],\n",
      "        [ 1.0187e-01, -1.0742e-02,  2.0447e-01],\n",
      "        [ 7.6904e-02,  8.3618e-02,  1.2286e-01],\n",
      "        [ 2.0337e-01, -1.2427e-01,  6.0516e-02],\n",
      "        [ 2.8613e-01, -3.0493e-01,  3.8910e-02],\n",
      "        [ 1.6089e-01, -8.0444e-02, -1.8030e-01],\n",
      "        [ 1.3745e-01, -8.3740e-02,  1.0095e-01],\n",
      "        [ 2.2119e-01, -4.0503e-01,  3.6060e-01],\n",
      "        [ 1.4185e-01, -5.0537e-01,  4.7461e-01],\n",
      "        [ 2.3462e-01, -3.3472e-01,  2.0581e-01],\n",
      "        [ 2.3645e-01, -3.5229e-01,  5.5298e-02],\n",
      "        [ 2.1655e-01, -3.5980e-02,  2.7148e-01],\n",
      "        [ 2.6758e-01, -2.8198e-01,  3.0298e-01],\n",
      "        [ 3.1836e-01, -3.7915e-01,  1.9241e-02],\n",
      "        [ 1.7053e-01, -2.9785e-01,  2.4890e-01],\n",
      "        [ 4.4580e-01, -3.2812e-01,  1.0608e-01],\n",
      "        [ 1.7200e-01, -3.3447e-01,  2.3657e-01],\n",
      "        [ 2.6099e-01, -4.6069e-01,  3.6597e-01],\n",
      "        [-2.9480e-02,  5.8868e-02,  1.8958e-01],\n",
      "        [ 2.9614e-01, -2.1826e-01,  1.2036e-01],\n",
      "        [ 1.3702e-02, -2.4384e-02,  1.5320e-01],\n",
      "        [ 1.5735e-01, -2.1973e-01, -8.4595e-02],\n",
      "        [-4.7638e-02, -1.6003e-01,  3.3423e-01],\n",
      "        [ 4.9744e-02, -1.7188e-01, -5.1537e-03],\n",
      "        [-7.7393e-02, -5.8136e-02,  1.0999e-01],\n",
      "        [ 1.2650e-02, -1.7725e-01, -1.1401e-01],\n",
      "        [ 4.7705e-01, -2.9810e-01,  2.6123e-01],\n",
      "        [ 3.5791e-01,  1.1298e-01,  2.0117e-01],\n",
      "        [ 3.3838e-01, -9.4788e-02,  2.3169e-01],\n",
      "        [ 3.5986e-01, -1.2756e-02, -1.4087e-01],\n",
      "        [ 1.8604e-01, -2.3401e-01,  8.8379e-02],\n",
      "        [ 2.7368e-01, -2.2900e-01, -3.8940e-01],\n",
      "        [ 1.9104e-01, -3.3447e-01, -3.0289e-02],\n",
      "        [ 5.0079e-02, -2.7075e-01, -2.5732e-01],\n",
      "        [-2.3645e-01, -1.0999e-01,  3.2397e-01],\n",
      "        [ 1.1987e-01,  2.1881e-02,  2.6917e-02],\n",
      "        [ 2.6074e-01, -2.8833e-01,  3.1128e-01],\n",
      "        [ 3.3667e-01, -2.6489e-01,  1.2524e-01],\n",
      "        [ 4.0137e-01, -3.5425e-01,  2.7612e-01],\n",
      "        [ 7.3584e-01, -3.6230e-01, -2.8015e-02],\n",
      "        [ 3.2861e-01, -1.8542e-01,  1.5369e-01],\n",
      "        [ 5.7568e-01, -4.0869e-01,  3.0701e-02],\n",
      "        [ 3.2031e-01, -5.2704e-02,  2.6196e-01],\n",
      "        [ 3.2690e-01, -3.8330e-01,  1.0876e-01],\n",
      "        [ 1.9421e-01, -3.6011e-02,  4.1699e-01],\n",
      "        [ 1.0651e-01, -3.2471e-01,  3.0396e-01],\n",
      "        [ 7.1678e-03,  1.8945e-01,  9.6069e-02],\n",
      "        [-1.0535e-01, -1.7188e-01,  3.6670e-01],\n",
      "        [-4.9927e-02, -2.5391e-01,  2.4829e-01],\n",
      "        [-3.4332e-02, -1.1597e-01, -1.1548e-01],\n",
      "        [ 1.5833e-01, -3.4119e-02, -1.4905e-01],\n",
      "        [ 1.0266e-01, -6.9946e-02,  1.3969e-02],\n",
      "        [ 3.3789e-01, -1.9568e-01, -3.5400e-02],\n",
      "        [ 1.4783e-01,  1.7334e-02,  1.1292e-01],\n",
      "        [ 1.8018e-01, -1.0345e-01,  1.5967e-01],\n",
      "        [ 3.7573e-01, -1.8066e-01, -1.6281e-02],\n",
      "        [ 1.2830e-01, -3.1592e-01,  8.3069e-02],\n",
      "        [ 3.8916e-01, -4.1333e-01, -2.2534e-01],\n",
      "        [ 1.9922e-01, -4.3506e-01,  7.7393e-02]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3223, 0.3235, 0.3542],\n",
      "        [0.3130, 0.2595, 0.4275],\n",
      "        [0.3782, 0.2859, 0.3359],\n",
      "        [0.3638, 0.2517, 0.3845],\n",
      "        [0.3560, 0.1997, 0.4446],\n",
      "        [0.3167, 0.2319, 0.4514],\n",
      "        [0.4111, 0.2274, 0.3613],\n",
      "        [0.3125, 0.3079, 0.3796],\n",
      "        [0.2834, 0.3545, 0.3618],\n",
      "        [0.4187, 0.2520, 0.3293],\n",
      "        [0.3271, 0.3372, 0.3354],\n",
      "        [0.3462, 0.2710, 0.3831],\n",
      "        [0.3154, 0.3384, 0.3462],\n",
      "        [0.3489, 0.3416, 0.3096],\n",
      "        [0.2632, 0.3521, 0.3848],\n",
      "        [0.2764, 0.3394, 0.3843],\n",
      "        [0.3333, 0.2976, 0.3691],\n",
      "        [0.3274, 0.3296, 0.3428],\n",
      "        [0.3865, 0.2786, 0.3350],\n",
      "        [0.4282, 0.2372, 0.3345],\n",
      "        [0.4006, 0.3147, 0.2847],\n",
      "        [0.3616, 0.2898, 0.3486],\n",
      "        [0.3726, 0.1992, 0.4282],\n",
      "        [0.3428, 0.1794, 0.4780],\n",
      "        [0.3940, 0.2230, 0.3828],\n",
      "        [0.4185, 0.2323, 0.3491],\n",
      "        [0.3530, 0.2742, 0.3728],\n",
      "        [0.3826, 0.2208, 0.3965],\n",
      "        [0.4465, 0.2223, 0.3311],\n",
      "        [0.3694, 0.2312, 0.3994],\n",
      "        [0.4602, 0.2123, 0.3276],\n",
      "        [0.3745, 0.2257, 0.3997],\n",
      "        [0.3850, 0.1871, 0.4277],\n",
      "        [0.2996, 0.3274, 0.3730],\n",
      "        [0.4104, 0.2454, 0.3442],\n",
      "        [0.3213, 0.3093, 0.3694],\n",
      "        [0.4048, 0.2776, 0.3176],\n",
      "        [0.2979, 0.2661, 0.4363],\n",
      "        [0.3640, 0.2915, 0.3445],\n",
      "        [0.3101, 0.3162, 0.3740],\n",
      "        [0.3694, 0.3054, 0.3254],\n",
      "        [0.4412, 0.2032, 0.3555],\n",
      "        [0.3792, 0.2969, 0.3242],\n",
      "        [0.3926, 0.2546, 0.3528],\n",
      "        [0.4358, 0.3003, 0.2642],\n",
      "        [0.3901, 0.2563, 0.3538],\n",
      "        [0.4717, 0.2854, 0.2430],\n",
      "        [0.4180, 0.2471, 0.3350],\n",
      "        [0.4062, 0.2949, 0.2988],\n",
      "        [0.2573, 0.2920, 0.4507],\n",
      "        [0.3550, 0.3218, 0.3235],\n",
      "        [0.3804, 0.2196, 0.4001],\n",
      "        [0.4243, 0.2324, 0.3433],\n",
      "        [0.4250, 0.1997, 0.3750],\n",
      "        [0.5557, 0.1853, 0.2588],\n",
      "        [0.4102, 0.2454, 0.3445],\n",
      "        [0.5117, 0.1913, 0.2969],\n",
      "        [0.3799, 0.2617, 0.3584],\n",
      "        [0.4355, 0.2141, 0.3503],\n",
      "        [0.3286, 0.2610, 0.4104],\n",
      "        [0.3486, 0.2266, 0.4248],\n",
      "        [0.3037, 0.3645, 0.3320],\n",
      "        [0.2825, 0.2644, 0.4531],\n",
      "        [0.3162, 0.2578, 0.4260],\n",
      "        [0.3516, 0.3240, 0.3242],\n",
      "        [0.3906, 0.3223, 0.2871],\n",
      "        [0.3628, 0.3052, 0.3320],\n",
      "        [0.4395, 0.2578, 0.3027],\n",
      "        [0.3518, 0.3086, 0.3396],\n",
      "        [0.3660, 0.2756, 0.3584],\n",
      "        [0.4446, 0.2549, 0.3005],\n",
      "        [0.3850, 0.2469, 0.3679],\n",
      "        [0.5029, 0.2253, 0.2720],\n",
      "        [0.4141, 0.2195, 0.3665]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1282, -0.0112,  0.1843],\n",
      "        [-0.0294,  0.0064,  0.0563],\n",
      "        [-0.0336,  0.0987,  0.0210],\n",
      "        [ 0.1482,  0.1090,  0.1550],\n",
      "        [ 0.0193, -0.2549,  0.2566],\n",
      "        [ 0.0640, -0.2377,  0.1957],\n",
      "        [-0.1356, -0.0638,  0.0245],\n",
      "        [-0.1821,  0.1064,  0.0477],\n",
      "        [-0.0955,  0.2332,  0.1033],\n",
      "        [ 0.2247, -0.2122, -0.0737],\n",
      "        [ 0.0614, -0.2546, -0.0017],\n",
      "        [ 0.0479, -0.1240,  0.0151],\n",
      "        [ 0.1481, -0.1868,  0.2163],\n",
      "        [ 0.1035,  0.1357,  0.0791],\n",
      "        [ 0.0411, -0.2351,  0.4431],\n",
      "        [-0.1248, -0.0358,  0.2649],\n",
      "        [-0.0580, -0.1731, -0.0732],\n",
      "        [-0.0842, -0.1304, -0.0843],\n",
      "        [ 0.1517, -0.0433, -0.0739],\n",
      "        [ 0.0274, -0.2197,  0.1515],\n",
      "        [ 0.1234, -0.1989, -0.1542],\n",
      "        [ 0.2161, -0.2554,  0.0409]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2864, 0.3220, 0.3916],\n",
      "        [0.3198, 0.3315, 0.3486],\n",
      "        [0.3127, 0.3569, 0.3303],\n",
      "        [0.3369, 0.3240, 0.3391],\n",
      "        [0.3303, 0.2510, 0.4187],\n",
      "        [0.3472, 0.2568, 0.3960],\n",
      "        [0.3079, 0.3308, 0.3613],\n",
      "        [0.2783, 0.3713, 0.3503],\n",
      "        [0.2771, 0.3848, 0.3381],\n",
      "        [0.4187, 0.2705, 0.3108],\n",
      "        [0.3748, 0.2732, 0.3518],\n",
      "        [0.3560, 0.2996, 0.3445],\n",
      "        [0.3589, 0.2568, 0.3843],\n",
      "        [0.3323, 0.3433, 0.3245],\n",
      "        [0.3074, 0.2332, 0.4595],\n",
      "        [0.2800, 0.3062, 0.4136],\n",
      "        [0.3477, 0.3098, 0.3425],\n",
      "        [0.3384, 0.3232, 0.3384],\n",
      "        [0.3816, 0.3140, 0.3044],\n",
      "        [0.3433, 0.2681, 0.3887],\n",
      "        [0.4028, 0.2920, 0.3052],\n",
      "        [0.4060, 0.2534, 0.3408]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1998, -0.0833,  0.1653],\n",
      "        [-0.1196, -0.2472,  0.0062],\n",
      "        [ 0.0280, -0.1473, -0.0795],\n",
      "        [ 0.2896, -0.2222,  0.1335],\n",
      "        [-0.1199, -0.3293, -0.1930],\n",
      "        [ 0.2421, -0.2869,  0.1204],\n",
      "        [-0.0685, -0.2659, -0.0454],\n",
      "        [ 0.2817, -0.2708,  0.2620],\n",
      "        [ 0.0650,  0.0587,  0.0884],\n",
      "        [ 0.3582, -0.1497,  0.2375],\n",
      "        [ 0.0575, -0.1565,  0.2808],\n",
      "        [ 0.5273, -0.1323,  0.2595],\n",
      "        [ 0.0906,  0.1373,  0.1327],\n",
      "        [ 0.2421, -0.1815,  0.2251],\n",
      "        [ 0.2710, -0.0668,  0.0700],\n",
      "        [ 0.3010, -0.1121, -0.0583],\n",
      "        [ 0.0196, -0.0664, -0.0444],\n",
      "        [ 0.1603, -0.2329, -0.0901],\n",
      "        [ 0.2561, -0.2417, -0.0874],\n",
      "        [ 0.1917, -0.4917, -0.0975],\n",
      "        [ 0.1105, -0.3726, -0.1164],\n",
      "        [ 0.2747, -0.6738, -0.0328]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2805, 0.3152, 0.4043],\n",
      "        [0.3318, 0.2920, 0.3762],\n",
      "        [0.3652, 0.3066, 0.3281],\n",
      "        [0.4072, 0.2441, 0.3484],\n",
      "        [0.3650, 0.2959, 0.3391],\n",
      "        [0.4041, 0.2382, 0.3579],\n",
      "        [0.3516, 0.2886, 0.3599],\n",
      "        [0.3914, 0.2252, 0.3835],\n",
      "        [0.3313, 0.3293, 0.3394],\n",
      "        [0.4019, 0.2418, 0.3562],\n",
      "        [0.3271, 0.2642, 0.4089],\n",
      "        [0.4382, 0.2266, 0.3352],\n",
      "        [0.3235, 0.3391, 0.3374],\n",
      "        [0.3792, 0.2482, 0.3728],\n",
      "        [0.3950, 0.2817, 0.3232],\n",
      "        [0.4238, 0.2803, 0.2959],\n",
      "        [0.3501, 0.3213, 0.3284],\n",
      "        [0.4077, 0.2751, 0.3174],\n",
      "        [0.4316, 0.2625, 0.3062],\n",
      "        [0.4436, 0.2240, 0.3323],\n",
      "        [0.4143, 0.2556, 0.3301],\n",
      "        [0.4712, 0.1825, 0.3464]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0964, -0.2330,  0.4709],\n",
      "        [-0.0033, -0.1458, -0.1626],\n",
      "        [ 0.1199, -0.1185, -0.0179],\n",
      "        [ 0.0281, -0.0223,  0.0263],\n",
      "        [ 0.0679, -0.1785, -0.2241],\n",
      "        [-0.1082,  0.0608,  0.0329],\n",
      "        [ 0.3352, -0.2920, -0.3779],\n",
      "        [-0.0662,  0.0094,  0.0964],\n",
      "        [-0.1558, -0.2192,  0.2415],\n",
      "        [-0.3701, -0.2986,  0.2742],\n",
      "        [-0.1254, -0.3269, -0.0629],\n",
      "        [-0.2388, -0.3372,  0.2021],\n",
      "        [-0.1705, -0.2693,  0.0864],\n",
      "        [-0.1628, -0.5020,  0.0267],\n",
      "        [-0.2241, -0.3062,  0.1311],\n",
      "        [-0.2056, -0.3928,  0.1744],\n",
      "        [ 0.0910, -0.2944, -0.1156],\n",
      "        [ 0.3787, -0.5918,  0.1372],\n",
      "        [ 0.2983, -0.2878, -0.3274],\n",
      "        [ 0.3040, -0.3440, -0.0113]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2751, 0.2399, 0.4851],\n",
      "        [0.3677, 0.3188, 0.3135],\n",
      "        [0.3760, 0.2964, 0.3276],\n",
      "        [0.3391, 0.3225, 0.3384],\n",
      "        [0.3955, 0.3091, 0.2954],\n",
      "        [0.2998, 0.3550, 0.3452],\n",
      "        [0.4941, 0.2639, 0.2421],\n",
      "        [0.3071, 0.3313, 0.3613],\n",
      "        [0.2920, 0.2739, 0.4343],\n",
      "        [0.2512, 0.2700, 0.4788],\n",
      "        [0.3469, 0.2837, 0.3694],\n",
      "        [0.2891, 0.2620, 0.4492],\n",
      "        [0.3125, 0.2832, 0.4043],\n",
      "        [0.3423, 0.2439, 0.4138],\n",
      "        [0.2988, 0.2751, 0.4260],\n",
      "        [0.3037, 0.2520, 0.4443],\n",
      "        [0.4011, 0.2727, 0.3262],\n",
      "        [0.4619, 0.1750, 0.3628],\n",
      "        [0.4783, 0.2661, 0.2559],\n",
      "        [0.4438, 0.2322, 0.3240]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0050, -0.3967,  0.2881],\n",
      "        [ 0.0992,  0.0406, -0.0964],\n",
      "        [-0.0546, -0.0285,  0.3137],\n",
      "        [-0.0542, -0.2039,  0.0339],\n",
      "        [-0.2021, -0.4321,  0.2942],\n",
      "        [ 0.0035, -0.2200,  0.2012],\n",
      "        [-0.0604, -0.2537, -0.1674],\n",
      "        [ 0.0983, -0.2712,  0.0280],\n",
      "        [-0.0980, -0.2036, -0.2191],\n",
      "        [ 0.1230, -0.2174,  0.0458],\n",
      "        [ 0.1060, -0.3218, -0.2930],\n",
      "        [ 0.1975, -0.2986,  0.0285]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3315, 0.2241, 0.4443],\n",
      "        [0.3616, 0.3411, 0.2974],\n",
      "        [0.2881, 0.2957, 0.4163],\n",
      "        [0.3386, 0.2915, 0.3699],\n",
      "        [0.2910, 0.2312, 0.4780],\n",
      "        [0.3313, 0.2649, 0.4038],\n",
      "        [0.3672, 0.3027, 0.3301],\n",
      "        [0.3811, 0.2634, 0.3552],\n",
      "        [0.3589, 0.3230, 0.3181],\n",
      "        [0.3792, 0.2698, 0.3511],\n",
      "        [0.4304, 0.2808, 0.2888],\n",
      "        [0.4077, 0.2482, 0.3442]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-1.3196e-01, -8.2703e-02,  9.3567e-02],\n",
      "        [ 2.6636e-01, -3.0103e-01,  2.4512e-01],\n",
      "        [ 2.1936e-01, -3.1714e-01,  1.7114e-01],\n",
      "        [ 2.1851e-01, -3.9941e-01,  2.8589e-01],\n",
      "        [ 1.6223e-01, -2.8418e-01, -1.1591e-01],\n",
      "        [-3.5583e-02, -1.8555e-01,  2.0309e-02],\n",
      "        [-3.1708e-02, -2.8564e-01,  3.9819e-01],\n",
      "        [ 1.4294e-01, -4.5093e-01,  1.7261e-01],\n",
      "        [ 5.3467e-02, -3.4277e-01, -1.3574e-01],\n",
      "        [ 1.2244e-01, -2.2900e-01,  1.5454e-01],\n",
      "        [-3.6530e-02, -1.6772e-01, -1.2558e-02],\n",
      "        [-2.2705e-02, -2.0496e-01,  2.4017e-02],\n",
      "        [ 6.5674e-02, -1.2024e-01,  2.9022e-02],\n",
      "        [ 1.0956e-01, -1.7200e-01, -1.3147e-01],\n",
      "        [-1.5442e-01,  1.0321e-01, -8.7830e-02],\n",
      "        [ 4.8920e-02,  5.3589e-02,  2.5562e-01],\n",
      "        [-4.1443e-02, -1.5674e-01,  1.7258e-02],\n",
      "        [-5.0171e-02, -1.2048e-01,  1.8298e-01],\n",
      "        [ 9.9731e-02, -3.1433e-02,  1.6098e-02],\n",
      "        [ 7.8613e-02,  6.1279e-02,  1.3000e-01],\n",
      "        [-1.3831e-01,  1.0229e-01, -1.5430e-01],\n",
      "        [ 1.5063e-01, -2.6245e-01,  1.0950e-01],\n",
      "        [ 2.2888e-04, -3.2166e-02,  1.2708e-01],\n",
      "        [ 6.9641e-02, -4.5471e-02,  2.7344e-01],\n",
      "        [ 3.9093e-02,  1.2512e-01,  2.0715e-01],\n",
      "        [-1.6223e-01, -5.4199e-02,  2.0081e-01],\n",
      "        [ 6.5369e-02, -4.2343e-03,  1.6284e-01],\n",
      "        [-7.1945e-03, -1.3464e-01,  7.0312e-02],\n",
      "        [-5.7190e-02, -3.9032e-02, -1.8323e-01],\n",
      "        [-1.0681e-01, -5.9845e-02, -7.8003e-02],\n",
      "        [-5.8594e-02,  1.8665e-01, -1.5381e-01],\n",
      "        [-1.1005e-01, -1.6907e-01, -3.0426e-02],\n",
      "        [-2.5977e-01, -5.6061e-02, -2.5696e-02],\n",
      "        [-1.4844e-01, -1.2335e-01,  8.4106e-02],\n",
      "        [ 9.9304e-02, -1.0736e-01, -8.0322e-02],\n",
      "        [-3.8361e-02, -3.7012e-01, -3.9734e-02],\n",
      "        [-4.0894e-02,  8.1238e-02, -2.2607e-01],\n",
      "        [-1.3220e-01, -4.3671e-02, -2.1973e-01],\n",
      "        [-3.0685e-02, -2.8857e-01, -1.7188e-01],\n",
      "        [ 9.5154e-02, -3.7061e-01, -2.9126e-01],\n",
      "        [ 3.6804e-02, -1.9458e-01, -7.3792e-02],\n",
      "        [ 1.8494e-01, -3.5278e-01, -2.2058e-01],\n",
      "        [ 9.0561e-03,  2.6050e-01,  2.1106e-01],\n",
      "        [ 4.9072e-02, -1.6907e-02,  5.6549e-02],\n",
      "        [-1.5125e-01,  1.0059e-01,  1.6492e-01],\n",
      "        [-8.4351e-02, -1.4893e-01,  3.0176e-01],\n",
      "        [-1.5295e-01, -4.1107e-02,  1.6846e-01],\n",
      "        [-1.9775e-01, -2.6880e-01,  1.9470e-01],\n",
      "        [ 1.2408e-01, -8.5144e-03,  6.7993e-02],\n",
      "        [ 4.7485e-02, -4.9774e-02,  5.1117e-02],\n",
      "        [-1.6327e-02,  1.1285e-01, -1.3098e-01],\n",
      "        [-1.7053e-01, -8.2169e-03, -2.3303e-01],\n",
      "        [-1.2128e-01,  2.0654e-01, -2.3730e-01],\n",
      "        [-1.7468e-01,  9.3750e-02, -3.8599e-01],\n",
      "        [-7.8369e-02, -1.1078e-01, -2.5220e-01],\n",
      "        [ 1.0199e-01, -2.4597e-01, -1.2463e-01],\n",
      "        [ 1.5430e-01, -3.1567e-01,  1.3397e-02],\n",
      "        [-1.2372e-01, -9.8389e-02, -7.8857e-02],\n",
      "        [-2.1240e-02, -1.4514e-01,  3.7079e-02],\n",
      "        [-1.7371e-01, -1.4160e-01,  6.3171e-02],\n",
      "        [-1.4282e-01, -4.8615e-02, -6.4453e-02],\n",
      "        [-2.2430e-03, -8.7280e-02, -2.3230e-01],\n",
      "        [ 1.4526e-02, -3.0542e-01, -3.3264e-02],\n",
      "        [ 2.1265e-01, -1.6431e-01,  2.1439e-02],\n",
      "        [-1.9934e-01, -1.9263e-01, -2.4933e-02],\n",
      "        [ 5.3192e-02, -7.0984e-02, -1.2732e-01],\n",
      "        [ 9.9411e-03, -3.0914e-02,  1.9485e-02],\n",
      "        [-4.4769e-02,  1.9238e-01, -1.5625e-01],\n",
      "        [-1.6736e-01,  1.7981e-01, -1.5247e-01],\n",
      "        [ 3.2104e-02, -1.6235e-01,  1.6556e-02],\n",
      "        [-8.3923e-02, -3.3130e-01, -2.0215e-01],\n",
      "        [ 1.4563e-01, -3.3813e-01,  7.1960e-02]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3027, 0.3181, 0.3794],\n",
      "        [0.3928, 0.2227, 0.3845],\n",
      "        [0.3940, 0.2305, 0.3755],\n",
      "        [0.3833, 0.2067, 0.4102],\n",
      "        [0.4172, 0.2668, 0.3159],\n",
      "        [0.3428, 0.2949, 0.3623],\n",
      "        [0.3018, 0.2341, 0.4639],\n",
      "        [0.3872, 0.2139, 0.3989],\n",
      "        [0.3999, 0.2690, 0.3311],\n",
      "        [0.3655, 0.2571, 0.3774],\n",
      "        [0.3447, 0.3022, 0.3530],\n",
      "        [0.3472, 0.2893, 0.3638],\n",
      "        [0.3579, 0.2971, 0.3450],\n",
      "        [0.3936, 0.2971, 0.3093],\n",
      "        [0.2974, 0.3848, 0.3179],\n",
      "        [0.3091, 0.3105, 0.3801],\n",
      "        [0.3389, 0.3020, 0.3594],\n",
      "        [0.3130, 0.2917, 0.3953],\n",
      "        [0.3577, 0.3135, 0.3289],\n",
      "        [0.3293, 0.3237, 0.3469],\n",
      "        [0.3071, 0.3906, 0.3022],\n",
      "        [0.3816, 0.2524, 0.3662],\n",
      "        [0.3223, 0.3120, 0.3657],\n",
      "        [0.3208, 0.2859, 0.3933],\n",
      "        [0.3057, 0.3330, 0.3616],\n",
      "        [0.2815, 0.3137, 0.4048],\n",
      "        [0.3296, 0.3074, 0.3633],\n",
      "        [0.3376, 0.2974, 0.3650],\n",
      "        [0.3447, 0.3511, 0.3040],\n",
      "        [0.3250, 0.3406, 0.3345],\n",
      "        [0.3137, 0.4009, 0.2852],\n",
      "        [0.3306, 0.3115, 0.3579],\n",
      "        [0.2866, 0.3513, 0.3621],\n",
      "        [0.3042, 0.3120, 0.3838],\n",
      "        [0.3774, 0.3071, 0.3154],\n",
      "        [0.3682, 0.2642, 0.3677],\n",
      "        [0.3376, 0.3816, 0.2808],\n",
      "        [0.3323, 0.3630, 0.3044],\n",
      "        [0.3787, 0.2925, 0.3289],\n",
      "        [0.4333, 0.2720, 0.2944],\n",
      "        [0.3718, 0.2952, 0.3330],\n",
      "        [0.4443, 0.2595, 0.2961],\n",
      "        [0.2849, 0.3665, 0.3486],\n",
      "        [0.3396, 0.3181, 0.3423],\n",
      "        [0.2734, 0.3516, 0.3750],\n",
      "        [0.2935, 0.2749, 0.4316],\n",
      "        [0.2859, 0.3198, 0.3943],\n",
      "        [0.2930, 0.2729, 0.4338],\n",
      "        [0.3545, 0.3105, 0.3352],\n",
      "        [0.3435, 0.3118, 0.3447],\n",
      "        [0.3301, 0.3755, 0.2944],\n",
      "        [0.3210, 0.3774, 0.3015],\n",
      "        [0.3049, 0.4233, 0.2717],\n",
      "        [0.3208, 0.4194, 0.2598],\n",
      "        [0.3560, 0.3447, 0.2993],\n",
      "        [0.3994, 0.2820, 0.3184],\n",
      "        [0.4011, 0.2507, 0.3484],\n",
      "        [0.3257, 0.3340, 0.3406],\n",
      "        [0.3398, 0.3000, 0.3601],\n",
      "        [0.3030, 0.3130, 0.3840],\n",
      "        [0.3145, 0.3455, 0.3401],\n",
      "        [0.3687, 0.3386, 0.2930],\n",
      "        [0.3733, 0.2710, 0.3557],\n",
      "        [0.3982, 0.2732, 0.3289],\n",
      "        [0.3127, 0.3149, 0.3723],\n",
      "        [0.3679, 0.3250, 0.3071],\n",
      "        [0.3367, 0.3232, 0.3401],\n",
      "        [0.3162, 0.4009, 0.2830],\n",
      "        [0.2915, 0.4126, 0.2959],\n",
      "        [0.3562, 0.2932, 0.3506],\n",
      "        [0.3745, 0.2925, 0.3328],\n",
      "        [0.3928, 0.2422, 0.3650]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0363, -0.1477,  0.0843],\n",
      "        [ 0.0264,  0.0901, -0.1699],\n",
      "        [-0.0463, -0.1235, -0.0533],\n",
      "        [ 0.2489, -0.0083, -0.0132],\n",
      "        [ 0.3899, -0.4800, -0.1687],\n",
      "        [ 0.3301, -0.5420,  0.0807],\n",
      "        [-0.0229, -0.4338,  0.1309],\n",
      "        [ 0.0029, -0.3105,  0.0317],\n",
      "        [-0.0111, -0.4175,  0.0063],\n",
      "        [-0.0223, -0.4241,  0.1246],\n",
      "        [ 0.0223, -0.6831, -0.0070],\n",
      "        [ 0.1140, -0.2922,  0.0749],\n",
      "        [ 0.2191, -0.3103,  0.1103],\n",
      "        [ 0.0409, -0.1641,  0.2468],\n",
      "        [ 0.1134, -0.0795,  0.3259],\n",
      "        [-0.0082, -0.3359,  0.2920],\n",
      "        [ 0.1769, -0.3340,  0.2573],\n",
      "        [ 0.1631, -0.4272,  0.1836],\n",
      "        [ 0.1648, -0.1755,  0.2408],\n",
      "        [ 0.1870,  0.0492,  0.0096],\n",
      "        [ 0.1816, -0.1829,  0.0495],\n",
      "        [ 0.0962, -0.1234,  0.0354],\n",
      "        [ 0.1288, -0.1803,  0.1445],\n",
      "        [-0.0957,  0.0485, -0.0020],\n",
      "        [ 0.0444, -0.2137,  0.0649],\n",
      "        [-0.0685, -0.0875,  0.0165],\n",
      "        [-0.0601, -0.0655,  0.0352],\n",
      "        [ 0.0169, -0.1295, -0.1799],\n",
      "        [ 0.1547,  0.0124, -0.1040],\n",
      "        [ 0.2385, -0.1614,  0.1221],\n",
      "        [ 0.0306, -0.0307,  0.0807],\n",
      "        [ 0.1649,  0.0856,  0.0976],\n",
      "        [ 0.0611, -0.0572,  0.1565],\n",
      "        [ 0.0924, -0.0701,  0.3345],\n",
      "        [ 0.0785, -0.2749,  0.5083],\n",
      "        [ 0.0207, -0.4783,  0.2517],\n",
      "        [ 0.4307, -0.4966, -0.0419],\n",
      "        [ 0.2510, -0.4011,  0.0143],\n",
      "        [ 0.2754, -0.5342, -0.0529],\n",
      "        [ 0.2145, -0.4341, -0.0438]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3472, 0.2888, 0.3643],\n",
      "        [0.3464, 0.3691, 0.2847],\n",
      "        [0.3425, 0.3171, 0.3403],\n",
      "        [0.3933, 0.3042, 0.3025],\n",
      "        [0.5024, 0.2104, 0.2874],\n",
      "        [0.4551, 0.1903, 0.3547],\n",
      "        [0.3535, 0.2344, 0.4121],\n",
      "        [0.3623, 0.2649, 0.3728],\n",
      "        [0.3726, 0.2482, 0.3792],\n",
      "        [0.3538, 0.2367, 0.4097],\n",
      "        [0.4058, 0.2003, 0.3940],\n",
      "        [0.3806, 0.2534, 0.3660],\n",
      "        [0.4023, 0.2369, 0.3608],\n",
      "        [0.3286, 0.2676, 0.4038],\n",
      "        [0.3267, 0.2693, 0.4041],\n",
      "        [0.3257, 0.2346, 0.4397],\n",
      "        [0.3726, 0.2235, 0.4038],\n",
      "        [0.3884, 0.2152, 0.3965],\n",
      "        [0.3584, 0.2549, 0.3867],\n",
      "        [0.3691, 0.3215, 0.3091],\n",
      "        [0.3889, 0.2703, 0.3408],\n",
      "        [0.3645, 0.2927, 0.3430],\n",
      "        [0.3635, 0.2668, 0.3694],\n",
      "        [0.3074, 0.3550, 0.3376],\n",
      "        [0.3579, 0.2766, 0.3655],\n",
      "        [0.3257, 0.3196, 0.3547],\n",
      "        [0.3232, 0.3213, 0.3555],\n",
      "        [0.3723, 0.3218, 0.3059],\n",
      "        [0.3789, 0.3286, 0.2925],\n",
      "        [0.3906, 0.2617, 0.3477],\n",
      "        [0.3342, 0.3145, 0.3513],\n",
      "        [0.3499, 0.3232, 0.3271],\n",
      "        [0.3347, 0.2974, 0.3682],\n",
      "        [0.3201, 0.2722, 0.4077],\n",
      "        [0.3086, 0.2168, 0.4744],\n",
      "        [0.3489, 0.2118, 0.4395],\n",
      "        [0.4954, 0.1959, 0.3088],\n",
      "        [0.4329, 0.2255, 0.3416],\n",
      "        [0.4619, 0.2056, 0.3325],\n",
      "        [0.4358, 0.2278, 0.3364]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1104, -0.1832,  0.1109],\n",
      "        [ 0.1718,  0.0357, -0.0682],\n",
      "        [-0.1458,  0.0823, -0.3003],\n",
      "        [-0.0715, -0.2781,  0.2397],\n",
      "        [-0.2900, -0.2893, -0.0862],\n",
      "        [-0.0128, -0.3687,  0.1735],\n",
      "        [ 0.0178, -0.1230, -0.0016],\n",
      "        [-0.0466, -0.3538,  0.2751],\n",
      "        [ 0.0771, -0.3633,  0.1721],\n",
      "        [ 0.0922, -0.4729,  0.2189],\n",
      "        [ 0.1180, -0.4138, -0.0074],\n",
      "        [ 0.2510, -0.3979,  0.1484],\n",
      "        [-0.0566, -0.3650,  0.0805],\n",
      "        [ 0.0922, -0.2983, -0.0988],\n",
      "        [ 0.0955, -0.3291, -0.1046],\n",
      "        [ 0.2340,  0.2399,  0.3301],\n",
      "        [ 0.1909,  0.2241,  0.1478],\n",
      "        [ 0.4880,  0.0160, -0.0709],\n",
      "        [ 0.3884,  0.0428, -0.0243],\n",
      "        [ 0.3625, -0.0101, -0.0149],\n",
      "        [ 0.4421, -0.0593, -0.0335],\n",
      "        [ 0.0569,  0.2864, -0.1254],\n",
      "        [ 0.0686, -0.2130, -0.1006],\n",
      "        [-0.0208,  0.0181, -0.2109],\n",
      "        [-0.2190,  0.0532, -0.2150],\n",
      "        [-0.3491,  0.2932, -0.3579],\n",
      "        [ 0.0159, -0.0406, -0.0193],\n",
      "        [-0.0211, -0.1910, -0.0580],\n",
      "        [ 0.0968, -0.2617,  0.0272],\n",
      "        [-0.0489, -0.0233,  0.2700],\n",
      "        [-0.0704, -0.1094,  0.1832],\n",
      "        [ 0.0535, -0.1707,  0.0446],\n",
      "        [ 0.0889, -0.1045,  0.0264],\n",
      "        [ 0.0795,  0.0024,  0.0059],\n",
      "        [ 0.1670, -0.0421,  0.0017],\n",
      "        [ 0.1631,  0.1222,  0.0103],\n",
      "        [ 0.3301,  0.0692,  0.1825],\n",
      "        [ 0.0457,  0.0233,  0.1580],\n",
      "        [ 0.2671,  0.1451,  0.0873],\n",
      "        [ 0.1666, -0.0784,  0.1949],\n",
      "        [ 0.0212, -0.1311,  0.2622],\n",
      "        [-0.1187, -0.1126,  0.2139],\n",
      "        [ 0.2693, -0.1349, -0.0508],\n",
      "        [-0.0847, -0.0151,  0.1220],\n",
      "        [ 0.2499, -0.1458, -0.1659],\n",
      "        [ 0.1547,  0.0258,  0.0346],\n",
      "        [ 0.2430, -0.1054, -0.2233],\n",
      "        [ 0.2563, -0.1465,  0.0806],\n",
      "        [ 0.3103,  0.0670, -0.1077],\n",
      "        [ 0.2233,  0.2449,  0.1003],\n",
      "        [ 0.1595,  0.1388, -0.1348],\n",
      "        [ 0.1440,  0.1378,  0.2318],\n",
      "        [ 0.0912,  0.1075, -0.0454],\n",
      "        [-0.2019,  0.2542,  0.0789],\n",
      "        [ 0.1890,  0.0865,  0.0354],\n",
      "        [ 0.1427,  0.0551,  0.0709],\n",
      "        [ 0.0994, -0.1058,  0.1357],\n",
      "        [ 0.1619,  0.1625,  0.0831],\n",
      "        [-0.0526,  0.1201,  0.2798],\n",
      "        [-0.0746,  0.1953,  0.3284],\n",
      "        [ 0.2383,  0.0930,  0.1377],\n",
      "        [ 0.1498,  0.0927,  0.3289],\n",
      "        [ 0.3186, -0.0317,  0.3313],\n",
      "        [ 0.3706,  0.0884,  0.4165],\n",
      "        [ 0.2296, -0.0947,  0.1185],\n",
      "        [ 0.4219, -0.1749,  0.2695],\n",
      "        [ 0.3469, -0.1791,  0.0449],\n",
      "        [ 0.4065, -0.3472,  0.2876],\n",
      "        [ 0.3032, -0.1017,  0.1449],\n",
      "        [ 0.3994, -0.3184,  0.2225],\n",
      "        [ 0.3633, -0.2874,  0.1387],\n",
      "        [ 0.2539, -0.3245,  0.3687],\n",
      "        [ 0.2368, -0.3335, -0.0222],\n",
      "        [ 0.1560, -0.2047,  0.3481],\n",
      "        [ 0.1450, -0.3293,  0.3027],\n",
      "        [ 0.3359, -0.2646,  0.4265],\n",
      "        [ 0.0875, -0.1089, -0.0560],\n",
      "        [ 0.1577, -0.4050,  0.2971],\n",
      "        [-0.0851, -0.2140, -0.1353],\n",
      "        [ 0.1208, -0.3655,  0.2585]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3147, 0.2927, 0.3926],\n",
      "        [0.3760, 0.3281, 0.2959],\n",
      "        [0.3213, 0.4036, 0.2751],\n",
      "        [0.3147, 0.2559, 0.4294],\n",
      "        [0.3098, 0.3101, 0.3799],\n",
      "        [0.3442, 0.2411, 0.4146],\n",
      "        [0.3508, 0.3049, 0.3442],\n",
      "        [0.3210, 0.2361, 0.4429],\n",
      "        [0.3645, 0.2346, 0.4009],\n",
      "        [0.3699, 0.2102, 0.4199],\n",
      "        [0.4050, 0.2379, 0.3572],\n",
      "        [0.4124, 0.2155, 0.3721],\n",
      "        [0.3469, 0.2549, 0.3979],\n",
      "        [0.3997, 0.2703, 0.3301],\n",
      "        [0.4043, 0.2644, 0.3311],\n",
      "        [0.3218, 0.3237, 0.3542],\n",
      "        [0.3342, 0.3455, 0.3201],\n",
      "        [0.4556, 0.2842, 0.2605],\n",
      "        [0.4221, 0.2986, 0.2793],\n",
      "        [0.4211, 0.2900, 0.2888],\n",
      "        [0.4490, 0.2720, 0.2791],\n",
      "        [0.3235, 0.4070, 0.2695],\n",
      "        [0.3848, 0.2903, 0.3250],\n",
      "        [0.3489, 0.3628, 0.2883],\n",
      "        [0.3015, 0.3958, 0.3027],\n",
      "        [0.2568, 0.4883, 0.2546],\n",
      "        [0.3435, 0.3247, 0.3318],\n",
      "        [0.3562, 0.3005, 0.3433],\n",
      "        [0.3801, 0.2656, 0.3545],\n",
      "        [0.2939, 0.3015, 0.4043],\n",
      "        [0.3076, 0.2959, 0.3965],\n",
      "        [0.3584, 0.2864, 0.3552],\n",
      "        [0.3618, 0.2983, 0.3398],\n",
      "        [0.3503, 0.3242, 0.3254],\n",
      "        [0.3760, 0.3052, 0.3188],\n",
      "        [0.3547, 0.3406, 0.3044],\n",
      "        [0.3799, 0.2925, 0.3276],\n",
      "        [0.3230, 0.3157, 0.3613],\n",
      "        [0.3677, 0.3254, 0.3071],\n",
      "        [0.3557, 0.2783, 0.3660],\n",
      "        [0.3193, 0.2742, 0.4065],\n",
      "        [0.2942, 0.2959, 0.4102],\n",
      "        [0.4177, 0.2788, 0.3035],\n",
      "        [0.3030, 0.3247, 0.3723],\n",
      "        [0.4287, 0.2886, 0.2827],\n",
      "        [0.3616, 0.3179, 0.3206],\n",
      "        [0.4287, 0.3025, 0.2688],\n",
      "        [0.3989, 0.2666, 0.3345],\n",
      "        [0.4094, 0.3210, 0.2695],\n",
      "        [0.3440, 0.3516, 0.3042],\n",
      "        [0.3669, 0.3596, 0.2734],\n",
      "        [0.3240, 0.3220, 0.3538],\n",
      "        [0.3462, 0.3518, 0.3020],\n",
      "        [0.2563, 0.4043, 0.3394],\n",
      "        [0.3623, 0.3269, 0.3108],\n",
      "        [0.3513, 0.3218, 0.3269],\n",
      "        [0.3506, 0.2856, 0.3638],\n",
      "        [0.3418, 0.3420, 0.3159],\n",
      "        [0.2791, 0.3318, 0.3892],\n",
      "        [0.2627, 0.3442, 0.3931],\n",
      "        [0.3611, 0.3123, 0.3267],\n",
      "        [0.3184, 0.3008, 0.3809],\n",
      "        [0.3679, 0.2593, 0.3728],\n",
      "        [0.3569, 0.2693, 0.3738],\n",
      "        [0.3821, 0.2761, 0.3418],\n",
      "        [0.4150, 0.2285, 0.3564],\n",
      "        [0.4292, 0.2537, 0.3174],\n",
      "        [0.4241, 0.1996, 0.3765],\n",
      "        [0.3967, 0.2646, 0.3386],\n",
      "        [0.4299, 0.2097, 0.3604],\n",
      "        [0.4309, 0.2249, 0.3442],\n",
      "        [0.3728, 0.2091, 0.4182],\n",
      "        [0.4280, 0.2419, 0.3303],\n",
      "        [0.3438, 0.2396, 0.4165],\n",
      "        [0.3579, 0.2228, 0.4192],\n",
      "        [0.3784, 0.2075, 0.4141],\n",
      "        [0.3721, 0.3057, 0.3223],\n",
      "        [0.3677, 0.2095, 0.4229],\n",
      "        [0.3533, 0.3105, 0.3359],\n",
      "        [0.3621, 0.2225, 0.4155]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.2993, -0.1714,  0.2571],\n",
      "        [-0.0774, -0.3010,  0.1576],\n",
      "        [-0.2439, -0.2717,  0.1216],\n",
      "        [ 0.0787, -0.2067, -0.1989],\n",
      "        [ 0.2131, -0.2401,  0.1378],\n",
      "        [ 0.2395, -0.0778,  0.0835],\n",
      "        [ 0.3357, -0.3047,  0.1178],\n",
      "        [ 0.1218, -0.0492,  0.2742],\n",
      "        [ 0.0194, -0.0079,  0.0948],\n",
      "        [ 0.0909,  0.0135,  0.1443],\n",
      "        [ 0.2502, -0.1028,  0.0554],\n",
      "        [ 0.2029, -0.1682,  0.0616],\n",
      "        [ 0.1121, -0.2448,  0.0891],\n",
      "        [ 0.1108, -0.0714,  0.2015],\n",
      "        [ 0.1166,  0.1320,  0.1231],\n",
      "        [ 0.1203, -0.0907,  0.1195],\n",
      "        [ 0.3694, -0.0549, -0.1289],\n",
      "        [ 0.0383, -0.4177, -0.0257],\n",
      "        [ 0.2705, -0.1156,  0.0011],\n",
      "        [ 0.2133, -0.1318, -0.0622],\n",
      "        [ 0.2598, -0.0275,  0.0102],\n",
      "        [ 0.4033, -0.2499, -0.0504],\n",
      "        [ 0.0356, -0.1313,  0.1143],\n",
      "        [ 0.0187, -0.2654,  0.2487],\n",
      "        [ 0.1267,  0.0060,  0.1368],\n",
      "        [-0.0884, -0.0032,  0.1787],\n",
      "        [-0.1222,  0.0734,  0.2998],\n",
      "        [-0.1119, -0.0474,  0.2194],\n",
      "        [ 0.0742, -0.2430,  0.1118],\n",
      "        [ 0.0207, -0.1565, -0.0081],\n",
      "        [-0.0655, -0.0850,  0.1466],\n",
      "        [-0.0141, -0.1443,  0.1466],\n",
      "        [ 0.1403, -0.3301,  0.0144],\n",
      "        [-0.1323, -0.1786,  0.2466],\n",
      "        [-0.1108, -0.3318,  0.3408],\n",
      "        [-0.0953, -0.3057,  0.0220],\n",
      "        [-0.1219, -0.4839, -0.1567],\n",
      "        [ 0.0635, -0.4438, -0.0066],\n",
      "        [-0.3723, -0.2629, -0.0138],\n",
      "        [-0.0231, -0.1582, -0.0466],\n",
      "        [-0.2086, -0.3113,  0.0179],\n",
      "        [ 0.0047, -0.1779,  0.0774]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2576, 0.2927, 0.4495],\n",
      "        [0.3264, 0.2610, 0.4128],\n",
      "        [0.2930, 0.2849, 0.4221],\n",
      "        [0.3984, 0.2996, 0.3020],\n",
      "        [0.3901, 0.2479, 0.3618],\n",
      "        [0.3870, 0.2817, 0.3311],\n",
      "        [0.4290, 0.2261, 0.3450],\n",
      "        [0.3325, 0.2803, 0.3872],\n",
      "        [0.3276, 0.3188, 0.3533],\n",
      "        [0.3354, 0.3105, 0.3540],\n",
      "        [0.3960, 0.2781, 0.3259],\n",
      "        [0.3909, 0.2698, 0.3394],\n",
      "        [0.3735, 0.2615, 0.3650],\n",
      "        [0.3416, 0.2847, 0.3740],\n",
      "        [0.3308, 0.3359, 0.3330],\n",
      "        [0.3560, 0.2883, 0.3557],\n",
      "        [0.4421, 0.2893, 0.2686],\n",
      "        [0.3889, 0.2465, 0.3647],\n",
      "        [0.4092, 0.2781, 0.3125],\n",
      "        [0.4053, 0.2871, 0.3076],\n",
      "        [0.3953, 0.2966, 0.3081],\n",
      "        [0.4639, 0.2415, 0.2947],\n",
      "        [0.3416, 0.2891, 0.3694],\n",
      "        [0.3320, 0.2500, 0.4180],\n",
      "        [0.3452, 0.3059, 0.3489],\n",
      "        [0.2944, 0.3208, 0.3848],\n",
      "        [0.2673, 0.3250, 0.4077],\n",
      "        [0.2891, 0.3083, 0.4026],\n",
      "        [0.3616, 0.2632, 0.3752],\n",
      "        [0.3560, 0.2981, 0.3459],\n",
      "        [0.3108, 0.3049, 0.3843],\n",
      "        [0.3276, 0.2876, 0.3848],\n",
      "        [0.3989, 0.2493, 0.3518],\n",
      "        [0.2927, 0.2795, 0.4277],\n",
      "        [0.2966, 0.2377, 0.4658],\n",
      "        [0.3408, 0.2761, 0.3831],\n",
      "        [0.3757, 0.2615, 0.3628],\n",
      "        [0.3945, 0.2375, 0.3679],\n",
      "        [0.2820, 0.3145, 0.4036],\n",
      "        [0.3508, 0.3064, 0.3428],\n",
      "        [0.3169, 0.2859, 0.3972],\n",
      "        [0.3438, 0.2864, 0.3696]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0312, -0.2151,  0.1401],\n",
      "        [ 0.0091,  0.0194,  0.1043],\n",
      "        [-0.1416, -0.0668, -0.2327],\n",
      "        [-0.0257,  0.1699,  0.0406],\n",
      "        [-0.1104,  0.1179, -0.0151],\n",
      "        [ 0.2788,  0.0578,  0.1108],\n",
      "        [ 0.1306,  0.0107,  0.3313],\n",
      "        [-0.0588,  0.3655,  0.1464],\n",
      "        [-0.0876,  0.1743, -0.1178],\n",
      "        [-0.1433,  0.2498,  0.1801],\n",
      "        [ 0.1873,  0.2815, -0.3088],\n",
      "        [ 0.0994, -0.0392,  0.0613],\n",
      "        [-0.2261,  0.3933, -0.0651],\n",
      "        [-0.1587,  0.3010, -0.0617],\n",
      "        [-0.1094,  0.3757,  0.0352],\n",
      "        [ 0.0887,  0.2325,  0.2349],\n",
      "        [ 0.1278,  0.2145, -0.1472],\n",
      "        [-0.1127,  0.4148, -0.2817],\n",
      "        [ 0.1428,  0.2939, -0.2220],\n",
      "        [-0.1155,  0.3657, -0.2947],\n",
      "        [-0.1018,  0.3228, -0.2654],\n",
      "        [-0.1459,  0.1708, -0.1824],\n",
      "        [-0.0396,  0.2595, -0.2064],\n",
      "        [ 0.2404,  0.1465, -0.1289],\n",
      "        [ 0.1121,  0.0923, -0.1620],\n",
      "        [ 0.1564,  0.0221,  0.0262],\n",
      "        [ 0.0020,  0.0361, -0.1192],\n",
      "        [ 0.0455,  0.0279,  0.0872],\n",
      "        [ 0.1873, -0.2961, -0.2439],\n",
      "        [ 0.2549, -0.2081, -0.1195]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3313, 0.2756, 0.3931],\n",
      "        [0.3215, 0.3250, 0.3535],\n",
      "        [0.3345, 0.3604, 0.3052],\n",
      "        [0.3044, 0.3704, 0.3252],\n",
      "        [0.2979, 0.3743, 0.3276],\n",
      "        [0.3777, 0.3030, 0.3193],\n",
      "        [0.3215, 0.2854, 0.3931],\n",
      "        [0.2661, 0.4070, 0.3269],\n",
      "        [0.3059, 0.3975, 0.2966],\n",
      "        [0.2588, 0.3835, 0.3577],\n",
      "        [0.3694, 0.4058, 0.2249],\n",
      "        [0.3530, 0.3074, 0.3398],\n",
      "        [0.2480, 0.4607, 0.2913],\n",
      "        [0.2712, 0.4297, 0.2991],\n",
      "        [0.2646, 0.4297, 0.3057],\n",
      "        [0.3020, 0.3486, 0.3494],\n",
      "        [0.3508, 0.3826, 0.2666],\n",
      "        [0.2825, 0.4788, 0.2386],\n",
      "        [0.3499, 0.4070, 0.2429],\n",
      "        [0.2896, 0.4685, 0.2421],\n",
      "        [0.2961, 0.4526, 0.2515],\n",
      "        [0.2998, 0.4114, 0.2891],\n",
      "        [0.3130, 0.4221, 0.2649],\n",
      "        [0.3843, 0.3499, 0.2656],\n",
      "        [0.3650, 0.3577, 0.2773],\n",
      "        [0.3633, 0.3176, 0.3191],\n",
      "        [0.3423, 0.3542, 0.3032],\n",
      "        [0.3306, 0.3247, 0.3447],\n",
      "        [0.4412, 0.2720, 0.2866],\n",
      "        [0.4316, 0.2717, 0.2969]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.3816, -0.1460,  0.1153],\n",
      "        [ 0.1306, -0.0666,  0.0831],\n",
      "        [ 0.0479, -0.1632, -0.0958],\n",
      "        [ 0.3647, -0.2617,  0.1864],\n",
      "        [ 0.1166, -0.1774, -0.1865],\n",
      "        [ 0.2866, -0.2108,  0.0553],\n",
      "        [-0.1738, -0.0643,  0.0506],\n",
      "        [ 0.1520, -0.3608,  0.1489],\n",
      "        [-0.1320, -0.2600,  0.0336],\n",
      "        [ 0.1240, -0.3054,  0.0453],\n",
      "        [ 0.0565, -0.1130, -0.0894],\n",
      "        [ 0.1076, -0.0327,  0.2239],\n",
      "        [-0.0280, -0.2175,  0.2893],\n",
      "        [ 0.1479, -0.0502,  0.2307],\n",
      "        [ 0.1715, -0.0799,  0.1509],\n",
      "        [ 0.0327,  0.0681,  0.1387],\n",
      "        [ 0.0908, -0.0837,  0.0079],\n",
      "        [ 0.0468,  0.0193,  0.2769],\n",
      "        [-0.1677, -0.2634,  0.1993],\n",
      "        [-0.1289,  0.1517,  0.1895],\n",
      "        [-0.1675,  0.0724, -0.0263],\n",
      "        [ 0.1157, -0.1600,  0.2147],\n",
      "        [ 0.1820, -0.3362,  0.0990],\n",
      "        [-0.0556, -0.0453,  0.1116],\n",
      "        [ 0.0895, -0.2563,  0.1265],\n",
      "        [ 0.0620, -0.3416,  0.2622],\n",
      "        [-0.2703, -0.1935, -0.0489],\n",
      "        [ 0.2930, -0.1884,  0.2290],\n",
      "        [ 0.0496, -0.2712, -0.1414],\n",
      "        [ 0.1560, -0.3970,  0.1392],\n",
      "        [-0.1746, -0.3499, -0.3367],\n",
      "        [ 0.2207, -0.4128,  0.1134]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2559, 0.3237, 0.4204],\n",
      "        [0.3604, 0.2959, 0.3438],\n",
      "        [0.3738, 0.3025, 0.3237],\n",
      "        [0.4216, 0.2255, 0.3528],\n",
      "        [0.4026, 0.3000, 0.2974],\n",
      "        [0.4165, 0.2532, 0.3303],\n",
      "        [0.2969, 0.3313, 0.3716],\n",
      "        [0.3853, 0.2307, 0.3840],\n",
      "        [0.3269, 0.2876, 0.3857],\n",
      "        [0.3884, 0.2527, 0.3589],\n",
      "        [0.3691, 0.3118, 0.3191],\n",
      "        [0.3342, 0.2905, 0.3755],\n",
      "        [0.3125, 0.2585, 0.4292],\n",
      "        [0.3440, 0.2822, 0.3738],\n",
      "        [0.3628, 0.2820, 0.3552],\n",
      "        [0.3176, 0.3291, 0.3533],\n",
      "        [0.3623, 0.3042, 0.3335],\n",
      "        [0.3093, 0.3010, 0.3894],\n",
      "        [0.2983, 0.2710, 0.4307],\n",
      "        [0.2703, 0.3579, 0.3716],\n",
      "        [0.2922, 0.3713, 0.3364],\n",
      "        [0.3494, 0.2651, 0.3857],\n",
      "        [0.3975, 0.2367, 0.3657],\n",
      "        [0.3132, 0.3164, 0.3704],\n",
      "        [0.3643, 0.2578, 0.3779],\n",
      "        [0.3462, 0.2312, 0.4229],\n",
      "        [0.3005, 0.3245, 0.3750],\n",
      "        [0.3914, 0.2418, 0.3669],\n",
      "        [0.3918, 0.2844, 0.3237],\n",
      "        [0.3909, 0.2249, 0.3843],\n",
      "        [0.3718, 0.3120, 0.3162],\n",
      "        [0.4116, 0.2185, 0.3699]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.5010,  0.1912, -0.0118],\n",
      "        [-0.0980,  0.2529, -0.0749],\n",
      "        [-0.0350, -0.0948,  0.0189],\n",
      "        [-0.3320,  0.1923,  0.2712],\n",
      "        [ 0.0128,  0.0284,  0.0428],\n",
      "        [ 0.0497, -0.2773,  0.2057],\n",
      "        [ 0.1676,  0.1288, -0.0961],\n",
      "        [ 0.1072, -0.0678, -0.3303],\n",
      "        [ 0.2717, -0.1107, -0.0945],\n",
      "        [-0.0613, -0.0641,  0.0291],\n",
      "        [-0.0846, -0.0765,  0.0480],\n",
      "        [-0.0071, -0.2729,  0.1149],\n",
      "        [ 0.1130, -0.0928,  0.1132],\n",
      "        [-0.0746, -0.1771,  0.2664],\n",
      "        [-0.1509, -0.0205,  0.2042],\n",
      "        [-0.2250, -0.0862, -0.0432],\n",
      "        [-0.0922,  0.1725,  0.0281],\n",
      "        [-0.1649,  0.0383,  0.0286],\n",
      "        [-0.1080,  0.1968,  0.0261],\n",
      "        [ 0.0082,  0.0938, -0.0168],\n",
      "        [ 0.0168,  0.1060, -0.0955],\n",
      "        [-0.0046,  0.0045, -0.1316],\n",
      "        [-0.1578,  0.0880, -0.0784],\n",
      "        [-0.2983,  0.2832,  0.1365],\n",
      "        [-0.3396,  0.0037, -0.0833],\n",
      "        [-0.2849,  0.0517, -0.0957],\n",
      "        [-0.4758,  0.0710, -0.1229],\n",
      "        [-0.4971,  0.0787, -0.0948],\n",
      "        [-0.2646, -0.0187, -0.2610],\n",
      "        [-0.3220,  0.0146,  0.0073],\n",
      "        [-0.3726,  0.1353, -0.0894],\n",
      "        [-0.2576,  0.0614,  0.2036],\n",
      "        [-0.0416,  0.2581,  0.1810],\n",
      "        [-0.0835,  0.1825,  0.2181],\n",
      "        [ 0.2725, -0.0878,  0.0593],\n",
      "        [ 0.1810, -0.0905, -0.0731],\n",
      "        [ 0.0824,  0.1598, -0.1722],\n",
      "        [-0.0153, -0.0847,  0.0118],\n",
      "        [-0.0157,  0.1168,  0.0676],\n",
      "        [-0.0524,  0.2030,  0.0300],\n",
      "        [-0.0433,  0.1114,  0.1022],\n",
      "        [ 0.1322,  0.0499, -0.0541],\n",
      "        [ 0.1137,  0.3550, -0.1630],\n",
      "        [ 0.0724, -0.2460,  0.2732],\n",
      "        [ 0.0341, -0.0856,  0.0702],\n",
      "        [-0.1136,  0.0519,  0.1418],\n",
      "        [-0.0839, -0.1624,  0.1785],\n",
      "        [-0.0377, -0.3198,  0.0956],\n",
      "        [-0.0449, -0.4070,  0.1759],\n",
      "        [ 0.2380, -0.3943, -0.2141],\n",
      "        [ 0.0635, -0.0941, -0.1710],\n",
      "        [ 0.3325, -0.2632, -0.3340],\n",
      "        [ 0.0934, -0.1565, -0.2849],\n",
      "        [ 0.1646, -0.3542, -0.1063],\n",
      "        [ 0.1691, -0.2666, -0.2096],\n",
      "        [ 0.1583, -0.3403, -0.1891],\n",
      "        [ 0.2286, -0.2507, -0.1052],\n",
      "        [-0.1453, -0.3413,  0.1940],\n",
      "        [ 0.0023, -0.1934, -0.0432],\n",
      "        [ 0.0260, -0.1918,  0.0698]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2161, 0.4316, 0.3523],\n",
      "        [0.2903, 0.4124, 0.2971],\n",
      "        [0.3337, 0.3142, 0.3521],\n",
      "        [0.2213, 0.3740, 0.4048],\n",
      "        [0.3284, 0.3335, 0.3384],\n",
      "        [0.3459, 0.2495, 0.4045],\n",
      "        [0.3662, 0.3523, 0.2815],\n",
      "        [0.4023, 0.3379, 0.2598],\n",
      "        [0.4209, 0.2871, 0.2920],\n",
      "        [0.3235, 0.3225, 0.3540],\n",
      "        [0.3174, 0.3201, 0.3625],\n",
      "        [0.3452, 0.2646, 0.3901],\n",
      "        [0.3555, 0.2893, 0.3555],\n",
      "        [0.3022, 0.2727, 0.4250],\n",
      "        [0.2805, 0.3196, 0.4001],\n",
      "        [0.2986, 0.3430, 0.3582],\n",
      "        [0.2915, 0.3799, 0.3286],\n",
      "        [0.2908, 0.3564, 0.3528],\n",
      "        [0.2856, 0.3875, 0.3267],\n",
      "        [0.3264, 0.3555, 0.3184],\n",
      "        [0.3347, 0.3660, 0.2993],\n",
      "        [0.3459, 0.3491, 0.3047],\n",
      "        [0.2976, 0.3804, 0.3220],\n",
      "        [0.2307, 0.4128, 0.3564],\n",
      "        [0.2700, 0.3809, 0.3491],\n",
      "        [0.2771, 0.3879, 0.3350],\n",
      "        [0.2408, 0.4163, 0.3428],\n",
      "        [0.2340, 0.4163, 0.3499],\n",
      "        [0.3047, 0.3896, 0.3057],\n",
      "        [0.2639, 0.3694, 0.3667],\n",
      "        [0.2507, 0.4165, 0.3328],\n",
      "        [0.2524, 0.3472, 0.4004],\n",
      "        [0.2778, 0.3750, 0.3472],\n",
      "        [0.2734, 0.3567, 0.3696],\n",
      "        [0.3992, 0.2783, 0.3225],\n",
      "        [0.3940, 0.3003, 0.3057],\n",
      "        [0.3501, 0.3784, 0.2715],\n",
      "        [0.3379, 0.3152, 0.3472],\n",
      "        [0.3098, 0.3535, 0.3367],\n",
      "        [0.2961, 0.3823, 0.3215],\n",
      "        [0.3008, 0.3511, 0.3479],\n",
      "        [0.3635, 0.3347, 0.3018],\n",
      "        [0.3298, 0.4199, 0.2502],\n",
      "        [0.3391, 0.2466, 0.4143],\n",
      "        [0.3420, 0.3035, 0.3545],\n",
      "        [0.2881, 0.3398, 0.3721],\n",
      "        [0.3101, 0.2866, 0.4031],\n",
      "        [0.3452, 0.2603, 0.3945],\n",
      "        [0.3398, 0.2366, 0.4236],\n",
      "        [0.4614, 0.2451, 0.2935],\n",
      "        [0.3782, 0.3230, 0.2991],\n",
      "        [0.4844, 0.2668, 0.2487],\n",
      "        [0.4058, 0.3162, 0.2781],\n",
      "        [0.4241, 0.2524, 0.3235],\n",
      "        [0.4290, 0.2773, 0.2937],\n",
      "        [0.4321, 0.2625, 0.3054],\n",
      "        [0.4282, 0.2651, 0.3066],\n",
      "        [0.3101, 0.2549, 0.4353],\n",
      "        [0.3601, 0.2959, 0.3440],\n",
      "        [0.3511, 0.2822, 0.3667]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.2021, -0.2029,  0.0637],\n",
      "        [ 0.0469, -0.1436, -0.0972],\n",
      "        [ 0.0919, -0.0271, -0.2258],\n",
      "        [-0.0665, -0.0141, -0.0544],\n",
      "        [-0.0734, -0.0619, -0.2793],\n",
      "        [ 0.1243, -0.3154, -0.0848],\n",
      "        [ 0.0013, -0.2783, -0.1700],\n",
      "        [ 0.2380, -0.5278,  0.1261],\n",
      "        [ 0.0432, -0.2085,  0.1599],\n",
      "        [ 0.0425, -0.0774,  0.0222],\n",
      "        [-0.0109, -0.1186,  0.4197],\n",
      "        [ 0.0648, -0.0487,  0.3398],\n",
      "        [ 0.1029, -0.1279,  0.1041],\n",
      "        [ 0.1965, -0.3540,  0.3203],\n",
      "        [-0.0516, -0.3882, -0.1882],\n",
      "        [ 0.2837, -0.4312, -0.0785]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3027, 0.3025, 0.3948],\n",
      "        [0.3713, 0.3071, 0.3215],\n",
      "        [0.3823, 0.3394, 0.2783],\n",
      "        [0.3262, 0.3438, 0.3301],\n",
      "        [0.3540, 0.3579, 0.2881],\n",
      "        [0.4072, 0.2625, 0.3303],\n",
      "        [0.3848, 0.2910, 0.3242],\n",
      "        [0.4238, 0.1971, 0.3789],\n",
      "        [0.3447, 0.2681, 0.3875],\n",
      "        [0.3489, 0.3093, 0.3418],\n",
      "        [0.2910, 0.2612, 0.4478],\n",
      "        [0.3115, 0.2781, 0.4102],\n",
      "        [0.3577, 0.2839, 0.3582],\n",
      "        [0.3691, 0.2129, 0.4180],\n",
      "        [0.3867, 0.2761, 0.3372],\n",
      "        [0.4575, 0.2239, 0.3186]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 1.3770e-01, -2.3254e-01,  1.4832e-01],\n",
      "        [ 8.3466e-03, -1.1499e-01, -8.0078e-02],\n",
      "        [ 1.7700e-01, -1.2988e-01, -9.2041e-02],\n",
      "        [ 5.9296e-02,  2.8976e-02,  1.9971e-01],\n",
      "        [ 7.5317e-02,  2.2986e-01,  7.4768e-02],\n",
      "        [-9.6008e-02,  2.8223e-01,  2.5586e-01],\n",
      "        [ 1.0010e-01,  9.1797e-02, -4.2603e-02],\n",
      "        [ 7.8796e-02, -1.5222e-01, -1.2225e-01],\n",
      "        [ 2.9395e-01, -2.8955e-01, -4.3530e-01],\n",
      "        [ 1.7542e-01, -8.3740e-02, -9.0759e-02],\n",
      "        [ 5.1318e-01, -1.1670e-01, -1.5686e-01],\n",
      "        [ 4.2456e-01, -4.5972e-01, -1.3901e-02],\n",
      "        [ 3.8477e-01, -2.6855e-01, -1.8689e-01],\n",
      "        [ 8.1726e-02, -4.2511e-02, -1.1761e-01],\n",
      "        [ 2.2327e-01, -4.2694e-02,  7.6294e-02],\n",
      "        [ 2.8540e-01, -4.5746e-02,  1.3660e-01],\n",
      "        [ 3.7085e-01,  1.1755e-01,  2.5192e-02],\n",
      "        [ 1.3684e-01,  5.2826e-02, -8.6609e-02],\n",
      "        [ 7.4646e-02,  8.7463e-02,  2.8610e-04],\n",
      "        [ 1.7932e-01,  1.2549e-01, -3.9124e-02],\n",
      "        [ 2.2998e-01, -2.8702e-02,  1.8555e-01],\n",
      "        [ 2.4695e-01,  1.0492e-01,  7.0129e-02],\n",
      "        [ 3.0029e-01,  2.6758e-01, -2.0166e-01],\n",
      "        [ 3.2104e-01,  1.1615e-01, -2.4811e-02],\n",
      "        [ 4.7803e-01,  1.7798e-01, -1.4368e-01],\n",
      "        [ 3.2471e-01,  1.5222e-01,  8.1726e-02],\n",
      "        [ 4.1260e-01, -4.1595e-02, -1.0040e-01],\n",
      "        [ 4.0283e-01, -1.8713e-01, -1.2817e-02],\n",
      "        [ 3.4375e-01, -1.1005e-01, -1.7960e-02],\n",
      "        [ 4.4092e-01,  5.0232e-02, -8.3862e-02],\n",
      "        [-5.7465e-02,  8.5083e-02, -1.7883e-01],\n",
      "        [ 1.1450e-01,  1.2866e-01, -1.7554e-01],\n",
      "        [-1.6577e-01,  3.3752e-02, -1.4917e-01],\n",
      "        [ 2.6031e-02,  1.1768e-01, -4.4556e-02],\n",
      "        [ 4.3121e-02, -7.7759e-02, -1.6693e-02],\n",
      "        [-1.0846e-01, -3.5095e-02, -1.9226e-01],\n",
      "        [ 1.7346e-01, -2.0776e-01, -7.6233e-02],\n",
      "        [ 9.2896e-02, -2.6172e-01, -3.5596e-01],\n",
      "        [ 3.4863e-01, -3.9453e-01, -2.6855e-01],\n",
      "        [ 2.6025e-01, -3.5571e-01, -3.3691e-01],\n",
      "        [ 3.3911e-01, -3.6841e-01, -1.9861e-01],\n",
      "        [ 1.7419e-01, -4.4116e-01, -9.8206e-02],\n",
      "        [ 3.1934e-01, -8.1360e-02, -2.9834e-01],\n",
      "        [ 1.6956e-01, -1.9690e-01,  1.0425e-01],\n",
      "        [ 9.0027e-02, -2.1362e-01,  1.1420e-01],\n",
      "        [ 1.1841e-01, -1.5491e-01, -1.1981e-01],\n",
      "        [ 2.6978e-01, -1.1682e-01,  5.2948e-03],\n",
      "        [ 2.2034e-01, -2.5464e-01,  1.9092e-01],\n",
      "        [ 2.6440e-01, -2.5610e-01, -8.2825e-02],\n",
      "        [ 1.2183e-01, -1.8054e-01,  2.0691e-01]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3701, 0.2556, 0.3743],\n",
      "        [0.3572, 0.3157, 0.3269],\n",
      "        [0.4001, 0.2944, 0.3057],\n",
      "        [0.3203, 0.3108, 0.3687],\n",
      "        [0.3159, 0.3687, 0.3157],\n",
      "        [0.2576, 0.3760, 0.3662],\n",
      "        [0.3499, 0.3469, 0.3032],\n",
      "        [0.3828, 0.3040, 0.3132],\n",
      "        [0.4902, 0.2734, 0.2363],\n",
      "        [0.3940, 0.3040, 0.3020],\n",
      "        [0.4893, 0.2605, 0.2502],\n",
      "        [0.4858, 0.2007, 0.3135],\n",
      "        [0.4797, 0.2495, 0.2708],\n",
      "        [0.3701, 0.3269, 0.3032],\n",
      "        [0.3804, 0.2915, 0.3284],\n",
      "        [0.3877, 0.2783, 0.3340],\n",
      "        [0.4026, 0.3125, 0.2849],\n",
      "        [0.3677, 0.3381, 0.2942],\n",
      "        [0.3401, 0.3445, 0.3157],\n",
      "        [0.3635, 0.3445, 0.2922],\n",
      "        [0.3665, 0.2830, 0.3506],\n",
      "        [0.3696, 0.3206, 0.3098],\n",
      "        [0.3887, 0.3762, 0.2352],\n",
      "        [0.3965, 0.3230, 0.2805],\n",
      "        [0.4390, 0.3252, 0.2357],\n",
      "        [0.3809, 0.3206, 0.2986],\n",
      "        [0.4478, 0.2842, 0.2681],\n",
      "        [0.4517, 0.2502, 0.2981],\n",
      "        [0.4290, 0.2725, 0.2986],\n",
      "        [0.4409, 0.2983, 0.2607],\n",
      "        [0.3291, 0.3794, 0.2915],\n",
      "        [0.3621, 0.3672, 0.2708],\n",
      "        [0.3088, 0.3772, 0.3140],\n",
      "        [0.3303, 0.3621, 0.3079],\n",
      "        [0.3535, 0.3132, 0.3330],\n",
      "        [0.3337, 0.3591, 0.3069],\n",
      "        [0.4062, 0.2773, 0.3164],\n",
      "        [0.4275, 0.2998, 0.2727],\n",
      "        [0.4963, 0.2361, 0.2678],\n",
      "        [0.4783, 0.2583, 0.2632],\n",
      "        [0.4814, 0.2373, 0.2812],\n",
      "        [0.4343, 0.2347, 0.3308],\n",
      "        [0.4526, 0.3032, 0.2441],\n",
      "        [0.3801, 0.2637, 0.3562],\n",
      "        [0.3621, 0.2671, 0.3708],\n",
      "        [0.3923, 0.2986, 0.3091],\n",
      "        [0.4087, 0.2776, 0.3137],\n",
      "        [0.3857, 0.2399, 0.3745],\n",
      "        [0.4346, 0.2583, 0.3071],\n",
      "        [0.3535, 0.2612, 0.3850]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0200, -0.2341,  0.1897],\n",
      "        [-0.0121, -0.0664,  0.1083],\n",
      "        [-0.0962, -0.1425, -0.0559],\n",
      "        [-0.0728, -0.0336, -0.0421],\n",
      "        [ 0.1926, -0.0844, -0.1479],\n",
      "        [ 0.0213, -0.2727,  0.0425],\n",
      "        [ 0.0737, -0.3372,  0.1674],\n",
      "        [-0.0369, -0.2917, -0.0186],\n",
      "        [ 0.0654, -0.2137, -0.1920],\n",
      "        [ 0.1836, -0.2798, -0.0173],\n",
      "        [ 0.1152, -0.1036,  0.0334],\n",
      "        [ 0.2006, -0.4856,  0.2522],\n",
      "        [ 0.2888, -0.2925,  0.2346],\n",
      "        [-0.0287, -0.2142,  0.3674],\n",
      "        [-0.0086, -0.0193,  0.2712],\n",
      "        [-0.1880, -0.1393, -0.0274],\n",
      "        [-0.0959, -0.1493,  0.0562],\n",
      "        [ 0.0483, -0.1708,  0.2732],\n",
      "        [-0.0076, -0.2883, -0.0569],\n",
      "        [ 0.1096, -0.3782,  0.2529]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3289, 0.2654, 0.4055],\n",
      "        [0.3252, 0.3081, 0.3667],\n",
      "        [0.3337, 0.3186, 0.3474],\n",
      "        [0.3257, 0.3386, 0.3357],\n",
      "        [0.4050, 0.3069, 0.2881],\n",
      "        [0.3613, 0.2693, 0.3691],\n",
      "        [0.3621, 0.2401, 0.3977],\n",
      "        [0.3579, 0.2773, 0.3645],\n",
      "        [0.3953, 0.2991, 0.3057],\n",
      "        [0.4087, 0.2571, 0.3342],\n",
      "        [0.3669, 0.2949, 0.3381],\n",
      "        [0.3911, 0.1969, 0.4119],\n",
      "        [0.3989, 0.2231, 0.3779],\n",
      "        [0.3015, 0.2505, 0.4480],\n",
      "        [0.3020, 0.2986, 0.3994],\n",
      "        [0.3101, 0.3257, 0.3643],\n",
      "        [0.3213, 0.3047, 0.3740],\n",
      "        [0.3274, 0.2629, 0.4099],\n",
      "        [0.3694, 0.2791, 0.3516],\n",
      "        [0.3613, 0.2218, 0.4170]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.1479, -0.4670,  0.2764],\n",
      "        [ 0.1544, -0.5737,  0.3533],\n",
      "        [ 0.0538, -0.3674,  0.2214],\n",
      "        [ 0.1503, -0.1719,  0.1349],\n",
      "        [ 0.0338, -0.1473,  0.0638],\n",
      "        [ 0.0825, -0.1604, -0.0655],\n",
      "        [ 0.1159, -0.1899,  0.0352],\n",
      "        [ 0.3435,  0.0302,  0.1053],\n",
      "        [ 0.3911, -0.2069,  0.4314],\n",
      "        [ 0.1328, -0.1694,  0.2988],\n",
      "        [ 0.2935, -0.2981, -0.0548],\n",
      "        [ 0.3232, -0.2661,  0.2094],\n",
      "        [ 0.2737, -0.2189,  0.0937],\n",
      "        [ 0.2795, -0.3401,  0.1447],\n",
      "        [ 0.1964, -0.5449,  0.1367],\n",
      "        [ 0.1500, -0.5308,  0.0084],\n",
      "        [ 0.1881, -0.4795, -0.0951],\n",
      "        [ 0.2551, -0.2874,  0.2693],\n",
      "        [ 0.2382, -0.4541,  0.0338],\n",
      "        [ 0.2974, -0.2068, -0.2059],\n",
      "        [ 0.1351, -0.1284, -0.2092],\n",
      "        [ 0.0735, -0.0776,  0.0817],\n",
      "        [ 0.3003, -0.1250, -0.1687],\n",
      "        [ 0.2693, -0.1010,  0.1631],\n",
      "        [ 0.0471,  0.1877, -0.0318],\n",
      "        [ 0.0864, -0.1442,  0.4009],\n",
      "        [-0.0592, -0.0053,  0.2241],\n",
      "        [-0.0804, -0.0240,  0.4172],\n",
      "        [ 0.0441,  0.2050,  0.2732],\n",
      "        [-0.0526, -0.0070,  0.2362],\n",
      "        [-0.0920,  0.1329, -0.0135],\n",
      "        [-0.1018,  0.0013,  0.1262],\n",
      "        [-0.0105,  0.1504,  0.0418],\n",
      "        [-0.0263, -0.1732,  0.0997],\n",
      "        [-0.0638, -0.1837, -0.0840],\n",
      "        [ 0.2041, -0.2264,  0.0558],\n",
      "        [-0.0278, -0.1771,  0.0410],\n",
      "        [-0.0159, -0.0595,  0.1026],\n",
      "        [-0.0843,  0.1307,  0.0086],\n",
      "        [ 0.0207,  0.0028, -0.1748],\n",
      "        [-0.1272,  0.1577,  0.0630],\n",
      "        [-0.0291, -0.3208,  0.0476],\n",
      "        [ 0.2510, -0.2690,  0.1459],\n",
      "        [ 0.0995, -0.3647,  0.1782],\n",
      "        [-0.0040, -0.1793,  0.1565],\n",
      "        [ 0.0507, -0.2433,  0.0891],\n",
      "        [-0.0028, -0.0833, -0.1912],\n",
      "        [ 0.0723, -0.2847, -0.1006],\n",
      "        [ 0.1488, -0.0798, -0.2549],\n",
      "        [ 0.2681, -0.2281,  0.2053],\n",
      "        [ 0.1608, -0.0030,  0.2256],\n",
      "        [-0.0905, -0.0390,  0.0458],\n",
      "        [-0.0709, -0.0143, -0.1571],\n",
      "        [ 0.0908, -0.1152,  0.1384],\n",
      "        [ 0.1168, -0.1212,  0.0141],\n",
      "        [ 0.0746, -0.1675, -0.0862],\n",
      "        [ 0.1727,  0.0018, -0.1283],\n",
      "        [ 0.1056, -0.2263,  0.2292],\n",
      "        [ 0.2103, -0.2688, -0.0665],\n",
      "        [ 0.2001, -0.1857,  0.1926]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3735, 0.2019, 0.4246],\n",
      "        [0.3699, 0.1786, 0.4514],\n",
      "        [0.3523, 0.2312, 0.4165],\n",
      "        [0.3691, 0.2673, 0.3635],\n",
      "        [0.3491, 0.2913, 0.3596],\n",
      "        [0.3777, 0.2964, 0.3259],\n",
      "        [0.3760, 0.2771, 0.3469],\n",
      "        [0.3970, 0.2903, 0.3127],\n",
      "        [0.3860, 0.2123, 0.4019],\n",
      "        [0.3425, 0.2532, 0.4043],\n",
      "        [0.4426, 0.2450, 0.3125],\n",
      "        [0.4087, 0.2267, 0.3647],\n",
      "        [0.4087, 0.2498, 0.3416],\n",
      "        [0.4146, 0.2231, 0.3623],\n",
      "        [0.4136, 0.1970, 0.3894],\n",
      "        [0.4211, 0.2133, 0.3655],\n",
      "        [0.4412, 0.2263, 0.3325],\n",
      "        [0.3853, 0.2240, 0.3909],\n",
      "        [0.4319, 0.2161, 0.3521],\n",
      "        [0.4529, 0.2734, 0.2737],\n",
      "        [0.4038, 0.3103, 0.2861],\n",
      "        [0.3486, 0.2998, 0.3516],\n",
      "        [0.4387, 0.2869, 0.2744],\n",
      "        [0.3862, 0.2666, 0.3472],\n",
      "        [0.3252, 0.3743, 0.3005],\n",
      "        [0.3162, 0.2510, 0.4329],\n",
      "        [0.2957, 0.3120, 0.3923],\n",
      "        [0.2700, 0.2856, 0.4441],\n",
      "        [0.2915, 0.3423, 0.3665],\n",
      "        [0.2957, 0.3096, 0.3948],\n",
      "        [0.3000, 0.3755, 0.3245],\n",
      "        [0.2971, 0.3296, 0.3733],\n",
      "        [0.3098, 0.3638, 0.3264],\n",
      "        [0.3335, 0.2881, 0.3784],\n",
      "        [0.3489, 0.3093, 0.3418],\n",
      "        [0.3979, 0.2588, 0.3433],\n",
      "        [0.3411, 0.2937, 0.3652],\n",
      "        [0.3245, 0.3105, 0.3652],\n",
      "        [0.2996, 0.3716, 0.3289],\n",
      "        [0.3564, 0.3501, 0.2932],\n",
      "        [0.2825, 0.3757, 0.3418],\n",
      "        [0.3538, 0.2642, 0.3821],\n",
      "        [0.4009, 0.2383, 0.3608],\n",
      "        [0.3689, 0.2319, 0.3992],\n",
      "        [0.3318, 0.2786, 0.3896],\n",
      "        [0.3591, 0.2676, 0.3733],\n",
      "        [0.3635, 0.3354, 0.3010],\n",
      "        [0.3936, 0.2754, 0.3311],\n",
      "        [0.4060, 0.3230, 0.2710],\n",
      "        [0.3926, 0.2389, 0.3687],\n",
      "        [0.3430, 0.2913, 0.3660],\n",
      "        [0.3125, 0.3291, 0.3582],\n",
      "        [0.3362, 0.3557, 0.3083],\n",
      "        [0.3494, 0.2842, 0.3665],\n",
      "        [0.3716, 0.2930, 0.3354],\n",
      "        [0.3794, 0.2979, 0.3230],\n",
      "        [0.3872, 0.3264, 0.2866],\n",
      "        [0.3511, 0.2520, 0.3972],\n",
      "        [0.4207, 0.2605, 0.3188],\n",
      "        [0.3743, 0.2544, 0.3713]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0284, -0.1755,  0.1755],\n",
      "        [-0.0307, -0.2656,  0.2529],\n",
      "        [ 0.0625, -0.1858, -0.0707],\n",
      "        [ 0.2435, -0.2539,  0.2150],\n",
      "        [ 0.0799, -0.0229,  0.0884],\n",
      "        [ 0.3618, -0.0040,  0.0793],\n",
      "        [ 0.2271, -0.1045,  0.3325],\n",
      "        [ 0.1537, -0.0619,  0.1879],\n",
      "        [ 0.0225,  0.0117, -0.0254],\n",
      "        [-0.0297, -0.0944,  0.2435],\n",
      "        [ 0.0640, -0.1611, -0.0446],\n",
      "        [ 0.1229, -0.1875,  0.3169]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3237, 0.2793, 0.3970],\n",
      "        [0.3206, 0.2534, 0.4258],\n",
      "        [0.3765, 0.2937, 0.3296],\n",
      "        [0.3877, 0.2357, 0.3767],\n",
      "        [0.3435, 0.3101, 0.3464],\n",
      "        [0.4087, 0.2834, 0.3081],\n",
      "        [0.3535, 0.2537, 0.3928],\n",
      "        [0.3521, 0.2837, 0.3643],\n",
      "        [0.3398, 0.3362, 0.3240],\n",
      "        [0.3076, 0.2883, 0.4043],\n",
      "        [0.3711, 0.2961, 0.3328],\n",
      "        [0.3394, 0.2488, 0.4119]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-6.8550e-03, -7.3486e-02,  2.3047e-01],\n",
      "        [-2.4338e-02, -1.6586e-02,  4.6631e-02],\n",
      "        [-1.2659e-01,  3.3643e-01, -4.0865e-04],\n",
      "        [ 4.4250e-02,  2.6489e-01, -1.4490e-01],\n",
      "        [ 1.6346e-03,  3.2166e-02, -2.0007e-01],\n",
      "        [ 1.5393e-01,  1.5479e-01, -1.6693e-02],\n",
      "        [ 5.3802e-02, -1.1987e-01, -8.9783e-02],\n",
      "        [ 5.6580e-02, -2.8351e-02, -1.7480e-01],\n",
      "        [-1.4626e-02, -9.8267e-02,  1.8036e-02],\n",
      "        [-1.2341e-01,  5.3787e-03,  3.5278e-01],\n",
      "        [-5.1056e-02, -6.9153e-02,  1.4392e-01],\n",
      "        [ 1.4185e-01,  5.1910e-02,  2.7124e-01],\n",
      "        [-1.2457e-01,  8.0505e-02,  3.4454e-02],\n",
      "        [ 2.4792e-01, -2.1704e-01,  2.6123e-01],\n",
      "        [-1.4992e-03, -9.3262e-02,  2.6196e-01],\n",
      "        [ 8.5510e-02, -1.1688e-01, -4.5837e-02],\n",
      "        [ 1.3574e-01, -6.7505e-02, -9.6359e-03],\n",
      "        [ 4.1211e-01, -1.5186e-01,  2.3535e-01],\n",
      "        [ 3.9868e-01,  9.0942e-02,  2.6489e-02],\n",
      "        [ 5.0830e-01,  4.4342e-02,  4.6082e-02],\n",
      "        [ 2.3145e-01,  7.1838e-02,  3.1714e-01],\n",
      "        [ 7.7087e-02,  4.5288e-02,  1.4844e-01],\n",
      "        [ 1.5710e-01, -2.6367e-01,  4.2633e-02],\n",
      "        [ 3.5248e-02,  1.3855e-01,  1.7322e-01],\n",
      "        [ 1.1133e-01,  4.4409e-01, -1.1053e-01],\n",
      "        [ 1.7120e-02,  4.1846e-01,  7.4280e-02],\n",
      "        [ 1.5845e-01,  1.9409e-01, -3.4973e-02],\n",
      "        [ 2.3041e-02,  1.5759e-01, -8.0200e-02],\n",
      "        [-7.9529e-02,  3.6957e-02,  5.1056e-02],\n",
      "        [-2.1216e-01,  6.6147e-03,  1.2213e-01],\n",
      "        [-8.3435e-02,  5.2917e-02,  2.0923e-01],\n",
      "        [ 2.6294e-01,  2.7485e-03,  1.9867e-02],\n",
      "        [ 1.7773e-01,  1.0425e-01, -7.3608e-02],\n",
      "        [ 1.4978e-01,  4.3335e-02, -7.3059e-02],\n",
      "        [-1.7059e-02,  2.1631e-01, -2.1008e-01],\n",
      "        [-1.9995e-01,  4.2627e-01, -7.1182e-03],\n",
      "        [-8.5297e-03,  1.6370e-01,  5.9814e-02],\n",
      "        [-7.7026e-02,  2.4329e-01, -7.5867e-02],\n",
      "        [ 1.3208e-01, -1.8726e-01,  1.3770e-01],\n",
      "        [ 8.7036e-02, -2.4817e-01,  2.1143e-01],\n",
      "        [-1.5137e-01, -9.8572e-03, -8.2092e-02],\n",
      "        [-2.8320e-01,  2.5848e-02,  1.2256e-01],\n",
      "        [ 6.0425e-02, -2.2705e-01,  5.3192e-02],\n",
      "        [-8.0566e-02, -9.8572e-02,  1.0333e-01],\n",
      "        [-5.4077e-02,  3.2812e-01,  1.7358e-01],\n",
      "        [-8.6304e-02,  4.8755e-01, -1.0217e-01],\n",
      "        [-9.2010e-03,  2.7368e-01, -6.2012e-02],\n",
      "        [-1.0107e-01,  2.6245e-01, -1.6528e-01],\n",
      "        [ 1.4294e-01, -1.0431e-01, -2.1008e-01],\n",
      "        [ 3.3765e-01, -2.2546e-01, -1.6211e-01],\n",
      "        [ 3.1348e-01, -1.0706e-01, -3.5858e-02],\n",
      "        [ 2.7881e-01, -2.8223e-01, -1.2146e-01],\n",
      "        [ 4.4238e-01, -8.6182e-02, -1.4087e-01],\n",
      "        [ 3.1567e-01, -2.3328e-01, -2.6062e-02],\n",
      "        [ 2.3230e-01, -2.5659e-01, -1.3306e-01],\n",
      "        [ 1.2964e-01, -3.1201e-01,  7.4463e-02]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3123, 0.2920, 0.3958],\n",
      "        [0.3245, 0.3271, 0.3484],\n",
      "        [0.2686, 0.4268, 0.3047],\n",
      "        [0.3252, 0.4055, 0.2693],\n",
      "        [0.3511, 0.3621, 0.2869],\n",
      "        [0.3516, 0.3518, 0.2964],\n",
      "        [0.3694, 0.3105, 0.3201],\n",
      "        [0.3687, 0.3386, 0.2925],\n",
      "        [0.3386, 0.3115, 0.3499],\n",
      "        [0.2668, 0.3035, 0.4297],\n",
      "        [0.3127, 0.3071, 0.3801],\n",
      "        [0.3276, 0.2996, 0.3728],\n",
      "        [0.2942, 0.3611, 0.3447],\n",
      "        [0.3787, 0.2378, 0.3835],\n",
      "        [0.3113, 0.2839, 0.4050],\n",
      "        [0.3713, 0.3032, 0.3254],\n",
      "        [0.3730, 0.3044, 0.3225],\n",
      "        [0.4155, 0.2363, 0.3481],\n",
      "        [0.4126, 0.3032, 0.2842],\n",
      "        [0.4426, 0.2783, 0.2788],\n",
      "        [0.3398, 0.2898, 0.3704],\n",
      "        [0.3286, 0.3184, 0.3530],\n",
      "        [0.3923, 0.2576, 0.3499],\n",
      "        [0.3071, 0.3406, 0.3525],\n",
      "        [0.3130, 0.4365, 0.2507],\n",
      "        [0.2815, 0.4204, 0.2981],\n",
      "        [0.3496, 0.3623, 0.2881],\n",
      "        [0.3284, 0.3755, 0.2961],\n",
      "        [0.3064, 0.3442, 0.3491],\n",
      "        [0.2747, 0.3418, 0.3835],\n",
      "        [0.2869, 0.3289, 0.3843],\n",
      "        [0.3914, 0.3018, 0.3069],\n",
      "        [0.3694, 0.3433, 0.2874],\n",
      "        [0.3704, 0.3330, 0.2964],\n",
      "        [0.3240, 0.4089, 0.2671],\n",
      "        [0.2449, 0.4580, 0.2969],\n",
      "        [0.3069, 0.3645, 0.3286],\n",
      "        [0.2959, 0.4077, 0.2964],\n",
      "        [0.3660, 0.2659, 0.3682],\n",
      "        [0.3511, 0.2512, 0.3977],\n",
      "        [0.3103, 0.3574, 0.3325],\n",
      "        [0.2588, 0.3525, 0.3884],\n",
      "        [0.3645, 0.2734, 0.3621],\n",
      "        [0.3140, 0.3083, 0.3774],\n",
      "        [0.2688, 0.3938, 0.3374],\n",
      "        [0.2661, 0.4722, 0.2617],\n",
      "        [0.3052, 0.4050, 0.2896],\n",
      "        [0.2961, 0.4260, 0.2778],\n",
      "        [0.4026, 0.3145, 0.2830],\n",
      "        [0.4595, 0.2617, 0.2788],\n",
      "        [0.4233, 0.2781, 0.2986],\n",
      "        [0.4463, 0.2546, 0.2991],\n",
      "        [0.4656, 0.2744, 0.2598],\n",
      "        [0.4370, 0.2524, 0.3105],\n",
      "        [0.4333, 0.2659, 0.3008],\n",
      "        [0.3862, 0.2483, 0.3655]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1458, -0.3308,  0.1033],\n",
      "        [-0.0443,  0.1096, -0.2666],\n",
      "        [ 0.1672,  0.0599, -0.3909],\n",
      "        [ 0.1923,  0.0966, -0.1735],\n",
      "        [-0.0192,  0.1028, -0.1798],\n",
      "        [ 0.1553, -0.1808,  0.2218],\n",
      "        [ 0.2991, -0.0391,  0.2190],\n",
      "        [-0.0212,  0.0501, -0.0312],\n",
      "        [ 0.1891,  0.0670, -0.2428],\n",
      "        [-0.0914,  0.0145,  0.0637],\n",
      "        [-0.0842, -0.3281, -0.1584],\n",
      "        [ 0.1099, -0.1808,  0.0381]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3210, 0.2668, 0.4119],\n",
      "        [0.3372, 0.3931, 0.2698],\n",
      "        [0.4048, 0.3635, 0.2317],\n",
      "        [0.3843, 0.3491, 0.2666],\n",
      "        [0.3354, 0.3789, 0.2856],\n",
      "        [0.3594, 0.2568, 0.3840],\n",
      "        [0.3794, 0.2705, 0.3501],\n",
      "        [0.3264, 0.3506, 0.3232],\n",
      "        [0.3945, 0.3491, 0.2561],\n",
      "        [0.3049, 0.3391, 0.3562],\n",
      "        [0.3687, 0.2888, 0.3423],\n",
      "        [0.3733, 0.2791, 0.3474]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.2007, -0.0259,  0.2308],\n",
      "        [ 0.1851, -0.0553,  0.3572],\n",
      "        [ 0.0523, -0.1897, -0.1107],\n",
      "        [ 0.1825, -0.0674,  0.0279],\n",
      "        [-0.1149, -0.0075, -0.1130],\n",
      "        [ 0.1360,  0.1277, -0.2233],\n",
      "        [ 0.0312, -0.1420, -0.0416],\n",
      "        [-0.0351, -0.0060, -0.2097],\n",
      "        [ 0.1475,  0.0869,  0.1012],\n",
      "        [ 0.0476,  0.2100,  0.0615],\n",
      "        [ 0.0508, -0.0883,  0.0764],\n",
      "        [-0.1254,  0.1584,  0.1462],\n",
      "        [-0.0798,  0.1868, -0.1270],\n",
      "        [ 0.0116,  0.1176,  0.1681],\n",
      "        [-0.0336,  0.2031, -0.0020],\n",
      "        [-0.2167,  0.2917,  0.0400],\n",
      "        [-0.2262,  0.2042, -0.0659],\n",
      "        [ 0.0729, -0.0672,  0.0814],\n",
      "        [-0.0652,  0.0213, -0.1531],\n",
      "        [-0.0565,  0.0173, -0.0523],\n",
      "        [ 0.2015,  0.1799,  0.2141],\n",
      "        [ 0.0801,  0.1642,  0.1371],\n",
      "        [-0.0120,  0.2170, -0.0438],\n",
      "        [ 0.1177,  0.2825,  0.0784],\n",
      "        [-0.0227, -0.0078,  0.1593],\n",
      "        [-0.2778,  0.1821,  0.1295],\n",
      "        [ 0.0035,  0.1194, -0.0031],\n",
      "        [-0.1001,  0.1661, -0.2837],\n",
      "        [-0.2222, -0.0367, -0.1125],\n",
      "        [-0.2961, -0.0482, -0.0359],\n",
      "        [-0.3215, -0.0367, -0.1223],\n",
      "        [-0.1053, -0.0781, -0.0134],\n",
      "        [-0.2438, -0.4036, -0.1180],\n",
      "        [-0.0076, -0.2030, -0.0366]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2681, 0.3193, 0.4126],\n",
      "        [0.3362, 0.2644, 0.3994],\n",
      "        [0.3796, 0.2979, 0.3225],\n",
      "        [0.3794, 0.2954, 0.3250],\n",
      "        [0.3210, 0.3574, 0.3215],\n",
      "        [0.3718, 0.3687, 0.2595],\n",
      "        [0.3608, 0.3035, 0.3354],\n",
      "        [0.3486, 0.3589, 0.2927],\n",
      "        [0.3452, 0.3250, 0.3296],\n",
      "        [0.3135, 0.3687, 0.3179],\n",
      "        [0.3452, 0.3005, 0.3542],\n",
      "        [0.2747, 0.3647, 0.3604],\n",
      "        [0.3069, 0.4006, 0.2927],\n",
      "        [0.3047, 0.3389, 0.3564],\n",
      "        [0.3032, 0.3840, 0.3127],\n",
      "        [0.2529, 0.4204, 0.3269],\n",
      "        [0.2695, 0.4143, 0.3162],\n",
      "        [0.3474, 0.3020, 0.3503],\n",
      "        [0.3328, 0.3628, 0.3047],\n",
      "        [0.3247, 0.3494, 0.3259],\n",
      "        [0.3342, 0.3271, 0.3386],\n",
      "        [0.3179, 0.3457, 0.3364],\n",
      "        [0.3101, 0.3896, 0.3003],\n",
      "        [0.3184, 0.3755, 0.3062],\n",
      "        [0.3110, 0.3157, 0.3730],\n",
      "        [0.2446, 0.3877, 0.3677],\n",
      "        [0.3208, 0.3604, 0.3188],\n",
      "        [0.3188, 0.4160, 0.2654],\n",
      "        [0.3013, 0.3625, 0.3362],\n",
      "        [0.2795, 0.3582, 0.3625],\n",
      "        [0.2817, 0.3745, 0.3438],\n",
      "        [0.3201, 0.3289, 0.3508],\n",
      "        [0.3350, 0.2854, 0.3796],\n",
      "        [0.3579, 0.2944, 0.3477]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1132, -0.2455, -0.1284],\n",
      "        [-0.0602,  0.3245, -0.0759],\n",
      "        [ 0.3276,  0.1515, -0.1724],\n",
      "        [ 0.2620,  0.1345, -0.1088],\n",
      "        [ 0.1061,  0.1836, -0.0885],\n",
      "        [ 0.0688,  0.2114,  0.0031],\n",
      "        [ 0.2852, -0.0102, -0.1123],\n",
      "        [ 0.3433, -0.0413,  0.0201],\n",
      "        [ 0.1709, -0.0766, -0.1003],\n",
      "        [ 0.1338, -0.0844, -0.1648],\n",
      "        [ 0.1859,  0.0671, -0.1228],\n",
      "        [ 0.1615, -0.1090, -0.1307],\n",
      "        [ 0.2729, -0.0742, -0.1989],\n",
      "        [-0.0403,  0.0610, -0.2549],\n",
      "        [ 0.2053, -0.1495, -0.2566],\n",
      "        [ 0.1670,  0.0897, -0.3372],\n",
      "        [ 0.4802, -0.0268, -0.4431],\n",
      "        [ 0.2739, -0.0772,  0.0523],\n",
      "        [ 0.3176, -0.2100, -0.3252],\n",
      "        [ 0.2074,  0.0281,  0.0983]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3496, 0.3062, 0.3442],\n",
      "        [0.2896, 0.4253, 0.2852],\n",
      "        [0.4089, 0.3430, 0.2480],\n",
      "        [0.3889, 0.3425, 0.2686],\n",
      "        [0.3445, 0.3721, 0.2834],\n",
      "        [0.3237, 0.3733, 0.3030],\n",
      "        [0.4138, 0.3081, 0.2781],\n",
      "        [0.4158, 0.2832, 0.3010],\n",
      "        [0.3933, 0.3069, 0.2998],\n",
      "        [0.3928, 0.3159, 0.2915],\n",
      "        [0.3813, 0.3386, 0.2800],\n",
      "        [0.3984, 0.3040, 0.2976],\n",
      "        [0.4290, 0.3032, 0.2676],\n",
      "        [0.3433, 0.3799, 0.2769],\n",
      "        [0.4290, 0.3008, 0.2703],\n",
      "        [0.3953, 0.3660, 0.2388],\n",
      "        [0.5000, 0.3013, 0.1986],\n",
      "        [0.3992, 0.2810, 0.3198],\n",
      "        [0.4727, 0.2788, 0.2485],\n",
      "        [0.3660, 0.3059, 0.3281]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-2.2046e-01,  4.3213e-02,  3.8965e-01],\n",
      "        [-5.4932e-02,  1.4282e-01,  2.5269e-01],\n",
      "        [ 2.7710e-02,  6.2195e-02,  5.0087e-03],\n",
      "        [ 6.8481e-02,  1.4978e-01,  1.7358e-01],\n",
      "        [ 1.0689e-02,  1.9080e-01,  2.1643e-01],\n",
      "        [ 5.9448e-02,  5.6549e-02,  6.7993e-02],\n",
      "        [ 1.0571e-01,  1.4380e-01, -2.3572e-01],\n",
      "        [-4.6661e-02,  5.4474e-02, -1.2154e-02],\n",
      "        [ 1.9153e-01,  2.0288e-01, -2.9370e-01],\n",
      "        [-9.5520e-03,  1.7065e-01,  2.2534e-01],\n",
      "        [ 3.7781e-02, -2.8052e-01, -5.4932e-02],\n",
      "        [-6.6910e-03, -1.0278e-01, -5.7007e-02],\n",
      "        [ 3.8110e-01, -1.6870e-01, -3.3960e-01],\n",
      "        [-3.8195e-04,  6.7749e-02,  7.7667e-03],\n",
      "        [-1.6003e-01, -1.6406e-01, -5.6091e-02],\n",
      "        [-2.6947e-02, -9.9792e-02,  1.3525e-01],\n",
      "        [-3.5419e-03, -1.4320e-02,  1.1682e-01],\n",
      "        [-3.1799e-02,  8.6594e-03,  2.7466e-01],\n",
      "        [ 1.5906e-01,  1.3159e-01, -4.5837e-02],\n",
      "        [ 8.6823e-03,  1.2915e-01,  3.7036e-01],\n",
      "        [ 2.2949e-01,  4.0375e-02, -1.1139e-01],\n",
      "        [-1.5662e-01,  1.7249e-01,  2.8564e-01],\n",
      "        [-1.0300e-02, -2.1362e-02, -3.8940e-02],\n",
      "        [ 1.0419e-01,  1.5601e-01,  1.1475e-01],\n",
      "        [-1.8005e-02,  1.0376e-01, -1.1890e-01],\n",
      "        [-8.8440e-02, -4.4220e-02,  5.0934e-02],\n",
      "        [ 2.5342e-01, -9.4177e-02, -6.6711e-02],\n",
      "        [ 1.8958e-01,  1.6159e-02, -6.7932e-02],\n",
      "        [ 1.7017e-01, -1.9875e-03,  2.7441e-01],\n",
      "        [-1.5710e-01,  2.8735e-01,  1.2927e-01],\n",
      "        [ 3.0054e-01, -3.4241e-02,  1.6577e-01],\n",
      "        [ 3.8849e-02,  4.1260e-02,  2.4268e-01],\n",
      "        [ 2.7344e-01, -1.6638e-01, -3.2837e-02],\n",
      "        [-3.7170e-02, -1.0339e-01, -3.9429e-02],\n",
      "        [ 2.0776e-01, -1.9943e-02,  1.9824e-01],\n",
      "        [-2.1332e-02,  3.0859e-01,  7.0435e-02],\n",
      "        [ 1.1572e-01, -1.5662e-01, -6.8787e-02],\n",
      "        [-4.5959e-02,  3.5693e-01,  1.8750e-01],\n",
      "        [-1.2039e-02,  9.9731e-02,  1.7746e-02],\n",
      "        [-3.8574e-02,  2.9346e-01,  1.0181e-01],\n",
      "        [ 2.3682e-01,  1.9202e-01, -1.1151e-01],\n",
      "        [-8.4915e-03,  1.7529e-01,  1.9547e-02],\n",
      "        [-4.6631e-02,  2.7084e-03,  1.7053e-01],\n",
      "        [ 4.0924e-02,  2.2034e-02, -4.7150e-02],\n",
      "        [ 1.7249e-01, -7.0801e-02, -3.5742e-01],\n",
      "        [ 1.6199e-01, -2.2766e-01, -1.2427e-01],\n",
      "        [ 3.5059e-01, -9.3811e-02, -2.5708e-01],\n",
      "        [ 3.1421e-01, -1.9348e-01, -2.6798e-03],\n",
      "        [ 1.7639e-01, -1.5137e-01, -1.0574e-02],\n",
      "        [ 3.8379e-01, -2.1179e-01,  2.2852e-01],\n",
      "        [ 2.7881e-01, -1.7834e-01, -9.9792e-02],\n",
      "        [ 9.7412e-02, -1.3855e-01, -3.5095e-02],\n",
      "        [ 8.0338e-03, -1.7871e-01, -6.8909e-02],\n",
      "        [ 1.1444e-01, -3.3594e-01,  2.6953e-01],\n",
      "        [ 1.6284e-01, -2.3218e-01,  1.2500e-01],\n",
      "        [-1.6541e-02, -4.3793e-02,  1.6821e-01],\n",
      "        [ 6.5308e-02, -2.3895e-02,  3.2806e-02],\n",
      "        [ 3.7231e-02, -4.1382e-01, -1.2347e-01],\n",
      "        [ 2.7637e-01, -2.7686e-01, -2.0532e-01],\n",
      "        [ 2.1997e-01, -2.8687e-01, -5.3497e-02]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2415, 0.3142, 0.4443],\n",
      "        [0.2795, 0.3406, 0.3801],\n",
      "        [0.3320, 0.3435, 0.3245],\n",
      "        [0.3130, 0.3394, 0.3477],\n",
      "        [0.2920, 0.3496, 0.3586],\n",
      "        [0.3328, 0.3318, 0.3354],\n",
      "        [0.3638, 0.3779, 0.2585],\n",
      "        [0.3184, 0.3523, 0.3296],\n",
      "        [0.3806, 0.3850, 0.2344],\n",
      "        [0.2888, 0.3459, 0.3652],\n",
      "        [0.3789, 0.2756, 0.3455],\n",
      "        [0.3499, 0.3176, 0.3325],\n",
      "        [0.4846, 0.2795, 0.2357],\n",
      "        [0.3247, 0.3477, 0.3274],\n",
      "        [0.3220, 0.3208, 0.3572],\n",
      "        [0.3220, 0.2993, 0.3787],\n",
      "        [0.3208, 0.3174, 0.3618],\n",
      "        [0.2942, 0.3062, 0.3997],\n",
      "        [0.3586, 0.3491, 0.2922],\n",
      "        [0.2805, 0.3164, 0.4028],\n",
      "        [0.3938, 0.3259, 0.2800],\n",
      "        [0.2534, 0.3523, 0.3943],\n",
      "        [0.3376, 0.3340, 0.3281],\n",
      "        [0.3264, 0.3438, 0.3298],\n",
      "        [0.3296, 0.3723, 0.2981],\n",
      "        [0.3130, 0.3271, 0.3599],\n",
      "        [0.4111, 0.2903, 0.2986],\n",
      "        [0.3826, 0.3218, 0.2957],\n",
      "        [0.3389, 0.2852, 0.3760],\n",
      "        [0.2571, 0.4009, 0.3423],\n",
      "        [0.3862, 0.2764, 0.3374],\n",
      "        [0.3098, 0.3105, 0.3799],\n",
      "        [0.4202, 0.2705, 0.3093],\n",
      "        [0.3408, 0.3191, 0.3401],\n",
      "        [0.3589, 0.2856, 0.3555],\n",
      "        [0.2869, 0.3989, 0.3145],\n",
      "        [0.3857, 0.2937, 0.3206],\n",
      "        [0.2661, 0.3979, 0.3359],\n",
      "        [0.3176, 0.3552, 0.3271],\n",
      "        [0.2822, 0.3933, 0.3247],\n",
      "        [0.3757, 0.3591, 0.2651],\n",
      "        [0.3096, 0.3721, 0.3184],\n",
      "        [0.3037, 0.3191, 0.3772],\n",
      "        [0.3452, 0.3386, 0.3162],\n",
      "        [0.4214, 0.3303, 0.2480],\n",
      "        [0.4119, 0.2788, 0.3093],\n",
      "        [0.4575, 0.2935, 0.2491],\n",
      "        [0.4292, 0.2583, 0.3125],\n",
      "        [0.3921, 0.2825, 0.3252],\n",
      "        [0.4153, 0.2290, 0.3557],\n",
      "        [0.4314, 0.2732, 0.2954],\n",
      "        [0.3752, 0.2964, 0.3286],\n",
      "        [0.3628, 0.3010, 0.3359],\n",
      "        [0.3564, 0.2272, 0.4163],\n",
      "        [0.3794, 0.2556, 0.3652],\n",
      "        [0.3149, 0.3064, 0.3787],\n",
      "        [0.3469, 0.3174, 0.3357],\n",
      "        [0.4019, 0.2559, 0.3423],\n",
      "        [0.4561, 0.2622, 0.2817],\n",
      "        [0.4231, 0.2549, 0.3220]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0724, -0.2231,  0.2844],\n",
      "        [-0.0459, -0.1288,  0.1265],\n",
      "        [-0.4346, -0.1724,  0.3762],\n",
      "        [-0.1108, -0.0793,  0.1360],\n",
      "        [-0.1754, -0.1376,  0.0144],\n",
      "        [-0.2478, -0.2891, -0.0547],\n",
      "        [-0.2754, -0.0259,  0.0424],\n",
      "        [-0.0203, -0.0340,  0.1470],\n",
      "        [-0.0622, -0.0700,  0.0801],\n",
      "        [-0.0878, -0.1283, -0.0589],\n",
      "        [-0.0111, -0.3435, -0.3411],\n",
      "        [-0.0528, -0.0372, -0.3564],\n",
      "        [-0.1332, -0.1733, -0.2537],\n",
      "        [ 0.0809, -0.2356, -0.1292],\n",
      "        [-0.0526, -0.0398, -0.0087],\n",
      "        [-0.0190, -0.0609,  0.1622],\n",
      "        [-0.0421,  0.0790, -0.2198],\n",
      "        [ 0.0513, -0.2098,  0.0862],\n",
      "        [ 0.0717, -0.1088,  0.4651],\n",
      "        [ 0.0509, -0.1262,  0.3186],\n",
      "        [-0.0532,  0.0997,  0.4368],\n",
      "        [ 0.1438, -0.0848,  0.4187],\n",
      "        [-0.0554,  0.0998,  0.1754],\n",
      "        [ 0.1753, -0.0704,  0.0839],\n",
      "        [-0.0024, -0.1842,  0.0371],\n",
      "        [ 0.1014, -0.1655, -0.1028],\n",
      "        [ 0.0093, -0.1910,  0.0174],\n",
      "        [ 0.2117, -0.5684, -0.1899],\n",
      "        [ 0.1812, -0.4109, -0.4805],\n",
      "        [ 0.1832, -0.6646,  0.1146],\n",
      "        [-0.0973, -0.5044,  0.1703],\n",
      "        [-0.0118, -0.3596, -0.0104],\n",
      "        [-0.4263, -0.4192, -0.3049],\n",
      "        [ 0.0807, -0.4529, -0.1240]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3040, 0.2615, 0.4343],\n",
      "        [0.3218, 0.2961, 0.3823],\n",
      "        [0.2198, 0.2856, 0.4944],\n",
      "        [0.3020, 0.3115, 0.3865],\n",
      "        [0.3079, 0.3198, 0.3723],\n",
      "        [0.3152, 0.3025, 0.3823],\n",
      "        [0.2734, 0.3508, 0.3757],\n",
      "        [0.3157, 0.3113, 0.3730],\n",
      "        [0.3179, 0.3154, 0.3665],\n",
      "        [0.3345, 0.3213, 0.3442],\n",
      "        [0.4104, 0.2944, 0.2952],\n",
      "        [0.3630, 0.3689, 0.2681],\n",
      "        [0.3513, 0.3374, 0.3113],\n",
      "        [0.3938, 0.2869, 0.3191],\n",
      "        [0.3271, 0.3313, 0.3418],\n",
      "        [0.3167, 0.3037, 0.3796],\n",
      "        [0.3372, 0.3806, 0.2822],\n",
      "        [0.3564, 0.2744, 0.3691],\n",
      "        [0.3015, 0.2517, 0.4468],\n",
      "        [0.3181, 0.2664, 0.4155],\n",
      "        [0.2634, 0.3069, 0.4299],\n",
      "        [0.3213, 0.2556, 0.4231],\n",
      "        [0.2917, 0.3408, 0.3674],\n",
      "        [0.3711, 0.2903, 0.3386],\n",
      "        [0.3479, 0.2900, 0.3621],\n",
      "        [0.3875, 0.2966, 0.3159],\n",
      "        [0.3538, 0.2896, 0.3567],\n",
      "        [0.4700, 0.2155, 0.3145],\n",
      "        [0.4832, 0.2673, 0.2494],\n",
      "        [0.4233, 0.1814, 0.3953],\n",
      "        [0.3364, 0.2239, 0.4397],\n",
      "        [0.3694, 0.2607, 0.3699],\n",
      "        [0.3188, 0.3210, 0.3601],\n",
      "        [0.4165, 0.2443, 0.3394]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0055, -0.1409,  0.1421],\n",
      "        [-0.0898, -0.0269, -0.0232],\n",
      "        [ 0.1229, -0.1218, -0.1892],\n",
      "        [ 0.1179,  0.1025, -0.1656],\n",
      "        [-0.0170,  0.1210, -0.1317],\n",
      "        [ 0.0504,  0.1345, -0.0352],\n",
      "        [ 0.1249, -0.2588, -0.1301],\n",
      "        [ 0.0603, -0.0453,  0.0714],\n",
      "        [ 0.0006, -0.0549, -0.1659],\n",
      "        [ 0.0856, -0.2234,  0.1238],\n",
      "        [-0.0103,  0.0009, -0.2000],\n",
      "        [-0.3613,  0.3049,  0.1072],\n",
      "        [-0.3550, -0.0917, -0.1170],\n",
      "        [-0.2668, -0.2445,  0.1266],\n",
      "        [-0.1107, -0.1522, -0.0657],\n",
      "        [-0.0772, -0.2362,  0.0665],\n",
      "        [-0.0605, -0.4355,  0.1906],\n",
      "        [ 0.5127, -0.2583,  0.0828],\n",
      "        [ 0.1393, -0.3511,  0.2666],\n",
      "        [-0.0915,  0.1289,  0.2052],\n",
      "        [-0.0663,  0.1522, -0.0505],\n",
      "        [-0.1957,  0.3750, -0.0961],\n",
      "        [-0.2408,  0.2417,  0.0009],\n",
      "        [-0.0376, -0.0464,  0.0115],\n",
      "        [-0.1080, -0.2357,  0.0072],\n",
      "        [ 0.0526, -0.1301,  0.1917],\n",
      "        [ 0.0099, -0.0166, -0.0811],\n",
      "        [ 0.0267, -0.1730, -0.0307],\n",
      "        [ 0.1282, -0.0129,  0.0676],\n",
      "        [ 0.1248, -0.0358,  0.2035],\n",
      "        [ 0.2448, -0.2732,  0.1919],\n",
      "        [ 0.0875, -0.0639,  0.0811],\n",
      "        [ 0.2983, -0.1902,  0.2402],\n",
      "        [ 0.2578, -0.1975,  0.1428],\n",
      "        [-0.0493, -0.1851, -0.0067],\n",
      "        [ 0.2499, -0.3604,  0.0260],\n",
      "        [ 0.1383, -0.1440,  0.2744],\n",
      "        [ 0.1313, -0.0505,  0.3608],\n",
      "        [ 0.0667, -0.0142,  0.2148],\n",
      "        [ 0.2258,  0.0667, -0.1083],\n",
      "        [ 0.0112,  0.2739,  0.0558],\n",
      "        [ 0.2786,  0.0632,  0.0717],\n",
      "        [ 0.2927,  0.1725, -0.0108],\n",
      "        [ 0.2007,  0.3281,  0.0961],\n",
      "        [ 0.4551,  0.0667,  0.0451],\n",
      "        [ 0.2747, -0.0497,  0.0933],\n",
      "        [ 0.2476, -0.0943, -0.1906],\n",
      "        [ 0.0883,  0.0040, -0.1442],\n",
      "        [ 0.1205, -0.2915, -0.2034],\n",
      "        [ 0.1836, -0.2026, -0.0567]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3298, 0.2881, 0.3823],\n",
      "        [0.3191, 0.3398, 0.3411],\n",
      "        [0.3977, 0.3113, 0.2910],\n",
      "        [0.3652, 0.3596, 0.2751],\n",
      "        [0.3291, 0.3777, 0.2932],\n",
      "        [0.3328, 0.3618, 0.3054],\n",
      "        [0.4072, 0.2773, 0.3154],\n",
      "        [0.3435, 0.3091, 0.3474],\n",
      "        [0.3582, 0.3389, 0.3032],\n",
      "        [0.3606, 0.2646, 0.3748],\n",
      "        [0.3523, 0.3562, 0.2915],\n",
      "        [0.2201, 0.4285, 0.3516],\n",
      "        [0.2800, 0.3645, 0.3555],\n",
      "        [0.2854, 0.2917, 0.4229],\n",
      "        [0.3328, 0.3191, 0.3481],\n",
      "        [0.3325, 0.2837, 0.3838],\n",
      "        [0.3364, 0.2312, 0.4324],\n",
      "        [0.4731, 0.2189, 0.3079],\n",
      "        [0.3638, 0.2229, 0.4133],\n",
      "        [0.2783, 0.3469, 0.3745],\n",
      "        [0.3066, 0.3816, 0.3115],\n",
      "        [0.2581, 0.4568, 0.2852],\n",
      "        [0.2568, 0.4160, 0.3271],\n",
      "        [0.3289, 0.3259, 0.3455],\n",
      "        [0.3330, 0.2932, 0.3738],\n",
      "        [0.3354, 0.2793, 0.3853],\n",
      "        [0.3464, 0.3374, 0.3162],\n",
      "        [0.3618, 0.2964, 0.3418],\n",
      "        [0.3560, 0.3091, 0.3350],\n",
      "        [0.3408, 0.2903, 0.3689],\n",
      "        [0.3931, 0.2341, 0.3728],\n",
      "        [0.3506, 0.3013, 0.3481],\n",
      "        [0.3911, 0.2400, 0.3689],\n",
      "        [0.3960, 0.2512, 0.3530],\n",
      "        [0.3428, 0.2993, 0.3579],\n",
      "        [0.4268, 0.2319, 0.3413],\n",
      "        [0.3450, 0.2600, 0.3950],\n",
      "        [0.3235, 0.2698, 0.4070],\n",
      "        [0.3245, 0.2993, 0.3762],\n",
      "        [0.3894, 0.3320, 0.2788],\n",
      "        [0.2988, 0.3887, 0.3125],\n",
      "        [0.3818, 0.3079, 0.3103],\n",
      "        [0.3809, 0.3379, 0.2812],\n",
      "        [0.3293, 0.3740, 0.2966],\n",
      "        [0.4270, 0.2896, 0.2834],\n",
      "        [0.3911, 0.2827, 0.3262],\n",
      "        [0.4246, 0.3015, 0.2739],\n",
      "        [0.3687, 0.3389, 0.2922],\n",
      "        [0.4192, 0.2776, 0.3032],\n",
      "        [0.4055, 0.2756, 0.3188]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.2001, -0.2771,  0.1542],\n",
      "        [ 0.0394, -0.1700,  0.0033],\n",
      "        [ 0.0396, -0.1666, -0.0702],\n",
      "        [ 0.2020, -0.3037, -0.0663],\n",
      "        [ 0.0207, -0.1022,  0.0034],\n",
      "        [ 0.1965, -0.2336, -0.0543],\n",
      "        [-0.2052, -0.1406, -0.0145],\n",
      "        [-0.0737,  0.0152, -0.0202],\n",
      "        [-0.2391,  0.0611,  0.0036],\n",
      "        [-0.0078,  0.2443,  0.0571],\n",
      "        [-0.0251, -0.0083, -0.0452],\n",
      "        [-0.0033,  0.1315,  0.1284],\n",
      "        [ 0.0709, -0.1531, -0.2280],\n",
      "        [ 0.0686, -0.0675,  0.0671],\n",
      "        [ 0.1370,  0.0324,  0.0334],\n",
      "        [ 0.1896, -0.1250,  0.0865],\n",
      "        [ 0.1010,  0.0085,  0.1691],\n",
      "        [ 0.2666, -0.1475,  0.0840],\n",
      "        [ 0.1332, -0.0018,  0.0122],\n",
      "        [ 0.1455, -0.2125,  0.1243],\n",
      "        [ 0.1692, -0.2274, -0.1696],\n",
      "        [ 0.0824, -0.1497, -0.0876]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2983, 0.2764, 0.4253],\n",
      "        [0.3604, 0.2922, 0.3474],\n",
      "        [0.3691, 0.3003, 0.3306],\n",
      "        [0.4224, 0.2546, 0.3230],\n",
      "        [0.3489, 0.3083, 0.3428],\n",
      "        [0.4119, 0.2678, 0.3203],\n",
      "        [0.3052, 0.3254, 0.3694],\n",
      "        [0.3176, 0.3472, 0.3352],\n",
      "        [0.2759, 0.3726, 0.3516],\n",
      "        [0.2981, 0.3835, 0.3181],\n",
      "        [0.3337, 0.3394, 0.3271],\n",
      "        [0.3044, 0.3484, 0.3472],\n",
      "        [0.3936, 0.3147, 0.2917],\n",
      "        [0.3484, 0.3040, 0.3477],\n",
      "        [0.3569, 0.3215, 0.3218],\n",
      "        [0.3799, 0.2773, 0.3428],\n",
      "        [0.3352, 0.3057, 0.3589],\n",
      "        [0.4009, 0.2649, 0.3340],\n",
      "        [0.3623, 0.3167, 0.3210],\n",
      "        [0.3733, 0.2610, 0.3655],\n",
      "        [0.4192, 0.2820, 0.2988],\n",
      "        [0.3794, 0.3008, 0.3201]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1095, -0.1913,  0.2644],\n",
      "        [ 0.1057, -0.1907,  0.2693],\n",
      "        [-0.1181,  0.2186,  0.0036],\n",
      "        [ 0.0408,  0.1299,  0.2744],\n",
      "        [-0.0723,  0.1334, -0.1749],\n",
      "        [ 0.1283, -0.0870,  0.1779],\n",
      "        [ 0.1271,  0.1251, -0.0318],\n",
      "        [ 0.2352, -0.0993, -0.1248],\n",
      "        [ 0.0325,  0.2629, -0.3982],\n",
      "        [ 0.1927, -0.2384, -0.1285],\n",
      "        [ 0.2656, -0.2019, -0.3533],\n",
      "        [ 0.2659, -0.2404,  0.0777]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2964, 0.2729, 0.4307],\n",
      "        [0.3423, 0.2546, 0.4031],\n",
      "        [0.2832, 0.3967, 0.3201],\n",
      "        [0.2979, 0.3257, 0.3765],\n",
      "        [0.3193, 0.3923, 0.2883],\n",
      "        [0.3501, 0.2822, 0.3677],\n",
      "        [0.3508, 0.3501, 0.2993],\n",
      "        [0.4143, 0.2966, 0.2891],\n",
      "        [0.3438, 0.4329, 0.2235],\n",
      "        [0.4211, 0.2737, 0.3054],\n",
      "        [0.4619, 0.2893, 0.2488],\n",
      "        [0.4114, 0.2479, 0.3408]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0547, -0.3013, -0.0197],\n",
      "        [ 0.2646, -0.2971,  0.0547],\n",
      "        [-0.0477, -0.0505,  0.0138],\n",
      "        [ 0.4709, -0.4480,  0.0226],\n",
      "        [ 0.3484, -0.2383, -0.0111],\n",
      "        [ 0.3987, -0.3989,  0.1288],\n",
      "        [ 0.1813,  0.0565, -0.3931],\n",
      "        [ 0.2135, -0.1857, -0.1081],\n",
      "        [ 0.4839, -0.0149, -0.3748],\n",
      "        [ 0.4302, -0.0336, -0.3025],\n",
      "        [ 0.3066, -0.0904,  0.0254],\n",
      "        [ 0.2981, -0.0114,  0.0145],\n",
      "        [ 0.2095,  0.0074, -0.0730],\n",
      "        [ 0.3445, -0.1184,  0.0612],\n",
      "        [ 0.3052, -0.0870, -0.1024],\n",
      "        [ 0.4165, -0.1296, -0.1815],\n",
      "        [ 0.0048, -0.2208,  0.1146],\n",
      "        [ 0.1614, -0.0581, -0.1869],\n",
      "        [-0.1206, -0.0114, -0.3386],\n",
      "        [ 0.2122, -0.2605, -0.3340],\n",
      "        [ 0.2073, -0.1366, -0.2366],\n",
      "        [ 0.2678, -0.3091, -0.0959],\n",
      "        [ 0.2627, -0.2749, -0.2788],\n",
      "        [ 0.2954, -0.3403,  0.0800]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3804, 0.2664, 0.3530],\n",
      "        [0.4199, 0.2395, 0.3406],\n",
      "        [0.3267, 0.3259, 0.3474],\n",
      "        [0.4907, 0.1958, 0.3135],\n",
      "        [0.4436, 0.2467, 0.3096],\n",
      "        [0.4517, 0.2035, 0.3450],\n",
      "        [0.4089, 0.3608, 0.2302],\n",
      "        [0.4175, 0.2800, 0.3025],\n",
      "        [0.4924, 0.2991, 0.2086],\n",
      "        [0.4741, 0.2981, 0.2278],\n",
      "        [0.4121, 0.2771, 0.3110],\n",
      "        [0.4021, 0.2952, 0.3027],\n",
      "        [0.3889, 0.3179, 0.2932],\n",
      "        [0.4197, 0.2642, 0.3162],\n",
      "        [0.4272, 0.2886, 0.2842],\n",
      "        [0.4697, 0.2720, 0.2583],\n",
      "        [0.3433, 0.2739, 0.3831],\n",
      "        [0.3987, 0.3201, 0.2812],\n",
      "        [0.3425, 0.3821, 0.2754],\n",
      "        [0.4541, 0.2830, 0.2629],\n",
      "        [0.4255, 0.3015, 0.2729],\n",
      "        [0.4431, 0.2489, 0.3081],\n",
      "        [0.4617, 0.2698, 0.2686],\n",
      "        [0.4282, 0.2267, 0.3452]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1205, -0.3193,  0.1951],\n",
      "        [ 0.1504,  0.0010,  0.0190],\n",
      "        [ 0.4131, -0.2903, -0.1122],\n",
      "        [ 0.3613, -0.1591, -0.0729],\n",
      "        [ 0.1664, -0.2632, -0.0876],\n",
      "        [ 0.0805, -0.1884,  0.1726],\n",
      "        [ 0.2651, -0.0969, -0.3562],\n",
      "        [ 0.1693, -0.0797,  0.0894],\n",
      "        [ 0.1327,  0.0247,  0.0527],\n",
      "        [ 0.2957, -0.1436, -0.0440],\n",
      "        [ 0.1804, -0.0146, -0.3174],\n",
      "        [ 0.2388, -0.2166,  0.1093],\n",
      "        [-0.0198, -0.2832, -0.2466],\n",
      "        [ 0.0234, -0.1093,  0.0688]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3135, 0.2568, 0.4297],\n",
      "        [0.3652, 0.3145, 0.3203],\n",
      "        [0.4792, 0.2372, 0.2834],\n",
      "        [0.4460, 0.2651, 0.2888],\n",
      "        [0.4121, 0.2683, 0.3196],\n",
      "        [0.3496, 0.2671, 0.3833],\n",
      "        [0.4478, 0.3118, 0.2405],\n",
      "        [0.3699, 0.2883, 0.3416],\n",
      "        [0.3545, 0.3181, 0.3271],\n",
      "        [0.4243, 0.2734, 0.3022],\n",
      "        [0.4114, 0.3386, 0.2500],\n",
      "        [0.3979, 0.2524, 0.3496],\n",
      "        [0.3899, 0.2996, 0.3108],\n",
      "        [0.3423, 0.2996, 0.3582]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.2113, -0.0616, -0.0839],\n",
      "        [ 0.0163,  0.0588,  0.0120],\n",
      "        [-0.1238, -0.0877,  0.4265],\n",
      "        [ 0.0896, -0.0764,  0.3345],\n",
      "        [-0.2404,  0.2310,  0.1343],\n",
      "        [ 0.0349,  0.1029,  0.1465],\n",
      "        [ 0.2871,  0.1692, -0.1519],\n",
      "        [-0.0061,  0.1373,  0.2019],\n",
      "        [-0.0113,  0.1980, -0.1869],\n",
      "        [ 0.1111,  0.2686, -0.1591],\n",
      "        [ 0.0331,  0.1183, -0.1849],\n",
      "        [-0.0467,  0.0230, -0.2571],\n",
      "        [-0.1804,  0.1091, -0.1838],\n",
      "        [-0.1027,  0.2827, -0.1799],\n",
      "        [-0.1257,  0.0775, -0.1292],\n",
      "        [ 0.0096,  0.1201, -0.1973],\n",
      "        [-0.1246, -0.0166,  0.0887],\n",
      "        [ 0.0770, -0.1112, -0.0769],\n",
      "        [ 0.1091, -0.0572, -0.1146],\n",
      "        [ 0.0907, -0.0066,  0.0429],\n",
      "        [ 0.2578,  0.0912, -0.0026],\n",
      "        [ 0.3677,  0.3276, -0.2473],\n",
      "        [ 0.2710, -0.0080, -0.2180],\n",
      "        [ 0.3735,  0.0474, -0.2534],\n",
      "        [ 0.1772,  0.2477, -0.2203],\n",
      "        [ 0.1986, -0.1028, -0.2212],\n",
      "        [ 0.0760, -0.1371, -0.2383],\n",
      "        [-0.1162, -0.0253, -0.1103]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3032, 0.3523, 0.3445],\n",
      "        [0.3291, 0.3433, 0.3276],\n",
      "        [0.2651, 0.2749, 0.4597],\n",
      "        [0.3201, 0.2710, 0.4089],\n",
      "        [0.2465, 0.3950, 0.3586],\n",
      "        [0.3137, 0.3357, 0.3506],\n",
      "        [0.3948, 0.3508, 0.2544],\n",
      "        [0.2954, 0.3408, 0.3638],\n",
      "        [0.3254, 0.4014, 0.2732],\n",
      "        [0.3408, 0.3989, 0.2603],\n",
      "        [0.3457, 0.3765, 0.2778],\n",
      "        [0.3469, 0.3721, 0.2810],\n",
      "        [0.3000, 0.4009, 0.2991],\n",
      "        [0.2944, 0.4329, 0.2727],\n",
      "        [0.3103, 0.3804, 0.3093],\n",
      "        [0.3413, 0.3811, 0.2776],\n",
      "        [0.2983, 0.3323, 0.3694],\n",
      "        [0.3723, 0.3083, 0.3193],\n",
      "        [0.3779, 0.3201, 0.3022],\n",
      "        [0.3496, 0.3171, 0.3333],\n",
      "        [0.3821, 0.3235, 0.2944],\n",
      "        [0.3997, 0.3840, 0.2162],\n",
      "        [0.4219, 0.3193, 0.2588],\n",
      "        [0.4434, 0.3198, 0.2368],\n",
      "        [0.3643, 0.3909, 0.2448],\n",
      "        [0.4172, 0.3086, 0.2742],\n",
      "        [0.3940, 0.3184, 0.2876],\n",
      "        [0.3225, 0.3533, 0.3245]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.2172, -0.1735,  0.0825],\n",
      "        [ 0.0739, -0.2388,  0.0948],\n",
      "        [ 0.1530, -0.2803, -0.0147],\n",
      "        [ 0.0888, -0.4385,  0.1968],\n",
      "        [ 0.1219,  0.0400, -0.2019],\n",
      "        [ 0.3770, -0.1743,  0.0266],\n",
      "        [ 0.0638, -0.2178,  0.0452],\n",
      "        [ 0.2128, -0.3328,  0.2549],\n",
      "        [ 0.2754, -0.2230,  0.1984],\n",
      "        [ 0.2057, -0.0745,  0.4126],\n",
      "        [ 0.0727,  0.0781,  0.5161],\n",
      "        [-0.0600,  0.2852,  0.3604],\n",
      "        [ 0.3091, -0.0825,  0.3191],\n",
      "        [ 0.2673,  0.0110,  0.3005],\n",
      "        [ 0.5312, -0.2634, -0.0698],\n",
      "        [ 0.3430, -0.1476, -0.0390],\n",
      "        [ 0.2751,  0.1904, -0.0648],\n",
      "        [-0.0400,  0.0478, -0.1677],\n",
      "        [ 0.0226,  0.2388, -0.2368],\n",
      "        [ 0.0276,  0.0097, -0.0206],\n",
      "        [ 0.1799,  0.0365, -0.1302],\n",
      "        [-0.0968,  0.0703,  0.1226],\n",
      "        [ 0.2034, -0.1060,  0.0234],\n",
      "        [ 0.2031, -0.0512,  0.0623],\n",
      "        [ 0.1838, -0.0875, -0.0806],\n",
      "        [ 0.1572, -0.0158,  0.1688],\n",
      "        [-0.1015,  0.1360,  0.2776],\n",
      "        [ 0.2328,  0.1227, -0.0856],\n",
      "        [ 0.1400,  0.1061,  0.0430],\n",
      "        [-0.1152,  0.1744,  0.1678],\n",
      "        [ 0.1142,  0.0105, -0.0293],\n",
      "        [ 0.0964, -0.0543,  0.1362],\n",
      "        [ 0.2795,  0.0881, -0.3369],\n",
      "        [ 0.0453,  0.2717, -0.0589],\n",
      "        [ 0.1731,  0.2321, -0.0501],\n",
      "        [ 0.0213,  0.0179, -0.0444],\n",
      "        [ 0.2161, -0.0507, -0.1649],\n",
      "        [ 0.0075,  0.0886, -0.0982],\n",
      "        [ 0.1708, -0.0023, -0.0209],\n",
      "        [ 0.2137,  0.2910,  0.0746],\n",
      "        [ 0.1798,  0.3535, -0.0673],\n",
      "        [ 0.1871,  0.3394,  0.0558],\n",
      "        [ 0.1129,  0.3896,  0.0535],\n",
      "        [ 0.2172,  0.1770,  0.1469],\n",
      "        [ 0.1893,  0.2515, -0.0201],\n",
      "        [ 0.2805,  0.0510,  0.0795],\n",
      "        [ 0.2190,  0.0117,  0.0177],\n",
      "        [ 0.0760,  0.1036,  0.1655],\n",
      "        [ 0.0710,  0.0846, -0.0246],\n",
      "        [-0.0237,  0.1625, -0.0594],\n",
      "        [ 0.0219,  0.1584, -0.0457],\n",
      "        [ 0.0316,  0.0482,  0.0037],\n",
      "        [-0.0065,  0.0357, -0.1952],\n",
      "        [ 0.0844,  0.0173, -0.0971],\n",
      "        [ 0.1777, -0.1381,  0.1846],\n",
      "        [ 0.0752, -0.2274,  0.1316],\n",
      "        [ 0.2644, -0.0316,  0.1527],\n",
      "        [ 0.1520, -0.0952,  0.2915],\n",
      "        [ 0.2041, -0.0102,  0.2656],\n",
      "        [ 0.2429, -0.0695,  0.2389],\n",
      "        [ 0.2510,  0.0274,  0.3625],\n",
      "        [ 0.1101,  0.2112,  0.3096],\n",
      "        [ 0.0958,  0.1667, -0.0847],\n",
      "        [ 0.2101,  0.0172,  0.2915],\n",
      "        [ 0.2450,  0.1220, -0.0057],\n",
      "        [ 0.1653, -0.0208,  0.2712],\n",
      "        [-0.0569, -0.2310,  0.0925],\n",
      "        [ 0.0451, -0.1508,  0.1035],\n",
      "        [-0.0717,  0.0583,  0.5312],\n",
      "        [ 0.2184,  0.0313,  0.2255],\n",
      "        [ 0.2288,  0.0558,  0.0437],\n",
      "        [ 0.2240, -0.0788,  0.0546],\n",
      "        [-0.0309,  0.0251,  0.2520],\n",
      "        [ 0.1432, -0.0579,  0.1400],\n",
      "        [ 0.0226, -0.0067,  0.2783],\n",
      "        [ 0.0468,  0.0555,  0.1459],\n",
      "        [ 0.1421, -0.0684,  0.1899],\n",
      "        [ 0.1185, -0.2219,  0.2944],\n",
      "        [ 0.1439, -0.1678,  0.2216],\n",
      "        [ 0.0268,  0.0232,  0.1918],\n",
      "        [-0.0054, -0.0140, -0.0424],\n",
      "        [ 0.0879, -0.1168, -0.1909],\n",
      "        [ 0.2175,  0.0313, -0.1610],\n",
      "        [ 0.1348,  0.2433, -0.1465],\n",
      "        [ 0.1310,  0.3237, -0.3289],\n",
      "        [ 0.0784,  0.1030,  0.0977],\n",
      "        [ 0.2107, -0.1550, -0.2532],\n",
      "        [ 0.1355, -0.1036,  0.0920]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2947, 0.3079, 0.3975],\n",
      "        [0.3633, 0.2659, 0.3708],\n",
      "        [0.4009, 0.2600, 0.3391],\n",
      "        [0.3699, 0.2183, 0.4119],\n",
      "        [0.3782, 0.3484, 0.2734],\n",
      "        [0.4385, 0.2527, 0.3088],\n",
      "        [0.3655, 0.2759, 0.3586],\n",
      "        [0.3813, 0.2209, 0.3977],\n",
      "        [0.3948, 0.2397, 0.3655],\n",
      "        [0.3350, 0.2532, 0.4119],\n",
      "        [0.2805, 0.2822, 0.4373],\n",
      "        [0.2542, 0.3589, 0.3870],\n",
      "        [0.3723, 0.2517, 0.3760],\n",
      "        [0.3562, 0.2756, 0.3682],\n",
      "        [0.5000, 0.2258, 0.2742],\n",
      "        [0.4358, 0.2668, 0.2974],\n",
      "        [0.3801, 0.3494, 0.2705],\n",
      "        [0.3364, 0.3674, 0.2961],\n",
      "        [0.3320, 0.4121, 0.2561],\n",
      "        [0.3406, 0.3347, 0.3247],\n",
      "        [0.3848, 0.3333, 0.2820],\n",
      "        [0.2917, 0.3450, 0.3633],\n",
      "        [0.3892, 0.2856, 0.3252],\n",
      "        [0.3782, 0.2932, 0.3286],\n",
      "        [0.3953, 0.3013, 0.3035],\n",
      "        [0.3506, 0.2949, 0.3547],\n",
      "        [0.2681, 0.3401, 0.3918],\n",
      "        [0.3811, 0.3416, 0.2773],\n",
      "        [0.3479, 0.3364, 0.3157],\n",
      "        [0.2729, 0.3647, 0.3623],\n",
      "        [0.3613, 0.3257, 0.3130],\n",
      "        [0.3447, 0.2966, 0.3586],\n",
      "        [0.4226, 0.3491, 0.2281],\n",
      "        [0.3169, 0.3975, 0.2856],\n",
      "        [0.3496, 0.3708, 0.2795],\n",
      "        [0.3411, 0.3398, 0.3193],\n",
      "        [0.4082, 0.3127, 0.2791],\n",
      "        [0.3352, 0.3635, 0.3015],\n",
      "        [0.3750, 0.3154, 0.3096],\n",
      "        [0.3389, 0.3662, 0.2949],\n",
      "        [0.3367, 0.4004, 0.2629],\n",
      "        [0.3289, 0.3828, 0.2883],\n",
      "        [0.3066, 0.4043, 0.2891],\n",
      "        [0.3457, 0.3320, 0.3223],\n",
      "        [0.3479, 0.3701, 0.2820],\n",
      "        [0.3828, 0.3042, 0.3130],\n",
      "        [0.3801, 0.3091, 0.3108],\n",
      "        [0.3203, 0.3293, 0.3503],\n",
      "        [0.3423, 0.3469, 0.3110],\n",
      "        [0.3154, 0.3801, 0.3044],\n",
      "        [0.3245, 0.3721, 0.3035],\n",
      "        [0.3345, 0.3401, 0.3254],\n",
      "        [0.3484, 0.3633, 0.2883],\n",
      "        [0.3611, 0.3376, 0.3013],\n",
      "        [0.3655, 0.2666, 0.3679],\n",
      "        [0.3574, 0.2642, 0.3782],\n",
      "        [0.3792, 0.2820, 0.3391],\n",
      "        [0.3413, 0.2666, 0.3923],\n",
      "        [0.3484, 0.2812, 0.3704],\n",
      "        [0.3667, 0.2683, 0.3652],\n",
      "        [0.3428, 0.2742, 0.3833],\n",
      "        [0.3005, 0.3325, 0.3669],\n",
      "        [0.3438, 0.3691, 0.2871],\n",
      "        [0.3438, 0.2834, 0.3728],\n",
      "        [0.3755, 0.3320, 0.2922],\n",
      "        [0.3398, 0.2822, 0.3779],\n",
      "        [0.3333, 0.2800, 0.3870],\n",
      "        [0.3469, 0.2852, 0.3679],\n",
      "        [0.2522, 0.2871, 0.4607],\n",
      "        [0.3525, 0.2925, 0.3550],\n",
      "        [0.3743, 0.3147, 0.3110],\n",
      "        [0.3872, 0.2861, 0.3269],\n",
      "        [0.2954, 0.3125, 0.3921],\n",
      "        [0.3552, 0.2905, 0.3542],\n",
      "        [0.3064, 0.2976, 0.3958],\n",
      "        [0.3213, 0.3240, 0.3547],\n",
      "        [0.3499, 0.2834, 0.3669],\n",
      "        [0.3445, 0.2450, 0.4106],\n",
      "        [0.3555, 0.2603, 0.3843],\n",
      "        [0.3149, 0.3137, 0.3713],\n",
      "        [0.3384, 0.3354, 0.3262],\n",
      "        [0.3889, 0.3169, 0.2942],\n",
      "        [0.3977, 0.3301, 0.2722],\n",
      "        [0.3484, 0.3884, 0.2629],\n",
      "        [0.3516, 0.4263, 0.2220],\n",
      "        [0.3284, 0.3367, 0.3350],\n",
      "        [0.4307, 0.2986, 0.2708],\n",
      "        [0.3643, 0.2869, 0.3489]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0025, -0.2250, -0.0678],\n",
      "        [ 0.1309, -0.3745,  0.1495],\n",
      "        [ 0.0683, -0.3618,  0.0909],\n",
      "        [ 0.1907, -0.3760,  0.2957],\n",
      "        [ 0.2576, -0.3110,  0.1416],\n",
      "        [ 0.2798, -0.3579,  0.2788],\n",
      "        [ 0.1354, -0.2200,  0.0045],\n",
      "        [ 0.3779, -0.0021,  0.2507],\n",
      "        [ 0.2277,  0.1644,  0.2281],\n",
      "        [ 0.2361,  0.1290,  0.2102],\n",
      "        [ 0.4043,  0.0964, -0.0052],\n",
      "        [ 0.3765, -0.2393,  0.2336],\n",
      "        [ 0.3003, -0.0336, -0.0753],\n",
      "        [ 0.3218,  0.0033,  0.1549],\n",
      "        [ 0.3403, -0.1311,  0.1865],\n",
      "        [ 0.3352, -0.1940,  0.0744],\n",
      "        [ 0.3840, -0.0772,  0.0671],\n",
      "        [ 0.1054,  0.1372,  0.0749],\n",
      "        [ 0.0996, -0.1343,  0.0386],\n",
      "        [ 0.0282, -0.0190,  0.0359],\n",
      "        [ 0.0640,  0.2510,  0.1023],\n",
      "        [ 0.1599,  0.1300, -0.0231],\n",
      "        [ 0.0875,  0.3955,  0.3499],\n",
      "        [ 0.0840,  0.3364,  0.1142],\n",
      "        [ 0.1226,  0.2367,  0.3892],\n",
      "        [ 0.2314,  0.0559,  0.2690],\n",
      "        [ 0.3518,  0.2747,  0.2764],\n",
      "        [ 0.5278,  0.0334,  0.1886],\n",
      "        [ 0.3479,  0.1549,  0.1703],\n",
      "        [ 0.6143,  0.0826,  0.3210],\n",
      "        [ 0.2097,  0.2073,  0.2983],\n",
      "        [ 0.4907,  0.0812,  0.3003],\n",
      "        [ 0.3066,  0.0674,  0.3662],\n",
      "        [ 0.3743,  0.2095,  0.3430],\n",
      "        [ 0.1204,  0.0958,  0.1292],\n",
      "        [-0.0637,  0.2183,  0.3574],\n",
      "        [-0.2302,  0.3416,  0.4592],\n",
      "        [ 0.0263,  0.2059,  0.7896],\n",
      "        [ 0.0646,  0.3330,  0.3677],\n",
      "        [-0.0148,  0.0844,  0.6196],\n",
      "        [-0.0519,  0.1613,  0.2915],\n",
      "        [-0.0594,  0.1378,  0.3364],\n",
      "        [ 0.4875, -0.0970,  0.0623],\n",
      "        [ 0.1807, -0.0862,  0.2498],\n",
      "        [ 0.0737,  0.0899,  0.3276],\n",
      "        [ 0.2391,  0.1041,  0.2355],\n",
      "        [ 0.2744,  0.0759,  0.1255],\n",
      "        [ 0.4011, -0.1418, -0.0407],\n",
      "        [ 0.3330,  0.0657,  0.2021],\n",
      "        [ 0.3274, -0.1674,  0.2983],\n",
      "        [ 0.3518, -0.0965,  0.0265],\n",
      "        [ 0.3875, -0.3213,  0.0185],\n",
      "        [ 0.3625, -0.1449,  0.0201],\n",
      "        [ 0.2788, -0.0778,  0.1434],\n",
      "        [ 0.2355, -0.1259,  0.0767],\n",
      "        [ 0.1707, -0.2291,  0.0077],\n",
      "        [ 0.4414, -0.1517,  0.0381],\n",
      "        [ 0.3787, -0.2139, -0.0052],\n",
      "        [ 0.1888, -0.0898,  0.1907],\n",
      "        [ 0.1780, -0.0695,  0.1918],\n",
      "        [ 0.1880,  0.1683,  0.1422],\n",
      "        [ 0.2335,  0.1479,  0.0895],\n",
      "        [ 0.0309,  0.0271,  0.0094],\n",
      "        [ 0.2032,  0.1002,  0.0071],\n",
      "        [ 0.0056, -0.0647,  0.0962],\n",
      "        [ 0.1399,  0.0573,  0.0339],\n",
      "        [ 0.0546,  0.0476,  0.1107],\n",
      "        [ 0.0430,  0.0484,  0.1335],\n",
      "        [ 0.2639,  0.1272, -0.0069],\n",
      "        [-0.2910, -0.0061, -0.0526],\n",
      "        [-0.0194,  0.1791, -0.1147],\n",
      "        [ 0.2683, -0.2095, -0.0842],\n",
      "        [ 0.1233,  0.1816,  0.2111],\n",
      "        [ 0.2477, -0.0265,  0.0935],\n",
      "        [ 0.2717,  0.0073, -0.2347],\n",
      "        [-0.1714,  0.1609, -0.0930],\n",
      "        [-0.2394,  0.2620, -0.1143],\n",
      "        [-0.1054,  0.1321, -0.0549],\n",
      "        [-0.1775,  0.2703,  0.0025],\n",
      "        [ 0.0872, -0.0113, -0.0820],\n",
      "        [-0.0411,  0.0773, -0.0042],\n",
      "        [-0.1104, -0.0722,  0.0402],\n",
      "        [ 0.1293, -0.1331,  0.2898],\n",
      "        [-0.1453, -0.0574, -0.0832],\n",
      "        [-0.0840, -0.0180, -0.4124],\n",
      "        [-0.0200, -0.0386, -0.0707],\n",
      "        [ 0.2311, -0.0083, -0.1649],\n",
      "        [ 0.4023, -0.2661,  0.1410],\n",
      "        [ 0.2688, -0.1716, -0.2168],\n",
      "        [ 0.2883, -0.3503,  0.1059]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3652, 0.2925, 0.3423],\n",
      "        [0.3813, 0.2301, 0.3887],\n",
      "        [0.3740, 0.2433, 0.3826],\n",
      "        [0.3733, 0.2119, 0.4148],\n",
      "        [0.4070, 0.2305, 0.3625],\n",
      "        [0.3958, 0.2091, 0.3953],\n",
      "        [0.3879, 0.2720, 0.3403],\n",
      "        [0.3899, 0.2666, 0.3433],\n",
      "        [0.3403, 0.3193, 0.3403],\n",
      "        [0.3481, 0.3127, 0.3391],\n",
      "        [0.4167, 0.3064, 0.2769],\n",
      "        [0.4155, 0.2245, 0.3601],\n",
      "        [0.4163, 0.2981, 0.2859],\n",
      "        [0.3887, 0.2825, 0.3289],\n",
      "        [0.4031, 0.2515, 0.3455],\n",
      "        [0.4238, 0.2496, 0.3264],\n",
      "        [0.4238, 0.2673, 0.3088],\n",
      "        [0.3330, 0.3438, 0.3230],\n",
      "        [0.3660, 0.2896, 0.3442],\n",
      "        [0.3376, 0.3220, 0.3403],\n",
      "        [0.3081, 0.3716, 0.3203],\n",
      "        [0.3567, 0.3462, 0.2971],\n",
      "        [0.2732, 0.3718, 0.3552],\n",
      "        [0.3015, 0.3879, 0.3105],\n",
      "        [0.2917, 0.3271, 0.3811],\n",
      "        [0.3477, 0.2915, 0.3608],\n",
      "        [0.3506, 0.3245, 0.3250],\n",
      "        [0.4307, 0.2627, 0.3066],\n",
      "        [0.3757, 0.3098, 0.3145],\n",
      "        [0.4285, 0.2517, 0.3196],\n",
      "        [0.3235, 0.3228, 0.3535],\n",
      "        [0.4016, 0.2666, 0.3318],\n",
      "        [0.3511, 0.2764, 0.3726],\n",
      "        [0.3550, 0.3010, 0.3440],\n",
      "        [0.3350, 0.3269, 0.3379],\n",
      "        [0.2598, 0.3445, 0.3958],\n",
      "        [0.2100, 0.3718, 0.4182],\n",
      "        [0.2303, 0.2756, 0.4941],\n",
      "        [0.2732, 0.3572, 0.3699],\n",
      "        [0.2507, 0.2769, 0.4727],\n",
      "        [0.2742, 0.3394, 0.3865],\n",
      "        [0.2700, 0.3289, 0.4011],\n",
      "        [0.4524, 0.2522, 0.2957],\n",
      "        [0.3525, 0.2700, 0.3777],\n",
      "        [0.3025, 0.3074, 0.3899],\n",
      "        [0.3484, 0.3044, 0.3472],\n",
      "        [0.3728, 0.3057, 0.3213],\n",
      "        [0.4497, 0.2612, 0.2891],\n",
      "        [0.3784, 0.2896, 0.3320],\n",
      "        [0.3875, 0.2362, 0.3762],\n",
      "        [0.4236, 0.2705, 0.3059],\n",
      "        [0.4580, 0.2255, 0.3167],\n",
      "        [0.4326, 0.2605, 0.3071],\n",
      "        [0.3887, 0.2720, 0.3394],\n",
      "        [0.3921, 0.2732, 0.3345],\n",
      "        [0.3967, 0.2661, 0.3372],\n",
      "        [0.4502, 0.2488, 0.3008],\n",
      "        [0.4475, 0.2474, 0.3049],\n",
      "        [0.3625, 0.2744, 0.3633],\n",
      "        [0.3579, 0.2793, 0.3628],\n",
      "        [0.3406, 0.3340, 0.3254],\n",
      "        [0.3591, 0.3298, 0.3110],\n",
      "        [0.3362, 0.3350, 0.3291],\n",
      "        [0.3672, 0.3311, 0.3018],\n",
      "        [0.3303, 0.3079, 0.3618],\n",
      "        [0.3545, 0.3264, 0.3188],\n",
      "        [0.3279, 0.3254, 0.3467],\n",
      "        [0.3225, 0.3242, 0.3530],\n",
      "        [0.3794, 0.3311, 0.2896],\n",
      "        [0.2778, 0.3694, 0.3528],\n",
      "        [0.3196, 0.3899, 0.2905],\n",
      "        [0.4304, 0.2668, 0.3025],\n",
      "        [0.3174, 0.3364, 0.3464],\n",
      "        [0.3821, 0.2905, 0.3274],\n",
      "        [0.4219, 0.3240, 0.2542],\n",
      "        [0.2876, 0.4011, 0.3113],\n",
      "        [0.2642, 0.4363, 0.2996],\n",
      "        [0.3013, 0.3821, 0.3169],\n",
      "        [0.2659, 0.4160, 0.3184],\n",
      "        [0.3635, 0.3293, 0.3069],\n",
      "        [0.3162, 0.3560, 0.3281],\n",
      "        [0.3123, 0.3245, 0.3630],\n",
      "        [0.3398, 0.2612, 0.3989],\n",
      "        [0.3169, 0.3459, 0.3372],\n",
      "        [0.3586, 0.3831, 0.2583],\n",
      "        [0.3411, 0.3347, 0.3242],\n",
      "        [0.4065, 0.3198, 0.2737],\n",
      "        [0.4382, 0.2245, 0.3374],\n",
      "        [0.4426, 0.2849, 0.2725],\n",
      "        [0.4236, 0.2236, 0.3528]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1987, -0.0420,  0.1142],\n",
      "        [ 0.2023, -0.0181, -0.1013],\n",
      "        [ 0.1553, -0.2380, -0.1262],\n",
      "        [ 0.3201, -0.0026, -0.1694],\n",
      "        [ 0.2333,  0.2159, -0.0319],\n",
      "        [ 0.1884, -0.0187,  0.3794],\n",
      "        [ 0.1935,  0.0643,  0.6694],\n",
      "        [ 0.0083, -0.0037,  0.3787],\n",
      "        [ 0.0195, -0.1790,  0.2554],\n",
      "        [-0.0175, -0.1942,  0.0168],\n",
      "        [ 0.2400,  0.0100, -0.0010],\n",
      "        [ 0.1788, -0.0295, -0.0200],\n",
      "        [ 0.2058, -0.0992, -0.0840],\n",
      "        [ 0.2842, -0.3774, -0.1730],\n",
      "        [ 0.2578, -0.4221, -0.0837],\n",
      "        [ 0.4302, -0.3015, -0.0019],\n",
      "        [ 0.3264, -0.2693,  0.1144],\n",
      "        [ 0.3037, -0.3411,  0.1527],\n",
      "        [ 0.1245, -0.3523, -0.0366],\n",
      "        [ 0.3440, -0.3625,  0.1290],\n",
      "        [ 0.2898, -0.2241, -0.2183],\n",
      "        [ 0.3215, -0.2849,  0.1587],\n",
      "        [ 0.1597,  0.1654,  0.2773],\n",
      "        [ 0.2222,  0.1033,  0.2167],\n",
      "        [ 0.1566,  0.0927,  0.2239],\n",
      "        [ 0.2223, -0.0346,  0.1750],\n",
      "        [ 0.2983, -0.2771,  0.1670],\n",
      "        [ 0.1960, -0.1316, -0.0960],\n",
      "        [ 0.1035,  0.0461, -0.2339],\n",
      "        [ 0.3345, -0.1224, -0.2830],\n",
      "        [ 0.0727,  0.1210, -0.2109],\n",
      "        [ 0.2090,  0.0609, -0.1277],\n",
      "        [ 0.2634,  0.1434, -0.1844],\n",
      "        [ 0.0407,  0.2825, -0.0779],\n",
      "        [ 0.3652,  0.1608, -0.2108],\n",
      "        [ 0.7036, -0.1896,  0.0538],\n",
      "        [ 0.3215,  0.0508,  0.3918],\n",
      "        [ 0.3081,  0.0745,  0.2053],\n",
      "        [ 0.2534,  0.2325,  0.2045],\n",
      "        [ 0.0266,  0.0764,  0.1622],\n",
      "        [ 0.1558,  0.0848, -0.0549],\n",
      "        [ 0.1987,  0.0308,  0.1436],\n",
      "        [ 0.3721, -0.1965,  0.1440],\n",
      "        [ 0.1650, -0.0798,  0.1965],\n",
      "        [ 0.4038, -0.0536,  0.0855],\n",
      "        [ 0.2266,  0.0441,  0.2036],\n",
      "        [ 0.2776, -0.0850,  0.1598],\n",
      "        [ 0.2371, -0.0107,  0.1921],\n",
      "        [ 0.2722,  0.0208,  0.2361],\n",
      "        [-0.1255,  0.2072,  0.0757],\n",
      "        [ 0.0689,  0.1610,  0.3301],\n",
      "        [ 0.0761,  0.0916,  0.2268],\n",
      "        [ 0.3455,  0.2310,  0.0655],\n",
      "        [ 0.3582,  0.1156, -0.1798],\n",
      "        [ 0.2600,  0.3137, -0.2130],\n",
      "        [ 0.3057,  0.3569, -0.0510],\n",
      "        [ 0.3013,  0.1785, -0.1509],\n",
      "        [ 0.2800,  0.1031,  0.0779],\n",
      "        [ 0.4568, -0.0416, -0.1697],\n",
      "        [ 0.3569,  0.0834,  0.0427],\n",
      "        [ 0.7734, -0.0297, -0.1719],\n",
      "        [ 0.3674, -0.1732,  0.3640],\n",
      "        [-0.0569,  0.2240,  0.6440],\n",
      "        [-0.1024,  0.2161,  0.4954],\n",
      "        [ 0.1509,  0.0927,  0.0086],\n",
      "        [ 0.2129,  0.2238,  0.1265],\n",
      "        [ 0.2776,  0.1207,  0.1406],\n",
      "        [ 0.4031, -0.0352, -0.0181],\n",
      "        [ 0.5503, -0.1941,  0.0731],\n",
      "        [ 0.3210, -0.0291,  0.2310],\n",
      "        [ 0.4077, -0.0116,  0.0409],\n",
      "        [ 0.2246,  0.0734,  0.1382],\n",
      "        [ 0.3931, -0.0440,  0.2321],\n",
      "        [ 0.0376,  0.0382,  0.2432],\n",
      "        [ 0.3286,  0.1283,  0.1606],\n",
      "        [-0.0274,  0.1913,  0.2185],\n",
      "        [ 0.5176,  0.0056,  0.4805],\n",
      "        [ 0.0582, -0.0711,  0.3594],\n",
      "        [ 0.2812, -0.0773,  0.3569],\n",
      "        [ 0.5679, -0.1906,  0.1892],\n",
      "        [ 0.2744, -0.2471, -0.0515],\n",
      "        [ 0.1583, -0.1320, -0.3882],\n",
      "        [ 0.4438, -0.3987, -0.1735],\n",
      "        [ 0.3660, -0.1342, -0.1715],\n",
      "        [ 0.3296,  0.2175, -0.0195],\n",
      "        [ 0.3049,  0.1503, -0.0465],\n",
      "        [ 0.3516,  0.1171, -0.2098],\n",
      "        [ 0.2998,  0.1522, -0.0142],\n",
      "        [ 0.7773,  0.0333, -0.3521],\n",
      "        [ 0.3113, -0.0798,  0.2019],\n",
      "        [ 0.3794,  0.0634,  0.3030],\n",
      "        [ 0.1628,  0.0443,  0.1313],\n",
      "        [ 0.2197,  0.0302, -0.0733],\n",
      "        [ 0.3411,  0.1013,  0.1500],\n",
      "        [ 0.3628,  0.0439,  0.0394],\n",
      "        [ 0.1891,  0.1239,  0.0173],\n",
      "        [ 0.4851, -0.0392,  0.0359],\n",
      "        [ 0.2922,  0.2578,  0.0122],\n",
      "        [ 0.3916, -0.1132,  0.0692],\n",
      "        [ 0.0895, -0.0432,  0.1771],\n",
      "        [ 0.0462,  0.0673,  0.1176],\n",
      "        [-0.1765,  0.2495,  0.0906],\n",
      "        [ 0.3152,  0.1464,  0.1239],\n",
      "        [ 0.1588,  0.4690,  0.0170],\n",
      "        [ 0.2301,  0.4270, -0.1711],\n",
      "        [ 0.1603,  0.4753, -0.1504],\n",
      "        [ 0.3574,  0.2380, -0.1901],\n",
      "        [ 0.1917,  0.2810, -0.1120],\n",
      "        [ 0.6855,  0.1863, -0.2407],\n",
      "        [ 0.2922, -0.0538,  0.1676],\n",
      "        [-0.0134,  0.2415,  0.2988],\n",
      "        [-0.0536,  0.1851,  0.2524],\n",
      "        [ 0.2318,  0.0620, -0.1350],\n",
      "        [ 0.3191,  0.2524,  0.0701],\n",
      "        [ 0.3154,  0.2274,  0.0230],\n",
      "        [ 0.2111,  0.0228,  0.0439],\n",
      "        [ 0.4143,  0.0452, -0.0249],\n",
      "        [ 0.3081,  0.2135,  0.0472],\n",
      "        [ 0.3193,  0.1317,  0.0645],\n",
      "        [-0.0428,  0.1385,  0.0531],\n",
      "        [ 0.2922,  0.1678,  0.3064],\n",
      "        [-0.1656,  0.2062,  0.3030],\n",
      "        [ 0.1727,  0.2900,  0.1935],\n",
      "        [-0.2161,  0.2290,  0.2008],\n",
      "        [ 0.3152,  0.1204,  0.1827],\n",
      "        [ 0.0759,  0.1632,  0.0139],\n",
      "        [ 0.2443,  0.4050,  0.0111],\n",
      "        [ 0.3184,  0.2874, -0.0920],\n",
      "        [ 0.4553,  0.0167, -0.2844],\n",
      "        [ 0.0581,  0.0490, -0.0280],\n",
      "        [ 0.2952, -0.1901, -0.2856],\n",
      "        [ 0.1348, -0.1237, -0.0179]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2827, 0.3308, 0.3865],\n",
      "        [0.3936, 0.3157, 0.2905],\n",
      "        [0.4116, 0.2778, 0.3105],\n",
      "        [0.4280, 0.3098, 0.2622],\n",
      "        [0.3635, 0.3574, 0.2791],\n",
      "        [0.3308, 0.2688, 0.4004],\n",
      "        [0.2866, 0.2520, 0.4614],\n",
      "        [0.2910, 0.2876, 0.4214],\n",
      "        [0.3240, 0.2656, 0.4102],\n",
      "        [0.3481, 0.2917, 0.3601],\n",
      "        [0.3875, 0.3079, 0.3044],\n",
      "        [0.3799, 0.3086, 0.3115],\n",
      "        [0.4023, 0.2966, 0.3010],\n",
      "        [0.4653, 0.2401, 0.2947],\n",
      "        [0.4509, 0.2285, 0.3206],\n",
      "        [0.4695, 0.2258, 0.3047],\n",
      "        [0.4238, 0.2335, 0.3428],\n",
      "        [0.4194, 0.2201, 0.3606],\n",
      "        [0.4045, 0.2512, 0.3442],\n",
      "        [0.4348, 0.2145, 0.3506],\n",
      "        [0.4546, 0.2720, 0.2734],\n",
      "        [0.4175, 0.2277, 0.3547],\n",
      "        [0.3193, 0.3213, 0.3594],\n",
      "        [0.3469, 0.3081, 0.3450],\n",
      "        [0.3325, 0.3120, 0.3557],\n",
      "        [0.3667, 0.2837, 0.3499],\n",
      "        [0.4099, 0.2306, 0.3594],\n",
      "        [0.4053, 0.2920, 0.3027],\n",
      "        [0.3762, 0.3552, 0.2686],\n",
      "        [0.4602, 0.2915, 0.2483],\n",
      "        [0.3569, 0.3745, 0.2688],\n",
      "        [0.3882, 0.3347, 0.2771],\n",
      "        [0.3960, 0.3511, 0.2529],\n",
      "        [0.3164, 0.4028, 0.2810],\n",
      "        [0.4207, 0.3428, 0.2365],\n",
      "        [0.5176, 0.2119, 0.2703],\n",
      "        [0.3525, 0.2690, 0.3784],\n",
      "        [0.3711, 0.2939, 0.3350],\n",
      "        [0.3411, 0.3340, 0.3247],\n",
      "        [0.3127, 0.3289, 0.3584],\n",
      "        [0.3647, 0.3398, 0.2954],\n",
      "        [0.3582, 0.3027, 0.3389],\n",
      "        [0.4233, 0.2397, 0.3369],\n",
      "        [0.3552, 0.2781, 0.3667],\n",
      "        [0.4236, 0.2681, 0.3081],\n",
      "        [0.3557, 0.2964, 0.3477],\n",
      "        [0.3870, 0.2693, 0.3440],\n",
      "        [0.3655, 0.2852, 0.3494],\n",
      "        [0.3647, 0.2837, 0.3518],\n",
      "        [0.2764, 0.3855, 0.3381],\n",
      "        [0.2947, 0.3230, 0.3826],\n",
      "        [0.3147, 0.3196, 0.3657],\n",
      "        [0.3777, 0.3369, 0.2854],\n",
      "        [0.4221, 0.3313, 0.2466],\n",
      "        [0.3733, 0.3940, 0.2327],\n",
      "        [0.3633, 0.3823, 0.2544],\n",
      "        [0.3967, 0.3508, 0.2524],\n",
      "        [0.3767, 0.3157, 0.3079],\n",
      "        [0.4668, 0.2837, 0.2495],\n",
      "        [0.4014, 0.3054, 0.2932],\n",
      "        [0.5444, 0.2439, 0.2115],\n",
      "        [0.3877, 0.2258, 0.3865],\n",
      "        [0.2305, 0.3052, 0.4644],\n",
      "        [0.2385, 0.3279, 0.4336],\n",
      "        [0.3557, 0.3357, 0.3086],\n",
      "        [0.3416, 0.3452, 0.3132],\n",
      "        [0.3667, 0.3135, 0.3198],\n",
      "        [0.4346, 0.2803, 0.2852],\n",
      "        [0.4773, 0.2267, 0.2961],\n",
      "        [0.3818, 0.2690, 0.3491],\n",
      "        [0.4255, 0.2798, 0.2949],\n",
      "        [0.3601, 0.3096, 0.3303],\n",
      "        [0.4004, 0.2585, 0.3408],\n",
      "        [0.3098, 0.3098, 0.3804],\n",
      "        [0.3755, 0.3074, 0.3174],\n",
      "        [0.2839, 0.3533, 0.3630],\n",
      "        [0.3901, 0.2339, 0.3760],\n",
      "        [0.3096, 0.2720, 0.4185],\n",
      "        [0.3601, 0.2515, 0.3884],\n",
      "        [0.4644, 0.2175, 0.3181],\n",
      "        [0.4319, 0.2563, 0.3118],\n",
      "        [0.4297, 0.3215, 0.2488],\n",
      "        [0.5078, 0.2186, 0.2737],\n",
      "        [0.4565, 0.2769, 0.2666],\n",
      "        [0.3848, 0.3440, 0.2712],\n",
      "        [0.3906, 0.3347, 0.2749],\n",
      "        [0.4236, 0.3350, 0.2416],\n",
      "        [0.3855, 0.3328, 0.2817],\n",
      "        [0.5562, 0.2642, 0.1797],\n",
      "        [0.3887, 0.2629, 0.3484],\n",
      "        [0.3765, 0.2747, 0.3489],\n",
      "        [0.3501, 0.3108, 0.3391],\n",
      "        [0.3887, 0.3215, 0.2898],\n",
      "        [0.3828, 0.3010, 0.3162],\n",
      "        [0.4080, 0.2966, 0.2954],\n",
      "        [0.3599, 0.3372, 0.3030],\n",
      "        [0.4485, 0.2654, 0.2861],\n",
      "        [0.3674, 0.3550, 0.2776],\n",
      "        [0.4294, 0.2593, 0.3110],\n",
      "        [0.3369, 0.2952, 0.3679],\n",
      "        [0.3230, 0.3301, 0.3469],\n",
      "        [0.2605, 0.3989, 0.3403],\n",
      "        [0.3745, 0.3164, 0.3093],\n",
      "        [0.3096, 0.4221, 0.2686],\n",
      "        [0.3464, 0.4216, 0.2319],\n",
      "        [0.3223, 0.4417, 0.2362],\n",
      "        [0.4055, 0.3599, 0.2346],\n",
      "        [0.3533, 0.3862, 0.2607],\n",
      "        [0.4993, 0.3030, 0.1978],\n",
      "        [0.3860, 0.2732, 0.3408],\n",
      "        [0.2734, 0.3528, 0.3738],\n",
      "        [0.2756, 0.3499, 0.3743],\n",
      "        [0.3943, 0.3328, 0.2732],\n",
      "        [0.3684, 0.3445, 0.2871],\n",
      "        [0.3757, 0.3440, 0.2805],\n",
      "        [0.3740, 0.3098, 0.3164],\n",
      "        [0.4280, 0.2959, 0.2759],\n",
      "        [0.3730, 0.3394, 0.2874],\n",
      "        [0.3840, 0.3184, 0.2976],\n",
      "        [0.3030, 0.3633, 0.3335],\n",
      "        [0.3452, 0.3047, 0.3501],\n",
      "        [0.2471, 0.3584, 0.3948],\n",
      "        [0.3179, 0.3574, 0.3247],\n",
      "        [0.2452, 0.3828, 0.3721],\n",
      "        [0.3706, 0.3049, 0.3245],\n",
      "        [0.3298, 0.3601, 0.3101],\n",
      "        [0.3372, 0.3960, 0.2671],\n",
      "        [0.3799, 0.3682, 0.2520],\n",
      "        [0.4712, 0.3040, 0.2249],\n",
      "        [0.3438, 0.3408, 0.3154],\n",
      "        [0.4597, 0.2830, 0.2573],\n",
      "        [0.3801, 0.2935, 0.3264]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.2756, -0.1333,  0.2559],\n",
      "        [ 0.0303,  0.0055, -0.1895],\n",
      "        [ 0.0809, -0.3545, -0.1327],\n",
      "        [-0.0777, -0.3728, -0.0054],\n",
      "        [ 0.1771, -0.1478,  0.0878],\n",
      "        [-0.1038,  0.1338,  0.1801],\n",
      "        [ 0.2084, -0.2025,  0.0606],\n",
      "        [ 0.0270,  0.1682,  0.2070],\n",
      "        [-0.0147,  0.1522,  0.1405],\n",
      "        [-0.2263,  0.4504,  0.3542],\n",
      "        [ 0.0333, -0.1249, -0.0462],\n",
      "        [-0.1409,  0.0102,  0.1836],\n",
      "        [-0.0464, -0.2830,  0.0028],\n",
      "        [-0.1166, -0.0325,  0.2581],\n",
      "        [-0.0806, -0.3228,  0.0121],\n",
      "        [-0.0077, -0.4500,  0.0348],\n",
      "        [ 0.1458, -0.5508, -0.1416],\n",
      "        [ 0.2308, -0.2832,  0.1433],\n",
      "        [ 0.1016, -0.2429,  0.0022],\n",
      "        [ 0.1921, -0.2812,  0.0804],\n",
      "        [ 0.2184, -0.4453, -0.2312],\n",
      "        [ 0.4055, -0.3030, -0.0320],\n",
      "        [ 0.0967, -0.4539, -0.0516],\n",
      "        [ 0.2241, -0.4331,  0.0983],\n",
      "        [ 0.1757, -0.5444, -0.2168],\n",
      "        [ 0.2620, -0.4954,  0.0693],\n",
      "        [ 0.2866, -0.6606, -0.1511],\n",
      "        [ 0.2452, -0.5166,  0.0151]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2595, 0.2991, 0.4414],\n",
      "        [0.3599, 0.3511, 0.2888],\n",
      "        [0.4075, 0.2637, 0.3291],\n",
      "        [0.3547, 0.2642, 0.3813],\n",
      "        [0.3792, 0.2739, 0.3469],\n",
      "        [0.2781, 0.3525, 0.3694],\n",
      "        [0.3960, 0.2625, 0.3416],\n",
      "        [0.2986, 0.3440, 0.3574],\n",
      "        [0.2986, 0.3528, 0.3486],\n",
      "        [0.2103, 0.4138, 0.3760],\n",
      "        [0.3601, 0.3074, 0.3325],\n",
      "        [0.2820, 0.3279, 0.3901],\n",
      "        [0.3521, 0.2781, 0.3699],\n",
      "        [0.2822, 0.3071, 0.4106],\n",
      "        [0.3469, 0.2725, 0.3806],\n",
      "        [0.3723, 0.2393, 0.3884],\n",
      "        [0.4448, 0.2216, 0.3337],\n",
      "        [0.3977, 0.2379, 0.3645],\n",
      "        [0.3826, 0.2710, 0.3464],\n",
      "        [0.3972, 0.2474, 0.3552],\n",
      "        [0.4646, 0.2391, 0.2964],\n",
      "        [0.4678, 0.2303, 0.3020],\n",
      "        [0.4102, 0.2365, 0.3535],\n",
      "        [0.4167, 0.2159, 0.3674],\n",
      "        [0.4624, 0.2251, 0.3125],\n",
      "        [0.4360, 0.2045, 0.3596],\n",
      "        [0.4917, 0.1907, 0.3174],\n",
      "        [0.4421, 0.2064, 0.3513]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0773, -0.1564,  0.4302],\n",
      "        [ 0.0103, -0.2080,  0.1429],\n",
      "        [ 0.2065, -0.3442, -0.1764],\n",
      "        [ 0.1290, -0.3723,  0.0953]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3110, 0.2462, 0.4426],\n",
      "        [0.3396, 0.2729, 0.3877],\n",
      "        [0.4429, 0.2554, 0.3020],\n",
      "        [0.3887, 0.2355, 0.3757]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0126, -0.0771,  0.0800],\n",
      "        [ 0.2747, -0.2085, -0.0562],\n",
      "        [ 0.3816, -0.0943, -0.1814],\n",
      "        [ 0.3633, -0.1331, -0.2629],\n",
      "        [-0.0728, -0.1819, -0.0426],\n",
      "        [ 0.1371,  0.0302, -0.0579],\n",
      "        [ 0.3650, -0.3162, -0.0152],\n",
      "        [ 0.0463, -0.3164,  0.0635],\n",
      "        [ 0.0177, -0.3579, -0.1541],\n",
      "        [ 0.2720, -0.0602, -0.0683],\n",
      "        [ 0.2487, -0.1615, -0.2272],\n",
      "        [ 0.0770,  0.0989, -0.0447],\n",
      "        [-0.0446,  0.1072, -0.1459],\n",
      "        [ 0.2134, -0.1171, -0.1932],\n",
      "        [ 0.1573,  0.0562, -0.1403],\n",
      "        [ 0.2050,  0.0953,  0.1460],\n",
      "        [ 0.3223,  0.0014,  0.1129],\n",
      "        [ 0.5278,  0.1060, -0.0202],\n",
      "        [ 0.1821, -0.0795, -0.1572],\n",
      "        [ 0.4683, -0.2140,  0.2471],\n",
      "        [ 0.0454, -0.0121,  0.0201],\n",
      "        [ 0.4480, -0.2585,  0.1050],\n",
      "        [ 0.0146, -0.2041, -0.1418],\n",
      "        [ 0.4114, -0.3464,  0.0964]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3296, 0.3088, 0.3616],\n",
      "        [0.4282, 0.2642, 0.3076],\n",
      "        [0.4565, 0.2837, 0.2600],\n",
      "        [0.4666, 0.2839, 0.2494],\n",
      "        [0.3416, 0.3064, 0.3521],\n",
      "        [0.3674, 0.3303, 0.3022],\n",
      "        [0.4568, 0.2311, 0.3123],\n",
      "        [0.3687, 0.2563, 0.3750],\n",
      "        [0.3955, 0.2715, 0.3330],\n",
      "        [0.4116, 0.2954, 0.2930],\n",
      "        [0.4377, 0.2903, 0.2720],\n",
      "        [0.3440, 0.3516, 0.3044],\n",
      "        [0.3259, 0.3794, 0.2947],\n",
      "        [0.4194, 0.3013, 0.2793],\n",
      "        [0.3779, 0.3416, 0.2805],\n",
      "        [0.3523, 0.3157, 0.3320],\n",
      "        [0.3943, 0.2861, 0.3198],\n",
      "        [0.4478, 0.2937, 0.2588],\n",
      "        [0.4028, 0.3101, 0.2869],\n",
      "        [0.4333, 0.2191, 0.3474],\n",
      "        [0.3425, 0.3235, 0.3340],\n",
      "        [0.4539, 0.2240, 0.3220],\n",
      "        [0.3762, 0.3022, 0.3215],\n",
      "        [0.4548, 0.2131, 0.3320]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-1.4954e-01, -1.3635e-01,  3.8391e-02],\n",
      "        [ 9.1248e-02, -2.1924e-01, -1.3220e-01],\n",
      "        [ 2.8849e-04, -7.2693e-02, -1.7603e-01],\n",
      "        [-1.8079e-01, -7.7454e-02, -9.3155e-03],\n",
      "        [-4.9500e-02, -2.8784e-01, -3.9917e-02],\n",
      "        [-6.6757e-03, -6.1981e-02,  1.9519e-01],\n",
      "        [ 1.2042e-01, -1.1871e-01, -1.2952e-01],\n",
      "        [-2.0361e-01, -1.0144e-01,  2.4170e-01],\n",
      "        [-2.0398e-01, -2.2705e-01,  1.0437e-01],\n",
      "        [-9.6130e-02, -3.0664e-01,  2.8809e-01],\n",
      "        [-2.4048e-01, -1.3196e-01, -2.9861e-02],\n",
      "        [-1.6162e-01, -5.5542e-02,  2.3706e-01],\n",
      "        [ 1.6602e-02, -8.0032e-03,  1.1121e-01],\n",
      "        [-1.6260e-01, -9.4299e-02,  2.9053e-01],\n",
      "        [ 1.6455e-01, -2.9150e-01, -8.6792e-02],\n",
      "        [-1.5613e-01,  4.2969e-02, -2.4878e-01],\n",
      "        [-3.6373e-03,  5.4413e-02, -7.0312e-02],\n",
      "        [ 3.8605e-02, -1.5161e-01, -1.9629e-01],\n",
      "        [ 3.2227e-01,  3.3508e-02, -2.1509e-01],\n",
      "        [ 3.1226e-01, -2.0679e-01, -2.8467e-01],\n",
      "        [ 2.8979e-01, -1.2842e-01, -1.7407e-01],\n",
      "        [ 9.7778e-02,  1.3464e-01, -1.4990e-01],\n",
      "        [ 3.6133e-01, -2.4744e-01, -1.7810e-01],\n",
      "        [ 2.4915e-01, -1.6406e-01, -1.9165e-01],\n",
      "        [ 8.0322e-02, -1.7609e-02, -3.2788e-01],\n",
      "        [ 4.1333e-01, -1.7834e-01, -2.7563e-01],\n",
      "        [ 4.4092e-01, -2.7734e-01, -4.1357e-01],\n",
      "        [ 3.3081e-01,  4.2152e-03, -3.3862e-01],\n",
      "        [ 8.1665e-02, -1.4258e-01,  1.9180e-02],\n",
      "        [-3.7628e-02, -3.9062e-03, -2.5732e-01],\n",
      "        [-7.3853e-02, -3.2153e-01, -2.8857e-01],\n",
      "        [-3.3081e-02,  1.5762e-02, -2.0361e-01],\n",
      "        [-1.8225e-01, -3.0176e-01, -2.4399e-02],\n",
      "        [-2.3230e-01, -1.1383e-01, -1.2042e-01],\n",
      "        [-6.1005e-02, -1.9592e-02, -1.0278e-01],\n",
      "        [-3.5913e-01, -1.3806e-01,  4.1473e-02],\n",
      "        [-3.5156e-01, -2.5513e-01,  1.1914e-01],\n",
      "        [-2.2430e-02, -2.1683e-02,  3.7506e-02],\n",
      "        [-2.8833e-01, -9.7839e-02,  1.4183e-02],\n",
      "        [-1.5967e-01, -5.8258e-02,  1.9775e-01],\n",
      "        [-8.9844e-02, -1.0376e-01,  9.5581e-02],\n",
      "        [ 4.5807e-02, -8.5388e-02, -5.2795e-02],\n",
      "        [-3.0176e-01,  1.1084e-01,  9.1309e-02],\n",
      "        [-1.3924e-02, -2.4573e-01, -3.2501e-02],\n",
      "        [ 3.1470e-01, -2.6660e-01, -6.0944e-02],\n",
      "        [ 1.5283e-01, -1.9995e-01, -2.3849e-02],\n",
      "        [ 1.9031e-01, -2.6245e-01,  1.3634e-02],\n",
      "        [-7.3547e-02, -3.3398e-01,  1.6638e-01],\n",
      "        [ 1.3710e-02, -3.6230e-01,  2.5684e-01],\n",
      "        [-8.3435e-02, -3.3051e-02,  2.6245e-01],\n",
      "        [ 2.4353e-01, -3.6450e-01,  2.8613e-01],\n",
      "        [ 5.0262e-02, -1.1584e-01,  1.1932e-01],\n",
      "        [ 3.1543e-01, -3.7939e-01,  1.1383e-02],\n",
      "        [ 2.5537e-01, -1.6333e-01, -1.1243e-01],\n",
      "        [-2.7573e-02, -5.2856e-02,  6.1157e-02],\n",
      "        [ 1.3330e-01, -1.4429e-01,  1.1969e-01],\n",
      "        [ 1.3680e-02, -1.5247e-01,  1.7993e-01],\n",
      "        [ 1.6418e-01, -2.5952e-01,  2.0227e-01],\n",
      "        [ 1.2048e-01, -1.7126e-01,  9.5764e-02],\n",
      "        [ 1.1841e-01, -9.3018e-02,  1.2402e-01],\n",
      "        [-7.8552e-02, -1.5491e-01,  1.1734e-02],\n",
      "        [ 4.9805e-01, -3.2959e-01,  6.6162e-02],\n",
      "        [ 1.5320e-01, -2.1741e-01,  3.9032e-02],\n",
      "        [ 2.9346e-01, -3.7384e-02, -1.1218e-01],\n",
      "        [ 2.6147e-01, -9.7717e-02,  3.4058e-02],\n",
      "        [-5.6976e-02,  8.2825e-02,  2.5781e-01],\n",
      "        [-4.8923e-04, -3.8391e-02,  2.0874e-01],\n",
      "        [-1.3647e-01,  2.8394e-01, -4.7058e-02],\n",
      "        [-1.2598e-01,  6.9214e-02,  1.7920e-01],\n",
      "        [-2.4902e-01,  2.2070e-01,  3.4393e-02],\n",
      "        [-1.7004e-01,  2.8394e-01,  1.6003e-03],\n",
      "        [ 2.7197e-01,  7.5221e-05,  1.5283e-01],\n",
      "        [ 7.0496e-02,  9.9548e-02,  1.1371e-01],\n",
      "        [ 2.3438e-01,  1.9791e-02, -9.9640e-03],\n",
      "        [ 2.3792e-01, -2.6562e-01,  1.7834e-01],\n",
      "        [ 1.9775e-01, -3.4644e-01,  1.0138e-01],\n",
      "        [ 1.0870e-01, -3.4717e-01,  2.5366e-01],\n",
      "        [-1.9507e-01, -6.1722e-03,  3.2739e-01],\n",
      "        [ 1.8402e-02, -1.3806e-01,  3.9368e-02],\n",
      "        [-2.2083e-01, -2.7100e-01,  1.2561e-01],\n",
      "        [-1.6833e-01, -1.5125e-01,  2.2083e-01],\n",
      "        [ 3.9917e-02,  2.9999e-02,  1.8320e-03],\n",
      "        [-5.9204e-02,  3.1471e-03,  3.1836e-01],\n",
      "        [-4.9011e-02,  1.1914e-01,  1.8298e-01],\n",
      "        [-2.3694e-01,  9.7168e-02,  1.5857e-01],\n",
      "        [-1.2781e-01,  6.7871e-02,  1.0504e-01],\n",
      "        [-4.6875e-02, -5.8167e-02, -3.5114e-03],\n",
      "        [-2.9785e-01,  3.2910e-01, -9.7839e-02],\n",
      "        [-9.6436e-02, -1.7120e-02, -2.6807e-01],\n",
      "        [-1.2280e-01, -6.6872e-03, -8.3252e-02],\n",
      "        [-6.1951e-03, -1.4648e-01, -2.7515e-01],\n",
      "        [-7.9346e-02, -1.5027e-01, -9.4543e-02]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3105, 0.3147, 0.3748],\n",
      "        [0.3948, 0.2896, 0.3157],\n",
      "        [0.3613, 0.3359, 0.3030],\n",
      "        [0.3035, 0.3364, 0.3601],\n",
      "        [0.3574, 0.2817, 0.3608],\n",
      "        [0.3154, 0.2986, 0.3860],\n",
      "        [0.3896, 0.3069, 0.3035],\n",
      "        [0.2727, 0.3020, 0.4255],\n",
      "        [0.2996, 0.2927, 0.4077],\n",
      "        [0.3049, 0.2471, 0.4480],\n",
      "        [0.2986, 0.3328, 0.3687],\n",
      "        [0.2776, 0.3086, 0.4136],\n",
      "        [0.3252, 0.3174, 0.3574],\n",
      "        [0.2744, 0.2939, 0.4316],\n",
      "        [0.4148, 0.2627, 0.3225],\n",
      "        [0.3193, 0.3896, 0.2910],\n",
      "        [0.3337, 0.3538, 0.3123],\n",
      "        [0.3821, 0.3159, 0.3020],\n",
      "        [0.4285, 0.3210, 0.2505],\n",
      "        [0.4661, 0.2773, 0.2566],\n",
      "        [0.4373, 0.2878, 0.2749],\n",
      "        [0.3547, 0.3682, 0.2771],\n",
      "        [0.4702, 0.2559, 0.2742],\n",
      "        [0.4338, 0.2871, 0.2793],\n",
      "        [0.3889, 0.3525, 0.2585],\n",
      "        [0.4866, 0.2693, 0.2443],\n",
      "        [0.5229, 0.2549, 0.2224],\n",
      "        [0.4478, 0.3230, 0.2292],\n",
      "        [0.3652, 0.2917, 0.3430],\n",
      "        [0.3525, 0.3645, 0.2830],\n",
      "        [0.3865, 0.3018, 0.3118],\n",
      "        [0.3457, 0.3630, 0.2915],\n",
      "        [0.3269, 0.2900, 0.3828],\n",
      "        [0.3083, 0.3469, 0.3447],\n",
      "        [0.3333, 0.3472, 0.3196],\n",
      "        [0.2673, 0.3335, 0.3992],\n",
      "        [0.2700, 0.2974, 0.4324],\n",
      "        [0.3264, 0.3267, 0.3467],\n",
      "        [0.2808, 0.3396, 0.3799],\n",
      "        [0.2827, 0.3130, 0.4043],\n",
      "        [0.3135, 0.3091, 0.3774],\n",
      "        [0.3594, 0.3152, 0.3257],\n",
      "        [0.2505, 0.3784, 0.3711],\n",
      "        [0.3604, 0.2859, 0.3538],\n",
      "        [0.4453, 0.2489, 0.3059],\n",
      "        [0.3936, 0.2766, 0.3298],\n",
      "        [0.4043, 0.2571, 0.3389],\n",
      "        [0.3289, 0.2534, 0.4180],\n",
      "        [0.3376, 0.2318, 0.4307],\n",
      "        [0.2886, 0.3035, 0.4080],\n",
      "        [0.3865, 0.2103, 0.4033],\n",
      "        [0.3425, 0.2903, 0.3672],\n",
      "        [0.4470, 0.2231, 0.3298],\n",
      "        [0.4255, 0.2800, 0.2947],\n",
      "        [0.3259, 0.3179, 0.3562],\n",
      "        [0.3645, 0.2761, 0.3594],\n",
      "        [0.3303, 0.2798, 0.3899],\n",
      "        [0.3713, 0.2430, 0.3857],\n",
      "        [0.3672, 0.2744, 0.3584],\n",
      "        [0.3552, 0.2876, 0.3572],\n",
      "        [0.3311, 0.3066, 0.3623],\n",
      "        [0.4792, 0.2095, 0.3113],\n",
      "        [0.3872, 0.2673, 0.3455],\n",
      "        [0.4192, 0.3013, 0.2795],\n",
      "        [0.4009, 0.2798, 0.3193],\n",
      "        [0.2842, 0.3267, 0.3892],\n",
      "        [0.3130, 0.3013, 0.3857],\n",
      "        [0.2766, 0.4211, 0.3025],\n",
      "        [0.2800, 0.3403, 0.3799],\n",
      "        [0.2546, 0.4072, 0.3381],\n",
      "        [0.2659, 0.4185, 0.3157],\n",
      "        [0.3774, 0.2876, 0.3350],\n",
      "        [0.3254, 0.3350, 0.3396],\n",
      "        [0.3860, 0.3115, 0.3025],\n",
      "        [0.3926, 0.2373, 0.3699],\n",
      "        [0.4019, 0.2332, 0.3650],\n",
      "        [0.3584, 0.2272, 0.4143],\n",
      "        [0.2568, 0.3103, 0.4331],\n",
      "        [0.3477, 0.2974, 0.3550],\n",
      "        [0.2971, 0.2827, 0.4202],\n",
      "        [0.2864, 0.2913, 0.4226],\n",
      "        [0.3386, 0.3352, 0.3259],\n",
      "        [0.2839, 0.3020, 0.4141],\n",
      "        [0.2903, 0.3435, 0.3662],\n",
      "        [0.2576, 0.3599, 0.3826],\n",
      "        [0.2876, 0.3496, 0.3628],\n",
      "        [0.3296, 0.3259, 0.3442],\n",
      "        [0.2443, 0.4573, 0.2983],\n",
      "        [0.3418, 0.3701, 0.2881],\n",
      "        [0.3162, 0.3550, 0.3289],\n",
      "        [0.3796, 0.3301, 0.2903],\n",
      "        [0.3428, 0.3193, 0.3376]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-8.2825e-02, -1.3130e-02, -8.0688e-02],\n",
      "        [-1.0901e-01,  9.2346e-02, -2.2595e-01],\n",
      "        [ 3.3386e-02,  1.3069e-02, -6.6711e-02],\n",
      "        [ 2.0190e-01, -5.6091e-02,  4.6570e-02],\n",
      "        [ 5.5145e-02,  6.1340e-02,  7.5378e-02],\n",
      "        [-1.4111e-01, -1.7731e-02,  7.3914e-02],\n",
      "        [ 1.0956e-01, -6.3538e-02, -1.1316e-01],\n",
      "        [ 2.2925e-01,  1.2769e-01, -1.8478e-02],\n",
      "        [ 2.5635e-01,  1.0217e-01,  6.8481e-02],\n",
      "        [ 3.0664e-01,  8.7708e-02,  2.5439e-01],\n",
      "        [ 2.4170e-01, -4.1901e-02,  3.1787e-01],\n",
      "        [ 1.7249e-01,  1.3623e-01,  2.7246e-01],\n",
      "        [ 8.5678e-03, -1.1267e-01,  1.2036e-01],\n",
      "        [ 1.4404e-01, -1.6833e-01,  2.7539e-01],\n",
      "        [ 2.3560e-01, -1.6443e-01, -6.9946e-02],\n",
      "        [-4.8709e-04, -1.6248e-01, -5.6305e-03],\n",
      "        [ 4.8859e-02, -1.5564e-01, -2.2485e-01],\n",
      "        [-3.0548e-02, -3.3862e-01,  7.3181e-02],\n",
      "        [ 2.4829e-01, -3.5986e-01,  1.0486e-01],\n",
      "        [ 4.5801e-01, -3.6011e-01,  4.6997e-02],\n",
      "        [ 3.0396e-01, -5.4541e-01, -8.5205e-02],\n",
      "        [ 3.0176e-01, -2.2180e-01,  2.2571e-01],\n",
      "        [ 2.6709e-01, -2.2839e-01,  5.1422e-02],\n",
      "        [ 2.1936e-01, -4.4946e-01,  3.3936e-01],\n",
      "        [ 2.8931e-02, -3.4277e-01,  1.5038e-02],\n",
      "        [-6.1417e-03, -1.3098e-01,  2.0764e-01],\n",
      "        [ 2.7557e-02, -7.5867e-02,  5.8044e-02],\n",
      "        [ 4.1772e-01,  6.3599e-02, -1.1902e-01],\n",
      "        [-1.0176e-03, -1.0724e-01, -1.0938e-01],\n",
      "        [ 5.5322e-01, -9.9731e-02,  3.3325e-02],\n",
      "        [ 5.2002e-01, -2.9468e-01,  2.2546e-01],\n",
      "        [ 5.5908e-02, -1.9067e-01,  2.1753e-01],\n",
      "        [ 2.4573e-01, -2.1082e-01,  4.2822e-01],\n",
      "        [ 2.5195e-01, -9.9243e-02,  3.0835e-01],\n",
      "        [ 4.3872e-01, -2.6514e-01,  3.3691e-01],\n",
      "        [ 2.4390e-01, -1.3904e-01,  2.2534e-01],\n",
      "        [ 2.6978e-01, -3.2300e-01,  1.3965e-01],\n",
      "        [ 7.2388e-02, -2.0703e-01, -3.4485e-02],\n",
      "        [ 4.4531e-01, -4.1357e-01, -3.9398e-02],\n",
      "        [ 2.1826e-01, -4.7754e-01,  1.7688e-01],\n",
      "        [ 2.0117e-01, -3.3081e-01, -2.1399e-01],\n",
      "        [ 1.5366e-02, -4.2749e-01,  1.1017e-02],\n",
      "        [-1.0260e-01, -4.7192e-01, -4.3373e-03],\n",
      "        [ 4.4785e-03, -4.0479e-01,  8.3862e-02]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3252, 0.3486, 0.3259],\n",
      "        [0.3213, 0.3928, 0.2859],\n",
      "        [0.3467, 0.3396, 0.3137],\n",
      "        [0.3804, 0.2939, 0.3257],\n",
      "        [0.3303, 0.3325, 0.3372],\n",
      "        [0.2966, 0.3357, 0.3677],\n",
      "        [0.3787, 0.3184, 0.3030],\n",
      "        [0.3726, 0.3367, 0.2908],\n",
      "        [0.3723, 0.3191, 0.3086],\n",
      "        [0.3633, 0.2920, 0.3447],\n",
      "        [0.3530, 0.2659, 0.3811],\n",
      "        [0.3257, 0.3142, 0.3601],\n",
      "        [0.3328, 0.2949, 0.3723],\n",
      "        [0.3481, 0.2549, 0.3970],\n",
      "        [0.4155, 0.2786, 0.3062],\n",
      "        [0.3516, 0.2988, 0.3496],\n",
      "        [0.3882, 0.3164, 0.2954],\n",
      "        [0.3516, 0.2583, 0.3901],\n",
      "        [0.4148, 0.2258, 0.3594],\n",
      "        [0.4753, 0.2097, 0.3152],\n",
      "        [0.4751, 0.2031, 0.3218],\n",
      "        [0.3970, 0.2351, 0.3679],\n",
      "        [0.4141, 0.2522, 0.3337],\n",
      "        [0.3789, 0.1941, 0.4270],\n",
      "        [0.3738, 0.2578, 0.3687],\n",
      "        [0.3203, 0.2827, 0.3967],\n",
      "        [0.3411, 0.3074, 0.3516],\n",
      "        [0.4373, 0.3069, 0.2556],\n",
      "        [0.3577, 0.3215, 0.3208],\n",
      "        [0.4729, 0.2461, 0.2810],\n",
      "        [0.4570, 0.2024, 0.3406],\n",
      "        [0.3381, 0.2644, 0.3975],\n",
      "        [0.3528, 0.2235, 0.4236],\n",
      "        [0.3621, 0.2549, 0.3831],\n",
      "        [0.4170, 0.2063, 0.3767],\n",
      "        [0.3755, 0.2561, 0.3687],\n",
      "        [0.4114, 0.2274, 0.3611],\n",
      "        [0.3767, 0.2849, 0.3384],\n",
      "        [0.4902, 0.2078, 0.3020],\n",
      "        [0.4067, 0.2029, 0.3904],\n",
      "        [0.4448, 0.2615, 0.2937],\n",
      "        [0.3792, 0.2434, 0.3774],\n",
      "        [0.3579, 0.2473, 0.3948],\n",
      "        [0.3640, 0.2418, 0.3940]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-1.7456e-02, -2.9321e-01,  1.1407e-01],\n",
      "        [-1.1401e-01,  2.3474e-01,  1.5405e-01],\n",
      "        [-3.2867e-02,  9.2163e-02, -2.0752e-01],\n",
      "        [ 1.5710e-01, -1.1688e-01, -1.5305e-02],\n",
      "        [ 1.0687e-01, -8.0688e-02, -1.9214e-01],\n",
      "        [ 4.2993e-01, -2.5848e-02, -3.8184e-01],\n",
      "        [ 3.4882e-02, -4.0210e-01, -2.6270e-01],\n",
      "        [ 1.2463e-01, -1.6675e-01, -8.4961e-02],\n",
      "        [ 2.0294e-02, -1.1475e-01,  2.0691e-01],\n",
      "        [-1.0950e-01,  4.8889e-02, -1.1945e-01],\n",
      "        [-2.0093e-01,  1.6006e-02, -1.1597e-01],\n",
      "        [-9.6436e-02, -3.9764e-02,  6.3416e-02],\n",
      "        [-1.3098e-01, -2.5511e-04,  1.5414e-04],\n",
      "        [-8.1116e-02,  3.5498e-01,  4.7150e-02],\n",
      "        [ 4.1431e-01,  2.8833e-01, -2.4395e-03],\n",
      "        [ 2.1729e-01,  1.2830e-01,  7.7820e-02],\n",
      "        [ 2.1448e-01,  2.4365e-01,  1.6891e-02],\n",
      "        [ 3.2883e-03,  4.1260e-01, -6.6284e-02],\n",
      "        [ 2.3608e-01,  2.3706e-01,  9.4849e-02],\n",
      "        [ 1.9348e-02, -3.8727e-02,  1.7517e-01],\n",
      "        [ 2.1143e-01, -1.3306e-01,  7.1594e-02],\n",
      "        [ 2.5903e-01, -1.6833e-01, -5.6122e-02],\n",
      "        [ 2.3450e-01, -2.1606e-01,  7.1716e-02],\n",
      "        [ 1.7871e-01,  6.3416e-02,  7.5684e-02],\n",
      "        [ 2.2018e-02,  4.1382e-02,  7.3792e-02],\n",
      "        [ 8.0627e-02,  1.6125e-01,  8.8074e-02],\n",
      "        [ 1.0974e-01,  1.0114e-01,  4.4495e-02],\n",
      "        [ 2.2156e-01,  1.2018e-01,  1.1206e-01],\n",
      "        [-9.2896e-02,  1.3416e-01,  3.2080e-01],\n",
      "        [-1.1597e-01,  2.7637e-01,  1.6708e-02],\n",
      "        [ 1.2585e-01,  5.2979e-02, -6.8855e-03],\n",
      "        [ 1.3306e-01, -1.3245e-01,  1.7105e-02],\n",
      "        [ 9.4238e-02,  7.6332e-03,  4.6883e-03],\n",
      "        [ 6.1462e-02, -1.0004e-01,  1.1176e-01],\n",
      "        [ 1.0144e-01, -1.9373e-01,  2.1838e-01],\n",
      "        [ 4.2700e-01, -1.8848e-01,  2.6855e-01],\n",
      "        [ 1.1414e-01,  2.5708e-01, -2.1765e-01],\n",
      "        [ 1.9739e-01,  2.4487e-01,  1.6858e-01],\n",
      "        [ 2.3108e-01,  1.3708e-01, -3.1403e-02],\n",
      "        [ 5.4639e-01,  1.1456e-01, -1.4307e-01],\n",
      "        [ 3.5132e-01,  1.3416e-01, -1.0199e-01],\n",
      "        [ 4.7559e-01,  1.1609e-01, -3.0444e-01],\n",
      "        [ 1.0376e-01,  3.1030e-01,  3.5004e-02],\n",
      "        [ 7.9834e-02,  2.3206e-01,  4.7180e-02],\n",
      "        [ 1.7627e-01,  1.4441e-01,  3.5645e-02],\n",
      "        [ 7.8430e-02,  1.5417e-01,  4.0039e-02],\n",
      "        [ 2.9932e-01,  2.1179e-01, -8.8135e-02],\n",
      "        [ 3.7866e-01,  2.1988e-02, -1.7236e-01],\n",
      "        [ 3.3569e-01,  1.3855e-01, -1.8677e-01],\n",
      "        [ 5.9375e-01,  1.7258e-02, -4.1797e-01],\n",
      "        [ 2.1332e-02,  5.2551e-02, -1.4722e-01],\n",
      "        [ 3.8666e-02, -5.0537e-02, -3.7134e-01],\n",
      "        [ 7.2289e-03, -1.7502e-02,  8.2474e-03],\n",
      "        [-6.4240e-03, -1.5881e-01, -2.9736e-01],\n",
      "        [ 4.2798e-01,  8.5022e-02, -2.2058e-01],\n",
      "        [ 2.5464e-01, -2.2449e-01,  1.4941e-01],\n",
      "        [ 3.6182e-03, -1.6675e-01, -3.5400e-01]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3450, 0.2617, 0.3933],\n",
      "        [0.2686, 0.3806, 0.3511],\n",
      "        [0.3364, 0.3811, 0.2825],\n",
      "        [0.3843, 0.2922, 0.3235],\n",
      "        [0.3889, 0.3225, 0.2886],\n",
      "        [0.4812, 0.3052, 0.2137],\n",
      "        [0.4187, 0.2705, 0.3108],\n",
      "        [0.3909, 0.2920, 0.3169],\n",
      "        [0.3247, 0.2837, 0.3914],\n",
      "        [0.3162, 0.3706, 0.3132],\n",
      "        [0.3003, 0.3730, 0.3269],\n",
      "        [0.3093, 0.3274, 0.3630],\n",
      "        [0.3049, 0.3474, 0.3477],\n",
      "        [0.2715, 0.4199, 0.3086],\n",
      "        [0.3936, 0.3469, 0.2595],\n",
      "        [0.3591, 0.3286, 0.3123],\n",
      "        [0.3508, 0.3613, 0.2878],\n",
      "        [0.2908, 0.4380, 0.2712],\n",
      "        [0.3486, 0.3489, 0.3027],\n",
      "        [0.3213, 0.3032, 0.3755],\n",
      "        [0.3879, 0.2749, 0.3372],\n",
      "        [0.4199, 0.2739, 0.3064],\n",
      "        [0.4021, 0.2563, 0.3418],\n",
      "        [0.3579, 0.3191, 0.3230],\n",
      "        [0.3254, 0.3318, 0.3428],\n",
      "        [0.3235, 0.3506, 0.3259],\n",
      "        [0.3416, 0.3386, 0.3198],\n",
      "        [0.3572, 0.3228, 0.3201],\n",
      "        [0.2654, 0.3330, 0.4014],\n",
      "        [0.2761, 0.4087, 0.3152],\n",
      "        [0.3564, 0.3313, 0.3123],\n",
      "        [0.3762, 0.2886, 0.3352],\n",
      "        [0.3533, 0.3240, 0.3230],\n",
      "        [0.3445, 0.2932, 0.3623],\n",
      "        [0.3486, 0.2595, 0.3918],\n",
      "        [0.4177, 0.2257, 0.3564],\n",
      "        [0.3484, 0.4019, 0.2499],\n",
      "        [0.3311, 0.3472, 0.3218],\n",
      "        [0.3733, 0.3398, 0.2871],\n",
      "        [0.4648, 0.3018, 0.2333],\n",
      "        [0.4097, 0.3298, 0.2605],\n",
      "        [0.4636, 0.3237, 0.2125],\n",
      "        [0.3162, 0.3887, 0.2952],\n",
      "        [0.3193, 0.3718, 0.3091],\n",
      "        [0.3525, 0.3413, 0.3062],\n",
      "        [0.3289, 0.3547, 0.3164],\n",
      "        [0.3853, 0.3530, 0.2615],\n",
      "        [0.4392, 0.3076, 0.2532],\n",
      "        [0.4143, 0.3401, 0.2456],\n",
      "        [0.5195, 0.2917, 0.1888],\n",
      "        [0.3477, 0.3586, 0.2937],\n",
      "        [0.3879, 0.3547, 0.2573],\n",
      "        [0.3359, 0.3276, 0.3362],\n",
      "        [0.3838, 0.3293, 0.2869],\n",
      "        [0.4480, 0.3179, 0.2341],\n",
      "        [0.3970, 0.2458, 0.3572],\n",
      "        [0.3933, 0.3318, 0.2751]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0738, -0.1635, -0.0025],\n",
      "        [ 0.0353,  0.1652,  0.0481],\n",
      "        [-0.0881,  0.1641,  0.1140],\n",
      "        [ 0.0737,  0.2693,  0.3206],\n",
      "        [ 0.0266, -0.0677, -0.0770],\n",
      "        [-0.2294,  0.1216,  0.1377],\n",
      "        [ 0.0603, -0.1015,  0.0256],\n",
      "        [ 0.2480,  0.0377, -0.0182],\n",
      "        [ 0.2023, -0.0834,  0.1819],\n",
      "        [ 0.2305,  0.1877,  0.2886],\n",
      "        [ 0.3206,  0.1849,  0.1791],\n",
      "        [ 0.2920,  0.1284,  0.2209],\n",
      "        [ 0.3259,  0.0296,  0.2231],\n",
      "        [ 0.0756,  0.1364,  0.1120],\n",
      "        [-0.0939,  0.0711,  0.1006],\n",
      "        [-0.2581,  0.3132,  0.1531],\n",
      "        [-0.0802,  0.0778,  0.1763],\n",
      "        [-0.0806,  0.1559,  0.3523],\n",
      "        [ 0.0171, -0.0432,  0.1495],\n",
      "        [ 0.2067, -0.1099,  0.0808],\n",
      "        [-0.2661, -0.2854,  0.2019],\n",
      "        [ 0.2021, -0.2903,  0.1130],\n",
      "        [-0.0839, -0.2673, -0.2754],\n",
      "        [ 0.2620, -0.5337, -0.0304]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3347, 0.3059, 0.3594],\n",
      "        [0.3174, 0.3613, 0.3213],\n",
      "        [0.2849, 0.3665, 0.3486],\n",
      "        [0.2861, 0.3479, 0.3662],\n",
      "        [0.3557, 0.3237, 0.3206],\n",
      "        [0.2588, 0.3677, 0.3735],\n",
      "        [0.3550, 0.3020, 0.3430],\n",
      "        [0.3882, 0.3145, 0.2974],\n",
      "        [0.3662, 0.2751, 0.3586],\n",
      "        [0.3313, 0.3174, 0.3511],\n",
      "        [0.3647, 0.3186, 0.3167],\n",
      "        [0.3596, 0.3054, 0.3350],\n",
      "        [0.3779, 0.2810, 0.3411],\n",
      "        [0.3225, 0.3428, 0.3345],\n",
      "        [0.2947, 0.3474, 0.3579],\n",
      "        [0.2336, 0.4138, 0.3525],\n",
      "        [0.2888, 0.3381, 0.3730],\n",
      "        [0.2627, 0.3325, 0.4048],\n",
      "        [0.3245, 0.3054, 0.3704],\n",
      "        [0.3831, 0.2791, 0.3379],\n",
      "        [0.2795, 0.2742, 0.4463],\n",
      "        [0.3960, 0.2419, 0.3621],\n",
      "        [0.3762, 0.3132, 0.3105],\n",
      "        [0.4551, 0.2053, 0.3396]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0822, -0.0118,  0.2172],\n",
      "        [ 0.0480,  0.0704,  0.1313],\n",
      "        [ 0.1069,  0.0905,  0.1869],\n",
      "        [ 0.0597,  0.1385, -0.1051],\n",
      "        [ 0.1877, -0.0526, -0.0817],\n",
      "        [ 0.2144,  0.0507, -0.1476],\n",
      "        [ 0.1041,  0.0019, -0.0307],\n",
      "        [-0.0831,  0.0708, -0.0911],\n",
      "        [-0.3997,  0.2426, -0.0482],\n",
      "        [-0.1931,  0.1323, -0.2085],\n",
      "        [-0.1068,  0.0024,  0.1912],\n",
      "        [-0.1132, -0.0499,  0.1942],\n",
      "        [-0.1405, -0.0218,  0.2568],\n",
      "        [ 0.3416, -0.2915,  0.2937],\n",
      "        [ 0.3879, -0.2764,  0.0884],\n",
      "        [ 0.1750, -0.0741,  0.0676],\n",
      "        [ 0.2898, -0.2522,  0.1526],\n",
      "        [ 0.2209, -0.1976, -0.0692],\n",
      "        [ 0.2834, -0.2147, -0.2727],\n",
      "        [ 0.1070,  0.0643, -0.2537],\n",
      "        [ 0.2534,  0.0518, -0.4150],\n",
      "        [-0.1122,  0.0296, -0.2920],\n",
      "        [ 0.2192, -0.1405, -0.2595],\n",
      "        [ 0.1559, -0.0865,  0.0564],\n",
      "        [-0.0443, -0.0778,  0.0790],\n",
      "        [-0.1320,  0.0775, -0.0657],\n",
      "        [ 0.1046, -0.0447,  0.0211],\n",
      "        [ 0.0185, -0.0476,  0.2878],\n",
      "        [ 0.0834, -0.1974,  0.0202],\n",
      "        [ 0.1088, -0.1199, -0.1493],\n",
      "        [ 0.2198, -0.1536, -0.0779],\n",
      "        [ 0.2725, -0.2371, -0.0656],\n",
      "        [-0.0079, -0.2524, -0.1151],\n",
      "        [-0.0443, -0.2126, -0.0341],\n",
      "        [ 0.2354, -0.2065, -0.2808],\n",
      "        [ 0.0567, -0.3962, -0.1633],\n",
      "        [ 0.0306, -0.2688,  0.0273],\n",
      "        [ 0.2031, -0.5923,  0.1523],\n",
      "        [ 0.1492, -0.5146,  0.0920],\n",
      "        [ 0.0427, -0.2708, -0.0037],\n",
      "        [ 0.0842, -0.0417, -0.2129],\n",
      "        [ 0.1069, -0.3118, -0.0210],\n",
      "        [ 0.2615, -0.1829, -0.4600],\n",
      "        [ 0.2480, -0.4290,  0.0495]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2922, 0.3135, 0.3943],\n",
      "        [0.3215, 0.3289, 0.3496],\n",
      "        [0.3262, 0.3208, 0.3533],\n",
      "        [0.3413, 0.3694, 0.2893],\n",
      "        [0.3921, 0.3083, 0.2996],\n",
      "        [0.3928, 0.3335, 0.2737],\n",
      "        [0.3601, 0.3252, 0.3147],\n",
      "        [0.3167, 0.3694, 0.3140],\n",
      "        [0.2314, 0.4397, 0.3289],\n",
      "        [0.2969, 0.4109, 0.2922],\n",
      "        [0.2888, 0.3220, 0.3892],\n",
      "        [0.2920, 0.3110, 0.3970],\n",
      "        [0.2766, 0.3115, 0.4116],\n",
      "        [0.4026, 0.2137, 0.3838],\n",
      "        [0.4434, 0.2281, 0.3286],\n",
      "        [0.3735, 0.2910, 0.3354],\n",
      "        [0.4077, 0.2371, 0.3552],\n",
      "        [0.4155, 0.2734, 0.3110],\n",
      "        [0.4585, 0.2786, 0.2629],\n",
      "        [0.3767, 0.3608, 0.2625],\n",
      "        [0.4292, 0.3508, 0.2200],\n",
      "        [0.3347, 0.3857, 0.2795],\n",
      "        [0.4314, 0.3010, 0.2673],\n",
      "        [0.3718, 0.2917, 0.3364],\n",
      "        [0.3228, 0.3120, 0.3650],\n",
      "        [0.3030, 0.3735, 0.3237],\n",
      "        [0.3596, 0.3098, 0.3308],\n",
      "        [0.3081, 0.2883, 0.4033],\n",
      "        [0.3711, 0.2803, 0.3484],\n",
      "        [0.3894, 0.3098, 0.3008],\n",
      "        [0.4114, 0.2832, 0.3054],\n",
      "        [0.4321, 0.2595, 0.3081],\n",
      "        [0.3728, 0.2920, 0.3350],\n",
      "        [0.3501, 0.2959, 0.3538],\n",
      "        [0.4465, 0.2871, 0.2666],\n",
      "        [0.4102, 0.2607, 0.3291],\n",
      "        [0.3652, 0.2708, 0.3640],\n",
      "        [0.4163, 0.1880, 0.3958],\n",
      "        [0.4065, 0.2094, 0.3840],\n",
      "        [0.3723, 0.2722, 0.3555],\n",
      "        [0.3811, 0.3359, 0.2832],\n",
      "        [0.3940, 0.2593, 0.3467],\n",
      "        [0.4700, 0.3015, 0.2285],\n",
      "        [0.4294, 0.2183, 0.3523]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1461, -0.2430,  0.1738],\n",
      "        [ 0.0470, -0.0970, -0.0072],\n",
      "        [-0.0046, -0.1748, -0.1577],\n",
      "        [-0.0067, -0.0084, -0.1903],\n",
      "        [ 0.0191, -0.1104, -0.3208],\n",
      "        [-0.0605, -0.0130,  0.0338],\n",
      "        [ 0.1271,  0.0779, -0.2148],\n",
      "        [ 0.0254, -0.1377, -0.0466],\n",
      "        [-0.2131, -0.1120, -0.3821],\n",
      "        [-0.0147, -0.0802, -0.1554],\n",
      "        [-0.2098, -0.0257, -0.0757],\n",
      "        [-0.0773,  0.0130,  0.0688],\n",
      "        [ 0.0366, -0.0102, -0.1487],\n",
      "        [ 0.1018, -0.1315,  0.1292],\n",
      "        [ 0.1638,  0.0398,  0.0614],\n",
      "        [ 0.1929,  0.1495,  0.1738],\n",
      "        [ 0.0950,  0.2637,  0.1859],\n",
      "        [ 0.2446,  0.0369,  0.3599],\n",
      "        [ 0.3315, -0.1155, -0.0783],\n",
      "        [ 0.1365,  0.0477,  0.3862],\n",
      "        [ 0.2211, -0.0825, -0.0334],\n",
      "        [-0.0602,  0.0651,  0.4287],\n",
      "        [ 0.0314, -0.0277,  0.0174],\n",
      "        [ 0.0410, -0.0009,  0.2499],\n",
      "        [-0.0906,  0.2136,  0.2759],\n",
      "        [-0.1354,  0.2366,  0.1942],\n",
      "        [-0.0133,  0.0962,  0.1571],\n",
      "        [-0.0864,  0.1132,  0.3350],\n",
      "        [ 0.1279, -0.0493,  0.0386],\n",
      "        [-0.1266, -0.1412,  0.1270],\n",
      "        [-0.0582,  0.0488,  0.4126],\n",
      "        [-0.2052,  0.0482,  0.2607],\n",
      "        [ 0.0760,  0.0354,  0.1316],\n",
      "        [ 0.1171, -0.0062,  0.0197],\n",
      "        [ 0.1031,  0.0910,  0.1539],\n",
      "        [ 0.0873, -0.1594,  0.2615],\n",
      "        [ 0.1019, -0.2705,  0.1733],\n",
      "        [-0.0415, -0.1981,  0.0019],\n",
      "        [ 0.0378, -0.0920, -0.0944],\n",
      "        [-0.1165, -0.1279,  0.0856],\n",
      "        [ 0.0754, -0.2052,  0.1465],\n",
      "        [-0.0196, -0.0464, -0.2216],\n",
      "        [-0.0568, -0.0341, -0.1442],\n",
      "        [-0.1765,  0.0066, -0.1497],\n",
      "        [-0.0922,  0.0240, -0.0914],\n",
      "        [ 0.0166,  0.1449, -0.0177],\n",
      "        [ 0.0634,  0.2445, -0.1549],\n",
      "        [ 0.1066, -0.1914,  0.0920],\n",
      "        [ 0.0519, -0.1934, -0.1548],\n",
      "        [ 0.0944, -0.2800,  0.0107]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3044, 0.2764, 0.4192],\n",
      "        [0.3555, 0.3079, 0.3367],\n",
      "        [0.3701, 0.3123, 0.3176],\n",
      "        [0.3533, 0.3528, 0.2939],\n",
      "        [0.3860, 0.3391, 0.2749],\n",
      "        [0.3176, 0.3333, 0.3491],\n",
      "        [0.3755, 0.3577, 0.2668],\n",
      "        [0.3596, 0.3057, 0.3347],\n",
      "        [0.3389, 0.3750, 0.2861],\n",
      "        [0.3564, 0.3337, 0.3096],\n",
      "        [0.2988, 0.3594, 0.3418],\n",
      "        [0.3076, 0.3367, 0.3560],\n",
      "        [0.3591, 0.3425, 0.2983],\n",
      "        [0.3547, 0.2808, 0.3645],\n",
      "        [0.3589, 0.3171, 0.3240],\n",
      "        [0.3403, 0.3259, 0.3340],\n",
      "        [0.3049, 0.3611, 0.3340],\n",
      "        [0.3408, 0.2769, 0.3823],\n",
      "        [0.4341, 0.2776, 0.2881],\n",
      "        [0.3125, 0.2861, 0.4014],\n",
      "        [0.3979, 0.2937, 0.3083],\n",
      "        [0.2656, 0.3010, 0.4331],\n",
      "        [0.3416, 0.3218, 0.3367],\n",
      "        [0.3132, 0.3005, 0.3862],\n",
      "        [0.2632, 0.3569, 0.3799],\n",
      "        [0.2603, 0.3777, 0.3621],\n",
      "        [0.3030, 0.3379, 0.3591],\n",
      "        [0.2671, 0.3259, 0.4070],\n",
      "        [0.3633, 0.3044, 0.3323],\n",
      "        [0.3054, 0.3010, 0.3936],\n",
      "        [0.2693, 0.2996, 0.4312],\n",
      "        [0.2576, 0.3318, 0.4104],\n",
      "        [0.3315, 0.3181, 0.3503],\n",
      "        [0.3582, 0.3167, 0.3250],\n",
      "        [0.3289, 0.3250, 0.3462],\n",
      "        [0.3364, 0.2629, 0.4006],\n",
      "        [0.3618, 0.2494, 0.3887],\n",
      "        [0.3450, 0.2949, 0.3601],\n",
      "        [0.3630, 0.3188, 0.3181],\n",
      "        [0.3113, 0.3076, 0.3811],\n",
      "        [0.3535, 0.2671, 0.3796],\n",
      "        [0.3584, 0.3489, 0.2927],\n",
      "        [0.3403, 0.3481, 0.3118],\n",
      "        [0.3098, 0.3721, 0.3181],\n",
      "        [0.3201, 0.3596, 0.3203],\n",
      "        [0.3223, 0.3665, 0.3113],\n",
      "        [0.3330, 0.3992, 0.2678],\n",
      "        [0.3667, 0.2722, 0.3613],\n",
      "        [0.3853, 0.3015, 0.3132],\n",
      "        [0.3835, 0.2637, 0.3528]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0652, -0.1897,  0.1451],\n",
      "        [ 0.2200,  0.0282,  0.0377],\n",
      "        [ 0.2156, -0.1070, -0.0863],\n",
      "        [ 0.1412,  0.0736,  0.2357],\n",
      "        [ 0.1285, -0.0876,  0.0380],\n",
      "        [ 0.2676, -0.0469, -0.0890],\n",
      "        [ 0.3108, -0.2177, -0.1880],\n",
      "        [ 0.3030, -0.0925, -0.3345],\n",
      "        [-0.0281, -0.0432, -0.1241],\n",
      "        [ 0.2239, -0.2018,  0.1465],\n",
      "        [ 0.2334, -0.2014, -0.0194],\n",
      "        [ 0.3784, -0.0221, -0.1448],\n",
      "        [ 0.1043, -0.2551, -0.2053],\n",
      "        [ 0.3064, -0.1510, -0.0253],\n",
      "        [ 0.1107, -0.2296, -0.0882],\n",
      "        [-0.2593,  0.1027, -0.0400],\n",
      "        [-0.2812,  0.0119, -0.1191],\n",
      "        [-0.2986,  0.1394, -0.2505],\n",
      "        [-0.1693,  0.0237, -0.4946],\n",
      "        [-0.0453, -0.1249, -0.0918]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3499, 0.2712, 0.3789],\n",
      "        [0.3760, 0.3105, 0.3135],\n",
      "        [0.4060, 0.2939, 0.3000],\n",
      "        [0.3296, 0.3081, 0.3623],\n",
      "        [0.3677, 0.2964, 0.3359],\n",
      "        [0.4114, 0.3005, 0.2881],\n",
      "        [0.4553, 0.2683, 0.2764],\n",
      "        [0.4541, 0.3059, 0.2401],\n",
      "        [0.3457, 0.3403, 0.3140],\n",
      "        [0.3877, 0.2534, 0.3589],\n",
      "        [0.4126, 0.2671, 0.3203],\n",
      "        [0.4419, 0.2961, 0.2620],\n",
      "        [0.4111, 0.2871, 0.3018],\n",
      "        [0.4255, 0.2693, 0.3054],\n",
      "        [0.3950, 0.2810, 0.3237],\n",
      "        [0.2717, 0.3901, 0.3381],\n",
      "        [0.2844, 0.3813, 0.3345],\n",
      "        [0.2778, 0.4307, 0.2915],\n",
      "        [0.3406, 0.4133, 0.2461],\n",
      "        [0.3474, 0.3208, 0.3318]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 1.1371e-01, -3.5425e-01,  2.9648e-02],\n",
      "        [ 2.4487e-01,  3.1830e-02,  6.3904e-02],\n",
      "        [ 2.3132e-01, -8.4106e-02, -1.3757e-01],\n",
      "        [ 4.0698e-01, -1.9775e-01,  9.4971e-02],\n",
      "        [ 2.5024e-01, -1.8274e-01, -1.5332e-01],\n",
      "        [-3.2013e-02, -1.6895e-01, -2.3675e-04],\n",
      "        [-8.5083e-02,  7.4890e-02, -1.3489e-01],\n",
      "        [ 2.5635e-01, -3.0029e-01,  1.7847e-01],\n",
      "        [ 1.4856e-01, -2.6196e-01, -3.0664e-01],\n",
      "        [ 4.0039e-01, -2.9395e-01,  8.8562e-02]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3928, 0.2460, 0.3611],\n",
      "        [0.3784, 0.3059, 0.3157],\n",
      "        [0.4131, 0.3013, 0.2856],\n",
      "        [0.4390, 0.2397, 0.3213],\n",
      "        [0.4316, 0.2800, 0.2883],\n",
      "        [0.3442, 0.3003, 0.3555],\n",
      "        [0.3201, 0.3755, 0.3044],\n",
      "        [0.4004, 0.2294, 0.3704],\n",
      "        [0.4353, 0.2886, 0.2761],\n",
      "        [0.4482, 0.2238, 0.3281]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0447, -0.2341,  0.3164],\n",
      "        [-0.0027, -0.1438,  0.1472],\n",
      "        [ 0.0016, -0.2725,  0.1356],\n",
      "        [-0.0218, -0.0766,  0.1592],\n",
      "        [ 0.0128, -0.0793,  0.0285],\n",
      "        [-0.0315,  0.1223, -0.0426],\n",
      "        [ 0.0043,  0.0139, -0.0277],\n",
      "        [-0.0968,  0.0236, -0.1423],\n",
      "        [ 0.2288, -0.3411, -0.0196],\n",
      "        [ 0.0721, -0.2191,  0.1156],\n",
      "        [-0.0235,  0.0152,  0.0553],\n",
      "        [-0.0487,  0.1544, -0.0047],\n",
      "        [-0.0880, -0.1049,  0.1511],\n",
      "        [-0.0483,  0.1161, -0.0027],\n",
      "        [ 0.0950, -0.1248, -0.0226],\n",
      "        [-0.0776,  0.2644, -0.1678]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3066, 0.2537, 0.4399],\n",
      "        [0.3301, 0.2866, 0.3833],\n",
      "        [0.3445, 0.2617, 0.3938],\n",
      "        [0.3179, 0.3010, 0.3811],\n",
      "        [0.3416, 0.3115, 0.3469],\n",
      "        [0.3169, 0.3696, 0.3135],\n",
      "        [0.3357, 0.3391, 0.3252],\n",
      "        [0.3242, 0.3657, 0.3098],\n",
      "        [0.4263, 0.2411, 0.3325],\n",
      "        [0.3582, 0.2676, 0.3740],\n",
      "        [0.3203, 0.3330, 0.3467],\n",
      "        [0.3059, 0.3748, 0.3196],\n",
      "        [0.3074, 0.3022, 0.3904],\n",
      "        [0.3101, 0.3655, 0.3245],\n",
      "        [0.3716, 0.2981, 0.3303],\n",
      "        [0.3010, 0.4238, 0.2751]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1301, -0.0532,  0.1804],\n",
      "        [ 0.1471, -0.0419,  0.2300],\n",
      "        [ 0.0150,  0.0905, -0.1686],\n",
      "        [ 0.1188,  0.0337, -0.0129],\n",
      "        [ 0.0167,  0.0055, -0.3428],\n",
      "        [ 0.0876, -0.0405, -0.2708],\n",
      "        [-0.0069, -0.0589, -0.3835],\n",
      "        [ 0.0226, -0.1002, -0.0653],\n",
      "        [ 0.1813, -0.1814, -0.2170],\n",
      "        [ 0.2112, -0.2708,  0.1186],\n",
      "        [ 0.0490,  0.0118, -0.4087],\n",
      "        [-0.0007, -0.0845, -0.0700],\n",
      "        [-0.0033, -0.1605,  0.2930],\n",
      "        [ 0.1473, -0.2103,  0.3667],\n",
      "        [ 0.0080, -0.0376,  0.0922],\n",
      "        [ 0.2004, -0.1544,  0.0420],\n",
      "        [ 0.2527, -0.1271, -0.1404],\n",
      "        [ 0.1913, -0.1625, -0.0332],\n",
      "        [ 0.4053, -0.3147, -0.0686],\n",
      "        [ 0.3503, -0.1089,  0.0048],\n",
      "        [ 0.3354, -0.1346, -0.0577],\n",
      "        [ 0.1868, -0.3342,  0.1763],\n",
      "        [ 0.1193, -0.2971, -0.0636],\n",
      "        [ 0.0709, -0.2224, -0.0805],\n",
      "        [ 0.0576,  0.1077, -0.1792],\n",
      "        [ 0.0431, -0.0428,  0.1439],\n",
      "        [ 0.1226, -0.0682, -0.2874],\n",
      "        [ 0.1646, -0.2125,  0.0055]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2903, 0.3135, 0.3960],\n",
      "        [0.3433, 0.2839, 0.3728],\n",
      "        [0.3435, 0.3706, 0.2859],\n",
      "        [0.3577, 0.3286, 0.3137],\n",
      "        [0.3721, 0.3679, 0.2598],\n",
      "        [0.3879, 0.3411, 0.2710],\n",
      "        [0.3794, 0.3601, 0.2603],\n",
      "        [0.3572, 0.3159, 0.3271],\n",
      "        [0.4224, 0.2939, 0.2837],\n",
      "        [0.3955, 0.2441, 0.3604],\n",
      "        [0.3853, 0.3711, 0.2437],\n",
      "        [0.3506, 0.3223, 0.3271],\n",
      "        [0.3125, 0.2671, 0.4204],\n",
      "        [0.3396, 0.2375, 0.4229],\n",
      "        [0.3286, 0.3140, 0.3574],\n",
      "        [0.3914, 0.2744, 0.3340],\n",
      "        [0.4238, 0.2900, 0.2861],\n",
      "        [0.3999, 0.2808, 0.3193],\n",
      "        [0.4741, 0.2307, 0.2952],\n",
      "        [0.4275, 0.2700, 0.3025],\n",
      "        [0.4348, 0.2717, 0.2935],\n",
      "        [0.3870, 0.2299, 0.3831],\n",
      "        [0.4011, 0.2646, 0.3342],\n",
      "        [0.3838, 0.2864, 0.3298],\n",
      "        [0.3521, 0.3701, 0.2778],\n",
      "        [0.3308, 0.3035, 0.3657],\n",
      "        [0.4016, 0.3318, 0.2666],\n",
      "        [0.3938, 0.2703, 0.3359]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-2.8027e-01, -1.3647e-01,  1.6678e-02],\n",
      "        [ 4.4403e-02,  8.8257e-02, -1.4551e-01],\n",
      "        [ 1.0382e-01,  1.5234e-01, -2.6562e-01],\n",
      "        [ 2.8516e-01, -1.4697e-01,  1.7041e-01],\n",
      "        [ 3.2080e-01, -2.2156e-01, -1.7712e-01],\n",
      "        [ 1.8030e-01, -2.9077e-01, -5.5969e-02],\n",
      "        [ 1.2781e-01, -1.5344e-01, -5.9448e-02],\n",
      "        [-1.2079e-01,  3.1860e-01, -1.0538e-03],\n",
      "        [-2.1875e-01,  5.6976e-02,  2.5464e-01],\n",
      "        [-2.2583e-01,  7.9407e-02,  1.0730e-01],\n",
      "        [-1.9397e-01, -1.5112e-01,  3.1219e-02],\n",
      "        [ 2.4933e-02, -1.3281e-01,  1.4038e-01],\n",
      "        [ 1.1359e-01, -1.3725e-02,  2.5854e-01],\n",
      "        [ 2.9230e-04, -1.1267e-01,  2.0703e-01],\n",
      "        [ 2.8271e-01, -1.1285e-01,  1.4697e-01],\n",
      "        [-1.2000e-01,  1.1786e-01,  3.8940e-01],\n",
      "        [ 1.1041e-01, -7.0007e-02,  1.6040e-01],\n",
      "        [-5.1880e-02, -1.7139e-01,  1.1133e-01],\n",
      "        [ 8.7814e-03, -2.3352e-01,  2.7368e-01],\n",
      "        [ 3.2422e-01, -5.5127e-01,  2.7979e-01],\n",
      "        [ 1.5259e-01, -2.3975e-01,  3.8849e-02],\n",
      "        [ 1.4478e-01, -2.9150e-01,  1.8201e-01],\n",
      "        [ 2.5558e-02, -1.1682e-01, -8.4656e-02],\n",
      "        [ 3.0396e-01, -2.6758e-01,  8.2642e-02],\n",
      "        [ 5.5762e-01, -2.0264e-01, -3.7988e-01],\n",
      "        [ 3.4790e-01, -4.9731e-01,  1.2878e-01],\n",
      "        [ 3.6108e-01, -4.0356e-01, -1.3206e-02],\n",
      "        [ 3.5571e-01, -2.1973e-01, -2.2607e-01],\n",
      "        [ 2.5415e-01, -4.5166e-01, -1.7078e-01],\n",
      "        [ 1.4539e-01, -2.1765e-01, -4.8187e-02],\n",
      "        [ 3.6157e-01, -3.0225e-01,  7.9956e-02],\n",
      "        [ 4.6265e-01, -1.0291e-01,  2.7252e-02],\n",
      "        [ 1.6260e-01,  2.3596e-01, -9.1980e-02],\n",
      "        [ 2.3486e-01, -9.9487e-02,  1.8616e-01],\n",
      "        [ 4.4556e-01,  4.9072e-02,  7.5684e-02],\n",
      "        [ 4.9707e-01, -1.2708e-01, -1.3562e-01],\n",
      "        [ 6.9189e-01, -2.8320e-01, -1.4587e-02],\n",
      "        [ 6.0547e-01, -2.8955e-01,  3.5980e-02],\n",
      "        [ 4.7534e-01, -5.4016e-02,  2.0117e-01],\n",
      "        [ 5.5176e-01,  1.0199e-01, -4.5074e-02],\n",
      "        [ 5.2979e-01,  1.3879e-01,  2.3087e-02],\n",
      "        [ 4.7949e-01,  9.4482e-02, -1.7932e-01],\n",
      "        [ 6.8555e-01, -1.0919e-01, -1.0779e-01],\n",
      "        [ 5.6445e-01, -1.5915e-02, -4.7827e-01],\n",
      "        [ 5.5908e-01,  6.1951e-03, -1.9592e-01],\n",
      "        [ 5.3271e-01,  3.0823e-02, -4.9316e-01],\n",
      "        [ 4.4873e-01,  1.1853e-01, -2.5586e-01],\n",
      "        [ 5.1465e-01,  1.1987e-01, -3.4814e-01],\n",
      "        [ 2.9956e-01, -4.6875e-02, -3.3154e-01],\n",
      "        [ 1.9531e-01, -1.4355e-01, -1.3147e-01],\n",
      "        [ 3.0493e-01, -1.4160e-01, -4.2920e-01],\n",
      "        [ 1.6150e-01, -3.1885e-01,  3.6804e-02]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2856, 0.3298, 0.3845],\n",
      "        [0.3481, 0.3638, 0.2881],\n",
      "        [0.3647, 0.3831, 0.2522],\n",
      "        [0.3936, 0.2554, 0.3508],\n",
      "        [0.4568, 0.2656, 0.2776],\n",
      "        [0.4143, 0.2585, 0.3271],\n",
      "        [0.3870, 0.2920, 0.3208],\n",
      "        [0.2717, 0.4219, 0.3064],\n",
      "        [0.2549, 0.3359, 0.4092],\n",
      "        [0.2666, 0.3616, 0.3718],\n",
      "        [0.3035, 0.3167, 0.3799],\n",
      "        [0.3359, 0.2869, 0.3772],\n",
      "        [0.3293, 0.2900, 0.3806],\n",
      "        [0.3203, 0.2861, 0.3938],\n",
      "        [0.3928, 0.2644, 0.3428],\n",
      "        [0.2542, 0.3225, 0.4231],\n",
      "        [0.3464, 0.2893, 0.3643],\n",
      "        [0.3264, 0.2896, 0.3840],\n",
      "        [0.3237, 0.2542, 0.4221],\n",
      "        [0.4214, 0.1755, 0.4031],\n",
      "        [0.3894, 0.2629, 0.3477],\n",
      "        [0.3726, 0.2408, 0.3867],\n",
      "        [0.3618, 0.3140, 0.3242],\n",
      "        [0.4226, 0.2386, 0.3386],\n",
      "        [0.5381, 0.2515, 0.2107],\n",
      "        [0.4480, 0.1924, 0.3599],\n",
      "        [0.4644, 0.2162, 0.3193],\n",
      "        [0.4714, 0.2651, 0.2634],\n",
      "        [0.4656, 0.2299, 0.3044],\n",
      "        [0.3970, 0.2761, 0.3271],\n",
      "        [0.4407, 0.2269, 0.3325],\n",
      "        [0.4514, 0.2563, 0.2920],\n",
      "        [0.3508, 0.3774, 0.2720],\n",
      "        [0.3748, 0.2683, 0.3569],\n",
      "        [0.4231, 0.2847, 0.2922],\n",
      "        [0.4839, 0.2593, 0.2571],\n",
      "        [0.5347, 0.2017, 0.2637],\n",
      "        [0.5063, 0.2069, 0.2866],\n",
      "        [0.4258, 0.2507, 0.3235],\n",
      "        [0.4570, 0.2915, 0.2515],\n",
      "        [0.4387, 0.2969, 0.2644],\n",
      "        [0.4551, 0.3096, 0.2355],\n",
      "        [0.5254, 0.2372, 0.2375],\n",
      "        [0.5229, 0.2927, 0.1843],\n",
      "        [0.4890, 0.2812, 0.2299],\n",
      "        [0.5093, 0.3083, 0.1825],\n",
      "        [0.4519, 0.3247, 0.2234],\n",
      "        [0.4771, 0.3215, 0.2013],\n",
      "        [0.4465, 0.3159, 0.2375],\n",
      "        [0.4109, 0.2927, 0.2964],\n",
      "        [0.4717, 0.3018, 0.2264],\n",
      "        [0.3999, 0.2473, 0.3530]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0710,  0.0026,  0.1621],\n",
      "        [ 0.4919, -0.1802,  0.0442],\n",
      "        [ 0.1462,  0.0797, -0.0154],\n",
      "        [ 0.2529, -0.2617,  0.0439],\n",
      "        [ 0.1276, -0.2573, -0.3022],\n",
      "        [ 0.0417,  0.0727, -0.0251],\n",
      "        [ 0.2737, -0.0260,  0.0132],\n",
      "        [-0.0585,  0.0841,  0.1503],\n",
      "        [ 0.2190, -0.1582,  0.0515],\n",
      "        [ 0.1638, -0.0356,  0.2289],\n",
      "        [ 0.1840,  0.1285, -0.2432],\n",
      "        [ 0.2839,  0.0252, -0.1638],\n",
      "        [ 0.2776,  0.0555, -0.3955],\n",
      "        [ 0.2764, -0.0582, -0.0271],\n",
      "        [ 0.1141,  0.0258,  0.1465],\n",
      "        [-0.0019,  0.3494,  0.0663],\n",
      "        [ 0.2070,  0.0482, -0.0468],\n",
      "        [ 0.1340,  0.0219, -0.1221],\n",
      "        [ 0.3396, -0.0284, -0.2842],\n",
      "        [ 0.4265,  0.0053,  0.1326],\n",
      "        [ 0.2473, -0.0125,  0.1039],\n",
      "        [ 0.2115,  0.0120, -0.1096],\n",
      "        [ 0.2086, -0.0383, -0.4153],\n",
      "        [ 0.2527, -0.1183, -0.2705],\n",
      "        [ 0.2971, -0.0583, -0.3298],\n",
      "        [ 0.1484, -0.0248, -0.2605],\n",
      "        [ 0.3594, -0.2620, -0.4753],\n",
      "        [ 0.0763, -0.1440, -0.1628]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2996, 0.3223, 0.3782],\n",
      "        [0.4651, 0.2375, 0.2974],\n",
      "        [0.3589, 0.3357, 0.3054],\n",
      "        [0.4150, 0.2482, 0.3367],\n",
      "        [0.4290, 0.2920, 0.2791],\n",
      "        [0.3372, 0.3477, 0.3152],\n",
      "        [0.3982, 0.2952, 0.3069],\n",
      "        [0.2954, 0.3406, 0.3640],\n",
      "        [0.3950, 0.2710, 0.3340],\n",
      "        [0.3464, 0.2839, 0.3696],\n",
      "        [0.3848, 0.3640, 0.2510],\n",
      "        [0.4148, 0.3203, 0.2651],\n",
      "        [0.4326, 0.3464, 0.2207],\n",
      "        [0.4075, 0.2917, 0.3008],\n",
      "        [0.3391, 0.3105, 0.3503],\n",
      "        [0.2864, 0.4070, 0.3066],\n",
      "        [0.3804, 0.3245, 0.2952],\n",
      "        [0.3748, 0.3350, 0.2900],\n",
      "        [0.4487, 0.3105, 0.2405],\n",
      "        [0.4165, 0.2732, 0.3103],\n",
      "        [0.3792, 0.2925, 0.3284],\n",
      "        [0.3931, 0.3220, 0.2852],\n",
      "        [0.4316, 0.3372, 0.2313],\n",
      "        [0.4380, 0.3022, 0.2595],\n",
      "        [0.4475, 0.3135, 0.2390],\n",
      "        [0.3992, 0.3357, 0.2651],\n",
      "        [0.5073, 0.2725, 0.2202],\n",
      "        [0.3862, 0.3098, 0.3040]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.2502, -0.2227,  0.1005],\n",
      "        [ 0.1615, -0.0469, -0.0810],\n",
      "        [ 0.0568, -0.1761, -0.1320],\n",
      "        [ 0.1646, -0.1918, -0.1384],\n",
      "        [ 0.0559, -0.2749, -0.2412],\n",
      "        [ 0.2467, -0.0065, -0.2172],\n",
      "        [ 0.1086, -0.1793, -0.2903],\n",
      "        [ 0.4009, -0.1343, -0.0476],\n",
      "        [ 0.2788, -0.1641, -0.0840],\n",
      "        [ 0.3193, -0.1169, -0.1877],\n",
      "        [ 0.3000, -0.3538, -0.1588],\n",
      "        [ 0.3374, -0.1008, -0.0186],\n",
      "        [ 0.4392, -0.1616, -0.0259],\n",
      "        [ 0.0840, -0.1895,  0.0442],\n",
      "        [ 0.2949, -0.4263,  0.2211],\n",
      "        [ 0.2612, -0.0655, -0.0798],\n",
      "        [ 0.1024, -0.1956, -0.0811],\n",
      "        [ 0.2502, -0.0105, -0.0369],\n",
      "        [ 0.2668, -0.2050,  0.2286],\n",
      "        [ 0.3784, -0.2189,  0.2472],\n",
      "        [ 0.3372, -0.1704,  0.2433],\n",
      "        [ 0.3040, -0.0255,  0.2252],\n",
      "        [ 0.1003,  0.0336,  0.4551],\n",
      "        [ 0.2944,  0.0443, -0.0970],\n",
      "        [ 0.1912, -0.0272,  0.3291],\n",
      "        [ 0.0804, -0.0554, -0.0370],\n",
      "        [-0.0876, -0.0329,  0.4038],\n",
      "        [ 0.1985, -0.0122,  0.1603],\n",
      "        [ 0.2317, -0.5044, -0.1604],\n",
      "        [ 0.1604, -0.2075,  0.0142]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2900, 0.2981, 0.4119],\n",
      "        [0.3850, 0.3127, 0.3022],\n",
      "        [0.3816, 0.3022, 0.3159],\n",
      "        [0.4099, 0.2871, 0.3027],\n",
      "        [0.4062, 0.2917, 0.3018],\n",
      "        [0.4158, 0.3228, 0.2615],\n",
      "        [0.4131, 0.3098, 0.2771],\n",
      "        [0.4497, 0.2632, 0.2871],\n",
      "        [0.4277, 0.2747, 0.2976],\n",
      "        [0.4446, 0.2876, 0.2678],\n",
      "        [0.4646, 0.2417, 0.2937],\n",
      "        [0.4263, 0.2751, 0.2986],\n",
      "        [0.4595, 0.2520, 0.2886],\n",
      "        [0.3674, 0.2795, 0.3530],\n",
      "        [0.4141, 0.2013, 0.3845],\n",
      "        [0.4111, 0.2966, 0.2922],\n",
      "        [0.3884, 0.2883, 0.3232],\n",
      "        [0.3967, 0.3057, 0.2976],\n",
      "        [0.3867, 0.2412, 0.3721],\n",
      "        [0.4119, 0.2267, 0.3613],\n",
      "        [0.3979, 0.2396, 0.3623],\n",
      "        [0.3782, 0.2722, 0.3496],\n",
      "        [0.2976, 0.2783, 0.4241],\n",
      "        [0.4075, 0.3171, 0.2754],\n",
      "        [0.3389, 0.2722, 0.3889],\n",
      "        [0.3621, 0.3162, 0.3220],\n",
      "        [0.2710, 0.2861, 0.4429],\n",
      "        [0.3606, 0.2922, 0.3472],\n",
      "        [0.4641, 0.2223, 0.3135],\n",
      "        [0.3911, 0.2708, 0.3379]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1731,  0.0062,  0.3140],\n",
      "        [ 0.1099, -0.1195,  0.0427],\n",
      "        [-0.0791, -0.0620,  0.1129],\n",
      "        [ 0.3000, -0.1927,  0.0467],\n",
      "        [ 0.1990, -0.2695,  0.1219],\n",
      "        [ 0.1831, -0.4026,  0.1783],\n",
      "        [ 0.1381, -0.1436,  0.0865],\n",
      "        [ 0.3611, -0.2063,  0.1149],\n",
      "        [ 0.0195, -0.1416,  0.4727],\n",
      "        [ 0.2151, -0.4849,  0.3677],\n",
      "        [-0.1120, -0.3552,  0.1819],\n",
      "        [ 0.0716, -0.2764,  0.2705],\n",
      "        [-0.0776, -0.3005,  0.1047],\n",
      "        [ 0.0431, -0.3999,  0.1181],\n",
      "        [ 0.1516, -0.3113,  0.1689],\n",
      "        [ 0.1093, -0.1880,  0.3389],\n",
      "        [ 0.4946, -0.2072,  0.2710],\n",
      "        [ 0.5854, -0.2798,  0.3013],\n",
      "        [ 0.2556,  0.0210, -0.0945],\n",
      "        [ 0.2898, -0.0198, -0.2883],\n",
      "        [ 0.0697,  0.1923,  0.0047],\n",
      "        [ 0.1348,  0.2898, -0.0114],\n",
      "        [ 0.0929, -0.0212, -0.0733],\n",
      "        [ 0.0789, -0.2216,  0.0333],\n",
      "        [-0.0845, -0.2603, -0.0464],\n",
      "        [ 0.0948, -0.3958,  0.1357]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2615, 0.3130, 0.4255],\n",
      "        [0.3662, 0.2913, 0.3425],\n",
      "        [0.3098, 0.3149, 0.3752],\n",
      "        [0.4189, 0.2559, 0.3252],\n",
      "        [0.3918, 0.2452, 0.3628],\n",
      "        [0.3918, 0.2181, 0.3899],\n",
      "        [0.3699, 0.2791, 0.3511],\n",
      "        [0.4258, 0.2415, 0.3328],\n",
      "        [0.2920, 0.2485, 0.4595],\n",
      "        [0.3757, 0.1866, 0.4377],\n",
      "        [0.3198, 0.2507, 0.4292],\n",
      "        [0.3418, 0.2413, 0.4170],\n",
      "        [0.3333, 0.2666, 0.3999],\n",
      "        [0.3677, 0.2361, 0.3962],\n",
      "        [0.3777, 0.2378, 0.3845],\n",
      "        [0.3333, 0.2476, 0.4192],\n",
      "        [0.4358, 0.2159, 0.3484],\n",
      "        [0.4600, 0.1937, 0.3462],\n",
      "        [0.4006, 0.3169, 0.2825],\n",
      "        [0.4358, 0.3198, 0.2445],\n",
      "        [0.3259, 0.3684, 0.3054],\n",
      "        [0.3298, 0.3853, 0.2849],\n",
      "        [0.3650, 0.3257, 0.3091],\n",
      "        [0.3708, 0.2747, 0.3545],\n",
      "        [0.3474, 0.2915, 0.3611],\n",
      "        [0.3767, 0.2307, 0.3926]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0611, -0.1797,  0.0698],\n",
      "        [ 0.2203, -0.0962, -0.0351],\n",
      "        [ 0.2322, -0.0930, -0.2102],\n",
      "        [ 0.1919,  0.0621,  0.1542],\n",
      "        [ 0.3074, -0.2666, -0.2462],\n",
      "        [ 0.3345, -0.2296,  0.0139]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3303, 0.2932, 0.3765],\n",
      "        [0.3994, 0.2910, 0.3093],\n",
      "        [0.4229, 0.3054, 0.2717],\n",
      "        [0.3521, 0.3091, 0.3389],\n",
      "        [0.4678, 0.2634, 0.2688],\n",
      "        [0.4358, 0.2479, 0.3162]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1043, -0.2625, -0.0013],\n",
      "        [ 0.0921,  0.0395, -0.1772],\n",
      "        [ 0.1863, -0.0420, -0.3647],\n",
      "        [ 0.3401, -0.0656, -0.1427],\n",
      "        [ 0.0961, -0.1815, -0.1095],\n",
      "        [ 0.2612, -0.4502,  0.1069],\n",
      "        [-0.0881, -0.1455,  0.0201],\n",
      "        [ 0.0152, -0.0591,  0.1317],\n",
      "        [ 0.0446,  0.2130, -0.4055],\n",
      "        [ 0.2349, -0.1416,  0.1049],\n",
      "        [ 0.2092, -0.2489, -0.1925],\n",
      "        [ 0.4099, -0.2440,  0.0065]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3376, 0.2881, 0.3743],\n",
      "        [0.3687, 0.3499, 0.2815],\n",
      "        [0.4216, 0.3354, 0.2429],\n",
      "        [0.4380, 0.2920, 0.2703],\n",
      "        [0.3889, 0.2947, 0.3167],\n",
      "        [0.4258, 0.2091, 0.3650],\n",
      "        [0.3269, 0.3088, 0.3643],\n",
      "        [0.3276, 0.3042, 0.3682],\n",
      "        [0.3545, 0.4194, 0.2260],\n",
      "        [0.3899, 0.2676, 0.3425],\n",
      "        [0.4346, 0.2749, 0.2908],\n",
      "        [0.4570, 0.2377, 0.3054]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 2.0142e-02, -2.7979e-01,  1.1603e-01],\n",
      "        [-4.0314e-02, -2.1655e-01, -7.0923e-02],\n",
      "        [-8.6288e-03, -4.3243e-02, -1.3184e-01],\n",
      "        [ 4.8523e-02, -1.2964e-01,  1.8188e-01],\n",
      "        [-1.7896e-01, -5.2637e-01,  5.3528e-02],\n",
      "        [ 9.9487e-02, -2.7734e-01,  5.7556e-02],\n",
      "        [ 1.3831e-01, -2.9564e-03, -2.8223e-01],\n",
      "        [ 1.2764e-02, -1.3208e-01,  1.0693e-01],\n",
      "        [ 3.2349e-02, -2.9248e-01, -2.6074e-01],\n",
      "        [ 1.4392e-01, -1.6443e-01,  1.8213e-01],\n",
      "        [ 1.6003e-01, -3.0371e-01,  1.0139e-02],\n",
      "        [ 1.3586e-01, -4.8535e-01,  8.1177e-02],\n",
      "        [-5.5275e-03, -1.2445e-01, -1.9617e-01],\n",
      "        [ 2.6538e-01, -3.5669e-01,  3.0945e-02],\n",
      "        [-6.0608e-02, -2.1594e-01, -1.4001e-01],\n",
      "        [ 2.1301e-02, -1.2585e-01,  1.8518e-01],\n",
      "        [-1.4847e-02, -7.9041e-02,  1.5137e-01],\n",
      "        [ 2.3834e-02, -2.1875e-01,  8.1787e-02],\n",
      "        [ 1.1346e-01, -1.9421e-01, -1.4990e-01],\n",
      "        [ 9.9365e-02, -1.0480e-01, -2.6489e-02],\n",
      "        [-7.6103e-03, -2.0911e-01, -5.9326e-02],\n",
      "        [-2.5787e-02,  5.2826e-02,  2.4390e-01],\n",
      "        [ 2.3712e-02, -2.8534e-02,  2.4390e-01],\n",
      "        [-1.9409e-01, -1.9531e-03,  2.8735e-01],\n",
      "        [-1.0754e-01, -2.1240e-01,  1.9556e-01],\n",
      "        [ 3.4790e-02,  1.1035e-01, -1.0773e-01],\n",
      "        [ 1.2402e-01, -5.6427e-02, -1.4929e-01],\n",
      "        [ 2.3682e-01,  1.0181e-01, -1.3989e-01],\n",
      "        [ 1.1572e-01,  3.6030e-03, -5.9601e-02],\n",
      "        [-7.6965e-02,  1.2939e-01,  1.1224e-01],\n",
      "        [ 2.7710e-01, -1.8542e-01, -6.2561e-02],\n",
      "        [ 3.5352e-01, -7.1655e-02, -1.2878e-01],\n",
      "        [ 3.0334e-02, -3.0420e-01, -1.7120e-02],\n",
      "        [ 9.2468e-02, -7.2632e-02,  2.5562e-01],\n",
      "        [-2.4951e-01, -1.3977e-01,  6.7322e-02],\n",
      "        [ 2.3636e-02,  4.2975e-05,  1.3342e-01],\n",
      "        [ 5.9662e-02,  3.0640e-02,  6.6040e-02],\n",
      "        [ 7.3669e-02,  4.4281e-02,  3.4399e-01],\n",
      "        [ 7.2510e-02,  3.8025e-02,  2.5269e-01],\n",
      "        [ 1.4099e-01, -1.6101e-01,  1.8188e-01],\n",
      "        [ 3.1494e-01, -1.7529e-01,  9.5398e-02],\n",
      "        [ 3.5596e-01, -3.7183e-01,  2.9688e-01],\n",
      "        [ 1.2561e-01, -3.0518e-01,  3.9429e-01],\n",
      "        [ 1.9739e-01, -3.3252e-01,  4.1162e-01],\n",
      "        [-3.0731e-02, -2.5781e-01,  2.2339e-01],\n",
      "        [-1.4793e-02, -1.6443e-01,  1.1969e-01],\n",
      "        [ 1.3538e-01, -1.5991e-01,  1.0657e-01],\n",
      "        [ 3.6060e-01, -3.2178e-01,  4.4019e-01],\n",
      "        [ 1.4331e-01,  3.9062e-02,  2.0520e-01],\n",
      "        [ 2.1875e-01, -2.0532e-01,  6.5979e-02],\n",
      "        [ 2.9199e-01, -4.0222e-02,  2.4109e-01],\n",
      "        [ 3.1128e-01,  2.5558e-02,  1.3147e-01],\n",
      "        [ 1.5710e-01,  6.6162e-02,  5.6641e-02],\n",
      "        [ 1.7334e-01, -1.2018e-01,  2.8882e-01],\n",
      "        [ 6.1707e-02,  1.5637e-01,  1.7310e-01],\n",
      "        [-1.4978e-01,  1.8787e-01,  2.0044e-01],\n",
      "        [ 2.3865e-02, -2.0920e-02, -1.4209e-01],\n",
      "        [-1.9028e-02,  9.7900e-02, -1.3782e-01],\n",
      "        [-2.8625e-02,  1.2299e-01,  1.6113e-02],\n",
      "        [ 7.4097e-02, -6.5155e-03,  5.0568e-02],\n",
      "        [ 2.2388e-01, -1.6602e-01,  1.2952e-01],\n",
      "        [ 2.7451e-02,  2.1805e-02, -9.1370e-02],\n",
      "        [ 2.5098e-01, -1.5271e-01,  5.4749e-02],\n",
      "        [-5.3009e-02,  6.9397e-02, -1.5698e-01],\n",
      "        [ 3.0884e-01, -9.4482e-02, -4.6448e-02],\n",
      "        [ 5.1727e-02, -6.9237e-03,  1.4246e-01],\n",
      "        [-9.1858e-02,  1.5967e-01,  2.0935e-01],\n",
      "        [-3.1982e-01,  2.4170e-01,  1.0010e-01],\n",
      "        [-3.0835e-01, -2.2546e-01,  6.0059e-02],\n",
      "        [-3.3057e-01,  1.1670e-01,  2.0959e-01],\n",
      "        [-8.7097e-02,  3.6469e-02,  8.9905e-02],\n",
      "        [-3.0737e-01,  1.1761e-01,  2.3730e-01],\n",
      "        [-7.5562e-02, -6.4880e-02,  1.0132e-01],\n",
      "        [ 3.0151e-02,  1.3916e-01,  1.9873e-01],\n",
      "        [-4.6906e-02,  1.8018e-01,  2.4438e-01],\n",
      "        [-2.1704e-01,  3.0835e-01,  1.3046e-02],\n",
      "        [ 9.1553e-02,  1.6833e-01, -1.4941e-01],\n",
      "        [-3.5248e-02,  2.9883e-01, -3.9093e-02],\n",
      "        [-3.8879e-02,  1.7383e-01, -6.3660e-02],\n",
      "        [-8.7524e-02,  3.3478e-02, -1.3208e-01],\n",
      "        [-4.0665e-03,  4.3671e-02, -1.8127e-01],\n",
      "        [-1.4307e-01,  8.5388e-02, -2.3633e-01],\n",
      "        [-6.9519e-02, -1.1200e-01,  1.1359e-01],\n",
      "        [-1.1914e-01,  1.2793e-01,  1.5247e-01],\n",
      "        [-1.1237e-01,  1.4954e-01,  1.6553e-01],\n",
      "        [-2.3511e-01,  3.1934e-01,  9.5825e-02],\n",
      "        [-7.5500e-02,  1.6003e-01, -1.0950e-01],\n",
      "        [-3.1445e-01,  2.7222e-01,  8.8074e-02],\n",
      "        [-2.8564e-01,  2.4890e-01, -1.1047e-01],\n",
      "        [-1.7639e-01,  1.6223e-01, -1.0400e-01],\n",
      "        [-1.9873e-01,  3.4741e-01, -2.0605e-01],\n",
      "        [-1.8347e-01,  2.7881e-01, -5.3589e-02],\n",
      "        [-1.8518e-01, -2.5681e-02,  1.3794e-01],\n",
      "        [-2.7222e-02, -3.7964e-02, -7.5134e-02],\n",
      "        [-6.1432e-02,  2.3804e-02, -1.2378e-01],\n",
      "        [ 3.4790e-03,  6.4880e-02, -2.2339e-01],\n",
      "        [-4.4373e-02,  1.2718e-02, -8.6670e-02],\n",
      "        [ 5.5313e-03,  2.8711e-01, -2.4487e-01],\n",
      "        [-8.2275e-02,  1.3586e-01, -1.1932e-01],\n",
      "        [-5.3894e-02, -4.7150e-02, -8.9783e-02],\n",
      "        [ 2.0422e-01, -1.1444e-01,  7.1907e-03],\n",
      "        [ 9.0027e-02, -2.7847e-02,  1.6006e-02],\n",
      "        [-1.1475e-01, -9.1003e-02, -3.0835e-01],\n",
      "        [-1.1023e-01,  1.0597e-02, -1.5259e-01],\n",
      "        [-4.9774e-02, -3.2007e-01, -2.9395e-01],\n",
      "        [ 9.4910e-02, -1.2915e-01, -4.6509e-02]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3518, 0.2607, 0.3875],\n",
      "        [0.3562, 0.2986, 0.3455],\n",
      "        [0.3508, 0.3389, 0.3103],\n",
      "        [0.3357, 0.2808, 0.3835],\n",
      "        [0.3369, 0.2380, 0.4250],\n",
      "        [0.3782, 0.2593, 0.3625],\n",
      "        [0.3960, 0.3438, 0.2600],\n",
      "        [0.3374, 0.2920, 0.3706],\n",
      "        [0.4050, 0.2927, 0.3022],\n",
      "        [0.3606, 0.2649, 0.3745],\n",
      "        [0.4016, 0.2527, 0.3457],\n",
      "        [0.4026, 0.2163, 0.3811],\n",
      "        [0.3684, 0.3271, 0.3044],\n",
      "        [0.4297, 0.2306, 0.3398],\n",
      "        [0.3596, 0.3079, 0.3323],\n",
      "        [0.3289, 0.2839, 0.3875],\n",
      "        [0.3206, 0.3008, 0.3787],\n",
      "        [0.3516, 0.2759, 0.3726],\n",
      "        [0.3994, 0.2937, 0.3069],\n",
      "        [0.3708, 0.3022, 0.3269],\n",
      "        [0.3613, 0.2954, 0.3433],\n",
      "        [0.2949, 0.3191, 0.3862],\n",
      "        [0.3130, 0.2971, 0.3901],\n",
      "        [0.2610, 0.3164, 0.4226],\n",
      "        [0.3074, 0.2766, 0.4160],\n",
      "        [0.3396, 0.3662, 0.2944],\n",
      "        [0.3853, 0.3215, 0.2932],\n",
      "        [0.3906, 0.3413, 0.2681],\n",
      "        [0.3660, 0.3271, 0.3071],\n",
      "        [0.2910, 0.3577, 0.3516],\n",
      "        [0.4270, 0.2688, 0.3040],\n",
      "        [0.4404, 0.2878, 0.2717],\n",
      "        [0.3745, 0.2681, 0.3572],\n",
      "        [0.3306, 0.2803, 0.3892],\n",
      "        [0.2866, 0.3198, 0.3936],\n",
      "        [0.3232, 0.3159, 0.3608],\n",
      "        [0.3359, 0.3262, 0.3379],\n",
      "        [0.3047, 0.2959, 0.3994],\n",
      "        [0.3162, 0.3054, 0.3784],\n",
      "        [0.3596, 0.2659, 0.3745],\n",
      "        [0.4141, 0.2537, 0.3325],\n",
      "        [0.4124, 0.1991, 0.3887],\n",
      "        [0.3381, 0.2197, 0.4421],\n",
      "        [0.3538, 0.2081, 0.4382],\n",
      "        [0.3240, 0.2583, 0.4177],\n",
      "        [0.3328, 0.2866, 0.3806],\n",
      "        [0.3682, 0.2742, 0.3577],\n",
      "        [0.3865, 0.1953, 0.4185],\n",
      "        [0.3374, 0.3040, 0.3589],\n",
      "        [0.3979, 0.2605, 0.3416],\n",
      "        [0.3748, 0.2688, 0.3562],\n",
      "        [0.3865, 0.2905, 0.3230],\n",
      "        [0.3550, 0.3240, 0.3210],\n",
      "        [0.3486, 0.2600, 0.3914],\n",
      "        [0.3108, 0.3418, 0.3474],\n",
      "        [0.2617, 0.3669, 0.3716],\n",
      "        [0.3567, 0.3411, 0.3022],\n",
      "        [0.3320, 0.3733, 0.2949],\n",
      "        [0.3115, 0.3625, 0.3259],\n",
      "        [0.3450, 0.3181, 0.3369],\n",
      "        [0.3865, 0.2617, 0.3518],\n",
      "        [0.3469, 0.3450, 0.3081],\n",
      "        [0.4016, 0.2683, 0.3301],\n",
      "        [0.3298, 0.3728, 0.2974],\n",
      "        [0.4221, 0.2820, 0.2959],\n",
      "        [0.3291, 0.3103, 0.3604],\n",
      "        [0.2749, 0.3535, 0.3716],\n",
      "        [0.2339, 0.4102, 0.3560],\n",
      "        [0.2832, 0.3076, 0.4092],\n",
      "        [0.2336, 0.3655, 0.4009],\n",
      "        [0.3008, 0.3403, 0.3589],\n",
      "        [0.2351, 0.3596, 0.4053],\n",
      "        [0.3120, 0.3154, 0.3726],\n",
      "        [0.3032, 0.3381, 0.3589],\n",
      "        [0.2783, 0.3494, 0.3723],\n",
      "        [0.2532, 0.4282, 0.3186],\n",
      "        [0.3489, 0.3767, 0.2742],\n",
      "        [0.2947, 0.4116, 0.2937],\n",
      "        [0.3113, 0.3850, 0.3037],\n",
      "        [0.3242, 0.3657, 0.3101],\n",
      "        [0.3464, 0.3633, 0.2903],\n",
      "        [0.3157, 0.3967, 0.2876],\n",
      "        [0.3164, 0.3035, 0.3801],\n",
      "        [0.2783, 0.3564, 0.3652],\n",
      "        [0.2764, 0.3589, 0.3647],\n",
      "        [0.2419, 0.4211, 0.3369],\n",
      "        [0.3093, 0.3916, 0.2991],\n",
      "        [0.2329, 0.4187, 0.3484],\n",
      "        [0.2566, 0.4377, 0.3057],\n",
      "        [0.2876, 0.4033, 0.3091],\n",
      "        [0.2688, 0.4641, 0.2668],\n",
      "        [0.2683, 0.4260, 0.3057],\n",
      "        [0.2812, 0.3301, 0.3887],\n",
      "        [0.3398, 0.3362, 0.3240],\n",
      "        [0.3301, 0.3596, 0.3103],\n",
      "        [0.3496, 0.3718, 0.2786],\n",
      "        [0.3313, 0.3508, 0.3176],\n",
      "        [0.3223, 0.4270, 0.2507],\n",
      "        [0.3118, 0.3877, 0.3005],\n",
      "        [0.3364, 0.3389, 0.3247],\n",
      "        [0.3923, 0.2854, 0.3223],\n",
      "        [0.3550, 0.3154, 0.3296],\n",
      "        [0.3511, 0.3596, 0.2893],\n",
      "        [0.3240, 0.3655, 0.3105],\n",
      "        [0.3926, 0.2998, 0.3076],\n",
      "        [0.3750, 0.2996, 0.3254]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0606, -0.3647,  0.0653],\n",
      "        [ 0.2047, -0.0816,  0.0704],\n",
      "        [ 0.0110,  0.0922, -0.1028],\n",
      "        [ 0.2361, -0.0469,  0.1182],\n",
      "        [ 0.0774, -0.0988, -0.2983],\n",
      "        [-0.0218,  0.1791,  0.1472],\n",
      "        [ 0.0122, -0.1147,  0.4460],\n",
      "        [-0.0132,  0.0814,  0.2808],\n",
      "        [ 0.1665, -0.3477, -0.0090],\n",
      "        [-0.0297, -0.1757,  0.1628],\n",
      "        [ 0.0724, -0.3093,  0.0866],\n",
      "        [ 0.2505, -0.2419, -0.1194],\n",
      "        [ 0.2444, -0.3086, -0.0072],\n",
      "        [ 0.1831, -0.2286, -0.1427],\n",
      "        [-0.0168, -0.5225, -0.2238],\n",
      "        [ 0.0684, -0.2131, -0.3325],\n",
      "        [-0.0327, -0.4573, -0.2112],\n",
      "        [ 0.0160, -0.0789, -0.1429],\n",
      "        [-0.0296, -0.2482, -0.2059],\n",
      "        [ 0.0743, -0.1516,  0.0479],\n",
      "        [ 0.0872, -0.1903,  0.0043],\n",
      "        [ 0.0344, -0.0469, -0.1075],\n",
      "        [-0.0871, -0.0972, -0.2874],\n",
      "        [ 0.0317, -0.1283,  0.0251],\n",
      "        [ 0.1920, -0.0803, -0.4211],\n",
      "        [ 0.1687, -0.1816, -0.0165],\n",
      "        [ 0.1816, -0.2286, -0.3684],\n",
      "        [ 0.3203, -0.2546,  0.0210],\n",
      "        [ 0.2015, -0.0204, -0.1003],\n",
      "        [-0.1987, -0.0378,  0.1868],\n",
      "        [-0.0153,  0.0640, -0.0991],\n",
      "        [ 0.0518, -0.0290,  0.3469],\n",
      "        [-0.0660, -0.1725,  0.3416],\n",
      "        [-0.1134, -0.1398,  0.4443],\n",
      "        [ 0.0939, -0.3047, -0.0480],\n",
      "        [ 0.0574, -0.2979,  0.0605],\n",
      "        [ 0.1572, -0.2239, -0.3184],\n",
      "        [ 0.0702, -0.0466, -0.1132],\n",
      "        [ 0.1265, -0.1737, -0.1667],\n",
      "        [-0.3953, -0.1010,  0.0581],\n",
      "        [-0.1685, -0.1120,  0.1217],\n",
      "        [-0.2357, -0.0723,  0.1134],\n",
      "        [ 0.0327, -0.1616, -0.2316],\n",
      "        [-0.1511, -0.1874,  0.1090],\n",
      "        [-0.2177,  0.0040,  0.0402],\n",
      "        [-0.1233,  0.0399,  0.0765],\n",
      "        [-0.0835, -0.0750,  0.1627],\n",
      "        [-0.0119,  0.0526, -0.0260],\n",
      "        [-0.2323,  0.1328, -0.1553],\n",
      "        [-0.2316, -0.0222, -0.2417],\n",
      "        [ 0.0555,  0.1144, -0.3811],\n",
      "        [-0.0046, -0.0387, -0.1044],\n",
      "        [ 0.3523, -0.3062, -0.3147],\n",
      "        [ 0.1757, -0.2893, -0.0400]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3762, 0.2458, 0.3779],\n",
      "        [0.3809, 0.2861, 0.3330],\n",
      "        [0.3359, 0.3643, 0.2998],\n",
      "        [0.3784, 0.2852, 0.3364],\n",
      "        [0.3960, 0.3320, 0.2720],\n",
      "        [0.2935, 0.3589, 0.3477],\n",
      "        [0.2920, 0.2573, 0.4507],\n",
      "        [0.2905, 0.3193, 0.3899],\n",
      "        [0.4104, 0.2454, 0.3442],\n",
      "        [0.3250, 0.2810, 0.3940],\n",
      "        [0.3708, 0.2532, 0.3760],\n",
      "        [0.4343, 0.2654, 0.3000],\n",
      "        [0.4250, 0.2445, 0.3306],\n",
      "        [0.4194, 0.2778, 0.3027],\n",
      "        [0.4138, 0.2496, 0.3364],\n",
      "        [0.4124, 0.3113, 0.2764],\n",
      "        [0.4016, 0.2627, 0.3359],\n",
      "        [0.3621, 0.3291, 0.3088],\n",
      "        [0.3784, 0.3042, 0.3174],\n",
      "        [0.3608, 0.2878, 0.3513],\n",
      "        [0.3733, 0.2830, 0.3438],\n",
      "        [0.3584, 0.3306, 0.3110],\n",
      "        [0.3560, 0.3525, 0.2915],\n",
      "        [0.3513, 0.2996, 0.3491],\n",
      "        [0.4341, 0.3306, 0.2351],\n",
      "        [0.3945, 0.2778, 0.3276],\n",
      "        [0.4463, 0.2961, 0.2576],\n",
      "        [0.4341, 0.2443, 0.3218],\n",
      "        [0.3936, 0.3152, 0.2910],\n",
      "        [0.2744, 0.3223, 0.4033],\n",
      "        [0.3330, 0.3606, 0.3064],\n",
      "        [0.3062, 0.2825, 0.4114],\n",
      "        [0.2939, 0.2642, 0.4419],\n",
      "        [0.2688, 0.2617, 0.4695],\n",
      "        [0.3938, 0.2644, 0.3418],\n",
      "        [0.3699, 0.2593, 0.3708],\n",
      "        [0.4338, 0.2964, 0.2698],\n",
      "        [0.3674, 0.3269, 0.3059],\n",
      "        [0.4021, 0.2979, 0.3000],\n",
      "        [0.2554, 0.3428, 0.4019],\n",
      "        [0.2947, 0.3118, 0.3938],\n",
      "        [0.2781, 0.3276, 0.3943],\n",
      "        [0.3860, 0.3179, 0.2964],\n",
      "        [0.3066, 0.2957, 0.3977],\n",
      "        [0.2822, 0.3523, 0.3652],\n",
      "        [0.2942, 0.3464, 0.3594],\n",
      "        [0.3042, 0.3069, 0.3892],\n",
      "        [0.3276, 0.3494, 0.3230],\n",
      "        [0.2839, 0.4092, 0.3069],\n",
      "        [0.3103, 0.3826, 0.3071],\n",
      "        [0.3694, 0.3918, 0.2388],\n",
      "        [0.3481, 0.3367, 0.3152],\n",
      "        [0.4924, 0.2549, 0.2527],\n",
      "        [0.4109, 0.2581, 0.3311]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-1.3831e-01,  1.1377e-01,  2.0035e-02],\n",
      "        [-4.2152e-03, -5.5725e-02, -6.1920e-02],\n",
      "        [-1.7175e-01,  9.2896e-02, -1.1407e-01],\n",
      "        [-1.9421e-01,  1.2500e-01, -1.0773e-01],\n",
      "        [-1.4209e-01, -2.5253e-02,  3.8721e-01],\n",
      "        [-2.9541e-02, -1.0962e-01,  1.3354e-01],\n",
      "        [ 9.6619e-02, -1.3342e-01,  8.1970e-02],\n",
      "        [-2.2079e-02, -2.5539e-03, -6.3171e-02],\n",
      "        [-2.8320e-02, -9.4727e-02,  3.5553e-02],\n",
      "        [-9.4482e-02, -3.5791e-01,  8.6487e-02],\n",
      "        [ 1.2061e-01, -3.6548e-01, -3.1677e-02],\n",
      "        [ 1.3928e-01,  2.9938e-02,  1.6296e-01],\n",
      "        [-5.1422e-02,  4.6173e-02, -1.5186e-01],\n",
      "        [ 9.0576e-02,  2.1057e-01, -8.2302e-04],\n",
      "        [-3.4668e-02,  7.4402e-02, -1.3025e-01],\n",
      "        [ 3.5172e-03,  3.3783e-02, -1.5112e-01],\n",
      "        [ 2.4268e-01, -1.0114e-01,  6.7078e-02],\n",
      "        [ 2.9587e-02, -1.5747e-01, -1.9751e-01],\n",
      "        [ 1.2720e-01,  1.1011e-01, -2.6978e-01],\n",
      "        [ 4.1461e-04, -2.4634e-01,  1.1581e-02],\n",
      "        [ 3.1079e-01, -2.7563e-01, -2.2229e-01],\n",
      "        [ 2.2363e-01, -2.6074e-01,  2.0618e-01],\n",
      "        [ 6.7200e-02, -4.1656e-02,  4.7180e-02],\n",
      "        [-3.2387e-03, -2.7368e-01,  2.7417e-01],\n",
      "        [-4.7241e-02, -1.3741e-02, -8.1604e-02],\n",
      "        [-6.6223e-02,  3.4424e-02, -2.2446e-02],\n",
      "        [-5.2856e-02, -2.2034e-01, -2.4673e-02],\n",
      "        [-1.0504e-01, -7.7576e-02,  2.2186e-02],\n",
      "        [-1.8457e-01, -3.9001e-02,  1.5637e-01],\n",
      "        [-1.1627e-01,  5.7869e-03,  1.2988e-01],\n",
      "        [-4.4556e-02, -4.3060e-02,  2.2180e-01],\n",
      "        [ 6.9519e-02, -4.9164e-02,  8.8013e-02],\n",
      "        [-3.9368e-02, -2.3193e-01,  1.1938e-01],\n",
      "        [ 1.4941e-01, -4.0820e-01,  1.8567e-01],\n",
      "        [-1.1017e-01, -2.8442e-01,  8.3618e-02],\n",
      "        [-1.8738e-01, -4.2871e-01, -2.2369e-02],\n",
      "        [-2.4329e-01, -5.0342e-01,  7.7393e-02],\n",
      "        [ 2.0422e-01, -3.5767e-01, -4.2755e-02]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2891, 0.3721, 0.3389],\n",
      "        [0.3455, 0.3281, 0.3262],\n",
      "        [0.2974, 0.3875, 0.3152],\n",
      "        [0.2886, 0.3970, 0.3145],\n",
      "        [0.2617, 0.2942, 0.4443],\n",
      "        [0.3225, 0.2979, 0.3796],\n",
      "        [0.3596, 0.2859, 0.3545],\n",
      "        [0.3357, 0.3423, 0.3220],\n",
      "        [0.3333, 0.3118, 0.3552],\n",
      "        [0.3372, 0.2590, 0.4041],\n",
      "        [0.4043, 0.2487, 0.3472],\n",
      "        [0.3425, 0.3069, 0.3506],\n",
      "        [0.3325, 0.3667, 0.3008],\n",
      "        [0.3289, 0.3708, 0.3003],\n",
      "        [0.3306, 0.3689, 0.3005],\n",
      "        [0.3464, 0.3569, 0.2966],\n",
      "        [0.3926, 0.2783, 0.3293],\n",
      "        [0.3809, 0.3159, 0.3035],\n",
      "        [0.3767, 0.3701, 0.2532],\n",
      "        [0.3582, 0.2798, 0.3621],\n",
      "        [0.4666, 0.2595, 0.2739],\n",
      "        [0.3848, 0.2371, 0.3782],\n",
      "        [0.3477, 0.3118, 0.3406],\n",
      "        [0.3245, 0.2476, 0.4280],\n",
      "        [0.3333, 0.3447, 0.3220],\n",
      "        [0.3174, 0.3511, 0.3315],\n",
      "        [0.3479, 0.2942, 0.3579],\n",
      "        [0.3162, 0.3250, 0.3589],\n",
      "        [0.2808, 0.3247, 0.3948],\n",
      "        [0.2935, 0.3315, 0.3752],\n",
      "        [0.3025, 0.3030, 0.3948],\n",
      "        [0.3440, 0.3054, 0.3503],\n",
      "        [0.3337, 0.2751, 0.3911],\n",
      "        [0.3833, 0.2194, 0.3975],\n",
      "        [0.3274, 0.2751, 0.3975],\n",
      "        [0.3372, 0.2649, 0.3977],\n",
      "        [0.3176, 0.2449, 0.4375],\n",
      "        [0.4253, 0.2424, 0.3323]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.3035, -0.0428,  0.2107],\n",
      "        [ 0.0457,  0.2421, -0.1721],\n",
      "        [-0.1420,  0.2920, -0.0160],\n",
      "        [ 0.0344, -0.1886, -0.0080],\n",
      "        [-0.0058, -0.2839, -0.1256],\n",
      "        [-0.0304, -0.1122, -0.1592],\n",
      "        [ 0.2739, -0.1268, -0.1331],\n",
      "        [-0.0289,  0.1120,  0.0243],\n",
      "        [ 0.0538,  0.1510,  0.0440],\n",
      "        [-0.0773,  0.0789,  0.0023],\n",
      "        [ 0.0641,  0.1166, -0.0893],\n",
      "        [-0.1471,  0.1746,  0.1519],\n",
      "        [-0.2323,  0.1265,  0.1174],\n",
      "        [-0.3787,  0.3552, -0.0069],\n",
      "        [ 0.1580, -0.2042,  0.0673],\n",
      "        [-0.0540,  0.0646,  0.3193],\n",
      "        [-0.2213, -0.1519,  0.1304],\n",
      "        [-0.2322, -0.1619,  0.2228],\n",
      "        [ 0.1606, -0.2344, -0.0539],\n",
      "        [-0.1185, -0.2864,  0.2393],\n",
      "        [ 0.2367, -0.5718,  0.1565],\n",
      "        [-0.0192, -0.2654,  0.1790],\n",
      "        [ 0.2742, -0.3823,  0.0481],\n",
      "        [ 0.2317, -0.6475,  0.0826],\n",
      "        [ 0.0046, -0.2107, -0.2416],\n",
      "        [ 0.2286, -0.3267,  0.1880],\n",
      "        [ 0.0426, -0.2406, -0.0912],\n",
      "        [ 0.0756, -0.4941,  0.0766],\n",
      "        [-0.0219, -0.4023, -0.3452],\n",
      "        [ 0.0806, -0.4426,  0.0518]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2520, 0.3269, 0.4211],\n",
      "        [0.3311, 0.4028, 0.2661],\n",
      "        [0.2720, 0.4197, 0.3083],\n",
      "        [0.3625, 0.2900, 0.3474],\n",
      "        [0.3782, 0.2864, 0.3354],\n",
      "        [0.3569, 0.3291, 0.3140],\n",
      "        [0.4282, 0.2869, 0.2849],\n",
      "        [0.3120, 0.3591, 0.3289],\n",
      "        [0.3235, 0.3564, 0.3203],\n",
      "        [0.3076, 0.3594, 0.3330],\n",
      "        [0.3435, 0.3621, 0.2947],\n",
      "        [0.2683, 0.3701, 0.3618],\n",
      "        [0.2598, 0.3718, 0.3684],\n",
      "        [0.2206, 0.4595, 0.3198],\n",
      "        [0.3833, 0.2668, 0.3501],\n",
      "        [0.2795, 0.3147, 0.4060],\n",
      "        [0.2864, 0.3069, 0.4070],\n",
      "        [0.2742, 0.2939, 0.4319],\n",
      "        [0.4031, 0.2715, 0.3252],\n",
      "        [0.3052, 0.2581, 0.4365],\n",
      "        [0.4221, 0.1881, 0.3896],\n",
      "        [0.3333, 0.2605, 0.4062],\n",
      "        [0.4316, 0.2239, 0.3445],\n",
      "        [0.4392, 0.1824, 0.3784],\n",
      "        [0.3865, 0.3115, 0.3020],\n",
      "        [0.3945, 0.2264, 0.3789],\n",
      "        [0.3806, 0.2866, 0.3328],\n",
      "        [0.3896, 0.2203, 0.3899],\n",
      "        [0.4153, 0.2839, 0.3005],\n",
      "        [0.3899, 0.2311, 0.3789]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.2581, -0.2007,  0.0900],\n",
      "        [ 0.1024, -0.1631,  0.1281],\n",
      "        [-0.1763, -0.0362, -0.1733],\n",
      "        [-0.0564, -0.1213, -0.0075],\n",
      "        [ 0.0933, -0.0380, -0.1165],\n",
      "        [ 0.1577, -0.1041,  0.0564]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2878, 0.3047, 0.4075],\n",
      "        [0.3582, 0.2747, 0.3674],\n",
      "        [0.3171, 0.3647, 0.3181],\n",
      "        [0.3347, 0.3137, 0.3516],\n",
      "        [0.3721, 0.3262, 0.3018],\n",
      "        [0.3740, 0.2878, 0.3381]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.3872, -0.0007,  0.0602],\n",
      "        [ 0.3149, -0.2108,  0.0239],\n",
      "        [ 0.2959, -0.2416, -0.0590],\n",
      "        [ 0.3184, -0.3296,  0.2776],\n",
      "        [ 0.2271,  0.0116, -0.1680],\n",
      "        [ 0.3057, -0.0512,  0.0246],\n",
      "        [ 0.2629,  0.0022, -0.2910],\n",
      "        [ 0.2505, -0.0465, -0.0248],\n",
      "        [ 0.2164, -0.0189, -0.1757],\n",
      "        [ 0.1880, -0.0466,  0.1949],\n",
      "        [-0.1050,  0.2380,  0.2175],\n",
      "        [-0.0990,  0.1477,  0.2316],\n",
      "        [ 0.0977,  0.0905,  0.0729],\n",
      "        [ 0.1733,  0.4832,  0.2869],\n",
      "        [ 0.2340,  0.2446,  0.1617],\n",
      "        [ 0.1882,  0.1671,  0.0984],\n",
      "        [-0.0366,  0.0878,  0.3311],\n",
      "        [ 0.0090, -0.0167,  0.3953],\n",
      "        [ 0.0583,  0.1143,  0.1959],\n",
      "        [ 0.0993,  0.0427,  0.2212],\n",
      "        [ 0.0797,  0.1932,  0.1678],\n",
      "        [ 0.2277,  0.3921,  0.2502],\n",
      "        [ 0.1768,  0.1803,  0.3728],\n",
      "        [ 0.0966,  0.0210,  0.3010],\n",
      "        [ 0.0537,  0.0082, -0.0061],\n",
      "        [ 0.0068, -0.1865,  0.4221],\n",
      "        [-0.0206,  0.0891, -0.1628],\n",
      "        [-0.1202,  0.1272,  0.0591],\n",
      "        [-0.1060,  0.3674,  0.0605],\n",
      "        [-0.1289,  0.1680,  0.1711],\n",
      "        [-0.0724,  0.1494,  0.0972],\n",
      "        [ 0.0257, -0.0421,  0.1588],\n",
      "        [-0.0232, -0.0063, -0.1888],\n",
      "        [-0.2263, -0.0190,  0.1071],\n",
      "        [ 0.3447, -0.1172, -0.3081],\n",
      "        [-0.0392,  0.1809, -0.1702],\n",
      "        [ 0.2137, -0.0061,  0.0299],\n",
      "        [ 0.2925,  0.1197,  0.0242],\n",
      "        [ 0.2375,  0.1859, -0.1761],\n",
      "        [-0.0180,  0.0930,  0.0214],\n",
      "        [ 0.2380, -0.3530, -0.1765],\n",
      "        [-0.0005,  0.0465,  0.0096]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2478, 0.3647, 0.3875],\n",
      "        [0.4275, 0.2527, 0.3196],\n",
      "        [0.4375, 0.2556, 0.3069],\n",
      "        [0.4028, 0.2107, 0.3867],\n",
      "        [0.4033, 0.3252, 0.2717],\n",
      "        [0.4075, 0.2852, 0.3076],\n",
      "        [0.4265, 0.3286, 0.2450],\n",
      "        [0.3997, 0.2969, 0.3035],\n",
      "        [0.4055, 0.3206, 0.2739],\n",
      "        [0.3574, 0.2827, 0.3599],\n",
      "        [0.2639, 0.3718, 0.3643],\n",
      "        [0.2725, 0.3486, 0.3792],\n",
      "        [0.3369, 0.3345, 0.3286],\n",
      "        [0.2871, 0.3914, 0.3215],\n",
      "        [0.3401, 0.3438, 0.3164],\n",
      "        [0.3457, 0.3384, 0.3159],\n",
      "        [0.2795, 0.3167, 0.4038],\n",
      "        [0.2903, 0.2827, 0.4270],\n",
      "        [0.3120, 0.3301, 0.3582],\n",
      "        [0.3252, 0.3074, 0.3674],\n",
      "        [0.3113, 0.3486, 0.3401],\n",
      "        [0.3123, 0.3682, 0.3196],\n",
      "        [0.3105, 0.3118, 0.3777],\n",
      "        [0.3171, 0.2939, 0.3889],\n",
      "        [0.3452, 0.3298, 0.3252],\n",
      "        [0.2996, 0.2468, 0.4536],\n",
      "        [0.3352, 0.3740, 0.2908],\n",
      "        [0.2876, 0.3684, 0.3440],\n",
      "        [0.2642, 0.4241, 0.3120],\n",
      "        [0.2705, 0.3640, 0.3652],\n",
      "        [0.2913, 0.3635, 0.3452],\n",
      "        [0.3250, 0.3037, 0.3713],\n",
      "        [0.3491, 0.3550, 0.2959],\n",
      "        [0.2759, 0.3394, 0.3850],\n",
      "        [0.4651, 0.2930, 0.2421],\n",
      "        [0.3201, 0.3989, 0.2808],\n",
      "        [0.3796, 0.3047, 0.3159],\n",
      "        [0.3838, 0.3228, 0.2935],\n",
      "        [0.3831, 0.3638, 0.2532],\n",
      "        [0.3167, 0.3540, 0.3293],\n",
      "        [0.4517, 0.2500, 0.2983],\n",
      "        [0.3269, 0.3428, 0.3303]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-3.3997e-02, -2.0447e-01,  1.7517e-01],\n",
      "        [-3.1311e-02, -9.3445e-02,  9.1614e-02],\n",
      "        [-1.6556e-02,  4.0741e-02, -8.4961e-02],\n",
      "        [ 1.2634e-01, -1.9302e-02,  3.4088e-02],\n",
      "        [-1.4023e-02, -1.0522e-01,  9.6497e-02],\n",
      "        [ 1.6309e-01,  7.1472e-02, -7.7515e-02],\n",
      "        [ 1.0754e-01,  9.8999e-02, -1.0628e-02],\n",
      "        [ 1.3342e-01, -4.2877e-02, -2.0981e-02],\n",
      "        [ 2.7441e-01, -9.4299e-02, -2.0557e-01],\n",
      "        [ 3.0151e-01, -1.7334e-01, -9.6680e-02],\n",
      "        [ 1.5857e-01, -2.8369e-01, -1.2451e-01],\n",
      "        [ 1.6675e-01, -3.0273e-01,  8.3923e-02],\n",
      "        [ 3.0273e-01, -3.6523e-01, -1.8640e-01],\n",
      "        [ 1.8945e-01, -2.2278e-01, -1.9556e-01],\n",
      "        [ 1.9446e-01, -4.5679e-01, -8.9355e-02],\n",
      "        [ 1.7542e-01, -2.9517e-01, -3.1464e-02],\n",
      "        [ 1.1047e-01, -1.8030e-01, -2.3596e-01],\n",
      "        [ 2.0447e-01, -4.3750e-01, -5.9448e-02],\n",
      "        [ 2.3901e-01, -1.8677e-01,  1.9836e-01],\n",
      "        [ 2.3413e-01, -1.9250e-01,  4.8157e-02],\n",
      "        [ 8.8623e-02, -2.6562e-01, -3.1853e-04],\n",
      "        [ 2.6709e-01, -6.0425e-02,  1.7065e-01],\n",
      "        [ 2.8735e-01, -2.6050e-01,  2.2937e-01],\n",
      "        [ 3.8379e-01,  7.7515e-02,  3.6316e-02],\n",
      "        [ 2.0361e-01,  8.0383e-02,  1.8005e-01],\n",
      "        [-5.3619e-02,  5.4108e-02, -1.1681e-02],\n",
      "        [ 2.7295e-01, -1.3940e-01,  1.8570e-02],\n",
      "        [ 2.9834e-01, -2.5781e-01, -2.4536e-01],\n",
      "        [ 5.2979e-02, -2.7856e-01, -8.3923e-03],\n",
      "        [ 2.1936e-01, -1.9788e-01,  1.0368e-02],\n",
      "        [ 1.2476e-01,  5.3223e-02,  1.3770e-01],\n",
      "        [-1.6675e-01, -7.3364e-02,  2.6306e-02],\n",
      "        [ 2.7271e-01,  7.5500e-02, -9.0210e-02],\n",
      "        [ 1.6199e-01,  3.5583e-02, -8.4351e-02],\n",
      "        [ 5.2338e-02,  1.1981e-01,  1.5594e-02],\n",
      "        [ 1.3550e-01,  1.1639e-01, -1.3232e-01],\n",
      "        [ 8.1421e-02,  1.1316e-01, -2.6025e-01],\n",
      "        [ 1.3599e-01, -7.5256e-02, -1.3196e-01],\n",
      "        [ 5.0171e-02, -2.4719e-01, -3.6694e-01],\n",
      "        [ 1.3074e-01, -1.0938e-01, -1.5965e-03]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3252, 0.2742, 0.4006],\n",
      "        [0.3257, 0.3062, 0.3682],\n",
      "        [0.3342, 0.3538, 0.3120],\n",
      "        [0.3601, 0.3113, 0.3284],\n",
      "        [0.3301, 0.3013, 0.3687],\n",
      "        [0.3706, 0.3381, 0.2913],\n",
      "        [0.3472, 0.3442, 0.3086],\n",
      "        [0.3711, 0.3110, 0.3179],\n",
      "        [0.4329, 0.2993, 0.2678],\n",
      "        [0.4360, 0.2712, 0.2927],\n",
      "        [0.4172, 0.2681, 0.3145],\n",
      "        [0.3928, 0.2456, 0.3616],\n",
      "        [0.4705, 0.2412, 0.2883],\n",
      "        [0.4268, 0.2827, 0.2905],\n",
      "        [0.4397, 0.2292, 0.3311],\n",
      "        [0.4102, 0.2563, 0.3335],\n",
      "        [0.4075, 0.3047, 0.2881],\n",
      "        [0.4358, 0.2294, 0.3347],\n",
      "        [0.3826, 0.2500, 0.3674],\n",
      "        [0.4028, 0.2629, 0.3345],\n",
      "        [0.3821, 0.2681, 0.3496],\n",
      "        [0.3804, 0.2742, 0.3455],\n",
      "        [0.3965, 0.2292, 0.3743],\n",
      "        [0.4094, 0.3013, 0.2893],\n",
      "        [0.3496, 0.3091, 0.3413],\n",
      "        [0.3169, 0.3528, 0.3303],\n",
      "        [0.4102, 0.2717, 0.3181],\n",
      "        [0.4644, 0.2661, 0.2695],\n",
      "        [0.3762, 0.2700, 0.3538],\n",
      "        [0.4048, 0.2666, 0.3284],\n",
      "        [0.3396, 0.3162, 0.3440],\n",
      "        [0.3020, 0.3315, 0.3665],\n",
      "        [0.3975, 0.3262, 0.2764],\n",
      "        [0.3755, 0.3311, 0.2935],\n",
      "        [0.3296, 0.3525, 0.3176],\n",
      "        [0.3643, 0.3572, 0.2786],\n",
      "        [0.3645, 0.3765, 0.2590],\n",
      "        [0.3884, 0.3145, 0.2971],\n",
      "        [0.4163, 0.3093, 0.2744],\n",
      "        [0.3755, 0.2954, 0.3291]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.2072, -0.1349,  0.2988],\n",
      "        [ 0.4075, -0.4062,  0.0367],\n",
      "        [-0.1562, -0.4927,  0.0568],\n",
      "        [ 0.2161, -0.1172,  0.2255],\n",
      "        [ 0.0836, -0.2571,  0.0049],\n",
      "        [-0.0767, -0.2190,  0.2808],\n",
      "        [ 0.0374, -0.3125,  0.0093],\n",
      "        [ 0.0171,  0.0222,  0.2488],\n",
      "        [ 0.3884, -0.2764,  0.0856],\n",
      "        [ 0.3606, -0.1670,  0.1808],\n",
      "        [ 0.2888, -0.2072,  0.1667],\n",
      "        [ 0.0895, -0.0468,  0.2266],\n",
      "        [ 0.0936, -0.1390,  0.0055],\n",
      "        [ 0.0997, -0.0889,  0.1724],\n",
      "        [ 0.1638, -0.0880,  0.2449],\n",
      "        [ 0.2729, -0.2169,  0.3506],\n",
      "        [ 0.1456, -0.2727,  0.0147],\n",
      "        [ 0.0043, -0.1555,  0.4258],\n",
      "        [ 0.1355, -0.1155,  0.0671],\n",
      "        [ 0.3391, -0.1361,  0.2795],\n",
      "        [ 0.1316, -0.1895,  0.1158],\n",
      "        [ 0.2239,  0.0276,  0.0421],\n",
      "        [ 0.1880, -0.0936,  0.0071],\n",
      "        [ 0.2727, -0.1223,  0.1388],\n",
      "        [ 0.0797, -0.0909,  0.0236],\n",
      "        [ 0.1718, -0.1909,  0.1498],\n",
      "        [ 0.1936,  0.0129,  0.1259],\n",
      "        [ 0.1666, -0.1743,  0.0977],\n",
      "        [-0.0568, -0.2966, -0.1492],\n",
      "        [ 0.0286, -0.0911,  0.1335]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2678, 0.2878, 0.4443],\n",
      "        [0.4688, 0.2078, 0.3235],\n",
      "        [0.3389, 0.2419, 0.4192],\n",
      "        [0.3669, 0.2629, 0.3704],\n",
      "        [0.3794, 0.2698, 0.3506],\n",
      "        [0.3032, 0.2632, 0.4336],\n",
      "        [0.3735, 0.2632, 0.3633],\n",
      "        [0.3062, 0.3079, 0.3860],\n",
      "        [0.4438, 0.2283, 0.3279],\n",
      "        [0.4124, 0.2433, 0.3445],\n",
      "        [0.4009, 0.2441, 0.3550],\n",
      "        [0.3311, 0.2891, 0.3799],\n",
      "        [0.3691, 0.2927, 0.3381],\n",
      "        [0.3445, 0.2852, 0.3704],\n",
      "        [0.3494, 0.2717, 0.3789],\n",
      "        [0.3713, 0.2275, 0.4014],\n",
      "        [0.3945, 0.2595, 0.3459],\n",
      "        [0.2961, 0.2524, 0.4514],\n",
      "        [0.3687, 0.2869, 0.3445],\n",
      "        [0.3901, 0.2426, 0.3674],\n",
      "        [0.3691, 0.2678, 0.3633],\n",
      "        [0.3765, 0.3096, 0.3140],\n",
      "        [0.3862, 0.2915, 0.3223],\n",
      "        [0.3923, 0.2644, 0.3433],\n",
      "        [0.3586, 0.3022, 0.3391],\n",
      "        [0.3740, 0.2603, 0.3657],\n",
      "        [0.3611, 0.3015, 0.3374],\n",
      "        [0.3782, 0.2688, 0.3530],\n",
      "        [0.3706, 0.2915, 0.3379],\n",
      "        [0.3335, 0.2959, 0.3704]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1453, -0.1687,  0.3015],\n",
      "        [-0.1083,  0.1426,  0.0957],\n",
      "        [ 0.2720, -0.0999, -0.1761],\n",
      "        [ 0.4204,  0.0371,  0.1317],\n",
      "        [ 0.4407, -0.2440, -0.3169],\n",
      "        [ 0.3508,  0.0385,  0.1975],\n",
      "        [ 0.4211, -0.3267, -0.1399],\n",
      "        [ 0.3455, -0.2905,  0.2192],\n",
      "        [ 0.3132, -0.3586,  0.0469],\n",
      "        [ 0.3901, -0.3926,  0.1597],\n",
      "        [ 0.2079, -0.2856, -0.1768],\n",
      "        [ 0.0827, -0.2581,  0.0040],\n",
      "        [ 0.1213, -0.3992, -0.1759],\n",
      "        [ 0.0562, -0.1437, -0.1010],\n",
      "        [ 0.1805, -0.2654, -0.2861],\n",
      "        [ 0.0138,  0.1305, -0.3093],\n",
      "        [-0.0938, -0.0071, -0.1774],\n",
      "        [ 0.3999, -0.1770, -0.3000],\n",
      "        [ 0.2690, -0.0822, -0.2126],\n",
      "        [ 0.3689, -0.1494, -0.1592],\n",
      "        [ 0.3743, -0.3745, -0.4849],\n",
      "        [ 0.4211, -0.4749, -0.1838],\n",
      "        [ 0.1836, -0.1410, -0.1691],\n",
      "        [ 0.1993, -0.0284, -0.1006],\n",
      "        [ 0.1346, -0.1482, -0.1271],\n",
      "        [ 0.2028, -0.2751,  0.0110],\n",
      "        [ 0.2937, -0.4011,  0.1600],\n",
      "        [ 0.4133, -0.4692,  0.0824],\n",
      "        [ 0.4565, -0.3486, -0.0939],\n",
      "        [ 0.2720, -0.3870,  0.0615],\n",
      "        [ 0.4382, -0.2092, -0.0629],\n",
      "        [ 0.3777, -0.1270,  0.0965],\n",
      "        [ 0.1142, -0.0033, -0.0616],\n",
      "        [ 0.2585, -0.0620, -0.0071],\n",
      "        [ 0.1429, -0.0984, -0.0862],\n",
      "        [ 0.5103, -0.0890,  0.0592],\n",
      "        [ 0.2076,  0.0104,  0.0542],\n",
      "        [ 0.2932,  0.1321,  0.0522],\n",
      "        [ 0.2445,  0.0467, -0.1201],\n",
      "        [ 0.0184,  0.0736, -0.0476],\n",
      "        [ 0.1674,  0.3892, -0.1747],\n",
      "        [-0.0017,  0.3240,  0.1046],\n",
      "        [ 0.0882,  0.0646,  0.1186],\n",
      "        [ 0.1652,  0.0211,  0.3606],\n",
      "        [ 0.3389, -0.1301,  0.0878],\n",
      "        [ 0.0891, -0.1965, -0.0389],\n",
      "        [ 0.2046, -0.0662,  0.0656],\n",
      "        [ 0.1820, -0.3286,  0.0589],\n",
      "        [ 0.1696, -0.2534, -0.1138],\n",
      "        [-0.0288, -0.0534, -0.1407],\n",
      "        [ 0.0023, -0.0826, -0.0689],\n",
      "        [ 0.1724, -0.0327, -0.2620],\n",
      "        [ 0.1589, -0.0714, -0.3804],\n",
      "        [ 0.0501, -0.0585, -0.0501],\n",
      "        [ 0.1436, -0.3804, -0.3999],\n",
      "        [ 0.2216, -0.3733, -0.0077]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2825, 0.2759, 0.4417],\n",
      "        [0.2847, 0.3660, 0.3491],\n",
      "        [0.4294, 0.2961, 0.2744],\n",
      "        [0.4114, 0.2805, 0.3081],\n",
      "        [0.5068, 0.2556, 0.2375],\n",
      "        [0.3862, 0.2825, 0.3313],\n",
      "        [0.4893, 0.2316, 0.2791],\n",
      "        [0.4148, 0.2196, 0.3657],\n",
      "        [0.4392, 0.2244, 0.3364],\n",
      "        [0.4441, 0.2031, 0.3528],\n",
      "        [0.4365, 0.2664, 0.2971],\n",
      "        [0.3794, 0.2698, 0.3508],\n",
      "        [0.4280, 0.2542, 0.3179],\n",
      "        [0.3740, 0.3064, 0.3196],\n",
      "        [0.4412, 0.2825, 0.2766],\n",
      "        [0.3511, 0.3945, 0.2542],\n",
      "        [0.3323, 0.3623, 0.3057],\n",
      "        [0.4858, 0.2729, 0.2413],\n",
      "        [0.4307, 0.3032, 0.2661],\n",
      "        [0.4575, 0.2725, 0.2698],\n",
      "        [0.5273, 0.2494, 0.2233],\n",
      "        [0.5117, 0.2089, 0.2795],\n",
      "        [0.4124, 0.2981, 0.2898],\n",
      "        [0.3940, 0.3140, 0.2920],\n",
      "        [0.3962, 0.2986, 0.3049],\n",
      "        [0.4089, 0.2537, 0.3376],\n",
      "        [0.4211, 0.2102, 0.3684],\n",
      "        [0.4690, 0.1941, 0.3369],\n",
      "        [0.4941, 0.2209, 0.2849],\n",
      "        [0.4297, 0.2223, 0.3481],\n",
      "        [0.4697, 0.2458, 0.2844],\n",
      "        [0.4241, 0.2559, 0.3201],\n",
      "        [0.3665, 0.3259, 0.3074],\n",
      "        [0.4011, 0.2913, 0.3076],\n",
      "        [0.3875, 0.3044, 0.3081],\n",
      "        [0.4575, 0.2512, 0.2913],\n",
      "        [0.3733, 0.3064, 0.3203],\n",
      "        [0.3792, 0.3228, 0.2981],\n",
      "        [0.3977, 0.3262, 0.2761],\n",
      "        [0.3342, 0.3530, 0.3127],\n",
      "        [0.3379, 0.4219, 0.2401],\n",
      "        [0.2859, 0.3960, 0.3181],\n",
      "        [0.3325, 0.3247, 0.3428],\n",
      "        [0.3245, 0.2810, 0.3945],\n",
      "        [0.4160, 0.2603, 0.3237],\n",
      "        [0.3801, 0.2856, 0.3345],\n",
      "        [0.3799, 0.2898, 0.3306],\n",
      "        [0.4026, 0.2416, 0.3560],\n",
      "        [0.4153, 0.2720, 0.3127],\n",
      "        [0.3484, 0.3401, 0.3115],\n",
      "        [0.3508, 0.3223, 0.3267],\n",
      "        [0.4060, 0.3308, 0.2629],\n",
      "        [0.4207, 0.3340, 0.2452],\n",
      "        [0.3569, 0.3203, 0.3230],\n",
      "        [0.4602, 0.2725, 0.2673],\n",
      "        [0.4260, 0.2351, 0.3389]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.2502,  0.0649,  0.1975],\n",
      "        [ 0.0306, -0.1153, -0.1166],\n",
      "        [ 0.0580, -0.1250, -0.3440],\n",
      "        [-0.0046,  0.0597, -0.0702],\n",
      "        [ 0.1852,  0.0527, -0.0058],\n",
      "        [ 0.0452,  0.0781, -0.0407],\n",
      "        [ 0.1157,  0.1544,  0.0322],\n",
      "        [ 0.1919,  0.1187,  0.1809],\n",
      "        [ 0.0811, -0.0101, -0.0498],\n",
      "        [ 0.3970, -0.3025,  0.2427],\n",
      "        [ 0.1747,  0.1282, -0.1595],\n",
      "        [-0.0555, -0.1151,  0.1796],\n",
      "        [-0.0826, -0.0885,  0.1661],\n",
      "        [-0.1842, -0.2273,  0.2371],\n",
      "        [-0.1948, -0.0895,  0.3086],\n",
      "        [-0.2285, -0.2357,  0.3350],\n",
      "        [-0.2834, -0.0696,  0.4727],\n",
      "        [-0.0945, -0.1087,  0.1923],\n",
      "        [-0.0209, -0.3059,  0.4456],\n",
      "        [-0.0036, -0.4802,  0.3730],\n",
      "        [-0.0436, -0.2411,  0.0609],\n",
      "        [ 0.0704, -0.3154,  0.0923],\n",
      "        [ 0.1558, -0.1371, -0.0634],\n",
      "        [ 0.3013, -0.2576,  0.2344],\n",
      "        [ 0.3181, -0.1332,  0.0383],\n",
      "        [ 0.1864, -0.2336,  0.0140],\n",
      "        [-0.0457, -0.1648, -0.2231],\n",
      "        [ 0.1847, -0.3093, -0.0460],\n",
      "        [ 0.0604, -0.3279, -0.2303],\n",
      "        [ 0.1632, -0.1501, -0.0259]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2542, 0.3481, 0.3977],\n",
      "        [0.3667, 0.3169, 0.3164],\n",
      "        [0.3997, 0.3328, 0.2673],\n",
      "        [0.3330, 0.3552, 0.3118],\n",
      "        [0.3701, 0.3242, 0.3057],\n",
      "        [0.3389, 0.3501, 0.3110],\n",
      "        [0.3379, 0.3513, 0.3108],\n",
      "        [0.3425, 0.3184, 0.3389],\n",
      "        [0.3584, 0.3271, 0.3145],\n",
      "        [0.4248, 0.2111, 0.3640],\n",
      "        [0.3745, 0.3574, 0.2681],\n",
      "        [0.3118, 0.2937, 0.3945],\n",
      "        [0.3052, 0.3035, 0.3914],\n",
      "        [0.2871, 0.2751, 0.4377],\n",
      "        [0.2656, 0.2952, 0.4395],\n",
      "        [0.2666, 0.2649, 0.4685],\n",
      "        [0.2289, 0.2834, 0.4875],\n",
      "        [0.3013, 0.2971, 0.4014],\n",
      "        [0.2988, 0.2247, 0.4766],\n",
      "        [0.3250, 0.2017, 0.4734],\n",
      "        [0.3413, 0.2800, 0.3787],\n",
      "        [0.3701, 0.2517, 0.3782],\n",
      "        [0.3923, 0.2927, 0.3149],\n",
      "        [0.3989, 0.2281, 0.3730],\n",
      "        [0.4180, 0.2661, 0.3159],\n",
      "        [0.4001, 0.2629, 0.3369],\n",
      "        [0.3669, 0.3257, 0.3074],\n",
      "        [0.4160, 0.2539, 0.3303],\n",
      "        [0.4121, 0.2795, 0.3081],\n",
      "        [0.3909, 0.2856, 0.3235]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.3853, -0.2678,  0.0720],\n",
      "        [ 0.1548, -0.0451,  0.0382],\n",
      "        [ 0.0716, -0.2729, -0.0453],\n",
      "        [ 0.1528, -0.0975, -0.0290]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2700, 0.3035, 0.4265],\n",
      "        [0.3691, 0.3022, 0.3286],\n",
      "        [0.3848, 0.2727, 0.3425],\n",
      "        [0.3828, 0.2981, 0.3191]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.3638, -0.1741,  0.2803],\n",
      "        [ 0.0529, -0.1375,  0.1035],\n",
      "        [ 0.0609,  0.1904,  0.1473],\n",
      "        [ 0.1970,  0.1049,  0.2664],\n",
      "        [ 0.1731, -0.1476, -0.1708],\n",
      "        [ 0.1133, -0.1085,  0.2197],\n",
      "        [ 0.2766, -0.1517,  0.2452],\n",
      "        [ 0.2600, -0.1104,  0.1793],\n",
      "        [ 0.1703,  0.0245,  0.1270],\n",
      "        [ 0.2593,  0.1285,  0.1433],\n",
      "        [ 0.2205,  0.1460, -0.1591],\n",
      "        [ 0.1802, -0.1853,  0.0548],\n",
      "        [ 0.2578, -0.1860, -0.2720],\n",
      "        [ 0.2666, -0.2610,  0.1032]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2432, 0.2939, 0.4629],\n",
      "        [0.3474, 0.2871, 0.3655],\n",
      "        [0.3098, 0.3525, 0.3376],\n",
      "        [0.3352, 0.3057, 0.3591],\n",
      "        [0.4106, 0.2981, 0.2913],\n",
      "        [0.3433, 0.2749, 0.3818],\n",
      "        [0.3816, 0.2487, 0.3699],\n",
      "        [0.3828, 0.2642, 0.3530],\n",
      "        [0.3542, 0.3064, 0.3394],\n",
      "        [0.3613, 0.3169, 0.3218],\n",
      "        [0.3828, 0.3552, 0.2620],\n",
      "        [0.3882, 0.2693, 0.3425],\n",
      "        [0.4485, 0.2876, 0.2639],\n",
      "        [0.4099, 0.2419, 0.3481]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 5.6702e-02, -2.3779e-01,  1.9922e-01],\n",
      "        [ 3.0640e-01, -2.7368e-01,  9.0698e-02],\n",
      "        [ 7.6721e-02, -2.4200e-02, -3.1494e-01],\n",
      "        [ 1.2793e-01, -1.5686e-01, -2.9761e-01],\n",
      "        [ 2.0401e-02, -1.8628e-01, -3.8403e-01],\n",
      "        [ 2.4490e-02, -1.4661e-01, -1.7639e-01],\n",
      "        [ 1.4966e-01, -1.7773e-01, -3.1860e-01],\n",
      "        [ 3.3417e-02, -1.9141e-01,  1.0352e-01],\n",
      "        [ 7.3486e-02, -2.3987e-01, -3.4619e-01],\n",
      "        [ 1.5649e-01, -3.5254e-01, -1.0449e-01],\n",
      "        [-7.0007e-02, -8.1848e-02, -6.1426e-01],\n",
      "        [-8.1055e-02,  1.5271e-01, -2.7051e-01],\n",
      "        [-2.4670e-01,  4.3457e-02, -6.2012e-01],\n",
      "        [-1.9263e-01,  1.2140e-01, -5.6592e-01],\n",
      "        [-1.5942e-01,  7.1899e-02, -5.8398e-01],\n",
      "        [-3.0713e-01,  2.0789e-01, -2.0203e-01],\n",
      "        [ 1.3538e-01, -4.2908e-02, -1.8896e-01],\n",
      "        [-7.2693e-02,  1.5068e-02, -7.4646e-02],\n",
      "        [ 8.8684e-02, -4.0531e-04,  6.7017e-02],\n",
      "        [ 6.8970e-02, -8.1055e-02,  8.2397e-02],\n",
      "        [ 1.1566e-01, -8.5815e-02,  1.4685e-01],\n",
      "        [ 5.6366e-02, -8.8867e-02,  7.0496e-03],\n",
      "        [ 1.6370e-01, -1.6345e-01, -8.6548e-02],\n",
      "        [ 3.0273e-01, -1.7322e-01, -6.4514e-02],\n",
      "        [ 2.2803e-01, -1.1493e-01,  2.9297e-02],\n",
      "        [ 1.5234e-01, -5.1666e-02,  2.1692e-01],\n",
      "        [ 4.8389e-01,  6.5125e-02,  1.6455e-01],\n",
      "        [ 3.2764e-01, -2.0962e-03,  1.1035e-01],\n",
      "        [ 4.3677e-01,  3.2928e-02, -3.3057e-01],\n",
      "        [ 3.2520e-01,  1.3501e-01,  1.5991e-01],\n",
      "        [ 5.1465e-01, -6.0455e-02, -3.6743e-01],\n",
      "        [ 1.2231e-01, -4.8157e-02, -1.4465e-01],\n",
      "        [ 2.8955e-01,  3.7750e-02, -9.4910e-02],\n",
      "        [ 1.0628e-02,  2.6749e-02,  7.4829e-02],\n",
      "        [-6.3538e-02,  8.5999e-02, -7.2571e-02],\n",
      "        [-2.3145e-01,  5.8990e-02, -5.8807e-02],\n",
      "        [ 1.3708e-01, -2.2913e-01, -4.7632e-01],\n",
      "        [ 4.7638e-02, -3.4521e-01,  2.3865e-02],\n",
      "        [ 2.6685e-01, -1.9739e-01,  1.8921e-01],\n",
      "        [ 7.3853e-02, -2.1362e-01,  3.5791e-01],\n",
      "        [ 1.5088e-01, -1.7700e-01,  2.1179e-01],\n",
      "        [ 1.4124e-01,  2.6718e-02, -8.5678e-03],\n",
      "        [ 1.4221e-01, -1.2219e-01,  5.7739e-02],\n",
      "        [-2.6093e-02, -8.5022e-02, -1.4490e-01],\n",
      "        [ 2.6294e-01, -1.2988e-01, -1.1774e-01],\n",
      "        [-5.6190e-03, -1.4539e-01, -2.7344e-01],\n",
      "        [ 2.7390e-02, -1.2292e-01, -1.9226e-01],\n",
      "        [ 2.9639e-01, -3.4888e-01, -2.8275e-02],\n",
      "        [ 2.5073e-01, -1.3806e-01,  1.3496e-02],\n",
      "        [ 3.6621e-01, -2.9102e-01, -2.8473e-02],\n",
      "        [-2.9663e-02, -6.6956e-02,  3.3862e-01],\n",
      "        [-5.7678e-02,  1.6699e-01,  1.4091e-02],\n",
      "        [-1.5210e-01,  4.1008e-03, -1.9470e-01],\n",
      "        [-3.3295e-02, -1.7136e-02,  9.0637e-02],\n",
      "        [ 1.1078e-01, -2.4438e-01,  1.4038e-01],\n",
      "        [ 1.5942e-01, -1.3599e-01,  4.2053e-02],\n",
      "        [ 3.7451e-01, -1.7603e-01,  2.1103e-02],\n",
      "        [ 1.6675e-01, -2.1191e-01, -2.6047e-02],\n",
      "        [ 3.2617e-01, -4.4556e-01, -3.2253e-03],\n",
      "        [ 2.4084e-01,  3.5763e-03,  9.6497e-02],\n",
      "        [ 1.9958e-01, -1.0445e-02,  2.3483e-02],\n",
      "        [-3.7170e-02,  3.5187e-02, -8.4167e-02],\n",
      "        [ 1.2213e-01, -1.5649e-01,  2.1255e-02],\n",
      "        [-9.3445e-02, -7.7881e-02,  8.2703e-02],\n",
      "        [-3.2471e-02, -1.8091e-01,  1.5857e-01],\n",
      "        [-3.6548e-01,  1.8555e-01, -5.2368e-02],\n",
      "        [-2.4524e-01,  2.5659e-01,  6.5308e-02],\n",
      "        [ 1.2079e-01,  6.1340e-02, -6.0005e-03],\n",
      "        [-3.2562e-02, -1.6003e-01,  1.8921e-01],\n",
      "        [-4.0070e-02, -1.0852e-01,  5.0598e-02],\n",
      "        [-6.6040e-02, -3.2617e-01, -2.2766e-02],\n",
      "        [-7.7454e-02, -1.7249e-01, -9.8511e-02],\n",
      "        [-7.7820e-02, -6.4819e-02, -2.2717e-01],\n",
      "        [-8.5510e-02,  7.4768e-02, -1.7822e-01],\n",
      "        [-1.0034e-01, -6.2378e-02, -2.2018e-02],\n",
      "        [ 1.1703e-02, -2.0544e-01,  7.4097e-02],\n",
      "        [-1.5393e-01, -1.8506e-01,  2.4323e-02],\n",
      "        [ 7.6050e-02, -1.9702e-01,  4.0222e-02]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3450, 0.2571, 0.3979],\n",
      "        [0.4226, 0.2367, 0.3406],\n",
      "        [0.3877, 0.3503, 0.2620],\n",
      "        [0.4158, 0.3127, 0.2717],\n",
      "        [0.4031, 0.3279, 0.2690],\n",
      "        [0.3757, 0.3167, 0.3074],\n",
      "        [0.4260, 0.3071, 0.2668],\n",
      "        [0.3484, 0.2781, 0.3735],\n",
      "        [0.4187, 0.3062, 0.2751],\n",
      "        [0.4216, 0.2534, 0.3250],\n",
      "        [0.3894, 0.3848, 0.2260],\n",
      "        [0.3235, 0.4087, 0.2678],\n",
      "        [0.3306, 0.4419, 0.2275],\n",
      "        [0.3271, 0.4478, 0.2252],\n",
      "        [0.3430, 0.4324, 0.2245],\n",
      "        [0.2642, 0.4421, 0.2935],\n",
      "        [0.3906, 0.3269, 0.2825],\n",
      "        [0.3237, 0.3533, 0.3230],\n",
      "        [0.3457, 0.3162, 0.3381],\n",
      "        [0.3479, 0.2996, 0.3525],\n",
      "        [0.3511, 0.2869, 0.3621],\n",
      "        [0.3550, 0.3071, 0.3379],\n",
      "        [0.4001, 0.2883, 0.3115],\n",
      "        [0.4321, 0.2686, 0.2993],\n",
      "        [0.3953, 0.2805, 0.3240],\n",
      "        [0.3469, 0.2830, 0.3701],\n",
      "        [0.4194, 0.2759, 0.3047],\n",
      "        [0.3962, 0.2849, 0.3188],\n",
      "        [0.4690, 0.3132, 0.2178],\n",
      "        [0.3740, 0.3091, 0.3169],\n",
      "        [0.5059, 0.2847, 0.2095],\n",
      "        [0.3833, 0.3232, 0.2935],\n",
      "        [0.4067, 0.3162, 0.2769],\n",
      "        [0.3245, 0.3296, 0.3459],\n",
      "        [0.3171, 0.3684, 0.3145],\n",
      "        [0.2837, 0.3792, 0.3372],\n",
      "        [0.4475, 0.3103, 0.2423],\n",
      "        [0.3772, 0.2546, 0.3682],\n",
      "        [0.3916, 0.2461, 0.3623],\n",
      "        [0.3247, 0.2437, 0.4316],\n",
      "        [0.3594, 0.2588, 0.3818],\n",
      "        [0.3633, 0.3240, 0.3127],\n",
      "        [0.3723, 0.2856, 0.3420],\n",
      "        [0.3533, 0.3330, 0.3137],\n",
      "        [0.4241, 0.2864, 0.2898],\n",
      "        [0.3796, 0.3301, 0.2903],\n",
      "        [0.3755, 0.3230, 0.3015],\n",
      "        [0.4451, 0.2334, 0.3215],\n",
      "        [0.4055, 0.2749, 0.3198],\n",
      "        [0.4561, 0.2365, 0.3074],\n",
      "        [0.2935, 0.2827, 0.4241],\n",
      "        [0.3005, 0.3765, 0.3230],\n",
      "        [0.3198, 0.3738, 0.3064],\n",
      "        [0.3176, 0.3228, 0.3596],\n",
      "        [0.3662, 0.2566, 0.3772],\n",
      "        [0.3796, 0.2827, 0.3376],\n",
      "        [0.4387, 0.2529, 0.3081],\n",
      "        [0.3984, 0.2729, 0.3286],\n",
      "        [0.4585, 0.2119, 0.3298],\n",
      "        [0.3767, 0.2971, 0.3262],\n",
      "        [0.3774, 0.3059, 0.3167],\n",
      "        [0.3301, 0.3550, 0.3149],\n",
      "        [0.3757, 0.2844, 0.3398],\n",
      "        [0.3118, 0.3167, 0.3718],\n",
      "        [0.3254, 0.2805, 0.3940],\n",
      "        [0.2438, 0.4229, 0.3333],\n",
      "        [0.2490, 0.4114, 0.3396],\n",
      "        [0.3542, 0.3337, 0.3120],\n",
      "        [0.3196, 0.2815, 0.3989],\n",
      "        [0.3301, 0.3083, 0.3616],\n",
      "        [0.3552, 0.2739, 0.3708],\n",
      "        [0.3462, 0.3147, 0.3389],\n",
      "        [0.3479, 0.3525, 0.2996],\n",
      "        [0.3242, 0.3804, 0.2954],\n",
      "        [0.3206, 0.3330, 0.3467],\n",
      "        [0.3486, 0.2805, 0.3708],\n",
      "        [0.3159, 0.3064, 0.3777],\n",
      "        [0.3669, 0.2793, 0.3540]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-1.1276e-02, -1.5259e-01,  4.4250e-02],\n",
      "        [-1.9165e-01, -8.2581e-02,  5.5603e-02],\n",
      "        [-6.3904e-02, -1.0907e-01, -1.1298e-01],\n",
      "        [ 5.5275e-03, -1.0309e-01, -1.7712e-01],\n",
      "        [ 2.3865e-01,  1.0223e-02, -2.8809e-01],\n",
      "        [ 2.0264e-01,  5.0659e-02,  5.3406e-02],\n",
      "        [ 1.7688e-01,  1.8188e-02,  1.4258e-01],\n",
      "        [ 2.1204e-01, -1.2976e-01,  1.4819e-01],\n",
      "        [ 1.4087e-01, -9.8145e-02,  3.5950e-02],\n",
      "        [-1.5022e-02,  2.3608e-01, -7.9834e-02],\n",
      "        [ 1.0547e-01, -7.8735e-02, -8.9233e-02],\n",
      "        [-7.9346e-02, -2.0508e-02,  1.8883e-04],\n",
      "        [-6.7871e-02, -2.4646e-01, -2.2034e-01],\n",
      "        [-3.5767e-01, -2.3499e-01, -1.7212e-01],\n",
      "        [-1.8555e-01, -1.4429e-01, -6.6589e-02],\n",
      "        [-1.3232e-01,  4.4830e-02, -1.3831e-01],\n",
      "        [ 1.2268e-01, -1.7566e-01, -3.9795e-01],\n",
      "        [-4.1687e-02, -4.9957e-02, -6.5247e-02],\n",
      "        [ 2.4597e-01, -1.3013e-01, -3.7036e-01],\n",
      "        [ 2.3877e-01, -2.3730e-01, -1.3344e-02]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3418, 0.2969, 0.3613],\n",
      "        [0.2944, 0.3284, 0.3772],\n",
      "        [0.3440, 0.3286, 0.3274],\n",
      "        [0.3662, 0.3286, 0.3052],\n",
      "        [0.4189, 0.3335, 0.2474],\n",
      "        [0.3677, 0.3157, 0.3167],\n",
      "        [0.3547, 0.3027, 0.3428],\n",
      "        [0.3774, 0.2683, 0.3542],\n",
      "        [0.3721, 0.2930, 0.3350],\n",
      "        [0.3103, 0.3989, 0.2908],\n",
      "        [0.3767, 0.3132, 0.3101],\n",
      "        [0.3181, 0.3374, 0.3445],\n",
      "        [0.3711, 0.3103, 0.3186],\n",
      "        [0.2998, 0.3391, 0.3611],\n",
      "        [0.3157, 0.3289, 0.3555],\n",
      "        [0.3137, 0.3745, 0.3118],\n",
      "        [0.4280, 0.3176, 0.2544],\n",
      "        [0.3369, 0.3340, 0.3291],\n",
      "        [0.4492, 0.3083, 0.2426],\n",
      "        [0.4170, 0.2590, 0.3240]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.2966, -0.0259,  0.0826],\n",
      "        [-0.2190,  0.0763, -0.1594],\n",
      "        [-0.0960,  0.0940, -0.1410],\n",
      "        [ 0.0105, -0.0649,  0.0042],\n",
      "        [-0.1184,  0.1471,  0.0329],\n",
      "        [ 0.0445, -0.0700,  0.0968],\n",
      "        [-0.2683,  0.1821,  0.1068],\n",
      "        [-0.0868, -0.2744,  0.4438],\n",
      "        [-0.1726, -0.0202,  0.2196],\n",
      "        [-0.0967, -0.0417,  0.2786],\n",
      "        [ 0.0398, -0.0021,  0.0119],\n",
      "        [-0.3252, -0.3560,  0.0226],\n",
      "        [-0.2302, -0.2422,  0.1693],\n",
      "        [-0.5176, -0.1991,  0.2446],\n",
      "        [-0.0636, -0.2238, -0.0245],\n",
      "        [ 0.0934, -0.3594,  0.1566],\n",
      "        [ 0.0065, -0.3503,  0.3840],\n",
      "        [-0.0986, -0.3237,  0.4358],\n",
      "        [-0.0213, -0.1511,  0.1940],\n",
      "        [ 0.1285, -0.3884,  0.2500],\n",
      "        [ 0.1993, -0.0749, -0.0357],\n",
      "        [ 0.2277, -0.4197,  0.1422]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2651, 0.3474, 0.3875],\n",
      "        [0.2937, 0.3945, 0.3118],\n",
      "        [0.3159, 0.3821, 0.3020],\n",
      "        [0.3423, 0.3174, 0.3401],\n",
      "        [0.2883, 0.3760, 0.3354],\n",
      "        [0.3396, 0.3027, 0.3577],\n",
      "        [0.2485, 0.3899, 0.3616],\n",
      "        [0.2834, 0.2349, 0.4817],\n",
      "        [0.2744, 0.3196, 0.4060],\n",
      "        [0.2847, 0.3008, 0.4143],\n",
      "        [0.3411, 0.3271, 0.3318],\n",
      "        [0.2954, 0.2864, 0.4182],\n",
      "        [0.2874, 0.2839, 0.4285],\n",
      "        [0.2213, 0.3044, 0.4744],\n",
      "        [0.3457, 0.2947, 0.3596],\n",
      "        [0.3701, 0.2354, 0.3943],\n",
      "        [0.3167, 0.2216, 0.4619],\n",
      "        [0.2854, 0.2278, 0.4868],\n",
      "        [0.3206, 0.2817, 0.3977],\n",
      "        [0.3669, 0.2188, 0.4143],\n",
      "        [0.3921, 0.2981, 0.3098],\n",
      "        [0.4097, 0.2144, 0.3760]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1368, -0.0510,  0.1385],\n",
      "        [ 0.2007, -0.2798,  0.0006],\n",
      "        [-0.0309, -0.1848, -0.1449],\n",
      "        [ 0.0596, -0.2178,  0.0563],\n",
      "        [-0.0179, -0.2228, -0.1036],\n",
      "        [ 0.1357, -0.3933,  0.1646],\n",
      "        [-0.2705,  0.0670, -0.0563],\n",
      "        [-0.1017, -0.2391, -0.0188],\n",
      "        [-0.1088, -0.1816, -0.0204],\n",
      "        [-0.0978, -0.2090,  0.1923],\n",
      "        [-0.3125, -0.1376,  0.1254],\n",
      "        [-0.0525, -0.1869,  0.4092],\n",
      "        [ 0.0767, -0.0905,  0.3193],\n",
      "        [-0.1071, -0.1125,  0.2615],\n",
      "        [ 0.0072, -0.1497, -0.0398],\n",
      "        [-0.2391, -0.1611,  0.2673],\n",
      "        [-0.1318, -0.0248,  0.3291],\n",
      "        [-0.0026, -0.1290,  0.2042],\n",
      "        [-0.1220, -0.1536,  0.1788],\n",
      "        [-0.1227, -0.2477,  0.2937],\n",
      "        [-0.0442, -0.1545,  0.0638],\n",
      "        [-0.2195, -0.2605,  0.3303],\n",
      "        [-0.0230, -0.1942,  0.2043],\n",
      "        [-0.1897, -0.1041,  0.1483],\n",
      "        [-0.1234, -0.0986,  0.0605],\n",
      "        [-0.1016, -0.0338,  0.0435],\n",
      "        [-0.1320, -0.0398, -0.2966],\n",
      "        [ 0.0619, -0.3774,  0.1753],\n",
      "        [ 0.0204, -0.1122, -0.2080],\n",
      "        [ 0.0914, -0.4172,  0.0125]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2935, 0.3198, 0.3867],\n",
      "        [0.4104, 0.2537, 0.3359],\n",
      "        [0.3638, 0.3118, 0.3245],\n",
      "        [0.3630, 0.2751, 0.3618],\n",
      "        [0.3660, 0.2981, 0.3359],\n",
      "        [0.3818, 0.2250, 0.3931],\n",
      "        [0.2747, 0.3850, 0.3403],\n",
      "        [0.3381, 0.2947, 0.3672],\n",
      "        [0.3308, 0.3076, 0.3616],\n",
      "        [0.3096, 0.2769, 0.4136],\n",
      "        [0.2673, 0.3184, 0.4143],\n",
      "        [0.2888, 0.2527, 0.4585],\n",
      "        [0.3206, 0.2712, 0.4084],\n",
      "        [0.2908, 0.2891, 0.4202],\n",
      "        [0.3560, 0.3044, 0.3396],\n",
      "        [0.2673, 0.2891, 0.4436],\n",
      "        [0.2703, 0.3010, 0.4287],\n",
      "        [0.3215, 0.2832, 0.3953],\n",
      "        [0.3013, 0.2917, 0.4070],\n",
      "        [0.2942, 0.2595, 0.4460],\n",
      "        [0.3323, 0.2976, 0.3701],\n",
      "        [0.2708, 0.2600, 0.4692],\n",
      "        [0.3228, 0.2720, 0.4053],\n",
      "        [0.2864, 0.3120, 0.4016],\n",
      "        [0.3098, 0.3176, 0.3726],\n",
      "        [0.3101, 0.3318, 0.3584],\n",
      "        [0.3396, 0.3723, 0.2881],\n",
      "        [0.3618, 0.2332, 0.4053],\n",
      "        [0.3743, 0.3279, 0.2979],\n",
      "        [0.3960, 0.2382, 0.3660]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[ 0.0388, -0.1544,  0.1743],\n",
      "        [ 0.2002,  0.1093,  0.0268],\n",
      "        [ 0.2722, -0.2411, -0.2383],\n",
      "        [ 0.4756, -0.0750,  0.1771],\n",
      "        [ 0.0643, -0.2374, -0.0567],\n",
      "        [ 0.0765, -0.1340,  0.1042],\n",
      "        [-0.2375, -0.0142, -0.3567],\n",
      "        [ 0.0276,  0.0653, -0.0027],\n",
      "        [ 0.0603,  0.0616, -0.2786],\n",
      "        [ 0.3923, -0.1459, -0.0158],\n",
      "        [-0.1045,  0.0448,  0.1464],\n",
      "        [ 0.0315, -0.0317,  0.2556],\n",
      "        [-0.0812, -0.1847, -0.1289],\n",
      "        [ 0.0064, -0.0910,  0.0754],\n",
      "        [-0.1177,  0.1078, -0.1054],\n",
      "        [-0.0759, -0.2712,  0.2313],\n",
      "        [-0.0612, -0.1807,  0.0788],\n",
      "        [ 0.2054, -0.2035,  0.1660],\n",
      "        [-0.3000,  0.0346, -0.2416],\n",
      "        [ 0.0320,  0.2981,  0.0533],\n",
      "        [-0.0099,  0.0693,  0.0426],\n",
      "        [ 0.1442,  0.1237, -0.1494],\n",
      "        [-0.1554,  0.2064, -0.3040],\n",
      "        [ 0.1932, -0.1194, -0.0443],\n",
      "        [ 0.2520,  0.0215, -0.1218],\n",
      "        [ 0.2252, -0.0804,  0.0161],\n",
      "        [ 0.1625,  0.0479, -0.3455],\n",
      "        [ 0.4006, -0.2283, -0.2008],\n",
      "        [ 0.1727, -0.2551, -0.2671],\n",
      "        [ 0.3252, -0.3420, -0.0326]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3367, 0.2776, 0.3857],\n",
      "        [0.3630, 0.3315, 0.3054],\n",
      "        [0.4548, 0.2722, 0.2729],\n",
      "        [0.4314, 0.2487, 0.3201],\n",
      "        [0.3809, 0.2817, 0.3374],\n",
      "        [0.3523, 0.2854, 0.3623],\n",
      "        [0.3186, 0.3984, 0.2830],\n",
      "        [0.3323, 0.3452, 0.3225],\n",
      "        [0.3684, 0.3689, 0.2625],\n",
      "        [0.4446, 0.2595, 0.2957],\n",
      "        [0.2903, 0.3369, 0.3728],\n",
      "        [0.3135, 0.2942, 0.3923],\n",
      "        [0.3503, 0.3159, 0.3340],\n",
      "        [0.3357, 0.3047, 0.3596],\n",
      "        [0.3062, 0.3838, 0.3101],\n",
      "        [0.3142, 0.2585, 0.4272],\n",
      "        [0.3291, 0.2922, 0.3787],\n",
      "        [0.3809, 0.2529, 0.3662],\n",
      "        [0.2893, 0.4041, 0.3066],\n",
      "        [0.3005, 0.3923, 0.3071],\n",
      "        [0.3188, 0.3452, 0.3359],\n",
      "        [0.3669, 0.3594, 0.2737],\n",
      "        [0.3032, 0.4353, 0.2615],\n",
      "        [0.3967, 0.2903, 0.3130],\n",
      "        [0.4028, 0.3198, 0.2771],\n",
      "        [0.3926, 0.2891, 0.3184],\n",
      "        [0.4011, 0.3577, 0.2413],\n",
      "        [0.4805, 0.2561, 0.2634],\n",
      "        [0.4355, 0.2839, 0.2805],\n",
      "        [0.4519, 0.2319, 0.3162]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.1274,  0.0021,  0.2073],\n",
      "        [ 0.0048,  0.1069,  0.0265],\n",
      "        [-0.0815, -0.1438, -0.2024],\n",
      "        [ 0.2465, -0.1405,  0.0018],\n",
      "        [ 0.3347, -0.1315, -0.2385],\n",
      "        [ 0.2690, -0.0984, -0.1547],\n",
      "        [ 0.2810, -0.1145, -0.2207],\n",
      "        [ 0.3503,  0.1600,  0.1052],\n",
      "        [ 0.4192,  0.0563, -0.3064],\n",
      "        [ 0.2891, -0.0183, -0.0121],\n",
      "        [ 0.2347, -0.0592, -0.1722],\n",
      "        [ 0.0605,  0.1313,  0.4219],\n",
      "        [ 0.0290,  0.1504,  0.3328],\n",
      "        [-0.1371,  0.0840,  0.3186],\n",
      "        [-0.1030,  0.0570, -0.1958],\n",
      "        [ 0.0162,  0.0364,  0.2976],\n",
      "        [-0.1022,  0.1562,  0.2974],\n",
      "        [ 0.1666, -0.0994,  0.1934],\n",
      "        [ 0.0039, -0.1241,  0.1981],\n",
      "        [ 0.3474, -0.1641,  0.1299],\n",
      "        [ 0.0773, -0.0107,  0.1014],\n",
      "        [ 0.0771,  0.0291,  0.0484],\n",
      "        [ 0.0792,  0.0384,  0.0803],\n",
      "        [ 0.2097, -0.0327,  0.0412],\n",
      "        [-0.0443,  0.2108, -0.1289],\n",
      "        [ 0.0061,  0.2135,  0.1029],\n",
      "        [ 0.0146,  0.1531,  0.1516],\n",
      "        [ 0.2288,  0.1105,  0.2827],\n",
      "        [-0.0209,  0.1046, -0.0076],\n",
      "        [ 0.0559,  0.0061,  0.0202],\n",
      "        [-0.0740, -0.0426, -0.0335],\n",
      "        [ 0.0286,  0.1409,  0.1010],\n",
      "        [ 0.0154,  0.0309, -0.1776],\n",
      "        [-0.0296,  0.1906, -0.1874],\n",
      "        [-0.0849, -0.0893, -0.1782],\n",
      "        [-0.1448,  0.0378, -0.1982],\n",
      "        [-0.3484, -0.2010, -0.1487],\n",
      "        [-0.0184, -0.1515, -0.0928]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2827, 0.3220, 0.3953],\n",
      "        [0.3196, 0.3540, 0.3267],\n",
      "        [0.3540, 0.3325, 0.3135],\n",
      "        [0.4062, 0.2759, 0.3181],\n",
      "        [0.4563, 0.2864, 0.2573],\n",
      "        [0.4260, 0.2952, 0.2788],\n",
      "        [0.4387, 0.2954, 0.2656],\n",
      "        [0.3833, 0.3169, 0.3000],\n",
      "        [0.4587, 0.3191, 0.2220],\n",
      "        [0.4041, 0.2971, 0.2988],\n",
      "        [0.4148, 0.3091, 0.2761],\n",
      "        [0.2849, 0.3059, 0.4092],\n",
      "        [0.2871, 0.3240, 0.3889],\n",
      "        [0.2615, 0.3262, 0.4124],\n",
      "        [0.3242, 0.3804, 0.2954],\n",
      "        [0.2988, 0.3049, 0.3960],\n",
      "        [0.2642, 0.3420, 0.3938],\n",
      "        [0.3579, 0.2744, 0.3677],\n",
      "        [0.3232, 0.2844, 0.3926],\n",
      "        [0.4160, 0.2494, 0.3347],\n",
      "        [0.3401, 0.3115, 0.3484],\n",
      "        [0.3418, 0.3259, 0.3323],\n",
      "        [0.3376, 0.3242, 0.3381],\n",
      "        [0.3804, 0.2983, 0.3213],\n",
      "        [0.3115, 0.4021, 0.2864],\n",
      "        [0.3000, 0.3694, 0.3306],\n",
      "        [0.3035, 0.3486, 0.3479],\n",
      "        [0.3396, 0.3018, 0.3584],\n",
      "        [0.3179, 0.3604, 0.3220],\n",
      "        [0.3430, 0.3262, 0.3308],\n",
      "        [0.3254, 0.3357, 0.3389],\n",
      "        [0.3130, 0.3503, 0.3367],\n",
      "        [0.3521, 0.3577, 0.2903],\n",
      "        [0.3225, 0.4021, 0.2754],\n",
      "        [0.3440, 0.3425, 0.3135],\n",
      "        [0.3176, 0.3813, 0.3010],\n",
      "        [0.2959, 0.3428, 0.3613],\n",
      "        [0.3567, 0.3123, 0.3311]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0773, -0.4529,  0.2959],\n",
      "        [ 0.2751, -0.1925, -0.0800],\n",
      "        [ 0.2729,  0.0090, -0.0665],\n",
      "        [ 0.3860,  0.0854,  0.2012],\n",
      "        [ 0.2349,  0.1241, -0.0772],\n",
      "        [ 0.3154,  0.1362,  0.0469],\n",
      "        [-0.0809, -0.0539,  0.0674],\n",
      "        [ 0.2708,  0.0860,  0.3350],\n",
      "        [ 0.5010,  0.0211,  0.4651],\n",
      "        [ 0.3962,  0.2148,  0.3408],\n",
      "        [ 0.1664,  0.0214,  0.2666],\n",
      "        [ 0.2893, -0.0217,  0.0131],\n",
      "        [ 0.3076,  0.0203,  0.2788],\n",
      "        [ 0.3904,  0.0701,  0.1226],\n",
      "        [ 0.1592,  0.0509,  0.2024],\n",
      "        [ 0.3311,  0.0043,  0.0230],\n",
      "        [ 0.0607, -0.3691,  0.1461],\n",
      "        [ 0.2988, -0.1617, -0.2382]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.3186, 0.2188, 0.4626],\n",
      "        [0.4297, 0.2690, 0.3013],\n",
      "        [0.4031, 0.3096, 0.2871],\n",
      "        [0.3889, 0.2878, 0.3232],\n",
      "        [0.3806, 0.3408, 0.2786],\n",
      "        [0.3845, 0.3215, 0.2939],\n",
      "        [0.3137, 0.3223, 0.3640],\n",
      "        [0.3452, 0.2869, 0.3679],\n",
      "        [0.3870, 0.2395, 0.3733],\n",
      "        [0.3596, 0.3000, 0.3403],\n",
      "        [0.3367, 0.2913, 0.3721],\n",
      "        [0.4014, 0.2942, 0.3044],\n",
      "        [0.3674, 0.2756, 0.3569],\n",
      "        [0.4014, 0.2915, 0.3071],\n",
      "        [0.3398, 0.3052, 0.3550],\n",
      "        [0.4072, 0.2937, 0.2993],\n",
      "        [0.3650, 0.2374, 0.3975],\n",
      "        [0.4514, 0.2847, 0.2639]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "prima tensor([[-0.0712, -0.4265,  0.4202],\n",
      "        [ 0.1109, -0.1830,  0.0982],\n",
      "        [-0.0569, -0.3088, -0.2136],\n",
      "        [ 0.0762, -0.1394, -0.1204]], dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "dopo tensor([[0.2998, 0.2102, 0.4900],\n",
      "        [0.3660, 0.2727, 0.3613],\n",
      "        [0.3799, 0.2954, 0.3247],\n",
      "        [0.3806, 0.3066, 0.3127]], dtype=torch.float16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Predicted output sizes\n",
      "torch.Size([100, 132, 3])\n",
      "Batch moves size\n",
      "torch.Size([100, 132, 3])\n",
      "Start Back-prop\n",
      "End back-prop\n",
      "tensor([[[-0.1899, -0.2262,  0.1254],\n",
      "         [-0.2349, -0.0619, -0.0275],\n",
      "         [-0.0296, -0.0618,  0.0053],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.1422, -0.3765,  0.1070],\n",
      "         [ 0.0461,  0.0300, -0.0256],\n",
      "         [ 0.0962, -0.0557, -0.1694],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.1899, -0.2262,  0.1254],\n",
      "         [-0.2349, -0.0619, -0.0275],\n",
      "         [-0.0296, -0.0618,  0.0053],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1274,  0.0021,  0.2073],\n",
      "         [ 0.0048,  0.1069,  0.0265],\n",
      "         [-0.0815, -0.1438, -0.2024],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0773, -0.4529,  0.2959],\n",
      "         [ 0.2751, -0.1925, -0.0800],\n",
      "         [ 0.2729,  0.0090, -0.0665],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0712, -0.4265,  0.4202],\n",
      "         [ 0.1109, -0.1830,  0.0982],\n",
      "         [-0.0569, -0.3088, -0.2136],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]]], dtype=torch.float16,\n",
      "       grad_fn=<CopySlices>)\n",
      "score features PackedSequence(data=tensor([[ 1.0000,  1.0000,  1.0000,  ..., -1.0752, -0.3918, -0.4280]],\n",
      "       dtype=torch.float16), batch_sizes=tensor([1]), sorted_indices=tensor([0]), unsorted_indices=tensor([0]))\n",
      "predicted output [tensor([[nan, nan, nan]], dtype=torch.float16, grad_fn=<IndexBackward0>)]\n",
      "features  tensor([[ 1.0000,  1.0000,  1.0000,  ..., -1.0752, -0.3918, -0.4280]],\n",
      "       dtype=torch.float16)\n",
      "features  dimensione torch.Size([1, 3840])\n",
      "PackedSequence(data=tensor([[nan, nan, nan]], dtype=torch.float16, grad_fn=<CatBackward0>), batch_sizes=tensor([1]), sorted_indices=tensor([0]), unsorted_indices=tensor([0]))\n",
      "score features PackedSequence(data=tensor([[ 0.0428, -0.5259,  0.7617,  ..., -1.2227, -0.7529, -0.5820]],\n",
      "       dtype=torch.float16), batch_sizes=tensor([1]), sorted_indices=tensor([0]), unsorted_indices=tensor([0]))\n",
      "predicted output [tensor([[nan, nan, nan]], dtype=torch.float16, grad_fn=<IndexBackward0>)]\n",
      "features  tensor([[ 0.0428, -0.5259,  0.7617,  ..., -1.2227, -0.7529, -0.5820]],\n",
      "       dtype=torch.float16)\n",
      "features  dimensione torch.Size([1, 3840])\n",
      "PackedSequence(data=tensor([[nan, nan, nan]], dtype=torch.float16, grad_fn=<CatBackward0>), batch_sizes=tensor([1]), sorted_indices=tensor([0]), unsorted_indices=tensor([0]))\n",
      "[None, 0, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "def encode_moves(oracle,parser,heads,phrase,phrases_lemma):\n",
    "    stacks,buffers,moves=parser.simulate_parse(heads,phrase)\n",
    "    embedded_features=oracle.extract_features(phrase,phrases_lemma,stacks,buffers)\n",
    "    \n",
    "\n",
    "    expanded_moves=[]\n",
    "    for move in moves:\n",
    "        if(move==0): expanded_moves.append(torch.tensor([1,0,0]).to(torch.float16))\n",
    "        if(move==1): expanded_moves.append(torch.tensor([0,1,0]).to(torch.float16))\n",
    "        if(move==2): expanded_moves.append(torch.tensor([0,0,1]).to(torch.float16))\n",
    "\n",
    "    return embedded_features,expanded_moves\n",
    "\n",
    "#prende il dataset e per ogni frase genera il batch corrispettivo, genererà n=batch-size file    \n",
    "def create_batches(oracle,parser,batch_size,dataset):\n",
    "    batch_feature=[]\n",
    "    batch_moves=[]\n",
    "\n",
    "    index_batch=0\n",
    "    for i,sent in enumerate(dataset):     \n",
    "        if(i<1000):\n",
    "            heads=[-1]\n",
    "            words=[]\n",
    "            lemmas=[]\n",
    "\n",
    "            wrong_sent=0\n",
    "            for token in sent:\n",
    "                if(token.head is None): wrong_sent=1\n",
    "                if(token.form is None): wrong_sent=1\n",
    "                if(token.lemma is None): wrong_sent=1\n",
    "\n",
    "                heads.append(int(token.head))\n",
    "                words.append(token.form)\n",
    "                lemmas.append(token.lemma)\n",
    "            \n",
    "            if(wrong_sent==0):\n",
    "                sent_features,sent_moves = encode_moves(oracle,parser,heads,words,lemmas)\n",
    "                sent_features=torch.stack(sent_features,dim=0)\n",
    "                sent_moves=torch.stack(sent_moves)\n",
    "                batch_feature.append(sent_features)\n",
    "                batch_moves.append(sent_moves)\n",
    "            \n",
    "\n",
    "            if(len(batch_moves)==batch_size): \n",
    "                #print(sent_moves)\n",
    "                print(index_batch)\n",
    "                packed_features=pack_sequence(batch_feature,enforce_sorted=False)\n",
    "                packed_moves=pack_sequence(batch_moves,enforce_sorted=False)\n",
    "\n",
    "\n",
    "                torch.save((packed_features,packed_moves), f\"data/batches/tensor{index_batch}.pt\")\n",
    "                index_batch+=1\n",
    "                batch_feature=[]\n",
    "                batch_moves=[]\n",
    "\n",
    "#DA FARE:\n",
    "#1. Salvare batch da 50-100 frasi su file dati, ossia per ogni frase gli stati con relativi stack,buffer e move. \n",
    "#2. Importare batch per batch come nell'esempio di chat gpt.\n",
    "#3. Per ogni batch fare forward e back-prop di adam optimizer come nell'esempio di chat_gpt.\n",
    "\n",
    "\n",
    "\n",
    "#p1,m1=parser.encode_moves(heads,phrase,phrase)\n",
    "#p2,m2=parser.encode_moves(heads2,phrase2,phrase2)\n",
    "#print(m2)\n",
    "#torch.set_printoptions(profile=\"full\")\n",
    "#p1 = torch.stack(p1, dim=0)\n",
    "#p2 = torch.stack(p2, dim=0)\n",
    "#print(p1)\n",
    "#print(p2)\n",
    "#input=pack_sequence([p1, p2])\n",
    "\n",
    "#input_size = 3840  # Each element in the sequence is a vector of size 2\n",
    "#hidden_size = 64\n",
    "#num_layers = 1\n",
    "#output_size = 3  # Example output size\n",
    "#model = torch.nn.LSTM(input_size,hidden_size,num_layers,batch_first=True,bidirectional=False,proj_size=output_size)\n",
    "#model.half()\n",
    "#\n",
    "#output = model(input)\n",
    "#print(output)\n",
    "#print(\"OUTPUT\")\n",
    "#print(unpack_sequence(output[0]))\n",
    "\n",
    "\n",
    "oracle = Oracle()\n",
    "parser = Parser(oracle)\n",
    "#create_batches(oracle,parser,100,train_prepocesed)\n",
    "oracle.train_on_batches()\n",
    "phrases=\"Hamad Butt è morto nel 1994 a 32 anni .\".split()\n",
    "deps = parser.parsing(phrases,phrases)\n",
    "print(deps.get_heads())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
